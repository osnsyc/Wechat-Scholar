<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[机器之心SOTA模型]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[机器之心SOTA模型公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_b81ad58dc224.jpg</url>
      <title>gh_b81ad58dc224</title>
    </image>
    <item>
      <title><![CDATA[今日开源（2025-06-10）：Pixel-Reasoner，像素空间推理新范式，两阶段训练提升VLM性能，实现文本和视觉平衡]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwooWhCHsul1Yv8YT7TNZGs7D9lBmRnTgCEBXC9KYfXzANUM4AsrXibsvGS3GIr6Q0gd7f6djVVHLg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Pixel-Reasoner★Pixel-Reasoner项目旨在通过引入像素空间推理的概念，提升视觉语言模型（VLMs）在视觉任务中的推理能力。该项目通过一系列视觉推理操作，如放大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247498653&amp;idx=1&amp;sn=20167d67f2ddf78723ed5d27314c4a37&amp;chksm=c0a0f4f93ae9f3f35fc2f540e6672117f5fa58b000658783cd6e461ffd814d28323a95b5741b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 10:12:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-06-09）：dots.llm1，MoE模型激活参数14B，11.2万亿token预训练，媲美Qwen2.5]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwTynplARNrhmZ9WDp6j62T91J2fUiaf1639bNYicY9zsz1tm3KicL28Xic9XoxtqFam2dhzdB2iaulzyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：dots.llm1★dots.llm1是一个大规模的MoE（Mixture of Experts）模型，激活了142B参数中的14B，性能与最先进的模型相当。通过精心设计的数据处理流</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247498643&amp;idx=1&amp;sn=0f7fdc75998f13e6146a0efac684f20d&amp;chksm=c06d77f570bbe1d8b1313afb590ac1c622734c6cc82a5942688e947280872496247d4f4f43b6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 13:23:17 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-06-06）：Qwen3Embedding，0.6B至8B文本嵌入模型，多语言与长文本能力，检索任务显著提升]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkyMsTJjPnAqCCd7PA8fLl6POVHpkHVl0Z9OOtYEttJZo6HKFKic28gggdu6ib51eTryezVItslfMyiaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Qwen3 Embedding★Qwen3 Embedding 是 Qwen 系列的最新专有模型，专为文本嵌入和排序任务设计。该系列基于 Qwen3 系列的密集基础模型，提供多种尺寸</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247498633&amp;idx=1&amp;sn=dde340b97c8e12d7e0cb02e55172c5f6&amp;chksm=c08a885cdb54fa587b866524f8c5bcd9c0f8064d7df51addc69aff4490338e3fab4ed38ddccf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 06 Jun 2025 10:44:30 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-06-05）：ShapeLLM-Omni原生多模态3D大模型，7B参数，支持文本/图像生成与编辑3D内容]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxLqkEWeBSwrr0pKYjq1PCGiamC7Fxqxd6fXb8X8UtvmLSEalNLsesJ80txT86NannPsVJMLCo3UeQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：ShapeLLM-Omni★ShapeLLM-Omni是一个原生多模态大语言模型，专注于3D生成和理解。该项目由清华大学、盛数和北京大学的研究人员合作开发，旨在通过结合多模态数据来提</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247498612&amp;idx=1&amp;sn=df6dac0ac241835802809111e01b5694&amp;chksm=c01f17d222e29641dac7aa3d9329c167338a8b4e9eeda7bd29cbee3fbddf63ca72e8f3e2e44b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 05 Jun 2025 10:30:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-06-04）：Video-XL-2，长视频多模态转换模型，块预填充+双层解码优化，高效处理视频分析与生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwfvCyARGjbYGNJk4doUKHKoRqcWxsOzuO51d7yWqEwIkLtbHJIRm6sfRxh0GvM732M7vtCkV1TbQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Video-XL-2★Video-XL-2 是由北京人工智能研究院开发的一个视频到文本的多模态转换模型。该项目旨在通过高效的推理策略来处理长时间的视频内容。它提供了两种效率优化策略：</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247498602&amp;idx=1&amp;sn=d2e45f8c22344a37932f68ab8f1b1dd5&amp;chksm=c0179e79cb853025b3a3bef2efc022130d0d36a843547fb67bf309a2e36ef2e44355a7de3475&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 04 Jun 2025 10:40:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-06-03）：MiMo-VL视觉语言模型，7B参数，原生分辨率ViT跨模态对齐，混合策略强化学习优化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzeU59FXbibicxibh09oWfl56Mxe4jtl8bBHickbjmiaDHgjicwpRPBwibmYiaaKFicCp79h5yrUgfqNYJSJMQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：MiMo-VL★MiMo-VL 是一个紧凑而强大的视觉语言模型（VLM），其核心组件包括一个保留细粒度视觉细节的原生分辨率ViT编码器、用于高效跨模态对齐的MLP投影器，以及专门为复</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247498592&amp;idx=1&amp;sn=45a9ddf868d2849d45f7a379444d0501&amp;chksm=c01296962eeb38d6df57a449a97a3daef62d57b5ba1ea242a0095fae95d6cd85641337c98ee9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 10:27:25 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-05-30）：Chatterbox，生产级开源TTS模型，支持情感夸张控制，超低延迟适配多场景]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxQCqiaRUJ6Fu6HR7EYtDZiaKHaicreA2HllMG1zjCSDmRrPfgAYt5x2FMU6zoj7sotr2DRU8FibicXNAA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Chatterbox★Chatterbox是Resemble AI推出的首个生产级开源语音合成（TTS）模型。该模型在与ElevenLabs等领先的闭源系统的对比评估中表现优异，支持</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247498582&amp;idx=1&amp;sn=c391e1fbb4fc0fef6e63d03ec00276e5&amp;chksm=c0804a188ea0bb50b1abfdadb25ae466dc7914723ee28eae413381f37df9e33c608194ec88ce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 May 2025 14:12:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-05-29）：TwGI，7B多模态大模型，图像生成与推理，长视觉思维链突破被动观察，自回归统一架构优化输出]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzW6UcOzOH2vLCujI9FUk4diaZic9wF7s83ib5a6I5zbdCkuPNVpcU2cLdxMLUh68HSB5zibBdKJjmV9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Thinking with Generated Images★Thinking with Generated Images 项目旨在通过一个大型多模态模型（LMM）实现图像生成和推理</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247498571&amp;idx=1&amp;sn=0fc9e74c86c7785b84331fb3441962b1&amp;chksm=c058dce3cc305da7d3cf1d4a2a24b8ce4763247b90926f23650d72acfdf7caa790df92ea6c8f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 May 2025 10:20:51 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-05-28）：HunyuanPortrait，扩散式人像动画生成，预训练编码解耦身份/动作，注意力增强连贯性]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkyc9mXH5txVhGic8RoaIIx4BpHuibs9mX6gwgibsDJPGecFCAK3jrbibQKW0ibnicawJxQozv6ZePpTpfibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：HunyuanPortrait★HunyuanPortrait 是一个基于扩散模型的人像动画生成框架。通过使用预训练编码器解耦身份和动作，该项目能够生成逼真且时间一致的人像动画。它将</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247498561&amp;idx=1&amp;sn=4b735d2cbccd981640e9e3ec8325b84b&amp;chksm=c0e627c39cd0fe2a2ea5c60faf4527d20951288cdd01ad3017fb7194bf0dfff0391a893a3af0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 28 May 2025 11:03:40 +0000</pubDate>
    </item>
  </channel>
</rss>