<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[机器之心SOTA模型]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[机器之心SOTA模型公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/ciaIftfPzwlqVV4uGbvEOrJtup44iavdXZ3yKog9qnPkNQQ5O1Pbcn7UJGqTZS9k5NNUGZpibYic4T8/132</url>
      <title>gh_b81ad58dc224</title>
    </image>
    <item>
      <title><![CDATA[今日开源（2025-12-25）：通义开源Fun-Audio-Chat，双分辨率表征+鸡尾酒训练赋能全场景语音交互]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkz2Ld7oBhIhGpcrsOiboNibdStb8TKwsic1130BVxrYcHmLIp1Jaaicxw4jZxfl5DNJQFWeRZjkRcRnfw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Fun-Audio-Chat★Fun-Audio-Chat是一个大型音频语言模型，专为自然、低延迟的语音交互而设计。该项目引入了双分辨率语音表示（5Hz共享主干 + 25Hz精细头部</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247501060&amp;idx=1&amp;sn=9c1ce441bbb25574b641dbf8621a44f8&amp;chksm=c04b7ae7bf2613050d5675a3933a0011b6ff0a2847f578e9b7d0227c447dbd69af7126f3556a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Dec 2025 18:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-24）：港科大开源Robust-R1，首创显式退化感知推理，重构视觉理解抗干扰技术范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkw0RezCgwn3q2uGuPve2lZtBhANkY6tDzgyc8AubG5JznVFasEt0dm3iamib4iaLVN9ElEdbLI4yibkvw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Robust-R1★Robust-R1是一个专注于增强视觉理解鲁棒性的项目，旨在通过降解感知推理来提高模型在处理视觉信息时的稳定性和准确性。该项目提出了一种新颖的方法来识别和处理图像</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247501040&amp;idx=1&amp;sn=aa61d68330a9a4dbafaaab610bb69c99&amp;chksm=c05e1d795038f6983a15dd3910f0dd43a0c919a553a77680a3c10b3c14f99cc2d37e3f53f6b5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Dec 2025 18:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-23）：智谱开源GLM-4.7，多语言编码提质+终端任务增效，解锁复杂文本任务新可能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkw9k1KMqlibAwC0VT8jsbmqhlXnMwjCFhwrYoxzA7zytAMIPacI9xMJgeTNY95IeNj82b6q4dRFrag/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：GLM-4.7★GLM-4.7是一个多语言文本生成模型，专注于代码生成和复杂推理任务。相比其前身GLM-4.6，GLM-4.7在多语言编码和终端任务上有显著提升，并在工具使用和复杂推</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247501020&amp;idx=1&amp;sn=5986b07884d4252f5533bdb5dade5bce&amp;chksm=c00a5412e15ac8c4a01b68170038813f1136a84d869ac10de4e077fcba49f0d8b724afd62712&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Dec 2025 18:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-22）：英伟达新模型NitroGen开源，模仿人类游戏视频训练，赋能游戏自动化测试与下一代AI研发]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxx2vl6byYtXDMWfQ5QrJ5I5bZNEOm4EEFg7l3VFrlCibQjG9ia2K3Go4zKRCv2PhYUe1YsCFw7Wb1Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：NitroGen★NitroGen是一个统一的视觉到动作模型，旨在直接从原始帧中玩电子游戏。它以视频游戏画面为输入，输出游戏手柄动作。与通过奖励或任务目标训练的模型不同，NitroG</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500998&amp;idx=1&amp;sn=5be3abd06cd62e5f648707dd8c60ac56&amp;chksm=c0803ce349ea8f39306a1f17e5eab310196b415e278eed5ec4d8c7e8d10035f94ea0a95ef700&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Dec 2025 18:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-19）：谷歌开源双模型，基于Gemma 3架构优化，覆盖多模态处理与函数调用核心能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzQ4Kn3JjytVz56B2rJYNRRavJvRNRIFkZ7JcHsx40kmfibMKbfHRzaOQtZyuiajzLjTqMYm0xSyJbQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：T5Gemma 2★T5Gemma 2是Google开发的一系列轻量级但功能强大的编码器-解码器研究模型。该模型通过将预训练的仅解码器Gemma模型改编为编码器-解码器模型而构建。T</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500977&amp;idx=1&amp;sn=f089371e042edd5fa0e8745a6cd635d6&amp;chksm=c099b07355db73b5c2b8baadccbe03f990ebcf90335c98fcfe754a5908c787c90f6bdc1a3a9e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 19 Dec 2025 18:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-18）：小米开源MiMo-V2-Flash，以多令牌预测技术降低推理成本，实现大模型性能与效率双赢]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwF5s30VicOLwAZ6kpDo51FudglNL4YmiaQCooWsGEDrOPjk51DxibhUAVchibIqMD1zxMKxS3fmjf54w/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：MiMo-V2-Flash★MiMo-V2-Flash是一个拥有 3090 亿总参数和 150 亿活跃参数的多专家（MoE）语言模型。该模型专为高速推理和智能工作流设计，采用新颖的混</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500957&amp;idx=1&amp;sn=83f23b567c15fafc94b6e76be2a0bbc0&amp;chksm=c0ade365f12ef219e1c093ca118990f19a68f33c29822789dec7bc9827fa8c709073412944aa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Dec 2025 18:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-17）：微软开源3D生成模型TRELLIS.2， 凭40亿参数基座实现高保真PBR材质3D资产生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxLIhvCaooXnfXvWwpbDuYRTUV7eAax4icCywGiaq94zBkkhjIXG4nVtP8TUB38oLwAXZSwH4zIuIyg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：TRELLIS.2★TRELLIS.2 是一个先进的3D生成模型，专为高保真图像到3D生成而设计。它采用了一种新颖的“无场”稀疏体素结构，称为O-Voxel，以及一个大规模的流匹配T</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500937&amp;idx=1&amp;sn=5dee235ba08c513927d59fc0604cf298&amp;chksm=c047236923e510046246a88df525f30363d29dd5b556d4ad0ee95cf42d5f4ab4adf3062458ad&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 17 Dec 2025 17:52:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-16）：快手可灵与港科大联合推出UnityVideo，统一多模态视频理解框架，重塑视频生成与感知新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkw93qjkpb7jicRhqAoHobXPeAoZXL5mX6jynwc6Oe0PNoxGzM1TqPDpuPnBNqXq3bXpIEibQbvm9TibQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：UnityVideo★UnityVideo是一个统一的多模态多任务视频理解框架，旨在增强对世界的感知能力。该项目支持从文本生成高质量视频，并提供对视频生成的细粒度控制。它能够从视频中</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500917&amp;idx=1&amp;sn=0c314938a6e5298f7342e90333296bfb&amp;chksm=c09027d9335d91276a380cbeb952d3c7c33d1167e21529063bcb9dbeb046761526a383999ab8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 16 Dec 2025 17:43:43 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-15）：阶跃星辰开源新框架PaCoRe，凭 8B小模型实现百万 Token 并行推理，突破上下文限制]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzte4ibre4WNQpVaBSwCZJXxKOQapWicGrm6ictsIiaDYre0OaHHibtjDrr6AD7FxXkgdG3PoyRcwInR2g/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：PaCoRe★PaCoRe通过将推理的驱动从顺序深度转向协调的并行广度，突破模型上下文限制，大规模扩展测试时间计算。其框架通过大规模、基于结果的强化学习训练，掌握了协调多种并行见解所</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500898&amp;idx=1&amp;sn=d7f1b60eef0df264c5786690925816bc&amp;chksm=c0ff4b212600ba6f3dbc28ca4b7cd536c2f04d2c22a6349526886e69e262a8391d861454742a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 15 Dec 2025 17:42:13 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-12）：蚂蚁集团LLaDA2.0，WSD策略+多并行优化，撑起100B扩散语言模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwicdE5SVwfjC2E8VeCnZuUx1ia1LtJuzNNbLCSHLOCUtJOxP73BS1dXQIAsD2CnDLnSHDCIr7t46JQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：LLaDA2.0-mini★LLaDA2.0-mini 是一种扩散语言模型，采用16BA1B混合专家（MoE）架构。作为LLaDA系列的增强版，经过指令调优，优化用于实际应用。该模型</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500877&amp;idx=1&amp;sn=36a181eca5dc433b98e99be008c4cdbe&amp;chksm=c0050a52426f036a7956f50e437ded9a5812fbc7842597902ff5a0ebbf8fb65c0a6a61448c72&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 12 Dec 2025 17:43:06 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-11）：阿里开源Wan-Move，点级精细运动控制，赋能图像到视频模型高效升级]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwEhIQH7XnxgPibk6sOvOUXeLl47k7fGKkjc52FuefiaXtvbvA85Y7ohzKRqOBYqnrkXOnUicXOJFjiaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Wan-Move★Wan-Move是一个用于视频生成的简单且可扩展的运动控制框架。该项目通过潜在轨迹引导实现了精细的点级运动控制，能够生成5秒钟、480p分辨率的视频，运动控制能力达</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500852&amp;idx=1&amp;sn=25c9e7d010062a6549f5f6adfcba678b&amp;chksm=c0ef9f64c9ab35398285a97d840dd246db4efefc987ec56dfbbf874ba501010814199b21417c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 11 Dec 2025 17:48:08 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-10）：Mistral AI开源Devstral Small 2，以轻量架构赋能软件工程全流程自动化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxOINAzuxgTyQFCpbgxpbtN6aFbpP8dmjeQzlWzBjuibeRy4ZiaHXG7YVic5IiagR8cXToibicJxSmIhRicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Devstral Small 2★Devstral Small 2 是一个专为软件工程任务设计的Agent型大语言模型。该模型在使用工具探索代码库、编辑多个文件以及支持软件工程Age</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500808&amp;idx=1&amp;sn=d1946efcdb10907a0188467573e0a0d6&amp;chksm=c039657b2f08c0ea12ffacc433511bb6a1c82a9211628d659210cc0bf338a528ce2a1aaa8a4b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 10 Dec 2025 17:43:02 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-9）：清华大学与中科院开源LLaVA-UHD，PVC 渐进视觉压缩技术实现多模态模型高效原生分辨率编码]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwtCjt5qZ8n2kZcX3bkKj0vk7ARKEsUvdHp5ysb7H4w8kaWCR3iciaupcsgicG2BTmcpkibFvGYD7U9Zg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：LLaVA-UHD★LLaVA-UHD v3 是一个多模态大语言模型，基于我们提出的渐进视觉压缩（PVC）技术，实现了高效的原生分辨率编码。该模型在15个不同基准测试中表现出与先进的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500782&amp;idx=1&amp;sn=c45ad5e53f4bafee08d399f1d11d5189&amp;chksm=c0727c2d4e054842cf7f1659f963a9a46111b8edc16124036279024b93c487b66cfc8245fb60&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 09 Dec 2025 17:41:51 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-8）：LLM360开源K2-V2，70B参数架构赋能复杂数学问题与Agent工作流技术落地]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxVZnf91jTgHcvKHfIjCDfwDxJ5091iaia2EFq6vzNUhC3Y9icTnZ1N1T0kMR2N9JrqicgwevB0g3MSIw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：K2-V2-Instruct★K2-V2-Instruct是LLM360系列中最强大的开源模型之一，采用70B参数的稠密Transformer架构。该模型不仅具备标准的事实知识和对话</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500762&amp;idx=1&amp;sn=f0c06d5ca49b15635e9db63039bcc12e&amp;chksm=c051a0aa95f53ddf5485e73d1847e07fb856f901f29cb48e410e3631608792930cf1916ac116&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 08 Dec 2025 16:59:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-5）：南洋理工与商汤科技开源NEO，重构视觉语言模型技术范式，达成 VLM 性能与效率平衡]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDky8pkw0oickM9MNopLXD4KTO35XnoNiabzSTQl5LIbLPHFf6FFibsDrXdoyjnmKuqtDY9NuQs8mQOOAA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：NEO★NEO项目旨在开发原生的视觉语言模型（VLM），通过统一像素-词编码、对齐和推理，提供一种密集的单体模型架构。NEO在仅使用3.9亿图文示例的情况下，从零开始发展出强大的视觉</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500742&amp;idx=1&amp;sn=7c4c3651874f355f69fe59c269fc4731&amp;chksm=c09fc825527f6fb4f11697bcc6acdb29964d15d14510549b3edebc43c0702be3b542f2496f9b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 05 Dec 2025 18:23:54 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-4）：中兴开源EmbodiedBrain1.0，使用SFT+RL双训练，突破具身智能对齐与实时性能瓶颈]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkw84Bqq0vrQxQ8cbtgLnrvEzmZGtuIbpoYFcPygxAPQYY1iaQ3mcjYYIEtF76NofJ4llMYqFCB91ag/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：EmbodiedBrain1.0 ★EmbodiedBrain1.0 是一个先进的具身智能大脑模型，旨在解决当前具身 AI 模型在Agent对齐、实时性能和真实评估方面的挑战。该项目</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500723&amp;idx=1&amp;sn=dcf337fee2d29084d0052d374c0a8962&amp;chksm=c051d1dabc46cb843fb7603c3d7ed7d8fa0cbe54755e0b8bbb22da653b2ee03508d1f38cb3de&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 04 Dec 2025 17:31:42 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-3）：Ministral 3系列开源，凭借量化技术实现边缘端高效部署，支撑多语言跨模态任务]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxAkd4omdehNqsCCL3kibyuG98y9iakwVIUO4kfJlk1ibeTDPF1MGKsfNqMOgtZ3jKqpf26ibDEfnibtew/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Ministral 3★Ministral 3 系列专为边缘设备部署设计，能够在多种硬件上运行。Ministral 3 3B 可以在 8GB 的 VRAM 中运行，若进一步量化则需求</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500704&amp;idx=1&amp;sn=c27266c089127c6142fb01d415432bf9&amp;chksm=c068b860a3675de2261c38d51cb17e0fb5b2b00ce945dfc28121271e06bcdba4b24691c779fd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 03 Dec 2025 17:46:44 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-2）：DeepSeek-V3.2开源，DSA稀疏注意力加持，算力与推理性能双突破]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxVdbclAlaicR2tDw3fyLupJsH0HgiaYYJ4ws9YcIA3Z3LMyPZRAdME0dZJ3Uxia0pjpdHZugvI0hm6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：DeepSeek-V3.2★DeepSeek-V3.2 是一个结合高计算效率与卓越推理和Agent性能的模型。其创新点包括 DeepSeek Sparse Attention（DSA</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500684&amp;idx=1&amp;sn=4909b3b0e70375a81eeb7b05837a8aa6&amp;chksm=c0544281d3c2384f8ba81a3431bb958774f73520089ea21d08c3a8872d9683b5232af13ff56b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 02 Dec 2025 17:19:26 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-12-1）：英伟达发布Nemotron-Flash，实现推理速度与精度双突破，重新定义小参数量模型性能边界]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkyiaAE501jhR0KI1ibDvRbEM05YZbFG0kzdvG5MuHicyndPPVslPicUmPSne4xOCKolgMTn4m21z4Pwng/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Nemotron-Flash★Nemotron-Flash 是一个新型的混合小型语言模型家族，设计重点在于实际延迟而非参数数量。其特点包括延迟优化的深度-宽度比、通过进化搜索发现的混</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500664&amp;idx=1&amp;sn=bf89bf65ac6013ab14031262ae424040&amp;chksm=c082b436dc4fcd2ec1c8aa6993060f43952814785d1a35dd6c2741803e15de029821b5776a78&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 01 Dec 2025 17:05:20 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-28）：DeepSeek-Math-V2开源，以 LLM 验证器实现自验证，攻克数学推理严谨性难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwrQicaRCG3nG4VhTVhF8DVhBk3FJBxSuOY1etC8tYZfoJxZKULouzhBKTxmIWDrEicd5WrQaRn4Jcw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：DeepSeek-Math-V2★DeepSeek-Math-V2 是一个旨在实现自验证数学推理的大型语言模型。通过强化学习奖励正确的最终答案，该模型在数学推理方面取得了显著进展。然</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500644&amp;idx=1&amp;sn=ea3f14f6ce7da3eba0573c28207b039c&amp;chksm=c0c5bb3a758f77e59b93745b11c2e35c6103243726d65604b197e281d0f59b3ed62504c44b8a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Nov 2025 17:18:06 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-27）：腾讯开源HunyuanVideo-1.5，以轻量架构实现消费级GPU高效视频生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxn4icc9LVhhUYZYDiaA3ukzQ0QDXtkibjV4ujF579c1ZmtBmaOHyLeBw2ibFPovM17e2VqfibiaBic5ePqw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：HunyuanVideo-1.5★HunyuanVideo-1.5 是一款领先的轻量级视频生成模型，仅用 8.3B 参数就实现了开源最先进的视觉质量和运动连贯性，能在消费级 GPU</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500604&amp;idx=1&amp;sn=45c64dbe0d4f655389a00912e93a7c8a&amp;chksm=c0f598efb2eddeacecb937a0f3943dda5ee556a3ceb518271f95e6fafa11bc92e3ddcb707dfe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Nov 2025 17:49:50 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-26）：小米开源 MiMo-Embodied，赋能智能驾驶与机器人交互落地，重塑动态环境理解与推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzXeXjib2iaiaJVrYzFXjaDF4ZDVWJqrKf5ZHY2pbtEwq3FVk3mZn6q42Bet4GzowYia3CNM8mJ4jmBJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：MiMo-Embodied★MiMo-Embodied 是小米推出的跨具身视觉语言基座模型，更是首个打通自动驾驶与具身 AI 两大核心领域的开源 VLM。它以 70 亿参数实现了领域</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500584&amp;idx=1&amp;sn=2d44ac22e2940f931a884afccdd482c4&amp;chksm=c03a2770e74ba16b61103ccefdd601d4670d498c5bf2ed3396fc65d00ad431f74d6b23eabb54&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Nov 2025 16:30:34 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-25）：微软发布 Fara，7 亿参数多模态 SLM，开创本地计算机使用 Agent 技术新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxVmPWFFeEkavAlbnNGrPn9gkibRCsicKGic72fRNUicFiabnIOyiahrTHNPXib37jfuR7XOb6LicjpgYIg9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Fara★Fara是微软推出的首个专为计算机使用设计的小型语言模型（SLM），具有7亿参数。作为一款超紧凑的计算机使用Agent（CUA），Fara-7B在其体积类别中实现了最先进的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500563&amp;idx=1&amp;sn=0645c094aa92a979dc98237152916b88&amp;chksm=c0a84b493df7ee58417a1919069a2184492dfa5a9ffcbd97375a082b9ad2d0c3deb04a4c5d3a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Nov 2025 18:00:07 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-24）：清华大学人工智能学院团队提出了DAVSP，双创新赋能 LVLMs，筑牢视觉语言模型安全防线]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzzCZWobJnZVUBH0TSPRksDjHSygBR7xQY8qEHZpibdPfvG0QfHCKPzeTPWpPhWgP2V7RuqAyA77Lg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：DAVSP★DAVSP（Deep Aligned Visual Safety Prompt）是一个旨在增强大型视觉语言模型（LVLMs）对抗恶意查询能力的项目。该项目通过引入视觉安全</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500543&amp;idx=1&amp;sn=820869b0c445feb3d537a280d93fd4a7&amp;chksm=c078630a4f5ae2c6cda8f7c1257e17e0ed0f9ce3812f6558c7486cb65e8b44c10050c2d3058f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Nov 2025 18:10:12 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-21）：Deepseek开源LPLB，动态重排专家+最优令牌分配，破解 MoE模型并行训练负载难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxtwELjyWk50MlLvhsxEVwPWLg94hvGicq4n8eywD1adWNlQdbUib1A492PGXVyER5avTkGmsPOb9bQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：LPLB★LPLB是一个基于线性规划的并行负载均衡器，旨在优化MoE（Mixture-of-Experts）模型的专家并行工作负载分配。它通过动态重排序专家、构建静态拓扑的副本以及为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500524&amp;idx=1&amp;sn=30884567d334425f05dd988b146e4122&amp;chksm=c0ab47f9e3c0862ea593a2d4d2abfa0e958351d0dfd12acd55d26247d02d069041c7b5aed5e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Nov 2025 17:38:43 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-20）：Meta开源sam3，支持文本/视觉多模态提示，开放词汇分割覆盖 27 万独特概念]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkyuibPzo2Es38A2RciaQObo0308kdEZ6hxta1XMLAwialO5bT9zthzFy3JBUWo9U0jkykmxzKwPuKpqg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：sam3★SAM 3 是一个统一的基础模型，用于图像和视频中的可提示分割。它能够通过文本或视觉提示（如点、框和掩码）检测、分割和跟踪对象。与其前身 SAM 2 相比，SAM 3 引入</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500505&amp;idx=1&amp;sn=4d7fded90ab754f1a29cf7d47eb7b706&amp;chksm=c04a76d8e4380aa7605ecabecb87a93ab2c622fe53504224c8d9d0b2d7fda3e3e310d7b6dbfc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Nov 2025 18:00:20 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-19）：何恺明团队新力作！JiT极简PyTorch实现高分辨率图像扩散生成，解锁像素级图像生成新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzkPwXXzaLWwFLw33v7AkjR3T3Xicfm0UGpFkiasj640bZWh0BOn0x1ENR9c4EJupeWLfMLkyll5CGg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：JiT★JiT 是一个基于 PyTorch 的高分辨率图像扩散模型的实现，旨在通过去噪生成模型进行像素级图像生成。该项目最初在 JAX+TPU 上实现，现已移植到 PyTorch+G</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500484&amp;idx=1&amp;sn=38f994aed760bf7329cc7bdf1f6c9312&amp;chksm=c0f595ea13703f61635f95cca6cb15dc45c9b2efc2e8fe59dad2b4e97a793b455eb6fc283f3d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Nov 2025 17:18:14 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-18）：字节联合港中文推出Video As Prompt，以混合变压器架构实现可控视频生成飞跃]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzXSGAIeiatOiajozNgUxQF6ru2PKRQ47kNSq4zqSyZlkrcMw35nRTIWCZwe7hcVWacKgxiaCIVkXsjA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Video-As-Prompt★Video-As-Prompt (VAP) 是首个统一的语义视频生成模型。其核心思想是通过一个具有目标语义的参考视频作为提示，来生成具有相同语义的动画</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500456&amp;idx=1&amp;sn=b83561cfe40d1e239ec812a13a317ebc&amp;chksm=c0b47949da2453706ecbd44dcbf31aa82b655796fe0f50d80bf2273123836409f1ea897c9ab2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Nov 2025 17:22:50 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-17）：中科院与美团联合开源VinciCoder，以视觉强化学习攻克视觉保真度痛点，统一多模态代码生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzLs7rPcAqvZlw0ibmZWP4wicFkUObNlgahyo5ZEdYHTZ0BPK6g8Sd7z3EtUrlQnIwvzUk7DwCAQ4Qg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：VinciCoder★VinciCoder 是一个多模态代码生成项目，旨在通过粗到细的视觉强化学习统一多模态代码生成。项目提供了丰富的数据集和训练脚本，支持从图表到代码、网页到HTM</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500411&amp;idx=1&amp;sn=5ed243aaf2e30959c44f3c5b5a2a1c68&amp;chksm=c0e2888e4d0a3e4f4f439d101bfb21aaeacb6be4d538359990b125aee7671548b9cac2297f0c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 17 Nov 2025 17:48:01 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-14）：字节开源InfinityStar，统一时空自回归框架，赋能高分辨率图像与视频合成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzC2R4fRTysc15F6lwxZSibA9tknCa4T9ic7iaibFt1EMgxRdjFQibOspLvy6no7ULV6Nicwqnia4nV7KNCA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：InfinityStar★InfinityStar 是一个统一的时空自回归框架，专注于高分辨率图像和动态视频的合成。该项目采用纯离散的自回归方法，能够在单一架构中同时捕捉空间和时间的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500348&amp;idx=1&amp;sn=ca5c46a60de61789a27585244fd07043&amp;chksm=c0fef6ec161bad5a69c6b751dccf8437fb3fed4341bd9a2649d1b4ca009031222b3bd986f5ca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 14 Nov 2025 18:14:08 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-13）：清华大学崔鹏团队推出LimiX，打破任务壁垒，以Transformer架构引领结构化数据泛化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkyWpylo9aTleFFX0yaL3qPSPqaQA7T10uOJ1HXt0l5rqyzo5f7nNBfHYXxPbibnWd9YOI1UibPMEKcA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：LimiX★LimiX是LDM系列的首个项目，旨在推动通用性的发展。该项目通过单一模型处理分类、回归、缺失值填补、特征选择、样本选择和因果推断等任务，促进从定制化管道到统一基础风格表</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500328&amp;idx=1&amp;sn=aa3285f3e833ee26adf6b784f354cefc&amp;chksm=c0ce5e980913084d21b60025bf78ad8c3eeb64e95fd010ea228408be4aaba1acf4ab6b93c8df&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 13 Nov 2025 18:10:43 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-12）：微博团队推出VibeThinker，实现数学 &amp; 代码任务高效突破，用小参数量实现大模型级性能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxUMdpxft4ibJ1GzZNReicOadFM39SyzsDNWEaFAyzHM0FpzF7ibhHcU4DKeA7ozsmB6IyRJljic5TWdA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：VibeThinker★VibeThinker 是一个拥有15亿参数的密集语言模型，该模型在数学和代码生成任务中表现出色，尤其在数学推理方面，超越了参数量大400倍的初始 DeepS</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500309&amp;idx=1&amp;sn=ce01b58ce08b85511b25aee091823a97&amp;chksm=c0682faa35b4edbfa35939f17278ff735d759a7a41d6a7d2f24646a3d2018514a7a2566daba3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 12 Nov 2025 17:32:51 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-11）：复旦⼤学、创智学院与新国立联合推出RoboOmni，以多模态端到端架构赋能机器人自然交互操控]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxtNUYU6pUo4yHEue5sSMnQLA28UV9NV38k8oMbOYuFDc71ra5Y0w2mLYaYgpab4RaWmY5vTrjApg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：RoboOmni★RoboOmni是一个用于机器人操控的多模态端到端操作大模型，旨在通过视觉、语音和环境音等多模态信号进行意图识别和动作执行。该项目引入了跨模态上下文指令的新设置，机</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500277&amp;idx=1&amp;sn=416449ec5aed766c1410a7783cdf95be&amp;chksm=c0a47c9334fda9ffb26b6f5b1330f637ca790ec205f098995eef7c07c63c9fab3d6ac0b1cde0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 11 Nov 2025 17:46:02 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-10）：Cambrian-S 开源，多模态融合 + VSI-590K 数据集，突破视频空间理解极限]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxTGVmUx5A8tFB5fH2ubK1w2DUBzuh4CibtLGjTWCIvsM0Vl02jIBwZYIOs8rKibmf2ia3P1kAvLEzPA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：cambrian-s★Cambrian-S项目旨在提升视频中的空间超感知能力。Cambrian-S模型在空间推理任务上表现出色，同时在通用视频理解任务上保持了竞争力。该项目发布了Ca</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500257&amp;idx=1&amp;sn=c4d004c5704c42b3b89bc92b9cd4850f&amp;chksm=c008c06f37448bf81acab6ed223b3d904f0680c47170d7ae7c9ddf6a75d4d573ca75cd582392&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 10 Nov 2025 19:32:58 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-7）：Kimi-K2-Thinking开源，MoE 架构 + 256k 上下文，解锁复杂任务深度推理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzel3Oj0eIsZNbjVXxVX3ZIhWO9gOVMgTS3GqCE9rvbSG0Kdb88nOEbbiarOzxbTdOow7awPJnhiaOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Kimi-K2-Thinking★Kimi-K2-Thinking 是 moonshot AI 推出的开源思考型大模型，专为复杂多步任务打造，兼具深度推理与动态工具调用能力。Kimi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500229&amp;idx=1&amp;sn=e023dc9f9490670718c944b049d41c78&amp;chksm=c020019c7dcc56186824ed6f55622e261f837d1a1ed451770e68491267db3ad0418cd78f8834&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Nov 2025 17:48:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-6）：英伟达推出OmniVinci，打通视、听、读、推理全链路，重构 LLM 感知与推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkyLNprV7a6ylsVHibPUgUuTENxKkGj5AlOFNoP57RBkcZSuegNJ6wsS51Wn49zJKfEh61fpicMpl7Lg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：OmniVinci★OmniVinci 是 NVIDIA 推出的全模态理解大语言模型（LLM），专注于实现视、听、读、说、推理的多模态融合能力。它通过优化架构与数据，在 Dailyo</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500191&amp;idx=1&amp;sn=a7015aba58acdf0f4b68fdeadff7e3aa&amp;chksm=c0308910403ef1073e784b21fb21a716cc8e4539e2f7f5de0cc34d0d01e91c898490e3210ca7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Nov 2025 16:09:15 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-5）：北大字节开源首个时空推理视频模型Open-o3-Video，重构视频推理范式，多基准性能突破]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxA4hM0njz3AZnePyFmqUbPns2G7kKRx76KZ0DmFd2Dn2TQZCU9sbrcKuN53IefN4EjbRzeo5ueQw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Open-o3-Video★Open-o3 Video 是一个非Agent框架，旨在通过显式的时空证据（如关键时间戳和边界框）来增强视频推理能力。该项目通过精心设计的 STGR 数据</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500172&amp;idx=1&amp;sn=99539d308842ae4d6ea37872e4234fa9&amp;chksm=c06da5bfe901582664f2268f27d2cdb731b6198f100716bf145e65be6a9fab6b6ee38f809347&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Nov 2025 17:43:17 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-4）：字节跳动推出 Ouro循环语言模型，预训练阶段直接构建推理能力，革新大模型知识操纵范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDky1Vl1WKE8icYtcPFfibsbCU7phx60p3SnBrDJwINkBE1vrbh1Bv5zYk8M7hibKJPicXL8LpyiaZOicvsdQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Ouro★Ouro 是字节跳动 Seed 团队联合多家机构推出的循环语言模型（Looped Language Models）项目，旨在将推理能力直接构建到预训练阶段，而非依赖训练后的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500153&amp;idx=1&amp;sn=f1d0941dd78c097cfc1a9a38e4e1eb73&amp;chksm=c020693bce67794baadae26360e384e01532dbe7166cb0e643c4ea092f7c2a998844926485c4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Nov 2025 18:05:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-11-3）：快手与南大实验室联合开发HiPO，以混合策略优化实现LLMs动态推理，双模式切换平衡正确性与效率]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzUwYQf2pKAJsthmwmY7iaG94wO0gJtHZQg5NiccSj46w3OpO2seEmleqYhWE8zhHibiczs7yTTicSrnZQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：HiPO★HiPO-8B是一个基于混合策略优化（Hybrid Policy Optimization）的新型强化学习框架，旨在实现大语言模型（LLMs）的动态推理能力。HiPO-8B</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500130&amp;idx=1&amp;sn=4c5f45f868bf6197fb4dd6a7fcf814fd&amp;chksm=c01b5a4f8f9b2ad05bfdd3bbcf637873f0d48eb4003da48e6bcd293693a9984d2b226912e919&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Nov 2025 18:20:43 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-31）：Kimi Linear开源，以KDA优化门控DeltaNet，1M令牌长上下文解码提速6倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkxnEw5kJqhxVhNib61Tzqkjayg2OTlS55eaP5se7F2IY2wT9ibjF9XR5hXPpibCBHSXWM18RCB5yTUVg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Kimi-Linear★Kimi Linear 是一种混合线性注意力架构，旨在超越传统的全注意力方法，适用于短、长和增强学习（RL）等多种上下文。其核心是 Kimi Delta At</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500107&amp;idx=1&amp;sn=49754d535bec89bbcab5352eb38cb131&amp;chksm=c0e549c2d432629f5c6f74afb7ac0db07ba506dba4ed2f5b9971bf60b61d74c5bad3bc1bcee8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 18:06:28 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-30）：MultiPL-MoE开源，路由权重归一化解决融合痛点，强化语法与语段建模]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkylssQgtiaS7YaoEHyn3FjPThn85914GibnROfialicOLzrvficic6K4s7cOTfoHYg7LcTr9jp0BMEMa4kA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：MultiPL-MoE★MultiPL-MoE是一个多编程语言扩展的大型语言模型，采用混合专家模型（MoE）来优化在token和segment级别的专家选择。token级别的MoE使</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500080&amp;idx=1&amp;sn=9b95bb222b55f81f677809a002642d0d&amp;chksm=c0beefd0637b308f07bca8f1f7f7596c16084374b7805602942745b19b736375e21665510790&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 19:44:49 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-29）：VFMTok开源，以视觉基础模型为核心，凭区域自适应量化与语义重建赋能自回归图像生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwGvOXugNkHQAOS3iardjZyCFThOr0ICc3OmFvFJJbhhXTBlXqQUnIAXKeSBWLic8nibgTaPa7hNg5CA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：VFMTok★VFMTok项目旨在通过视觉基础模型（VFM）作为有效的视觉标记器来实现自回归图像生成。该项目创新性地设计了区域自适应量化框架和语义重建目标，以减少预训练特征的冗余并保</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500061&amp;idx=1&amp;sn=edbdbe0a6450876ddf6e32332cdee8c4&amp;chksm=c07cf1b1c89204b2b94a69a2a64fcf9a794d4758d3539604e96f5db34e40598996b6973f7b4c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 18:06:52 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-28）：CapRL开源，以解耦两阶段流程 + 75K 问答数据，将强化学习引入开放式图像描述任务]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkw4v4yUuC5pA4Xu2WwGdqAXaaC3hMTutThoxpRu6rBVjT8HcrITYEibiaI8wicCaDPA5WFpyD1Dv1NBw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：CapRL★CapRL-3B 是一个轻量级的 3B 图像描述生成器，其感知能力可与 Qwen2.5-VL-72B 相媲美。该项目首次将可验证奖励的强化学习应用于开放式和主观的图像描述</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500042&amp;idx=1&amp;sn=cc25a59a2bfe12f34802c82821e6373c&amp;chksm=c077a691bee316f4b9bd98a5f440a498c635c19d6de7c0d7ec05d07bf5838c99565857af9506&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 18:43:58 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-27）：PRIME-RL开源突破，多阶段 RL 与协同进化系统加持，实现 IPhO 金牌级物理推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkx8LxnJme4QS5NicssDuQA4cG4d5aicMxn2x2ssffnJVLylQS6Npuprakby9zRBuPMyShXIougkaUlw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：P1★P1项目是PRIME-RL的首个开源模型系列，旨在通过多阶段强化学习和协同进化多智能体系统（PhysicsMinions）解决奥赛级别的物理推理问题。该项目在2025年国际物理</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247500023&amp;idx=1&amp;sn=27c83d1c6c9c78d261617fcdd79f3591&amp;chksm=c015bffaaefb04211ef56d1585954c16f8761bd90809bb077288b968033ff3fcf3b0090b9352&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 18:15:39 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-24）：港大开源OmniPart，预训练模型 + 交互演示加持，解锁高效部件感知 3D 生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzvLOZiaOfsa0nDTeKdcQGUtqV6iacyMwlBdtyLJN1iccSxFFcIic7ibXvIJAwVlpibWJKaXp4xW408ichWg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：OmniPart★OmniPart是一个面向3D生成的项目，旨在通过语义解耦和结构凝聚实现部件感知的3D生成。该项目提供了预训练模型、交互式演示、训练代码和数据处理工具，支持用户在3</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247499995&amp;idx=1&amp;sn=75a0418444842d1758fe6684d898a1ab&amp;chksm=c029e9822527396b76e5fc7aa44f659160f7da141926077c79eb54016dda3b000d76cc81813d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 24 Oct 2025 18:03:43 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-23）：开源多模态模型 DreamOmni2，指令驱动统一生成与编辑，攻克身份姿态一致性难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkwYdMHJcicIJWesUNunNOAtofFwPUoz9FKiavicEzicTjldIksu8fK62myEbkrB3z4TzZY1aCnxfRdnSg/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：DreamOmni2★DreamOmni2 是一个多模态指令驱动的编辑和生成模型。它在传统的基于具体对象的生成任务中表现优异，尤其在身份和姿态一致性方面。该模型还支持抽象属性的引用，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247499975&amp;idx=1&amp;sn=7a94aa3b7fc72816c25bc66d5b09e1c4&amp;chksm=c03fd1bf68398094cd7d81cb648276fe30e9d35c1e1e6cc588629234f0581c6856387911d1b1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 18:13:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-22）：EditScore开源，7B-72B 参数覆盖，精准评估指令引导图像编辑质量]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkzaskTt7IT0FQREMmbibeD2wX1QRewYfibyPuWpxbUgOEk03licjAicVyeK9ficFvhWsSM2ZibhMLDmsxpA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：EditScore★EditScore 是一系列最先进的开源奖励模型（7B–72B），旨在评估和增强指令引导的图像编辑。该项目引入了 EditReward-Bench，这是第一个专门</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247499956&amp;idx=1&amp;sn=290fdb7fbe94167645b8ce8d96ca2b7c&amp;chksm=c0063e1847fb3400a17cd825eee995bc47bcd56f3d60f2ee24c26e68273be81f35fdb6ab4047&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 22 Oct 2025 18:34:42 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-21）：Memalpha-4B开源，突破 LLM 记忆持久性与推理连贯性局限]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkww2NricqEI8yQM1MibmibUo6Z4bQvJicZJ1gDBNdEvozd6VJAJYZL6lMGa4f3bRibBOkMGIHQSIrscqCw/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：Memalpha-4B★Memalpha-4B是一种创新的语言模型，专注于多模态记忆和推理。核心特点是其先进的记忆增强机制，结合了大规模语言模型的深度学习能力与长期记忆存储的优势，有</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247499937&amp;idx=1&amp;sn=518f6f8310201d11193deae2e745557e&amp;chksm=c0d2ace877f396a4e5c0382124532b8bcf8b4667c0ae99da25932504f2fc95ce30fce9401975&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 21 Oct 2025 18:05:27 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-20）：DeepSeek-OCR开源，LLM 视角重构视觉编码器，解锁 OCR 压缩与识别新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkx6BfQsA9YwGFOO3pU0fExpdfG0aqjoNhvwG8sRCF1mP9sONhNoQNI3mwjf7rvQibvJkvJXIXc5GxA/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：DeepSeek-OCR★DeepSeek-OCR 是一个专注于视觉文本压缩的项目，旨在从大语言模型（LLM）的视角研究视觉编码器的作用。该项目提供了一种新的方法来处理图像和文本数据</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247499918&amp;idx=1&amp;sn=1320da464977304dc8283a58673054a9&amp;chksm=c0555c4a45991d2232fb43c6e179ec76e39a8d74f924665a949990d4e339a09b750de634df72&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 20 Oct 2025 18:06:44 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日开源（2025-10-17）：Facebook开源MobileLLM-Pro，128k 超长上下文窗口，跨任务泛化能力突出]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/GU2ibjU7TDkx8iaqEwpB6t1Ib1oMRSOVhEqLbibUDr2eLMwiajibxK3CibEWsUSfVaCW6ISWCNLeQDCG4p34xibO9dQjQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>🏆基座模型①项目：MobileLLM-Pro★MobileLLM-Pro 是 MobileLLM 系列中的一个基础语言模型，拥有 10 亿参数，专为在移动设备上高效执行各种通用语言建模任务而设计。该项</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzkyMzcwMDIyMQ==&amp;mid=2247499894&amp;idx=1&amp;sn=6cf940a4f4c087ffdb1398f253907aea&amp;chksm=c044138dd419d44e68b5af2ab74d9c84a214fbf0f3ee04c2c290e6fb810d8bd2bd96a6791dbc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 17 Oct 2025 18:25:36 +0800</pubDate>
    </item>
  </channel>
</rss>