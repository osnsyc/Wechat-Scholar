<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[我爱计算机视觉]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[我爱计算机视觉公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM6aYkwkiboia6lA9D7ANy49WBe9icxn5NQqJjvn4Pyntzvfw/132</url>
      <title>gh_e07180c244d1</title>
    </image>
    <item>
      <title><![CDATA[宾大提出F³：事件相机迎来“预测性”表征新范式，光流、分割、深度全SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtB0ib5icMePhR4iblOq43vhSj3XKH1ia8W8esTYPSqCgaC0x7zIKNQryRkDgeV0ChGRnlQ9wE1RLYqcg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天想和大家聊聊一种非常酷的传感器——事件相机（Event Camera），以及一篇来自宾夕法尼亚大学的最新研究，它为处理这类独特数据提出了一种极具启发性的新方法。事件相机和我们手机、相机里常见的传统</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638707&amp;idx=1&amp;sn=a5b88345beb4a0643f1c73764e87fffe&amp;chksm=97fde72e866df8f2d8cf3e221de24091ba5c9588e36b45781e2c41dea803f5a4cf6a6775623d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 05 Oct 2025 22:41:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南理工提出FMC-DETR：巧用“频率解耦”，航拍小目标检测精度飙升8.2% AP50]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtQJO9jUpDtyicfwaZshibtGvwshxJZFwyGB4vVFkLrGuE0eYkLEZ5FwUWXm2csiaqpccicjygeP4zyrw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在广阔的航拍图像中，要准确地找出那些只占了几个像素点的微小目标，比如远处的车辆、行人，无疑是一项极具挑战性的任务。这就像是在一幅巨大的画卷中“找茬”，不仅考验眼力，更考验对整个画面的理解能力。这项技术</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638660&amp;idx=1&amp;sn=ee5206c4ed4f83f1b28d3ed5a06b865d&amp;chksm=97bc5fedb9a4211c5ef60413bf695e3d3b8b2245513a5f910189b8f43a1655219b27d9d40fc9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 04 Oct 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | RAD：基于大规模3DGS孪生数字世界的端到端强化学习训练策略]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtQJO9jUpDtyicfwaZshibtGvSjygyicBPlJfAzIXYVBtWPxibcaMRFvVOElibeY8lJLS4S0bIEjXpiaPjw/640?wxtype=jpeg&amp;wxfrom=0"/><p>一、论文基本信息类别详情论文标题RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638621&amp;idx=1&amp;sn=53094d3e8f3baf73ea1d713c8f0c996d&amp;chksm=972e1021d09a24c30fb6c2410ea42525f189dec2ba4ef7df80b39931592d5cb5863c467af469&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 03 Oct 2025 12:41:49 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[武大新作MASt3R-Fusion：融合IMU与GNSS，为新一代视觉SLAM注入“多感官”智慧]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8ouFWiaGSZBaLpmDzz0yQPEInQ2lcoiatwWr2ayLsS6qdiayiazrsfiaTuwA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天CV君想和大家聊一个机器人和自动驾驶领域的核心技术——SLAM。简单来说，SLAM（即时定位与地图构建）就是要解决一个根本问题：一个机器人在未知环境中，如何知道“我在哪？”以及“周围长啥样</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638597&amp;idx=1&amp;sn=9d2668a10edb9ec779f97d7a0c992731&amp;chksm=97221ac64e4c07357ef3cd0db7207f32615c6b1fe38e08d87655c3e52ab131ba2eb0fb6b3104&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 02 Oct 2025 13:21:40 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[中科大、清华、快手等发布OpenGPT-4o-Image：为多模态AI打造的“超级燃料”，图像编辑性能提升18%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBgRTg3KmUVicQLS2RiaTlfkxvkeSLBrNDRkbuJIN9dsh8dadban7TNYYg/300?wxtype=jpeg&amp;wxfrom=0"/><p>如今，我们都对GPT-4o这类强大的多模态模型的威力惊叹不已，它们能看、能听、能说，还能生成和编辑图片。但一个灵魂拷问随之而来：要让这些模型变得更强，下一个突破口在哪里？答案可能出乎很多人的意料——</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638597&amp;idx=2&amp;sn=74ca0b987665c0e63e2a0e4f6fa8b92d&amp;chksm=9796344e1ac9055dfd25878676b863bf6bf3e94c4c6aa7902ccc5b2b7a4579e70afac547ddc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 02 Oct 2025 13:21:40 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工联合商汤提出Visual Jigsaw：像玩拼图一样，显著提升多模态大模型的视觉理解力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDB9LvkFxyVM30CmqicXwODg5vh6zO6dQFpypTsdpLV5XtQg5ibHm5aYIDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，多模态大语言模型（MLLM）的发展日新月异，但大家有没有发现，很多模型似乎更偏爱处理文字，而在“看图说话”的“看”这个环节，总感觉还差那么点意思。它们或许能识别出图像里的物体，但对于更精细的视觉</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638569&amp;idx=1&amp;sn=b54044764004f56e5d49e5a90ab89ab6&amp;chksm=97332836b25f56abffe9fe8b50b9f347d407f2641c815bd4ce86dc33909a0545582a255451f2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 14:13:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[天津大学联合腾讯提出Wan-Alpha：一键生成高质量透明视频，发丝级抠图不再是梦]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBibaCsGibCJlhicfEYXkRgNNIOwjkfz0h1e5XVBViakhoAoGEdBC4yFsqLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>对于视频创作者和设计师来说，获取带透明背景的视频素材（也就是RGBA视频）一直是个头疼的问题。无论是繁琐的手动抠图，还是效果不尽人意的自动工具，都耗费了大量时间和精力。随着AI视频生成技术的飞速发展，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638569&amp;idx=2&amp;sn=5d6ea97371bbd1a523b6fe308c425277&amp;chksm=97018df3d0a7403c6884598684fdf5d5fb637827bbbdf1b029cc16c0ef39048eaed5fb6bcf9b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 14:13:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 清华大学与华为等提出全新正则化方法，破解稀疏视图3DGS“协同适应”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBufibxKqprqSfLsGepluFSQvYxibUgicT18hUNR14POgFfIQVAmdKC6TdQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年，3D高斯溅射（3D Gaussian Splatting, 3DGS）技术因其出色的渲染质量和实时性能，在三维重建领域掀起了一股热潮。然而，这项技术在密集视图下表现优异，一旦训练数据变得稀疏（即</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638453&amp;idx=1&amp;sn=526fd0a7a4c6fa9a41f77a9bca5f7d9e&amp;chksm=97227d6c01511fd5dc75ab8e807a6455d919599271151572c010d3ca5ad9ef379077f7c7a999&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 16:04:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DeFacto：用强化学习治愈AI幻觉，让多模态模型“有据可查”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTttDVCqQ9gFaBE2oxXtrPErItXvjagPrYXTJ6zG0dGZ9dOdzicOfAe8NMMc7FQQI4NplPRXZV5VSWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：DeFacto: Counterfactual Thinking with Images for Enforcing Evidence-Grounded and Faithful Reaso</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638453&amp;idx=2&amp;sn=1d3171800ea06cf16cc83a1970a4cfb5&amp;chksm=978f2c79bd5a9543eb8cee832aa6eeffd0e65a381fc5b30d59b9572ee0b780194eb7f6062c4c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 16:04:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[YOLO26首份学界评论：端到端无NMS，目标成为边缘设备实时目标检测新标杆]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBCUAQMymGbNmUUzia9ju037B4WI501WdweD06MquW2P5bibKufXwzNHzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Ranjan Sapkota, Rahul Harsha Cheppally, Ajay Sharda, Manoj Karkee机构：康奈尔大学、堪萨斯州立大学论文地址：https://arx</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638453&amp;idx=3&amp;sn=41bf331d478908c376f3e5d47b4b9a2e&amp;chksm=97731a6c9fadf3b9c940633b324581f7532738d9bb59224ba98bb88979433849e63b8120f0e1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 16:04:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | Seg4Diff：无需分割头，揭示并放大扩散Transformer中的涌现分割能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8WZDXdYhkxWtzAtXCEDVtrOqE3gbOam6yPfzr1Ud23xhDJ8j2yicxjJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自韩国科学技术院（KAIST）、高丽大学和苏黎世联邦理工学院等机构的研究者们，共同发表了一篇题为 「Seg4Diff: Unveiling Open-Vocabulary Segmentation</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638378&amp;idx=1&amp;sn=b0575c3fc7c477f08574970aa7b50f2c&amp;chksm=97dbb6d3d7a38d13dad379f456a5fe39ce104681e0ef40decb4bcc65e01c0ef92b33d712beab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 12:11:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | UniPixel：首个统一对象指代与分割的像素级推理框架，让大模型看懂每一个像素]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8L4aVbyibeA6DTujfVHJBIZYB1moB9Tsjz9pV8mNMo71icU9vKEOrAqMw/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大型多模态模型（LMM）在作为通用多模态助手方面取得了巨大成功，尤其是在宏观的图像和视频语言理解上。然而，这些模型往往“观其大略”，对于深入到像素级别的细粒度理解能力却关注较少。为了弥补这一差</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638378&amp;idx=2&amp;sn=2d357f26972dbc498d99b5357da70e4c&amp;chksm=97c3e1edc32aab8f66b57ad73777aa5a83006fb77af28e1212e6b77d06490b6076b5a4481a5e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 12:11:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 北大等提出C²PPrompt：解耦类内与类间知识，破解联邦持续学习“双重遗忘”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8aKPBbxXmbaD1gesQk8JMg6kw6QKq3eKBv3lib7BEJlpXwELfhYyaKZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天想跟大家聊一篇来自北京大学、中国科学院大学和内蒙古工业大学的最新研究成果，这篇论文已经被 NeurIPS 2025 接收。想象一下，我们有很多智能设备（比如手机），它们各自在本地学习新知识，同时又</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638246&amp;idx=1&amp;sn=2e7a435ad3e62177ac5405b4583b83b2&amp;chksm=97b7162c252fce5b0fd9d7ef0203150bab4ea5c71d1030ae23d5e4992ac18ca245709b83f8d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Sep 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[InterDigital开源CompressAI-Vision：为“AI看”的视频压缩，打造一个“通用跑分平台”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8CoN1WhLH6gxY4Ft1s7SPxDP3cAuxicKDKByhxRRMjHmuylroecpljNg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好！如今，从自动驾驶到安防监控，AI摄像头无处不在。一个随之而来的问题是：海量的视频数据，如果都原封不动地传到云端分析，带宽和成本谁顶得住？于是，一个新领域应运而生——面向机器的视频压缩（Vide</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638246&amp;idx=2&amp;sn=ef3bbdd1fb667da892d97e0feb5c0053&amp;chksm=97273a1f748ddb681fb287fe4f61db955e692aab1d6fcd419055aeb0126018b8c6c8037d6563&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Sep 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦等揭秘机器人“大脑”安全漏洞：一张图就能让它“宕机”，攻击成功率76.2%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8QxzSgoBliadjOxGAc4tlCVLn4q7VO8mm5iaL6FIIKDpGIBM1L4YIEsJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天，来聊一个让人细思极恐的话题：当机器人的“数字大脑”被一张图片“冻结”，会发生什么？来自复旦大学、上海人工智能实验室和Sea AI Lab的研究者们，最近就揭示了这样一个严重的安全漏洞。他们提出了</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638237&amp;idx=1&amp;sn=233708a1dd10fe31d65c7b62eb5dd46c&amp;chksm=9726168b71f46e2bd72219a9342a133d21a1978fbc17206c7eeb42fed0885d8a68c2b14ca7eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 27 Sep 2025 11:14:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DASFAA 2025 | 湖大等提出SCRA-VQA：给LLM一份“精装修”的图像描述，无需训练提升VQA性能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8kR5VObDnvbvRNWJPicSiaIl9oqpNJOB448uqFwDdbwR401kHKGicicia3mg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好！如今，大语言模型（LLM）已经成了AI领域的“万能钥匙”，研究者们都想用它来解决各种任务，其中就包括视觉问答（VQA）。一个很自然的想法是：能不能直接“冻结”一个强大的LLM，不重新训练它，只</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638237&amp;idx=2&amp;sn=d22ffff7def78153a8f16c7d12f09a40&amp;chksm=97291f27e0b09f723311f65966bb74bc7a8d431bfe0e76b10979f901c682a45865354e35a8b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 27 Sep 2025 11:14:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[斯坦福推出VisualMimic：让机器人“眼观六路”，零样本完成复杂任务]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt7q7P0SJ2ogSq0RpXaS4wic6zicSO90ibB0NClibZwfcbEMoiaIw0E5LoyePYROCDHwvCUibBmnoXrO5tw/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，机器人领域的一项新进展吸引了我的注意。来自斯坦福大学研究者们，带来了一个名为 VisualMimic 的全新框架，让机器人只通过视觉模仿，就能完成一系列复杂的移动和操作任务。想象一下，一个机器人</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637958&amp;idx=1&amp;sn=7b107313e482e95c686389341f4968f5&amp;chksm=971cc97d99791050cbd1df03938c76041c88a5bc1f050f8d6127e40641be00958c3778c0706e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Sep 2025 11:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大发布RS3DBench：让遥感AI看懂3D世界，首个像素级对齐的大规模基准来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt7q7P0SJ2ogSq0RpXaS4wic0icQ3a93UqWicXnEkKLZxTEQZEiaE5G8hK9ZwjCSeiaIkziaujpYSyRA6pw/300?wxtype=jpeg&amp;wxfrom=0"/><p>分享一个来自浙江大学和杭州城市学院的硬核工作，它为遥感（Remote Sensing）领域的AI研究，补上了一块至关重要的拼图——真正的3D空间感知能力。我们都知道，AI在解读卫星图、航拍图这些遥感影</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637958&amp;idx=2&amp;sn=9bf5d36f8370196ada8c6732cd3ffa26&amp;chksm=97ea37a2cff4148d220e1acf8984605431614b50e3ed108d646328cd755beb0cf3be323e4f3b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Sep 2025 11:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[OCRBench v2 25年9月最新榜单发布！揭示多模态大模型文档智能真实水平]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd2kiayZvjkHY5IsW7lVgfBQADZEJM5KiclSZdTCzo0lHhAibD7rDmIA4Eicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>导读：现有多模态大模型（LMMs）在复杂多样的OCR任务中表现如何？华中科技大学白翔团队联合华南理工大学、阿德莱德大学和字节跳动联合推出新一代OCR评测基准OCRBench v2，并发布最新私有数据榜</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637510&amp;idx=1&amp;sn=ad33f7e477e2e8a9029c8b384a9f15cd&amp;chksm=975925e491d0e72ae3f30a25ed4d64a959cb0bee9956fdc803818049f179eb80dda3d086235e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Sep 2025 00:01:02 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[恶劣天气下的图像修复：南理工等提出LCDiff，让AI在雨雪雾天也能看得清]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd2Nf7yNoDkqqeyELvyrkX4f7ibVeSLoKm8u0dqQEjxVQB4PakicXNcFhaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>如何让AI在狂风暴雨、大雪纷飞、浓雾弥漫的天气里，也能“看”得清清楚楚。这不仅仅是听起来酷，对于自动驾驶、户外监控这些应用来说，简直是刚需中的刚需。恶劣天气下的图像修复（Adverse Weather</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637510&amp;idx=2&amp;sn=8b541444da5351b1617b76bf72ba7703&amp;chksm=976c8359a787be5d286150431f64faa5a0afd93a4c9a8306b37ee62a0c4564d9733bf8e141ff&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Sep 2025 00:01:02 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ContextFlow：无需训练的视频编辑新范式，实现电影级魔改！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd20ibQaNjXkl0S7ibHefQDRkRk16XeuIpovOrS4pRoNK5iazgfwND2YpQtg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家聊一个好玩又实用的技术，来自北大和港科大的朋友们提出来的一个叫 ContextFlow 的新模型。简单说，它能让你像P图一样轻松编辑视频里的物体，比如凭空加个东西、把A换成B，或者直接让某个</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637418&amp;idx=1&amp;sn=7be6207fc1e1f503dba15e1aade164b3&amp;chksm=973e9657631c69403a3168861d060709b293b2caf22ecbaeee6200fc36ad08cbcbb595b36e6b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Sep 2025 17:32:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动OmniInsert炸场：无需掩码，任意物体“贴”进视频，效果碾压闭源SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd2HdoGYvNichpFrl7RHvp709g24GCjjYekHDicaIzkL2ECJCMPXcLj54Vw/300?wxtype=jpeg&amp;wxfrom=0"/><p>搞视频编辑的朋友们，是不是经常觉得，想往视频里加个东西，这过程简直比登天还难？又要抠图，又要搞蒙版（mask），效果还经常不咋地，光影对不上，动起来也假假的。今天，咱就来聊个“王炸”级别的技术，它可能</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637418&amp;idx=2&amp;sn=6303fd2446ca057452c59326733d3788&amp;chksm=9780016665502454e9975aa1a29042d18fbc6adb994794ae7902ec80488d44561a6889f49a8a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Sep 2025 17:32:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Point-SSM：一种用于点云分析的极简状态空间模型，在医学点云任务上表现SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wI1nyHcPESG7hdfRDdvtcXNvBReWCutYYZ8250lTAjiblEccAWTaJHzRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文提出了一种名为 Point-SSM 的新型点云分析框架，它创新地将最近在序列建模领域大放异彩的状态空间模型（SSM，如Mamba）应用于无序的点云数据。通过引入多种 扫描策略 将点云序列化，Poi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637418&amp;idx=3&amp;sn=15fb8ef51f1521f9a4a0a9be936c5efc&amp;chksm=97fc3ac00102ead592d9d6fa561d768fd203aef596ee92a4ef2223247cfdcedc505ac87d4802&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Sep 2025 17:32:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI | 数据增强还在“盲操”？南大提出IPF-RDA，让模型训练告别信息丢失]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8r8pVhGicxSwwZDBiaw8TEdoqKB8gZN4x7nIDjNXh5qBNhXSLyTTuBb6A/640?wxtype=jpeg&amp;wxfrom=0"/><p>各位炼丹师们，大家好！今天CV君想和大家聊一个咱们训练模型时几乎天天在用，但又可能没那么在意的“常规操作”——数据增强（Data Augmentation）。简单说，数据增强就是通过对原始图片做些“小</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637025&amp;idx=1&amp;sn=6ec8f5aad63d31240f66561870523389&amp;chksm=974523e271af3e3e14d54cebaca5ed2c34007d32efe9d4f82d3cb36e10de2cb7be11cce7af76&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Sep 2025 16:08:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[SilentStriker：无声击溃大模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8Rl4Tlq2HibSialp7aGElrFhzJasKiaJ4OooLiaXlAYanqnkC7ZZII5Cvwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着大语言模型在各种关键领域的广泛应用，激发了大量关于其安全问题的相关研究。相较于已被广泛研究的输入操纵攻击（如提示注入，prompt injection），针对大语言模型的比特翻转攻击（Bit-Fl</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637025&amp;idx=2&amp;sn=da009e971c31dcf8c003af98b19535ff&amp;chksm=971240bdc23bc2523ff837a0554edb47ea172e21d13d2d7417d1af8a5b4b8ee5780621bdeb9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Sep 2025 16:08:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Yann LeCun团队新作LLM-JEPA：结合联合嵌入预测架构，显著提升大模型微调性能与效率，在代码生成任务上表现卓越]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8T6WK5v6f09MOy6FNbQ9HPyC4R3s8tQJicP4HwsBrl58BBXVY7TlSKEA/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前，大型语言模型（LLM）的训练和微调几乎完全依赖于“下一个词元预测”（Next Token Prediction）这一自回归的生成式任务。然而，在计算机视觉领域，一个名为 联合嵌入预测架构（Joi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637025&amp;idx=3&amp;sn=f3dd386a5c4bdc3b8984fe0416cc6727&amp;chksm=97b243bf5e79c3f2699d100352d3ceb01076e79317cc5823b405d8d66102c877d7e807deba70&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Sep 2025 16:08:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[苹果发布Manzano：一种简单可扩展的统一多模态大模型，其混合视觉Tokenizer统一了理解与生成任务，性能SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wIsoRYib0JKCUlhhrHugkWBCIibAVOqCbcCGOoAanyatS0tJw0IrKyoWYg/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍来自苹果今天发布的 Manzano 模型，这是一个简单且可扩展的统一多模态框架。它通过创新的 混合视觉Tokenizer ，成功地缓解了多模态大语言模型（LLM）在同时执行视觉理解和生成任务时</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636580&amp;idx=1&amp;sn=654a4b72ba9c5ea364df032e95511d27&amp;chksm=97dd8540121a6d773a01155baa9910d2ff41e24fd2e099c910c61e07d3cc421901318363e298&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Sep 2025 11:50:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动SAIL-VL2登顶OpenCompass，开源高效多模态新标杆]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wIIplATVwRYAckyibx8HDnCKfzOHSnEcEg88ZwOJe7icPYTJCUplDVps7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，字节跳动 Douyin SAIL 团队与新加坡国立大学 LV-NUS 实验室联合发布了其最新的开源视觉语言基础模型（LVM）—— SAIL-VL2。作为其前代 SAIL-VL 的强力续作，SAI</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636580&amp;idx=2&amp;sn=63cb646ee1a1422fa467d1c2f577cd35&amp;chksm=97abc06b0feaeb11e64f19a10ce6f77679ebfa962b96e6fe9015d8a6678663055c7cd53041b1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Sep 2025 11:50:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[博后年薪40万到90万 | 东方理工朱文韬课题组招聘AI方向博士后、研究助理教授、访问学生、实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wI8Ix01Ul0N8yz049posJFuicvJwlBGF3EecvwU7F9AHlEl8PlTFpwpgA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【博后年薪40万到90万】东方理工朱文韬课题组招聘AI方向博士后、研究助理教授、访问学生、实习生宁波东方理工大学宁波东方理工大学是一所由社会力量举办、国家重点支持、省市共同建设的小而精、高起点、高水平</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636580&amp;idx=3&amp;sn=6c065d6c8461c14d1374e535506b6e8a&amp;chksm=972a64a1df7373873ef181f04bde6e07eca9ee23ced8e0b32eb08586aa2747a38d602a01f4e0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Sep 2025 11:50:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别视频“抽帧”理解，美国东北大学新算法GRT算法实现高效可扩展的高帧率密集视频理解]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOQ1iaMicr3QclWE27SVl7NOMMz3zWBicFS5W0fQezetW2hMVsvrFemXltA/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前的视频大语言模型（VLLMs）在处理视频时，普遍面临一个核心瓶颈：为了节省巨大的计算成本，它们不得不“抽帧”处理，即只对视频中稀疏的几个关键帧进行分析，而丢弃了绝大部分的密集时序信息。这种做法在处</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636505&amp;idx=1&amp;sn=4e4978faf6a8b3d85bc374f54498901d&amp;chksm=97d12b2cfbc4b6d428f4c2acaa5262ef70e52ede85cd96fe0a88f865abe607147a759fcd17fa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 21 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[【招生招聘】阿卜杜拉国王科技大学孟彦达博士组全奖博士、博后、实习、交流生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvrpy6G01cVWkU3z9NrpIzs5QkM0mpswQVncWyg4DEqFSFgG2cCicJUWxXeWALBrWu6hvoicRje85AA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在英国求学与工作八年后，孟彦达博士将于 2025 年 10/11 月 加入阿卜杜拉国王科技大学（KAUST，US News 世界排名112） 生物工程系，担任助理教授（独立 PI）同时挂职于计算机科学</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636505&amp;idx=2&amp;sn=831ebaa40cf75cd61781e65f1c165c92&amp;chksm=97a96b547cf1efd520bc6ca45b39139a5372ddd3817e763273a93c6d9f382932a43e45e1c8ea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 21 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | DiffMVS/CasDiffMVS：一种置信度感知的扩散模型，实现轻量且准确的多视图立体三维重建]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOict6ibia8kPFOGPcFAXKgpO5fbEEtKE4D2XYfuc8Qb9kfhaVCeKGEXTHg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天要介绍的论文是来自苏黎世联邦理工学院、南洋理工大学等机构的研究者们发表在 IEEE TPAMI 2025 上的工作。该研究创新性地将近期在生成任务中大放异彩的 扩散模型（Diffusion Mod</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636472&amp;idx=1&amp;sn=2f08b9ffe438978def1d931f45ffdd17&amp;chksm=97cecac4a02d9ceb551d4f9e893e360a3de418c9db93647032f2b7dd13c604779792924cca8c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 20 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[北大等提出BEVUDA++，首次解决BEV感知跨域难题，夜间检测性能提升12.9%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOPuPs6P4zu7iacibbSq8yHOc359ianFcCiccWBxlY7DP5L52omg1DS2GIbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在自动驾驶技术中，以视觉为中心的鸟瞰图（Bird's Eye View, BEV）感知方案正变得越来越重要。然而，现有BEV模型的一个致命弱点是“水土不服”：在一个地方（如晴天的波士顿）训练好的模型，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636472&amp;idx=2&amp;sn=0a7874fbf6512d86f1573a350bdb2ff8&amp;chksm=97acdc94888b9fe33a9eb689d29c53068ebb89f6bda04298bcffa671281cec42caa01e349f9e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 20 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta新作SyncSeal：用深度学习“封印”同步信息，让数字水印不再怕裁剪和旋转]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOIyQ3vgMAwXXM7fKe50y3qK39q17C0N1q4frMOQqDRKFQAaBiaHH07Nw/640?wxtype=jpeg&amp;wxfrom=0"/><p>数字水印是保护图像版权、验证内容真实性的重要技术。然而，传统的水印技术非常脆弱，一张带水印的图片，只要经过简单的裁剪、旋转、缩放等几何变换，水印信息就可能“失之毫厘，谬以千里”，导致无法被正确提取。这</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636428&amp;idx=1&amp;sn=5f34ca69ea54fb2f10530fe0b8f03dda&amp;chksm=970e32cf5613e6ad1845a0f3f68da6465482080fa2cc7707016de4f7de24e149d9f9b1d0dad7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 19 Sep 2025 17:00:08 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿联酋大学CVLab IEEE Fellow团队招收2026春季/秋季全奖博士生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOZx5z5YrfwtbNRR1NL4QjnD3Ubb6D81gric0WujqEAt4281AoLlrPywQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿联酋大学信息学院计算机视觉实验室（CVLab）IEEE Fellow廖胜才博士团队招收多名2026春季或秋季入学的全奖博士生。现开始报名2026春季博士，2025年10月8日截止报名。这一批次的学生</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636428&amp;idx=2&amp;sn=2d47ad2395a42d37c30c6aaa4a78ed0e&amp;chksm=97118fd278cf026b878c84a984c2c1c70b08ab22afc1d6e4fb0268cd3f94a508f5b1d370a142&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 19 Sep 2025 17:00:08 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | 弱监督与自监督引领自动驾驶运动预测新范式，用场景分割“脑补”运动，仅需0.01%标注，性能媲美监督方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTur8IPrMT4ibM3LyLSw1GMGj9Q94pUmJqL63NGz0Kp6KuIGyTgCv99RsDWyC2w5PPHUDEib8xqmyOPQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天，介绍一篇新出的来自南洋理工大学和商汤科技的研究者们发表在顶级期刊 TPAMI 上的工作。这篇论文 《Weakly and Self-Supervised Class-Agnostic Motio</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635832&amp;idx=1&amp;sn=acf490d444da8c86aced6da215c3dbba&amp;chksm=97b9cdc23da11829e3bac23e3a8f75d789b7d6314f2592bd3184e0846303734d61c4b664e47e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Sep 2025 00:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南开大学等提出RAM++：从关注“降质”到关注“内容”，实现鲁棒的全能图像恢复]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTur8IPrMT4ibM3LyLSw1GMGjBcZ6S46LfmHOQiajE2jtiaoKTPIuU2AmZicyTzc94rE6l1hMJtmibMBWOQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>当AI模型面对一张雨天、雾天或充满噪点的模糊照片时，它应该先“识别”这是什么类型的降质，再去修复它？还是应该直接“想象”出这块区域原本清晰的样子？来自南开大学等机构的研究者们在一篇名为《RAM++:</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635832&amp;idx=2&amp;sn=f302f17c2a71911780d8de6d8c27dd8a&amp;chksm=976ba803640a211f63217447f194f0f90292983a09e9349add9a6e807d24a19e8de6430f10dd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Sep 2025 00:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯、复旦、上海创智学院提出SwiftVideo：首个Continuous-time视频蒸馏加速框架，实现业界最快最高清视频生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTur8IPrMT4ibM3LyLSw1GMGjRYtYs8Ozbjrkbliapib6gPrWHmiaSDwwibibhJNAgdAWzxUZARKrOf8M04Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇分享论文SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635762&amp;idx=1&amp;sn=9bcf9c12c921cd70c07fbd69020f731a&amp;chksm=9743f0e2723a0d668d6753137e1781126f3d2ec15039584bb5bf1995f8f3785e12c0d7b46bbc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 17 Sep 2025 11:03:10 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[斯坦福大学提出PSI：一种通过概率结构集成，从数据中学习可控、可灵活提示的世界模型的新系统]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuVUGiajwiaF5fKpXGW3qjkdib5kDaM5wxxM1HbqpP58wcNagcCfSFzX9c25SxuwjibUkEBBmq7zv6GFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文将为大家介绍一篇来自斯坦福大学的最新研究，该研究提出了一种名为 概率结构集成（Probabilistic Structure Integration, PSI） 的新系统。简单来说，PSI是一个可</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635570&amp;idx=1&amp;sn=790cb09aaf9244cf72289af560e04e1d&amp;chksm=97e4f2d7bdf1b7637424350c6340b5c5769c8f67601a2a26b0926fcbe81082ddddc85110a59b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 16 Sep 2025 13:37:44 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[BMVC 2025 | 无需源数据，Grad-CL如何利用梯度引导实现精准的眼底图像分割？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuVUGiajwiaF5fKpXGW3qjkdibLg0YKXl55ictFKVRolOu14G9qztglADeicPQWR0HdYfvNUWZRewwvBOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在眼科疾病诊断，尤其是青光眼的早期筛查中，对眼底图像中的视盘（Optic Disc, OD）和视杯（Optic Cup, OC）进行准确分割至关重要。然而，深度学习分割模型面临一个严峻的挑战：在一个数</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635570&amp;idx=2&amp;sn=f1506bbde99ed12911f604b596379c63&amp;chksm=9755578ceb76beb585f5a0ed27defe59db5af0f523adf6664fc2242c3516a36f63ebd021b7f6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 16 Sep 2025 13:37:44 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[超越GPT-4o，蚂蚁集团与南洋理工大学提出LaV-CoT：首个语言感知的视觉思维链]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsia3cw9WQic7PGxiatsic0iayOB4gFRXn5ZMNQgX22GFs31X0Ra3HffTQzrZIDpxBrtZwpa80d8rK37iag/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大型视觉语言模型（VLM）的飞速发展，它们在处理复杂的视觉问答任务时展现出惊人的能力。其中，思维链（Chain-of-Thought, CoT）技术通过模拟人类一步一步的思考过程，极大地增强了模型</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635405&amp;idx=1&amp;sn=3862a4306a3b99bc4bacdd0da7befbd0&amp;chksm=977b42a9d0ba212af98cb0fa58b736a031c41f6fdd2a1c6b499f33dcb9b32cd0940d2785fcbe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 15 Sep 2025 14:55:25 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepMind与牛津大学提出LayerLock：用渐进式层冻结实现高效、无崩溃的自监督视觉表征学习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsia3cw9WQic7PGxiatsic0iayOBUh8IGt7MZg6PgT3hwmYoZNHunNZ55zIkr1rQcP1hVFMYXPRQUv399A/300?wxtype=jpeg&amp;wxfrom=0"/><p>在自监督学习领域，如何让模型在没有标签的情况下学到有用的视觉表征，一直是核心挑战。其中，掩码自编码（MAE）是一个明星方法，但它依赖于繁重的像素重建任务。另一条路是预测网络自身的“潜在特征”，这更高效</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635405&amp;idx=2&amp;sn=50dcc6f4c0a98de0d85c59048d76a703&amp;chksm=97c30588ff71ea3074b66790adfa5f0fb1bfa0ce59c2580d47097f3acc43676edfeb1560fd75&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 15 Sep 2025 14:55:25 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[耗资15000个A100 GPU日！港中文、阿里等发布600万规模T2I推理数据集与基准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLlCzQhzYhGQU5wVYAguiaD9ckc0E6PFslOrsSZwrFVuTs5uicPSOqicjEt69MicXhDfaULmkzBOGcbA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，文生图（Text-to-Image, T2I）技术取得了飞速发展，但开源模型在处理需要复杂推理能力的提示词时，其性能仍与顶尖的闭源系统存在差距。这背后的核心挑战在于，社区缺乏大规模、以推理为中</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635294&amp;idx=1&amp;sn=1b1de9160c5b724c6deb2a9a124614bc&amp;chksm=97920d961a0f8eb89b4983977ac2944a488b4574ee09830a16fdf303dfa51f07ccb18023a043&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 14 Sep 2025 11:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[INFFUS 25 | FS-Diff：一步到位，用扩散模型同时实现多模态图像融合与超分辨率]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLlCzQhzYhGQU5wVYAguiaDHp3iaLcCO4Cb5T0nJ2usE46MWggnzHgwgb3pJsqgd7ibqfzJH3XChuJg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在许多现实场景中，例如无人机侦察、自动驾驶和医学诊断，常常需要将来自不同传感器的图像（如可见光和红外图像）进行融合，以获得比单一图像更丰富、更全面的信息。然而，这些原始图像往往分辨率较低，甚至可能因为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635294&amp;idx=2&amp;sn=7edf94571b2b13a04b516caa4979b351&amp;chksm=97271fa039e10ded81735ea3f724a0b280815bd1737101d379bbc373c8394456592251e5881d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 14 Sep 2025 11:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[让机器人“大脑”更轻更快：SQAP-VLA首次实现VLA模型量化与剪枝协同加速]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLlCzQhzYhGQU5wVYAguiaDJt04XYn18bvDia07bCzR1sSE6H5e9U16vn2ZzrBX5wRPqUJiaEfGN6jA/640?wxtype=jpeg&amp;wxfrom=0"/><p>视觉-语言-动作（Vision-Language-Action, VLA）大模型被誉为具身智能的“大脑”，它让机器人能够理解人类指令并与物理世界交互，展现了惊人的潜力。然而，这些模型巨大的计算和内存开</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635226&amp;idx=1&amp;sn=cdf3e866b16789ac1676a0aca13141b9&amp;chksm=972f0d0f81c4ecfaf4227e156149c25ef85169424afae4635cc2f2ec7872da71dd1e0d74c78b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 13 Sep 2025 18:14:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[成本不足60美元！开源U-ARM：让机器人模仿学习更亲民的通用遥操作界面]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLlCzQhzYhGQU5wVYAguiaDEoJBl9l65LlZibvoYdm2NWF1falibicZwpDsicicBnsc3mpacoIRDtvsIug/300?wxtype=jpeg&amp;wxfrom=0"/><p>在机器人学习领域，通过人类演示来教导机器人（即模仿学习）是最有效的数据收集方式之一。而“主从遥操作”（leader-follower teleoperation）系统，即操作员通过一个主端控制器（le</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635226&amp;idx=2&amp;sn=1903f9aa58a75293eb2b9ff708f0ec63&amp;chksm=970ff3272319c3366b57c644e55d59b1a3d4e01ec4239fcc395480997e819b8c33f2b050e6c6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 13 Sep 2025 18:14:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICRA 2025 | TANGO：机器人告别3D地图，仅靠RGB摄像头实现零样本长距离导航]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTumkrJXfuQ7kKHWJbDdY86YcfewhQeBWXJSZvHXx87RqpX8kYysDCRiaeTzEkBevt2an7t236fUv7Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>让机器人在复杂、陌生的环境中自主导航，是机器人学的核心挑战之一。传统方法通常依赖于预先构建的、全局一致的三维几何地图，或是通过大量数据训练得到的端到端控制器。前者构建和维护成本高昂，难以适应动态变化的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635082&amp;idx=1&amp;sn=79151da724bb8475292b6c3ee56e56f9&amp;chksm=9730613a6ce1ac82c716613fe07649608d7771ad3895e8cc373878fb0af7c9d51af9582820d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 12 Sep 2025 12:24:19 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[RewardDance：字节跳动提出视觉生成奖励扩展新范式，破解“奖励劫持”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsVASZWLEjOlVNSX15mdb0RWBRk5eAQsA4ASAjQr6iapiaUTxbFqFEAAzVaCHRw6O6dicIBRwxkg672w/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，来自字节跳动 Seed 团队的研究者们发布了一篇名为《RewardDance: Reward Scaling in Visual Generation》的技术报告，提出了一种名为 RewardD</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634818&amp;idx=1&amp;sn=c51b82bbf92da1cccdc3224c2a4d9ea4&amp;chksm=9713fb5e2aa924d21114266ba03e85f693dcae8ffa91bb800f5be229895fab2fce77cb069884&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 11 Sep 2025 12:28:40 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | H2OT：分层沙漏型Tokenizer，重塑高效视频姿态Transformer]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtbvdOZNia0MkibzpTSGFBAibEjMcibKxGCOGPMAg8F3fca2X29XRSzRlNTr0qsgj8o6icxIhMeeZpu6gw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天要介绍的论文是“HOT: Hierarchical Hourglass Tokenizer for Efficient Video Pose Transformers”，它提出了一种名为 H2OT</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634586&amp;idx=1&amp;sn=201d9822f56f1d3b157eb7058f06f3b6&amp;chksm=97355fc54bce42f0736baac6164f3310f72c7b9eff2e2facab1d3c821bc7890e546a5bd71458&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 10 Sep 2025 11:35:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | IGEV++：迭代多范围几何编码，刷新立体匹配技术新高度]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtbvdOZNia0MkibzpTSGFBAibENqibdGYfJQibTib5icvibAkP71OH2Fm8fhYf0odEnw9NcicOvvR8gfFMKGyA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍一篇在立体匹配领域取得突破性进展的论文 IGEV++ 。该研究通过一种新颖的深度网络架构，有效解决了在病态区域（ill-posed regions）和巨大视差范围下的匹配模糊性问题，在多个主流</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634531&amp;idx=1&amp;sn=25ff5f0ef28510ed05d133067dff3707&amp;chksm=97bff079b90b5b30acd585100cea7284294f3c458cb5ff259356ba2706831d745bb843c7fd0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 09 Sep 2025 11:42:41 +0800</pubDate>
    </item>
  </channel>
</rss>