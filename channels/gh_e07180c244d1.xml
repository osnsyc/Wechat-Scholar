<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[我爱计算机视觉]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[我爱计算机视觉公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_e07180c244d1.jpg</url>
      <title>gh_e07180c244d1</title>
    </image>
    <item>
      <title><![CDATA[Meta  Yann LeCun 团队最新研究：“回归特征：DINOv2为基，铸就强大的视频世界模型”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsOeicq7VYupmzibfHEYsvPPJnkySK6fR1qTB5ribRQiblDZAFmuTGDf09xxAqa2TYfr3XhXREGjMRvGw/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自Meta Yann LeCun 团队的最新研究《Back to the Features: DINO as a Foundation for Video World Models》，带来了一个名为</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631414&amp;idx=1&amp;sn=4ece6894dadd55f4454faa28cd88f2da&amp;chksm=9712df853568a44b0c2b2badb44290fb6feacf3547cc76247594e46d67cf43a7355eeceb61f3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 00:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IROS 2025 oral | MuStD：融合激光雷达与相机的3D检测新SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsOeicq7VYupmzibfHEYsvPPJBwMbBS0AuJ9jiamgro3Vticz1bqKKoiab6F5nWnibKZowxQJRgQMLjmgtQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在自动驾驶和机器人技术中，精确感知周围环境是实现安全可靠运行的基石。其中，3D目标检测，即在三维空间中识别并定位物体（如车辆、行人），是核心挑战之一。为了提升检测精度，融合激光雷达（LiDAR）提供的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631402&amp;idx=1&amp;sn=24188f29ad6865dfd026153f995fe603&amp;chksm=97cd37ff88b0d6eef31e7ab91e4efe781bbbf2d6cfc56b3128857519cd325b7e3816a8422bd0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 13:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 北大提出UPP：告别繁琐预处理，用“提示”让点云分析更鲁棒]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsOeicq7VYupmzibfHEYsvPPJXyp9sPLbFuYibFdqMKLkiafwlWibrc2Oa6SGXGjNfXPkEuheozJicdePSQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点云作为3D世界的数字基石，其分析与理解是自动驾驶、机器人和AR/VR等领域的关键技术。尽管预训练模型在点云分析任务上取得了巨大成功，但它们有一个共同的“软肋”：在面对真实世界中常见的低质量点云（即充</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631382&amp;idx=1&amp;sn=7e7336feda03a637f328ea219a946922&amp;chksm=9722246b50fd08e72e6c4ca262d2d91be65b53206bd664ea55595a4e4766856f310e92efd270&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 10:08:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[中科院等提出RealisVSR：细节为王，用扩散模型挑战真实世界4K视频超分]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsOeicq7VYupmzibfHEYsvPPJQceMhAIU2rRjMbUPfsx2iaf7vqiasHic4dNmzsSUiaXGbSpRRrnB1BFEHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着高清、超高清视频内容的普及，视频超分辨率（Video Super-Resolution, VSR）技术变得越来越重要。它旨在将低分辨率视频提升至高分辨率，同时恢复丢失的细节并保持时间上的一致性。近</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631369&amp;idx=1&amp;sn=d17deccfb32ee11726ac4fb8201623e0&amp;chksm=97e0efa13445410b0c8b8bd101407d844c9923346ea6cfe00f949d5cc0d747c3944ca43d39e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 08:01:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 浙大等提出 SGCDet：自适应3D体素构建，重新定义多视图室内3D检测]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvRp1kTauGNq8qTicibt7gRbIDzVsKodMVicuC1oDWrZeEYfxJiblslicuYBhrZdr4JSgT6yhgYPicia4ia8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>多视图室内3D目标检测是实现场景理解、增强现实和机器人导航的关键技术。然而，如何高效且准确地将多张2D图像信息“提升”到3D空间，一直是该领域的瓶颈。传统方法通常采用固定的投影方式构建3D体素（Vox</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631344&amp;idx=1&amp;sn=f46a8fa3d8fae0adba94e48f84e4692a&amp;chksm=9793e48f2b29a9948b65bffd2b94da143a813d59ebaa1d155afa87f43d06dfa814307b7b3408&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Jul 2025 22:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | “看一个，认所有”：OP-SAM让SAM模型仅凭一张标注，即可实现全自动息肉分割]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvRp1kTauGNq8qTicibt7gRbIxGwI5l2Urt8WhdDEWs6sJSnKHxTlleB5gRWiaYPLJqy19Xn6CqEbtJA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在结直肠癌的早期筛查中，准确、高效地分割出肠道内的息肉至关重要。然而，传统的全监督深度学习方法不仅需要大量耗时耗力的精细标注数据，而且在面对形态各异的息肉和不同设备带来的领域漂移时，性能往往大打折扣。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631330&amp;idx=1&amp;sn=e084ee7d24f86a1c059a595df10c7ba1&amp;chksm=97aca1a36da5b984b1e662525237b4ac13dfbc2fc1a10f4fbafaf0ab5fe2fbb70a41e2795181&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Jul 2025 14:23:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 告别数据依赖：专为目标检测设计的任务特定零样本量化感知训练]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsVG3khuCYwI1UrJK2TxTfgPPBxjjFJV89IH7Gq9YFTeSW8icVpKpjMy0icVBKnMgDic8YVia4Wfmt3zw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文解读一篇来自佐治亚理工学院和清华大学的研究论文《Task-Specific Zero-shot Quantization-Aware Training for Object Detection》。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631273&amp;idx=1&amp;sn=229a389c390d2317f63cdcdeca9f4acd&amp;chksm=9777c91a3e68628cb0c3387387a5d997801e4ecdd650b26f338980c034220234ab13a7c59459&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Jul 2025 15:12:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 不止于模仿：LDRLD深挖Logit内部关系，开启知识蒸馏新篇章]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsVG3khuCYwI1UrJK2TxTfg3CaCOD3yg98OnSPPNYDZWSSrYcCTfwnDejVa3HZAEjPXTYMFp5tTfw/640?wxtype=jpeg&amp;wxfrom=0"/><p>知识蒸馏（Knowledge Distillation, KD）作为一种高效的模型压缩和优化技术，其核心思想在于让一个强大的“教师”网络，将其所学到的“知识”传授给一个轻量的“学生”网络。其中，基于L</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631259&amp;idx=1&amp;sn=c199cb6b84f05bc584e0917d54382fd3&amp;chksm=979410b2bd04775b8b6d8a134f1477ed743431e003742119a844a062b661e0bd96990c7e9ee5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Jul 2025 10:37:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 超越标签本身：上交大等提出LGA，用大语言模型“解剖”动作，实现精准少样本识别]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsVG3khuCYwI1UrJK2TxTfggueo19xLdQH9pDpIa0grkY0PCtPO4H1E76lSFeFViakwaViaMHciaL92g/640?wxtype=jpeg&amp;wxfrom=0"/><p>少样本动作识别（Few-shot Action Recognition, FSAR）一直是计算机视觉领域的“老大难”问题。在每个类别只有寥寥数个样本的情况下，如何让模型学会识别复杂的、多样的动作？近年</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631246&amp;idx=1&amp;sn=896d198d8e68bac26c68bde4bf63990c&amp;chksm=97ac44b5398e2c877afdfda962db4d8c3995f57346dfe5f5a049ccae992b23d0158a6b62f996&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Jul 2025 07:30:25 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IROS 2025 | 清华等提出“本体感知”新方法，让无图自动驾驶"轨迹预测"准确率提升23.6%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv2yxm2BPzqHRHGKFUrQWQn9cdsw4DBnp89xVUD6micgMrrkClibUEFoLWMY2JdEiaXAvuEsibAAjnjbQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，一篇被机器人顶会 IROS 2025 接收的论文《Delving into Mapping Uncertainty for Mapless Trajectory Prediction》引发了业内</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631233&amp;idx=1&amp;sn=14d767ed9eca431d385310e3a462db18&amp;chksm=9755b40ab201b7a817136020d8204247e3e34fb2fdf4b3ba11fcb110ad27b5fddafb87c37c1e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Jul 2025 23:32:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | LMM-Det：释放大模型原生检测力，告别外挂检测器]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv2yxm2BPzqHRHGKFUrQWQnjBjIJlQCIGxErjhVID0t0Mxou6SnhzsFOM2xI1PlfmGayOakP58ZUQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型多模态模型（LMMs）无疑是当前AI领域最炙手可热的明星，它们在图像描述、视觉问答等任务上展现出的强大理解和推理能力，令人惊叹。然而，当面对一个基础但至关重要的视觉任务——目标检测（Object </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631208&amp;idx=1&amp;sn=1846a6e14b96fdfd779bbd7ac5548b34&amp;chksm=97863923309562d5b43a609d357c9c22107f627b5b38f703bc6e6f4eb9cbf0e536495d4d61f9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Jul 2025 14:52:01 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[上海 AI Lab 发布 Lumina-mGPT 2.0：自回归模型的华丽复兴，实力叫板顶尖扩散模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv2yxm2BPzqHRHGKFUrQWQn080Gkb4gwCa6IeSdk7Dd1pZI0jX8koSzDwCQaCzDEqEn9x2ZXRibOWQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天一篇名为《Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling》的技术报告引非常吸引人。该研究由上海人工智能实验室、香港中文大学、上</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631193&amp;idx=1&amp;sn=3a16d3a7be1034b42e06d63685879d88&amp;chksm=97437e5453bc0f4d58a858e6450901396ac409d727b04f16dcedfd13f53a9264f24896e98e7a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Jul 2025 07:44:53 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[HybridTM：鱼与熊掌亦可兼得，Transformer与Mamba混合模型登顶3D语义分割]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv2yxm2BPzqHRHGKFUrQWQnAtOPYXzgAF49bTqpI8MFicBoSGMnkibFiaxZ5oQRgy0A1IoLnWAmlrqLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在3D语义分割领域，Transformer以其强大的全局注意力机制（Attention）著称，能够有效捕捉长距离依赖关系，但其二次方计算复杂度在处理大规模点云时显得力不从心。而新兴的Mamba架构，凭</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631193&amp;idx=2&amp;sn=9c3e53041dfb5f72e7c62d08a04f49e9&amp;chksm=97d1883fdae3fb64e839b27374593f4d1d90327190d1873b8c62507969dfd693d6b05f0ea052&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Jul 2025 07:44:53 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[最新综述 | 不止于文本：一文读懂"可控视频生成"技术全景]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsMhR4rrnwFsRhyB6RGvHcO0jkFzbndM8Z9Jq9iaBt2HoDI0JibeHPfHtBHRbTFyiaDQYIyMwZ57EgRw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着AI生成内容（AIGC）的浪潮席卷全球，视频生成已成为其中最激动人心的前沿阵地。然而，从Sora的惊艳亮相到各类开源模型的涌现，一个核心挑战日益凸显：如何让AI生成的视频精准地听从人类的指令？本文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631160&amp;idx=1&amp;sn=293cd7772586832e1576cb79f637fabc&amp;chksm=97eec0c842d0a4fd118a4ec76c8f9342448e19bc96fe4ae40a994ef5003f0aa7fdcf789033a1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Jul 2025 22:17:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 哈工大、清华等提出首个双曲学习框架：HLFormer，革新局部相关视频检索]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsMhR4rrnwFsRhyB6RGvHcOn8vicsww9uEqZbNUyZynuHKf3TOtqETZRLbhEicBOCicmKFGFicSgFRBuQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在视频检索领域，一个关键且普遍的挑战是局部相关视频检索（Partially Relevant Video Retrieval, PRVR）：即根据一段只描述了部分内容的文本，从一段完整的、未裁剪的视频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631142&amp;idx=1&amp;sn=8f4391e22fa605fab92994e690a9880a&amp;chksm=975392ff27b2c43e7545aa3a1496106aceb5467e6d78271c0033e937b8a1a6212883fa628f65&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Jul 2025 12:17:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[上海交大、上海AI Lab 等提出SeC：告别像素级匹配，用“概念”理解和分割视频目标]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsbpo2XhrY4M7omThCY9asAkIKZficBMZwtt9OapsOqva0a7XV9HN41yRb3UOuKN5g93qGjRcBoKXQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍的论文是《SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction》，该研究直</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631085&amp;idx=1&amp;sn=81e4e6dd0fcc98495df5b8963f97db32&amp;chksm=97fcc303bda501860a3e05727a56d51e8197de91caec09b5f565fa587677c3e769c0d761896d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Jul 2025 09:34:51 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[PW-FNet：告别复杂自注意力，小波与傅里叶变换打造轻快强效的图像恢复新基线]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsbpo2XhrY4M7omThCY9asATvIM8xCMUURyPiaXiajicibdhoFEts6lwjA5VvV4MTpFY9CGqhS6hN9TjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在图像处理领域，如何让饱受风霜雨雪摧残的图片“重焕新生”，一直是学界和业界关注的焦点。近年来，基于Transformer的方法在图像恢复任务上大放异彩，但其庞大复杂的模型结构和高昂的计算成本，使其在需</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631085&amp;idx=2&amp;sn=d085beb86006f5981c2febdef12e7903&amp;chksm=972ef580df2dd39e13e1016f02c82804ee15c96ca30e2f8ca242ec69e7d73e2393b1c131254b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Jul 2025 09:34:51 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 虚拟试穿 | 中国海洋大学等提出OmniVTON：无需训练、跨越所有场景的通用模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsbpo2XhrY4M7omThCY9asAtp4xqMt5sfZjfV7djiaP6fQf7MBgzgv0m1M9dHTnQYqKc3PqafvT5ibA/640?wxtype=jpeg&amp;wxfrom=0"/><p>昨天，一篇名为 OmniVTON 的论文在技术圈引起了广泛关注。该研究提出了**首个无需训练的通用虚拟试穿（VTON）框架，巧妙地解耦了服装和姿态的约束，成功统一了“棚拍”（in-shop）和“街拍”</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631054&amp;idx=1&amp;sn=3ec60d69945c929cec952f558ad3b30d&amp;chksm=97eec0c0e2bb358a6ac2d86c93939a440c864bccb2d1a0681d98bf41e99c8bbe0394a3200e9a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Jul 2025 01:18:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | SkySense V2，一个模型统一“看”懂多模态遥感数据，蚂蚁集团与武大联手打造遥感界“全能选手]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvfEpN0oytNUnvybDGyicERCiccWquuy874DOvmickzGuE3A3pOGd4aurRFUtuibqZlicNabRgjxGZzLsg/640?wxtype=jpeg&amp;wxfrom=0"/><p>从城市发展规划到全球气候变化监测，从精准农业到自然灾害应急响应，遥感技术正以前所未有的深度和广度融入我们的生活。近年来，能够处理光学、雷达、红外等多种数据源的多模态遥感基础模型（MM-RSFM）成为该</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631038&amp;idx=1&amp;sn=21d83047c54c9e30bd3a66c734ec197a&amp;chksm=9767ea3491b31150aeda41785eb046cf5104a7293d185966a349bd63fc1ea929914aa95ce32c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Jul 2025 23:13:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 VQualA FIQA 冠军方案：自训练与知识蒸馏打造高效人脸图像质量评估]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvfEpN0oytNUnvybDGyicERCjhNqeqVgnfGZ58DLrUFncvpvS86vxpsHnkorbgibqqPKFZhFq0Jy0tA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍的论文是《Efficient Face Image Quality Assessment via Self-training and Knowledge Distillation》，该研究针对</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631027&amp;idx=1&amp;sn=36b6b914be812025b006a5daf8a31f4f&amp;chksm=97388973ac3f20098d8a083da03bde6ee4d4a92e6e72b89d8b4c4d1b5dd179fbdda667ec59c2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Jul 2025 14:59:24 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 南洋理工等提出TokensGen，化繁为简，用“浓缩Token”解锁长视频生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvfEpN0oytNUnvybDGyicERCkOfTvmGEsOribk0tE4YTAKiasUmdCpmRHNVfZt8t1UKlyPF55dpWHw8Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍的论文是《TokensGen: Harnessing Condensed Tokens for Long Video Generation》，该研究为攻克AI视频生成领域的“圣杯”级难题——生</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247631018&amp;idx=1&amp;sn=672e77cf1a14581082209a0d9798a974&amp;chksm=97adeeb3abb32a247df09a99366cd3d220620d218a3f0ada010cc17a6fe5ebe77178075d4554&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Jul 2025 13:36:03 +0000</pubDate>
    </item>
  </channel>
</rss>