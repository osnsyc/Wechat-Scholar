<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[我爱计算机视觉]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[我爱计算机视觉公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_e07180c244d1.jpg</url>
      <title>gh_e07180c244d1</title>
    </image>
    <item>
      <title><![CDATA[CVPR25｜零训练成本！中科大创新扩散模型概念擦除方法，先验保护较SOTA提升 10 倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvlicicwib30dFSdF1hbMoAJiacTCqBWESccQPW9RWKPicd6u76o9WqNN53ylI1nTwOPUkKQqIlrmicERSQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美当前，AI 图像生成技术迅猛发展，各类图文生成模型让用户能凭借简单文字描述创作出精美的图像。然而，这也引发了诸多问题，比如有人借此剽窃艺术风格、丑化 IP 角色和名人，甚至</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628158&amp;idx=1&amp;sn=07d77772091f0d8c66cfef9fb1e72688&amp;chksm=97dcbe525216e8b537e7b7e85346a37f4929784f6f5515b7aa8a35443d5a25de9c3f2cac46d3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 02:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025放榜！杀疯了，本科生连中三篇]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvlicicwib30dFSdF1hbMoAJiacUWT1nnkgaXPFKtVpgXLBqkBCbmia59luycxkb0B0xtjCONBLgVBEbAQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>刚刚，CVPR 2025录用结果出炉！今年，共有13008份有效投稿并进入评审流程，其中2878篇被录用，最终录用率为22.1%。近两年来，CVPR录用结果逐年递减。相较于去年（11532），CVPR</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628141&amp;idx=1&amp;sn=11e5cc424d7d9a5c344fc6209ef816f3&amp;chksm=9739f813c4b70745edea1eb7db2a980ac733b95571865ac2d08457f0e6c5ea71f53dd20058dc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 07:17:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[10个超实用Deepseek指令，国内外研究现状有救了，大大节省时间！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvlicicwib30dFSdF1hbMoAJiactZzOPb7ibJykujz8jv3w4dice3zbeK5eZ3MCWHs8hQNeicjWsxiaOOdj2A/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近deepseek这么火，是因为它真的能实际的帮助到我们！！上周三晚上，听了sunny老师给我们分享的超实用的deepseek指令后，第一个想法就是：如果我读研的时候有这个就好了，可以节省超多时间！</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628130&amp;idx=1&amp;sn=c0eeb9b43b2c23289f93b970c6debc48&amp;chksm=977af7911c475a43014f61730a1dcfe73bb8d17a23e6133baf76f7e99661149d39f4d40ab3f9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 02:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[亚洲首个！无问芯穹获FPGA’25最佳论文奖，提出首个视频生成大模型推理IP，软硬协同大幅提升硬件算力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsRAFpyH88hNW8hhD8IvPcQjSLibViaw3hUiastx0Z0gPJjPpAMZeGxh2LToLWT1lSVzhRfjIMuUzicmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美国际可重构计算领域顶级会议——FPGA 2025在落幕之时传来消息，今年的最佳论文颁发给了无问芯穹和上交、清华共同提出的视频生成大模型推理IP工作FlightVGM，这是F</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628130&amp;idx=2&amp;sn=e56cfaf094ac7f9378afd6bbacc67ff5&amp;chksm=97085b22dd30981b7141711d22cf9f9ad684b6a4027f9c8546cd34c4268a1379c121cd3c2c92&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 02:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Long-VITA：突破百万Tokens限制！开源多模态大模型新标杆]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsRAFpyH88hNW8hhD8IvPcQ8wv5ucxUia9btpLlO64FTA1NGbVVkDxiciaIlu3w91vL7xZMgiavxOicuOg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美近期，多模态大模型（MLLMs）发展迅速，但开源模型在长上下文场景（如长视频或高分辨率图像）中仍显著落后于闭源模型。部分专注于长上下文场景的开源模型在短上下文场景（如短视频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628121&amp;idx=1&amp;sn=35b87a387e635dd8d67ee3c4efe5bc13&amp;chksm=971e64dd6a86a9b77569792b5beb35ec7deceb295753daf1558dd6bfc75462e9bf4ba8f0a983&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 10:01:50 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[顶尖AI学者亲授 | VLA大模型前沿课限时开放]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsRAFpyH88hNW8hhD8IvPcQc0pmCSrdtjU2jTscHPUoWzvW8kUzyWaAHcN8sNicqJho8B7AVrwBa3w/640?wxtype=jpeg&amp;wxfrom=0"/><p>课程重磅官宣顶尖AI学者陈启峰教授主讲3月5日&amp;3月12日，每周三19:00独家直播连续两期深度解析VLA大模型最前沿学术成果与产业实践、发展趋势主讲嘉宾介绍      陈启峰元戎启行客座教授香港科技</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628103&amp;idx=1&amp;sn=ea8b7507372e58af07df90eeb0da490d&amp;chksm=97597c9b5e00d2edc0a5c5aec56f14ca076a4033d109515658a65aa654eae1f2fbf7deb8dc9a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 知名视频分割挑战赛PVUW第四届比赛已启动！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsRAFpyH88hNW8hhD8IvPcQKpLibRlaeIgLsZxTzYbDaiacOCicvNArqVtWgsQ5f5IPOOu2lzpc4xlow/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美第四届真实世界下的像素级视频理解挑战赛（The 4th PVUW challenge）主页/Call for Paper：https://pvuw.github.io/赛道</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628103&amp;idx=2&amp;sn=399857a0361adda8d38de5529872238b&amp;chksm=9739069856acf4a846d4262dcce537354093ba0f0c2bd69d3069298c19aabbde558df3e71ac1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 MINIMA：首个通用多模态图像匹配架构（模型、数据已全部开源）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvN5iaudj0S2Yg0grIL6s5UzQKTBZDBnic7nYfqcEB3mcE27vExTeDm6m4iaeiaJ7DLdkxyXNgebjO5gA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美论文信息：论文链接：https://arxiv.org/abs/2412.19412代码链接：https://github.com/LSXI7/MINIMA在线demo：h</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627988&amp;idx=1&amp;sn=90b17ede0bc5e76eba46f4558ef2b1cc&amp;chksm=97339b29a940cd76f8b28369ad54f9a06814aa8389d4220582016335d04eb647f773c7203a90&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 13:02:51 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 | 小红书等给AI图像检测上难度！数据集均通过人类感知“图灵测试”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsCJV3HSzlesSNaTfbsLTBvu90h9XkbvB6icr1aoNqc6CFszeTZRqtVZusTYxwt8dZkMQzQYVFfzxw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美AI生成内容已深度渗透至生活的方方面面，从艺术创作到设计领域，再到信息传播与版权保护，其影响力无处不在。然而，随着生成模型技术的飞速发展，如何精准甄别AI生成图像成为业界与</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627967&amp;idx=1&amp;sn=89e864ff70ebc7144ba754d240698022&amp;chksm=9766fad25117084b6fe4986e8a82dedf5b0d6dfe4584502b643f5caee38960063e6d07882e5e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 05:31:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NTIRE 2025 | 首届跨域少样本目标检测挑战赛 (CD-FSOD) 正式启动！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsCJV3HSzlesSNaTfbsLTBvk9A1uBlHZhqQiafZRtJVzTsTOs6sDTia3f8cfI0I4lCTGPuHyiciaSJonw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美NTIRE（New Trends in Image Restoration and Enhancement）是近年来全球图像复原与增强领域最具影响力的竞赛之一，已连续多年在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627966&amp;idx=1&amp;sn=42910f1050f4140196bf4577979077e3&amp;chksm=976f8edbf6762370d2994bc72593b245c6d93b3b3fe937cd27d31f7eb9a211956bd209440ebc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 05:42:59 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯混元提出：多模态大模型推理评估新基准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsq6AEy1qsyEVblu28C6ibxXiba07cugjBsL9UB3a41mGxTJu59ic1Ld0apIhcyKOKqoOjOicFIImEBZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models，腾讯</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627966&amp;idx=2&amp;sn=62d4a46221ea2bd1378725aacb3e626d&amp;chksm=9718420e8dd87d181d59ff4153ee921097874fbfc9432c9b824d568ab697b4beaa8cadb418bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 05:42:59 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[小红书&amp;上交多模态大模型新基准，Gemini 1.5 Pro准确率仅48%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsCJV3HSzlesSNaTfbsLTBvicZplC2ehkP7L7ib40axHwFyzpSUVvJBCml7SScxVYwsicCoOxN8ehhbg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美多模态大模型理解真实世界的水平到底如何？有新基准来衡量了。就在最近，小红书和上海交通大学联合提出WorldSense，一个全新的基准测试，用来评估多模态大模型（MLLMs）</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627957&amp;idx=1&amp;sn=34afc689151636b0034b91e2af31b943&amp;chksm=97a25d2b1b09544e0915585f592db4004c06fd032e6926da1ccf2e376c6895de9961521f12cf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 07:52:31 +0000</pubDate>
    </item>
  </channel>
</rss>