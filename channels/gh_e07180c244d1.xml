<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[我爱计算机视觉]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[我爱计算机视觉公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_e07180c244d1.jpg</url>
      

      <title>gh_e07180c244d1</title>
      

    </image>
    



















    <item>
      <title><![CDATA[UIUC与阿里通义实验室推出新型多层级手机智能体 攻克复杂任务场景 可自我进化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvzibcDdxz54zBODxRryHmXXk5xMH2QYwVrIibkNn5oHE8HmHOgxssVsP41X5EYqJtgsCicjEjcnO44g/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美项目主页：https://x-plug.github.io/MobileAgent/论文地址：https://arxiv.org/abs/2501.11733在如今的智能手</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627551&amp;idx=1&amp;sn=60a6983aa8f1394927e8ddbea01f3d3b&amp;chksm=97b83e0240d96ef0c7b064d4f85dd63ef95e6005aea0448cc0c679691e6b80841e18367fc0e7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 05 Feb 2025 12:31:46 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[ICLR 2025 | Ross: 多模态大模型的 MAE 时刻？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsUEVF8t4PHEhyCtk0M48C09ia9vZH9CsYJ21zdAuUL7EXoGMdGovRn7LkaZfUibYPK3TbB3j6eIoLw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美今天介绍我们在多模态大模型领域的一篇原创工作Reconstructive Visual Instruction Tuning，目前 Ross 已被 ICLR 2025 接收</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627490&amp;idx=1&amp;sn=c50534c405eeb8a0567b76c6542d3ecd&amp;chksm=979785e2c076e3eef08aa7f8ee2ba73b968e003e12d83156d9777fef7751c98eb688597a9b86&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 26 Jan 2025 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[贾佳亚团队 x Adobe提出GenProp，物体追踪移除特效样样在行]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsUEVF8t4PHEhyCtk0M48C0HketMEmlicXee9zykHENJzLoyhdwQd82VOaRSfyAOMEPB0HVUp7h8eQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美Text-to-Video模型已展现出世界模拟器的潜力，这种潜力能革新传统视觉任务吗？近日，贾佳亚团队联手Adobe团队，用GenProp（Generative Video</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627489&amp;idx=1&amp;sn=f042e290380750e509c270a9cb9c7afe&amp;chksm=9729c2d89f5bc8fde24254b692f9182fe1e930afe1ca38c3cde0b3113ba6b98468ee5e352bb5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 25 Jan 2025 14:16:31 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NVIDIA 自动驾驶安全报告出炉：实现从视觉、AI 到软件栈的全方位结合与升级！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsUEVF8t4PHEhyCtk0M48C0hglxeGWrnibG0LicicibKsEH8CnyiaBskrIe45e9Pl7BJZouEwgAo3rVKPA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美在自动驾驶领域，复杂环境中的安全决策、不断增长的算力需求和验证流程优化等等环环相扣，如何在当前快节奏的商业环境下解决这些挑战，对于智驾方案的高效规模化落地来说非常重要。NV</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627442&amp;idx=1&amp;sn=02435cb7d20d8835b9e89ddad17f794b&amp;chksm=9779656f5fc0772b7b666004e534069f751e96c1f12b64ee5afdc8aaa6385bba068e81f249e4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 24 Jan 2025 04:31:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AAAI 2025 | 上海交通大学提出 SiTo，基于相似性的选择来减少剪枝误差，免训高效，硬件友好]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsUEVF8t4PHEhyCtk0M48C0MYxttuqIibsvF42Tf9a4F5FetXkljCtHnIiciam1wh7a1ZicaNhKzn9j2g/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享 AAAI-2025 论文SiTo: Training-Free and Hardware-Friendly Acceleration for Diffusion </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627442&amp;idx=2&amp;sn=c7d80954fb2eba90f5267ff92937b06c&amp;chksm=97b15fdbdf0dacb274657bd353abea9eee0870f75b1abae1b5621200a2f9225048430cc37632&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 24 Jan 2025 04:31:24 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ASP-DAC’25最佳论文奖新鲜出炉！受传统视频处理流程启发，减少注意力计算量，突破VDiT计算瓶颈]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtEialNSEKdsAj8A1V7MiaEe4ZJpHkSqOQN4AYEHJGcvLL47EkCz9AXc3CRlzicrVycho42zZjbY983w/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美2025年1月23日，集成电路设计自动化领域的国际传统顶级会议之一的ASP-DAC（Asia and South Pacific Design Automation Con</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627421&amp;idx=1&amp;sn=5992f0faae68ef5bdea2ed5953b87447&amp;chksm=97b86dfa29921b35962de9300684641599e04d6e4637b714c671b4a876ab9ebcae29990841a9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 23 Jan 2025 11:32:41 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[基于解耦网络的彩色自定义弱光图像增强]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvLN8RYRzuJ9Gk6EEyOyKq8RIJZzZUibSZ3z2RhVqsDUmffTgoobI7vcZzHfnokEe4H72PqpNyJKzw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文Colorization-Inspired Customized Low-Light Image Enhancement by a Decoupled Netw</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627381&amp;idx=1&amp;sn=d37b9da77878b246c55888b80cb6659b&amp;chksm=9715f1119b07311b0d11089a32775ea029fbdb481a80ef8d784d60edfbbdff92c6c2b5ac553b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 22 Jan 2025 09:45:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[通义实验室提出WebWalker: 对RAG的二维升级]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTubVWuvljib7DIgWLP3h8YYSUGS0w9gzxaEPedgDNLW8PBjLVEqoTIZmvGHy5yG4RjAzS7ibdqBvBaQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美检索增强生成（RAG）在开放域问答任务中表现出色。然而，传统搜索引擎可能会检索浅层内容，限制了大型语言模型（LLM）处理复杂、多层次信息的能力。为了解决这个问题，我们引入了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627332&amp;idx=1&amp;sn=f142c31c1cc9e1dd17380ea622f2bc1b&amp;chksm=979388a5e5f8f3aa87ef2bc9dca9b99882c1b9e9fa11445c8ac656557c73f2e012758c4bc0a1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 21 Jan 2025 04:17:25 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[视觉定位任务新入门必读！跟进最新进展，视觉定位审稿人必读论文！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTthLjjRPb3S2mDBK2xB4PMuzy3jOnaQMTMjIOmoys6sWtU2AJR7GIeqlrwkAdHib0tibYicROznmI8TQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美导读：27页综述，354 篇参考文献！史上最详尽的视觉定位综述，内容覆盖过去十年的视觉定位发展总结，尤其对最近5年的视觉定位论文系统性回顾，内容既涵盖传统基于检测器的视觉定</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627302&amp;idx=1&amp;sn=f705f9e55ec9e37d35bac218861850e0&amp;chksm=9719cec1ef43bc9bd59076262bae8a9bb69440216e1aa8129e175f011f76d0bea0e3e259d752&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 20 Jan 2025 09:43:43 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AAAI 2025｜如何高效桥接视觉和语言，字节&amp;中大提出全新多模态大模型连接器ParGo]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYo5kDcfUhYthALWiayfAa3hgdFZgXscdCbZsJVpZZf28SDiaqh2lcibic6xLsQQDrVFGYko3b3oqicPw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美在多模态大语言模型（MLLMs）的发展中，视觉-语言连接器作为将视觉特征映射到LLM语言空间的关键组件，起到了桥梁作用。因此，它几乎成为了所有多模态大语言模型中不可或缺的结</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627243&amp;idx=1&amp;sn=446bc1b235ec8cdb59756c37eb5ba6e2&amp;chksm=9757355a54aacac1cf02d56a6b491a6bb89cf7e0bf5c64c3d9094a5ff53a24f72fa738fe1d3a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 17 Jan 2025 14:20:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[免费下载|火爆AI圈的深度学习 “四大名著”]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYo5kDcfUhYthALWiayfAa3VYWdtPYq0U9R3OlOhHLd7BqeuX3XYdAiawAvWCL8fILegnLwZncP91Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍人工智能的四大名著，今天来给大家介绍一下 √ 西瓜书《机器学习》周志华。讲述了机器学习核心数学理论知识和算法。适合作为学校的教材或者中阶读者自学使用，对于没有基础的初学者入门来说还是有点难度的，可</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627228&amp;idx=1&amp;sn=0e84fe2b22f262c2782035459c498604&amp;chksm=973776b65400c9b4095326b649a417c76b8a398b7a14ff5ba006ae435482d6fcf0f254727be9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 16 Jan 2025 04:27:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[同时提升摄像机控制效率、视频质量，可控视频生成架构AC3D来了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtgSiaaopurybeQOIBL2ic4MZPD9wRMx0DTtKvNEcyK9CjqxMjSUVibcjZec3SBZZNAKNkW6umFKX7bA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文转自机器之心。可控的视频生成需要实现对摄像机的精确控制。然而，控制视频生成模型的摄像机运动（camera control）总是不可避免地伴随着视频质量的下降。近期，来自</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627228&amp;idx=2&amp;sn=93d7818c1825085524d688f27aeeaca5&amp;chksm=97b5ae33e83bdccb88883398e4baff16a1028227b93cb79f5680510884753aaa7b56c67d9c0e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 16 Jan 2025 04:27:42 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MME-Finance 破圈：同花顺联合顶尖高校打造中英双语金融多模态基准]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTueKG3gcbUfZqia1gywrcyes8lJB4Fuk97qic7JwDGhJyQsz1eWQL3TtA5mXwZ6FdozzgQ6bpvibR7Uw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and R</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627199&amp;idx=1&amp;sn=70bc9b18c64729d299b2437701503ba4&amp;chksm=975c0ce84f33c7941301e68c566902183aacec083bbe95a3c76da299113a337c5a659d288535&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 Jan 2025 03:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[独自一人，怒发顶会]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv0fgt98hCfaibtmHLNKeRn0oT4ibJ9lz2ib3QSnz7sUaBDqP8wYP6VJj6u6tCN7K6ErHL0Sfd3QRUNg/640?wxtype=jpeg&amp;wxfrom=0"/><p>万物皆卷的时代，升学、就业的竞争越来越激烈，想要保研、申博、进大厂，没有高质量论文在手就相当于“裸奔”！尤其是这个人人惶恐又内卷的时代，想要抓住点什么来增强安全感。有一份拿得出手的成绩——发论文的数量</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627198&amp;idx=1&amp;sn=f805fd140d98a877c366574f618fd862&amp;chksm=9782474c8b88f169bd87b088efc9bfa34437fd7a0f7cea669c161533a2ccec098a7f833ee283&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 04:25:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[博后 | 博士 | 硕士 | 访问学生 | 阿联酋大学IEEE Fellow团队招募，人脸和人体的图像和视频生成方向]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv0fgt98hCfaibtmHLNKeRn010TXiasxpicrJ7bABUiajziawj2KoKxibWHRvGI6LwbXDUHQjCdumb0Z3Lw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，获取更多AI领域发展机会阿联酋大学IEEE Fellow团队招收博士后、博士生、硕士生和访问学生导师介绍廖胜才博士是IEEE Fellow和IAPR Fellow，主要从事计算机视觉研究，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627198&amp;idx=2&amp;sn=9170ced2653ebb984059f3e5cbe88cbf&amp;chksm=97eeb1307a28f3f09fb67ff3032c09ca3be944005bfeaac02fcbdd4f6b92f2cf47839aaac01c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 04:25:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GAN归来：模型大幅简化，训练更稳定，逆袭扩散模型，AI社区疯传]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv0fgt98hCfaibtmHLNKeRn0A6IZRibXeT4HAVlnicumwOFxyPcxYjPnygFiajsAO2Gy0JibNAODibaKmXw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文转自机器之心。GANs are so back!?2025 年了，GAN 能否击败扩散模型？答案是 Yes！本周五，AI 社区开始讨论一种全新极简主义 GAN（生成对抗</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627198&amp;idx=3&amp;sn=41ef4ce49a7128d3c300e019f0140d20&amp;chksm=9746b5bee9db1fac3927fe969ccd735ce0a8fef63856bb331b4c2026bc8fd58c01fae61021af&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 04:25:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文绘千里江山！1000万图文数据集Git-10M和生成式基础模型Text2Earth]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTueKG3gcbUfZqia1gywrcyesOaRibrdUtjwp9OSNmy5rZgsgsY2ic5zSqc2UVSogCdibjZMcbnRY6wgqg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文来自遥感与深度学习。分享论文Text2Earth: Unlocking Text-driven Remote Sensing Image Generation with</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627150&amp;idx=1&amp;sn=79f445560426b023a749f53bae2eccd0&amp;chksm=97015cfd5daa718057013f50dd95d6ad5e0a481bd236d95a0fa14e4e93d6ec67a8774b2df526&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 07:05:33 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[VITA-1.5: 迈向GPT-4o级实时视频-语音交互]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtiabwEP5j03iaHOEErowCqvlksnAx2PvwZ7UG5Vhtjltib0RwiaPJVk3AONH8zbCutjQbELZQAT2SmlA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美近年来，多模态大语言模型（MLLMs）主要聚焦在视觉和文本模态的融合上，对语音的关注较少。然而，语音在多模态对话系统中扮演着至关重要的角色。由于视觉和语音模态之间的差异，同</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627101&amp;idx=1&amp;sn=9db81a2cfddb5627182ee3ebeefa7cb0&amp;chksm=97f3f1c6ce25deb376a000c166ef2f002a660093680a7ee38dcb4ab5f0e9e9aad6c781856373&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 14:30:36 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[征稿 | CVPR 2025 Workshop 第一届像素级视觉基础模型研讨会征稿启动]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuUp1ibibQX2ONJmiaSQMNEEib99YhsicWsoB4xvGufHy99qNl8XQSyBgLFHaA8c4ibaTKTewIBuS8WXXZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美近年来，基础模型（Foundation Models）在自然语言处理领域取得了显著进展，其中以 GPT 系列为代表。这些模型规模庞大，通过自监督学习或视觉语言建模训练于多样</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627101&amp;idx=2&amp;sn=86df240119b776bb36190cee0e924b48&amp;chksm=9796cb568f615f4e43dbc326b439542a335c236075b19a5283cb027f338ecdf8b46d49fc124e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 14:30:36 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
