<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[我爱计算机视觉]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[我爱计算机视觉公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM6aYkwkiboia6lA9D7ANy49WBe9icxn5NQqJjvn4Pyntzvfw/132</url>
      <title>gh_e07180c244d1</title>
    </image>
    <item>
      <title><![CDATA[NeurIPS 2025 | Latent Harmony：潜空间和谐共生，实现UHD图像修复新SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv9so0J5tAxMejTVmE0zXQ3kjIia5p9ib2dRl6ibncuM0cLSFClbEiaWxv4nDa5F5gSRKpLPd1xz0af3g/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天CV君想和大家聊一篇非常有意思的新工作，它来自中国科学技术大学和上海人工智能实验室，并被 NeurIPS 2025 接收。这项研究聚焦于超高清（UHD）图像修复，提出了一个名为 Laten</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640508&amp;idx=1&amp;sn=3dacde954621ad9d05bf44aa978ef92c&amp;chksm=976dbd7335fb8e8b6c95376b4b2632cdb82c561f4ebe44c584b4eb0790b6d20ae0ee50e501e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | NTN-Diff：一石二鸟，利用空文本与频率感知破解图像修复难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvfxUxmBxdrd76bga45zN0PjSCpuibg1iabVCZo1TJicc1ic1YIvF9Y9XKpSRuE2HC295u8r351orVZ8A/300?wxtype=jpeg&amp;wxfrom=0"/><p>在文本引导的图像修复（Text-Guided Image Inpainting）领域，一个老大难问题始终困扰着研究者们：如何在根据文本描述填充缺失区域的同时，完美保留图像中未被遮挡的部分？很多时候，模</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640508&amp;idx=2&amp;sn=82febf7dd7a41eb6d45e09a1d49cebbe&amp;chksm=97945ce9883274478c098776ac6b2988491686bd1f17b89895875577207cd72ff1c478334954&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IROS 2025 Oral | RAG-6Dpose：三大创新模块，利用 CAD 作为知识库进行检索增强 6D 姿态估计]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv9so0J5tAxMejTVmE0zXQ3GZCJody1RAaHCmUKAQW8uOhM9VObicRkc8IDq6qqrKGc4k8rWnwia7xQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>准确的 6D 姿态估计对机器人操作至关重要，可实现像抓取这样任务中精确的物体定位。单目 6D 姿态估计旨在从一张 RGB 图像中准确预测物体的三维位置和朝向，这对机器人抓取与交互等任务非常关键。然而，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640313&amp;idx=1&amp;sn=c519aa8196af4d49206fa798d035556f&amp;chksm=97918e585542ab3945026d0af22c75e079f756c272c52db215ed5c0b5eb468dd7ec88c415b45&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 13:07:17 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IROS 2025 | 速度飙升24倍！巴黎萨克雷大学等提出HARP-NeXt：实时3D激光雷达分割新标杆]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvBzrQOREVzKT4UfnMW9TcYRAYo3o3gCyqGviag1YKN6F0ShAm68DHWQX7kw1WqompahKb4Vc2Ik2g/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是CV君。今天想和大家聊聊3D激光雷达（LiDAR）语义分割这个领域。对于自动驾驶和移动机器人来说，能实时、准确地理解周围环境至关重要，而LiDAR语义分割就是实现这一目标的关键技术。然而，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640313&amp;idx=2&amp;sn=319b1068b23b5356ac62edd9351f29b2&amp;chksm=97c210fccb6b11764e5b2224370236a42767527120138dfe92cadc28f8a6693337f3550f64c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 13:07:17 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[U-Bench：U-Net十年“大乱斗”终结者，100个变体、28个数据集的终极对决]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvfxUxmBxdrd76bga45zN0PEgmXkx2ib7t1TKtE0kepoBNl2fzaHIdhzUtzFGqIkb7sickMJcjvaPGw/640?wxtype=jpeg&amp;wxfrom=0"/><p>自2015年诞生以来，U-Net无疑是医学图像分割领域的“王者”，其优雅的U形结构和出色的性能，催生了数以千计的“变体”模型。然而，这个繁荣的生态也带来了一个问题：新模型层出不穷，但我们真的知道哪个更</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639919&amp;idx=1&amp;sn=fd4f39a9c066c69a8a6df5434ddf7441&amp;chksm=9717827550435ad86b4303aec44e5135361b1b2e9f164772c85bcaf78363f2f655e9a553d720&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 14:50:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[东京大学、牛津大学等联合发布VLA万字综述：机器人迈向通用智能的全栈指南]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvBzrQOREVzKT4UfnMW9TcYWx9R79CiaFc5atUIdzk4RJx7hmghuOn18Q3Nxd7icVU5kEFetrTtjkzA/300?wxtype=jpeg&amp;wxfrom=0"/><p>当大语言模型（LLM）和视觉语言模型（VLM）的能力不断溢出到机器人领域，一个激动人心的新方向——视觉-语言-动作（Vision-Language-Action, VLA）模型，正成为通往通用机器人之</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639919&amp;idx=2&amp;sn=df224c69de268ba102ff25427433177e&amp;chksm=977b2bb4d5371e0f0e9e70170d62cb719395a10560b439db4226fcec62f8361cfe70c657d63f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 14:50:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Diffusion²来袭：威斯康星大学&amp;华盛顿大学等提出双扩散模型，“回溯历史-预测未来”，破解自动驾驶“鬼探头”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtmWEI9nicjxnJ8zanDyuJwHdibhsxNxXaxnB7MokNcibhIE0V1mcRo6RKlzXYkc5eAJCo0r17icnicx1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>朋友们，今天我们来聊一篇非常有意思的论文，来自威斯康星大学麦迪逊分校、华盛顿大学和同济大学的研究者们，题为《Diffusion²: Dual Diffusion Model with Uncertai</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639615&amp;idx=1&amp;sn=f3ee6bc7c6c291c7f628ecd6f62f1b00&amp;chksm=977eb6ea4aafd9b2ca14efac20f310480c24d7831987b8a4ef3dddfc4b5c152e833ce8dd820b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 14:46:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[北大等提出TrackVLA++：赋予机器人推理与记忆，跟踪成功率飙升12%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvBzrQOREVzKT4UfnMW9TcYw2OW72DlER4zICD1QCpoBMv3VL0ceHb7ynQVDCIgdqe3GEBetq1Lug/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，具身智能领域又迎来一个非常有意思的工作。我们知道，让机器人像人一样在复杂的环境里持续跟住一个移动目标，其实非常困难，尤其是在目标被遮挡或者周围有长得很像的“路人甲”干扰时，机器人一不留神可能就“</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639615&amp;idx=2&amp;sn=91b87ca4a7ae75111f0888ae1c9957c2&amp;chksm=97c1c081e74cfef40141f3155f5012517489ffeab79b3b7eac52b8bade073f62d3d19b4b3d06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 14:46:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IROS 2025 | Waymo与谷歌DeepMind联手提出Drive&amp;Gen：用生成视频评估自动驾驶，虚拟测试更逼真]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtmWEI9nicjxnJ8zanDyuJwHDIPswGkuicpYYOiaNnlq1u1KAtIuwVfFwLNhEibPVeYDmlGTiapflXPNYw/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，自动驾驶领域迎来了两位“新玩家”：端到端（End-to-End, E2E）驾驶模型和视频生成模型。E2E模型试图用一个“大模型”直接从传感器输入预测驾驶操作，大大简化了传统复杂的模块化系统；而视</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639304&amp;idx=1&amp;sn=550ba355d4167df876744480c285f2f9&amp;chksm=979d4aad72ea38a473d2873e06feb22b8f5b584134c8d30f652a82ec9dd551c49172298fbb42&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 08 Oct 2025 12:09:23 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别深度传感器！慕尼黑工业大学提出DropD-SLAM：仅用单目RGB即可实现RGB-D级的SLAM精度]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtmWEI9nicjxnJ8zanDyuJwHgcKHOMPuNl54cWFLfc9e0IicWkatEwVqUTBzKhAhTicuhWXDPaB2Ocsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天，我们来聊一篇非常有意思的SLAM领域新工作，来自慕尼黑工业大学和3Dwe.ai的研究者们。他们提出了一个名为DropD-SLAM的系统，这个名字很直白，意思就是“扔掉深度（Dropping th</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639304&amp;idx=2&amp;sn=78ab7f916ec4433d758a363c4431eef2&amp;chksm=9735940e075bb713cb1faca2acbf0025537ee51c98453b4d8b55dcc8991aefa0c8c9f89c0f63&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 08 Oct 2025 12:09:23 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | 电子科大等提出EEMFlow：从事件相机学习高效Meshflow与光流，速度提升30倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsTeSh4RLoXLA8MMC9VPRNzqiad4NpfYTp2KkicXcSAo2WicLUlu7hydx3FLwXuEnpuDnSiceRfoOtTDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天想和大家聊一篇非常有意思的新工作，来自电子科技大学、香港科技大学和西南交通大学的研究者们，他们关注的是一个越来越火的领域——事件相机（Event Camera）。这篇被 TPAMI 202</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639120&amp;idx=1&amp;sn=75539d0808a7384c22a05b01ebcaf2bb&amp;chksm=975c5f1a84e6b583f424ade2ecac593d58b533a0619dbe10b63aa48e866c40543874bae5dea5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 07 Oct 2025 15:31:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[MICCAI 2025 | 莱斯大学提出MetaSeg：参数减少90%，元学习隐式网络重塑医学图像分割]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsTeSh4RLoXLA8MMC9VPRNzPgLv2qG6MCFvnIjQZibGfbeQ8njkzDK1tIS3za0xSszaoQicIV8IyVrQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，来自莱斯大学的研究者们在医学图像分割领域投下了一颗“重磅炸弹”。他们提出了一种名为 MetaSeg 的新框架，巧妙地将元学习（Meta-learning）和隐式神经表示（Implicit Neu</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639120&amp;idx=2&amp;sn=893a4e1f9ab2fe7893e98bd324f0c598&amp;chksm=974b3b801bfcc4e3a2b65beaa90cb79305f56da2cfe19cd283755c10ff218c32488d849444c6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 07 Oct 2025 15:31:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 慕尼黑工业大学提出SIM(3)等变网络：让3D形状补全告别“姿态偏见”，实现跨域泛化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsWzQRzR8ECqLgEf8Jbe1jOFpwy6j4OcCYQuoZcxSQApyqr36UsRgV0kyeXnNh4CicgBfM1wbkfSJw/640?wxtype=jpeg&amp;wxfrom=0"/><p>聊一篇关于3D形状补全的顶会论文。我们先简单聊聊为什么需要3D形状补全。在现实世界中，我们通过激光雷达（LiDAR）、深度相机等设备获取的3D数据几乎总是残缺不全的。这可能是因为物体被遮挡、传感器视角</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638848&amp;idx=1&amp;sn=8ed516b291a968b84634cc377d303bea&amp;chksm=97f750c087556e5fd03b962e8d621e5bbe37164a4be9fee4011e89b3d8d47c291e5432630920&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 06 Oct 2025 12:47:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 高通提出GCL：无需额外数据，通用多模态检索迎来“一统江湖”新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsWzQRzR8ECqLgEf8Jbe1jOOxEqdcrtgb23vZQD3LFt9E8DfAEhFfbibqPxnycvcPGvZEl0WNgvCEg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是CV君。今天想和大家聊一篇非常实用的论文，它来自高通AI研究院，并已被NeurIPS 2025接收。这篇工作聚焦于一个很现实的问题：我们如何让机器在面对图、文、甚至图文混合的内容时，都能“</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638848&amp;idx=2&amp;sn=79950ef2e3a274622482b51856321171&amp;chksm=97356856157b0d08df03b8c9539b9a78af241bdb96f9b26ce93d8fa29b4c63e4a2a0666746fd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 06 Oct 2025 12:47:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[宾大提出F³：事件相机迎来“预测性”表征新范式，光流、分割、深度全SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtB0ib5icMePhR4iblOq43vhSj3XKH1ia8W8esTYPSqCgaC0x7zIKNQryRkDgeV0ChGRnlQ9wE1RLYqcg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天想和大家聊聊一种非常酷的传感器——事件相机（Event Camera），以及一篇来自宾夕法尼亚大学的最新研究，它为处理这类独特数据提出了一种极具启发性的新方法。事件相机和我们手机、相机里常见的传统</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638707&amp;idx=1&amp;sn=a5b88345beb4a0643f1c73764e87fffe&amp;chksm=97fde72e866df8f2d8cf3e221de24091ba5c9588e36b45781e2c41dea803f5a4cf6a6775623d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 05 Oct 2025 22:41:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南理工提出FMC-DETR：巧用“频率解耦”，航拍小目标检测精度飙升8.2% AP50]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtQJO9jUpDtyicfwaZshibtGvwshxJZFwyGB4vVFkLrGuE0eYkLEZ5FwUWXm2csiaqpccicjygeP4zyrw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在广阔的航拍图像中，要准确地找出那些只占了几个像素点的微小目标，比如远处的车辆、行人，无疑是一项极具挑战性的任务。这就像是在一幅巨大的画卷中“找茬”，不仅考验眼力，更考验对整个画面的理解能力。这项技术</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638660&amp;idx=1&amp;sn=ee5206c4ed4f83f1b28d3ed5a06b865d&amp;chksm=97bc5fedb9a4211c5ef60413bf695e3d3b8b2245513a5f910189b8f43a1655219b27d9d40fc9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 04 Oct 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | RAD：基于大规模3DGS孪生数字世界的端到端强化学习训练策略]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtQJO9jUpDtyicfwaZshibtGvSjygyicBPlJfAzIXYVBtWPxibcaMRFvVOElibeY8lJLS4S0bIEjXpiaPjw/640?wxtype=jpeg&amp;wxfrom=0"/><p>一、论文基本信息类别详情论文标题RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638621&amp;idx=1&amp;sn=53094d3e8f3baf73ea1d713c8f0c996d&amp;chksm=972e1021d09a24c30fb6c2410ea42525f189dec2ba4ef7df80b39931592d5cb5863c467af469&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 03 Oct 2025 12:41:49 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[武大新作MASt3R-Fusion：融合IMU与GNSS，为新一代视觉SLAM注入“多感官”智慧]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8ouFWiaGSZBaLpmDzz0yQPEInQ2lcoiatwWr2ayLsS6qdiayiazrsfiaTuwA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天CV君想和大家聊一个机器人和自动驾驶领域的核心技术——SLAM。简单来说，SLAM（即时定位与地图构建）就是要解决一个根本问题：一个机器人在未知环境中，如何知道“我在哪？”以及“周围长啥样</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638597&amp;idx=1&amp;sn=9d2668a10edb9ec779f97d7a0c992731&amp;chksm=97221ac64e4c07357ef3cd0db7207f32615c6b1fe38e08d87655c3e52ab131ba2eb0fb6b3104&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 02 Oct 2025 13:21:40 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[中科大、清华、快手等发布OpenGPT-4o-Image：为多模态AI打造的“超级燃料”，图像编辑性能提升18%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBgRTg3KmUVicQLS2RiaTlfkxvkeSLBrNDRkbuJIN9dsh8dadban7TNYYg/300?wxtype=jpeg&amp;wxfrom=0"/><p>如今，我们都对GPT-4o这类强大的多模态模型的威力惊叹不已，它们能看、能听、能说，还能生成和编辑图片。但一个灵魂拷问随之而来：要让这些模型变得更强，下一个突破口在哪里？答案可能出乎很多人的意料——</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638597&amp;idx=2&amp;sn=74ca0b987665c0e63e2a0e4f6fa8b92d&amp;chksm=9796344e1ac9055dfd25878676b863bf6bf3e94c4c6aa7902ccc5b2b7a4579e70afac547ddc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 02 Oct 2025 13:21:40 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工联合商汤提出Visual Jigsaw：像玩拼图一样，显著提升多模态大模型的视觉理解力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDB9LvkFxyVM30CmqicXwODg5vh6zO6dQFpypTsdpLV5XtQg5ibHm5aYIDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，多模态大语言模型（MLLM）的发展日新月异，但大家有没有发现，很多模型似乎更偏爱处理文字，而在“看图说话”的“看”这个环节，总感觉还差那么点意思。它们或许能识别出图像里的物体，但对于更精细的视觉</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638569&amp;idx=1&amp;sn=b54044764004f56e5d49e5a90ab89ab6&amp;chksm=97332836b25f56abffe9fe8b50b9f347d407f2641c815bd4ce86dc33909a0545582a255451f2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 14:13:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[天津大学联合腾讯提出Wan-Alpha：一键生成高质量透明视频，发丝级抠图不再是梦]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBibaCsGibCJlhicfEYXkRgNNIOwjkfz0h1e5XVBViakhoAoGEdBC4yFsqLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>对于视频创作者和设计师来说，获取带透明背景的视频素材（也就是RGBA视频）一直是个头疼的问题。无论是繁琐的手动抠图，还是效果不尽人意的自动工具，都耗费了大量时间和精力。随着AI视频生成技术的飞速发展，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638569&amp;idx=2&amp;sn=5d6ea97371bbd1a523b6fe308c425277&amp;chksm=97018df3d0a7403c6884598684fdf5d5fb637827bbbdf1b029cc16c0ef39048eaed5fb6bcf9b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 14:13:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 清华大学与华为等提出全新正则化方法，破解稀疏视图3DGS“协同适应”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBufibxKqprqSfLsGepluFSQvYxibUgicT18hUNR14POgFfIQVAmdKC6TdQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年，3D高斯溅射（3D Gaussian Splatting, 3DGS）技术因其出色的渲染质量和实时性能，在三维重建领域掀起了一股热潮。然而，这项技术在密集视图下表现优异，一旦训练数据变得稀疏（即</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638453&amp;idx=1&amp;sn=526fd0a7a4c6fa9a41f77a9bca5f7d9e&amp;chksm=97227d6c01511fd5dc75ab8e807a6455d919599271151572c010d3ca5ad9ef379077f7c7a999&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 16:04:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DeFacto：用强化学习治愈AI幻觉，让多模态模型“有据可查”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTttDVCqQ9gFaBE2oxXtrPErItXvjagPrYXTJ6zG0dGZ9dOdzicOfAe8NMMc7FQQI4NplPRXZV5VSWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：DeFacto: Counterfactual Thinking with Images for Enforcing Evidence-Grounded and Faithful Reaso</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638453&amp;idx=2&amp;sn=1d3171800ea06cf16cc83a1970a4cfb5&amp;chksm=978f2c79bd5a9543eb8cee832aa6eeffd0e65a381fc5b30d59b9572ee0b780194eb7f6062c4c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 16:04:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[YOLO26首份学界评论：端到端无NMS，目标成为边缘设备实时目标检测新标杆]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBCUAQMymGbNmUUzia9ju037B4WI501WdweD06MquW2P5bibKufXwzNHzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Ranjan Sapkota, Rahul Harsha Cheppally, Ajay Sharda, Manoj Karkee机构：康奈尔大学、堪萨斯州立大学论文地址：https://arx</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638453&amp;idx=3&amp;sn=41bf331d478908c376f3e5d47b4b9a2e&amp;chksm=97731a6c9fadf3b9c940633b324581f7532738d9bb59224ba98bb88979433849e63b8120f0e1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 16:04:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | Seg4Diff：无需分割头，揭示并放大扩散Transformer中的涌现分割能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8WZDXdYhkxWtzAtXCEDVtrOqE3gbOam6yPfzr1Ud23xhDJ8j2yicxjJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自韩国科学技术院（KAIST）、高丽大学和苏黎世联邦理工学院等机构的研究者们，共同发表了一篇题为 「Seg4Diff: Unveiling Open-Vocabulary Segmentation</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638378&amp;idx=1&amp;sn=b0575c3fc7c477f08574970aa7b50f2c&amp;chksm=97dbb6d3d7a38d13dad379f456a5fe39ce104681e0ef40decb4bcc65e01c0ef92b33d712beab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 12:11:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | UniPixel：首个统一对象指代与分割的像素级推理框架，让大模型看懂每一个像素]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8L4aVbyibeA6DTujfVHJBIZYB1moB9Tsjz9pV8mNMo71icU9vKEOrAqMw/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大型多模态模型（LMM）在作为通用多模态助手方面取得了巨大成功，尤其是在宏观的图像和视频语言理解上。然而，这些模型往往“观其大略”，对于深入到像素级别的细粒度理解能力却关注较少。为了弥补这一差</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638378&amp;idx=2&amp;sn=2d357f26972dbc498d99b5357da70e4c&amp;chksm=97c3e1edc32aab8f66b57ad73777aa5a83006fb77af28e1212e6b77d06490b6076b5a4481a5e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 12:11:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 北大等提出C²PPrompt：解耦类内与类间知识，破解联邦持续学习“双重遗忘”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8aKPBbxXmbaD1gesQk8JMg6kw6QKq3eKBv3lib7BEJlpXwELfhYyaKZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天想跟大家聊一篇来自北京大学、中国科学院大学和内蒙古工业大学的最新研究成果，这篇论文已经被 NeurIPS 2025 接收。想象一下，我们有很多智能设备（比如手机），它们各自在本地学习新知识，同时又</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638246&amp;idx=1&amp;sn=2e7a435ad3e62177ac5405b4583b83b2&amp;chksm=97b7162c252fce5b0fd9d7ef0203150bab4ea5c71d1030ae23d5e4992ac18ca245709b83f8d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Sep 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[InterDigital开源CompressAI-Vision：为“AI看”的视频压缩，打造一个“通用跑分平台”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8CoN1WhLH6gxY4Ft1s7SPxDP3cAuxicKDKByhxRRMjHmuylroecpljNg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好！如今，从自动驾驶到安防监控，AI摄像头无处不在。一个随之而来的问题是：海量的视频数据，如果都原封不动地传到云端分析，带宽和成本谁顶得住？于是，一个新领域应运而生——面向机器的视频压缩（Vide</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638246&amp;idx=2&amp;sn=ef3bbdd1fb667da892d97e0feb5c0053&amp;chksm=97273a1f748ddb681fb287fe4f61db955e692aab1d6fcd419055aeb0126018b8c6c8037d6563&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Sep 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦等揭秘机器人“大脑”安全漏洞：一张图就能让它“宕机”，攻击成功率76.2%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8QxzSgoBliadjOxGAc4tlCVLn4q7VO8mm5iaL6FIIKDpGIBM1L4YIEsJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天，来聊一个让人细思极恐的话题：当机器人的“数字大脑”被一张图片“冻结”，会发生什么？来自复旦大学、上海人工智能实验室和Sea AI Lab的研究者们，最近就揭示了这样一个严重的安全漏洞。他们提出了</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638237&amp;idx=1&amp;sn=233708a1dd10fe31d65c7b62eb5dd46c&amp;chksm=9726168b71f46e2bd72219a9342a133d21a1978fbc17206c7eeb42fed0885d8a68c2b14ca7eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 27 Sep 2025 11:14:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DASFAA 2025 | 湖大等提出SCRA-VQA：给LLM一份“精装修”的图像描述，无需训练提升VQA性能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8kR5VObDnvbvRNWJPicSiaIl9oqpNJOB448uqFwDdbwR401kHKGicicia3mg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好！如今，大语言模型（LLM）已经成了AI领域的“万能钥匙”，研究者们都想用它来解决各种任务，其中就包括视觉问答（VQA）。一个很自然的想法是：能不能直接“冻结”一个强大的LLM，不重新训练它，只</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638237&amp;idx=2&amp;sn=d22ffff7def78153a8f16c7d12f09a40&amp;chksm=97291f27e0b09f723311f65966bb74bc7a8d431bfe0e76b10979f901c682a45865354e35a8b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 27 Sep 2025 11:14:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[斯坦福推出VisualMimic：让机器人“眼观六路”，零样本完成复杂任务]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt7q7P0SJ2ogSq0RpXaS4wic6zicSO90ibB0NClibZwfcbEMoiaIw0E5LoyePYROCDHwvCUibBmnoXrO5tw/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，机器人领域的一项新进展吸引了我的注意。来自斯坦福大学研究者们，带来了一个名为 VisualMimic 的全新框架，让机器人只通过视觉模仿，就能完成一系列复杂的移动和操作任务。想象一下，一个机器人</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637958&amp;idx=1&amp;sn=7b107313e482e95c686389341f4968f5&amp;chksm=971cc97d99791050cbd1df03938c76041c88a5bc1f050f8d6127e40641be00958c3778c0706e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Sep 2025 11:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大发布RS3DBench：让遥感AI看懂3D世界，首个像素级对齐的大规模基准来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt7q7P0SJ2ogSq0RpXaS4wic0icQ3a93UqWicXnEkKLZxTEQZEiaE5G8hK9ZwjCSeiaIkziaujpYSyRA6pw/300?wxtype=jpeg&amp;wxfrom=0"/><p>分享一个来自浙江大学和杭州城市学院的硬核工作，它为遥感（Remote Sensing）领域的AI研究，补上了一块至关重要的拼图——真正的3D空间感知能力。我们都知道，AI在解读卫星图、航拍图这些遥感影</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637958&amp;idx=2&amp;sn=9bf5d36f8370196ada8c6732cd3ffa26&amp;chksm=97ea37a2cff4148d220e1acf8984605431614b50e3ed108d646328cd755beb0cf3be323e4f3b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Sep 2025 11:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[OCRBench v2 25年9月最新榜单发布！揭示多模态大模型文档智能真实水平]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd2kiayZvjkHY5IsW7lVgfBQADZEJM5KiclSZdTCzo0lHhAibD7rDmIA4Eicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>导读：现有多模态大模型（LMMs）在复杂多样的OCR任务中表现如何？华中科技大学白翔团队联合华南理工大学、阿德莱德大学和字节跳动联合推出新一代OCR评测基准OCRBench v2，并发布最新私有数据榜</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637510&amp;idx=1&amp;sn=ad33f7e477e2e8a9029c8b384a9f15cd&amp;chksm=975925e491d0e72ae3f30a25ed4d64a959cb0bee9956fdc803818049f179eb80dda3d086235e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Sep 2025 00:01:02 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[恶劣天气下的图像修复：南理工等提出LCDiff，让AI在雨雪雾天也能看得清]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd2Nf7yNoDkqqeyELvyrkX4f7ibVeSLoKm8u0dqQEjxVQB4PakicXNcFhaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>如何让AI在狂风暴雨、大雪纷飞、浓雾弥漫的天气里，也能“看”得清清楚楚。这不仅仅是听起来酷，对于自动驾驶、户外监控这些应用来说，简直是刚需中的刚需。恶劣天气下的图像修复（Adverse Weather</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637510&amp;idx=2&amp;sn=8b541444da5351b1617b76bf72ba7703&amp;chksm=976c8359a787be5d286150431f64faa5a0afd93a4c9a8306b37ee62a0c4564d9733bf8e141ff&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Sep 2025 00:01:02 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ContextFlow：无需训练的视频编辑新范式，实现电影级魔改！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd20ibQaNjXkl0S7ibHefQDRkRk16XeuIpovOrS4pRoNK5iazgfwND2YpQtg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家聊一个好玩又实用的技术，来自北大和港科大的朋友们提出来的一个叫 ContextFlow 的新模型。简单说，它能让你像P图一样轻松编辑视频里的物体，比如凭空加个东西、把A换成B，或者直接让某个</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637418&amp;idx=1&amp;sn=7be6207fc1e1f503dba15e1aade164b3&amp;chksm=973e9657631c69403a3168861d060709b293b2caf22ecbaeee6200fc36ad08cbcbb595b36e6b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Sep 2025 17:32:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动OmniInsert炸场：无需掩码，任意物体“贴”进视频，效果碾压闭源SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd2HdoGYvNichpFrl7RHvp709g24GCjjYekHDicaIzkL2ECJCMPXcLj54Vw/300?wxtype=jpeg&amp;wxfrom=0"/><p>搞视频编辑的朋友们，是不是经常觉得，想往视频里加个东西，这过程简直比登天还难？又要抠图，又要搞蒙版（mask），效果还经常不咋地，光影对不上，动起来也假假的。今天，咱就来聊个“王炸”级别的技术，它可能</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637418&amp;idx=2&amp;sn=6303fd2446ca057452c59326733d3788&amp;chksm=9780016665502454e9975aa1a29042d18fbc6adb994794ae7902ec80488d44561a6889f49a8a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Sep 2025 17:32:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Point-SSM：一种用于点云分析的极简状态空间模型，在医学点云任务上表现SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wI1nyHcPESG7hdfRDdvtcXNvBReWCutYYZ8250lTAjiblEccAWTaJHzRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文提出了一种名为 Point-SSM 的新型点云分析框架，它创新地将最近在序列建模领域大放异彩的状态空间模型（SSM，如Mamba）应用于无序的点云数据。通过引入多种 扫描策略 将点云序列化，Poi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637418&amp;idx=3&amp;sn=15fb8ef51f1521f9a4a0a9be936c5efc&amp;chksm=97fc3ac00102ead592d9d6fa561d768fd203aef596ee92a4ef2223247cfdcedc505ac87d4802&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Sep 2025 17:32:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI | 数据增强还在“盲操”？南大提出IPF-RDA，让模型训练告别信息丢失]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8r8pVhGicxSwwZDBiaw8TEdoqKB8gZN4x7nIDjNXh5qBNhXSLyTTuBb6A/640?wxtype=jpeg&amp;wxfrom=0"/><p>各位炼丹师们，大家好！今天CV君想和大家聊一个咱们训练模型时几乎天天在用，但又可能没那么在意的“常规操作”——数据增强（Data Augmentation）。简单说，数据增强就是通过对原始图片做些“小</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637025&amp;idx=1&amp;sn=6ec8f5aad63d31240f66561870523389&amp;chksm=974523e271af3e3e14d54cebaca5ed2c34007d32efe9d4f82d3cb36e10de2cb7be11cce7af76&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Sep 2025 16:08:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[SilentStriker：无声击溃大模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8Rl4Tlq2HibSialp7aGElrFhzJasKiaJ4OooLiaXlAYanqnkC7ZZII5Cvwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着大语言模型在各种关键领域的广泛应用，激发了大量关于其安全问题的相关研究。相较于已被广泛研究的输入操纵攻击（如提示注入，prompt injection），针对大语言模型的比特翻转攻击（Bit-Fl</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637025&amp;idx=2&amp;sn=da009e971c31dcf8c003af98b19535ff&amp;chksm=971240bdc23bc2523ff837a0554edb47ea172e21d13d2d7417d1af8a5b4b8ee5780621bdeb9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Sep 2025 16:08:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Yann LeCun团队新作LLM-JEPA：结合联合嵌入预测架构，显著提升大模型微调性能与效率，在代码生成任务上表现卓越]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8T6WK5v6f09MOy6FNbQ9HPyC4R3s8tQJicP4HwsBrl58BBXVY7TlSKEA/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前，大型语言模型（LLM）的训练和微调几乎完全依赖于“下一个词元预测”（Next Token Prediction）这一自回归的生成式任务。然而，在计算机视觉领域，一个名为 联合嵌入预测架构（Joi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637025&amp;idx=3&amp;sn=f3dd386a5c4bdc3b8984fe0416cc6727&amp;chksm=97b243bf5e79c3f2699d100352d3ceb01076e79317cc5823b405d8d66102c877d7e807deba70&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Sep 2025 16:08:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[苹果发布Manzano：一种简单可扩展的统一多模态大模型，其混合视觉Tokenizer统一了理解与生成任务，性能SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wIsoRYib0JKCUlhhrHugkWBCIibAVOqCbcCGOoAanyatS0tJw0IrKyoWYg/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍来自苹果今天发布的 Manzano 模型，这是一个简单且可扩展的统一多模态框架。它通过创新的 混合视觉Tokenizer ，成功地缓解了多模态大语言模型（LLM）在同时执行视觉理解和生成任务时</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636580&amp;idx=1&amp;sn=654a4b72ba9c5ea364df032e95511d27&amp;chksm=97dd8540121a6d773a01155baa9910d2ff41e24fd2e099c910c61e07d3cc421901318363e298&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Sep 2025 11:50:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动SAIL-VL2登顶OpenCompass，开源高效多模态新标杆]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wIIplATVwRYAckyibx8HDnCKfzOHSnEcEg88ZwOJe7icPYTJCUplDVps7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，字节跳动 Douyin SAIL 团队与新加坡国立大学 LV-NUS 实验室联合发布了其最新的开源视觉语言基础模型（LVM）—— SAIL-VL2。作为其前代 SAIL-VL 的强力续作，SAI</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636580&amp;idx=2&amp;sn=63cb646ee1a1422fa467d1c2f577cd35&amp;chksm=97abc06b0feaeb11e64f19a10ce6f77679ebfa962b96e6fe9015d8a6678663055c7cd53041b1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Sep 2025 11:50:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[博后年薪40万到90万 | 东方理工朱文韬课题组招聘AI方向博士后、研究助理教授、访问学生、实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wI8Ix01Ul0N8yz049posJFuicvJwlBGF3EecvwU7F9AHlEl8PlTFpwpgA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【博后年薪40万到90万】东方理工朱文韬课题组招聘AI方向博士后、研究助理教授、访问学生、实习生宁波东方理工大学宁波东方理工大学是一所由社会力量举办、国家重点支持、省市共同建设的小而精、高起点、高水平</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636580&amp;idx=3&amp;sn=6c065d6c8461c14d1374e535506b6e8a&amp;chksm=972a64a1df7373873ef181f04bde6e07eca9ee23ced8e0b32eb08586aa2747a38d602a01f4e0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Sep 2025 11:50:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别视频“抽帧”理解，美国东北大学新算法GRT算法实现高效可扩展的高帧率密集视频理解]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOQ1iaMicr3QclWE27SVl7NOMMz3zWBicFS5W0fQezetW2hMVsvrFemXltA/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前的视频大语言模型（VLLMs）在处理视频时，普遍面临一个核心瓶颈：为了节省巨大的计算成本，它们不得不“抽帧”处理，即只对视频中稀疏的几个关键帧进行分析，而丢弃了绝大部分的密集时序信息。这种做法在处</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636505&amp;idx=1&amp;sn=4e4978faf6a8b3d85bc374f54498901d&amp;chksm=97d12b2cfbc4b6d428f4c2acaa5262ef70e52ede85cd96fe0a88f865abe607147a759fcd17fa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 21 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[【招生招聘】阿卜杜拉国王科技大学孟彦达博士组全奖博士、博后、实习、交流生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvrpy6G01cVWkU3z9NrpIzs5QkM0mpswQVncWyg4DEqFSFgG2cCicJUWxXeWALBrWu6hvoicRje85AA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在英国求学与工作八年后，孟彦达博士将于 2025 年 10/11 月 加入阿卜杜拉国王科技大学（KAUST，US News 世界排名112） 生物工程系，担任助理教授（独立 PI）同时挂职于计算机科学</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636505&amp;idx=2&amp;sn=831ebaa40cf75cd61781e65f1c165c92&amp;chksm=97a96b547cf1efd520bc6ca45b39139a5372ddd3817e763273a93c6d9f382932a43e45e1c8ea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 21 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | DiffMVS/CasDiffMVS：一种置信度感知的扩散模型，实现轻量且准确的多视图立体三维重建]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOict6ibia8kPFOGPcFAXKgpO5fbEEtKE4D2XYfuc8Qb9kfhaVCeKGEXTHg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天要介绍的论文是来自苏黎世联邦理工学院、南洋理工大学等机构的研究者们发表在 IEEE TPAMI 2025 上的工作。该研究创新性地将近期在生成任务中大放异彩的 扩散模型（Diffusion Mod</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636472&amp;idx=1&amp;sn=2f08b9ffe438978def1d931f45ffdd17&amp;chksm=97cecac4a02d9ceb551d4f9e893e360a3de418c9db93647032f2b7dd13c604779792924cca8c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 20 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[北大等提出BEVUDA++，首次解决BEV感知跨域难题，夜间检测性能提升12.9%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOPuPs6P4zu7iacibbSq8yHOc359ianFcCiccWBxlY7DP5L52omg1DS2GIbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在自动驾驶技术中，以视觉为中心的鸟瞰图（Bird's Eye View, BEV）感知方案正变得越来越重要。然而，现有BEV模型的一个致命弱点是“水土不服”：在一个地方（如晴天的波士顿）训练好的模型，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636472&amp;idx=2&amp;sn=0a7874fbf6512d86f1573a350bdb2ff8&amp;chksm=97acdc94888b9fe33a9eb689d29c53068ebb89f6bda04298bcffa671281cec42caa01e349f9e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 20 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta新作SyncSeal：用深度学习“封印”同步信息，让数字水印不再怕裁剪和旋转]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOIyQ3vgMAwXXM7fKe50y3qK39q17C0N1q4frMOQqDRKFQAaBiaHH07Nw/640?wxtype=jpeg&amp;wxfrom=0"/><p>数字水印是保护图像版权、验证内容真实性的重要技术。然而，传统的水印技术非常脆弱，一张带水印的图片，只要经过简单的裁剪、旋转、缩放等几何变换，水印信息就可能“失之毫厘，谬以千里”，导致无法被正确提取。这</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636428&amp;idx=1&amp;sn=5f34ca69ea54fb2f10530fe0b8f03dda&amp;chksm=970e32cf5613e6ad1845a0f3f68da6465482080fa2cc7707016de4f7de24e149d9f9b1d0dad7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 19 Sep 2025 17:00:08 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿联酋大学CVLab IEEE Fellow团队招收2026春季/秋季全奖博士生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOZx5z5YrfwtbNRR1NL4QjnD3Ubb6D81gric0WujqEAt4281AoLlrPywQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿联酋大学信息学院计算机视觉实验室（CVLab）IEEE Fellow廖胜才博士团队招收多名2026春季或秋季入学的全奖博士生。现开始报名2026春季博士，2025年10月8日截止报名。这一批次的学生</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636428&amp;idx=2&amp;sn=2d47ad2395a42d37c30c6aaa4a78ed0e&amp;chksm=97118fd278cf026b878c84a984c2c1c70b08ab22afc1d6e4fb0268cd3f94a508f5b1d370a142&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 19 Sep 2025 17:00:08 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | 弱监督与自监督引领自动驾驶运动预测新范式，用场景分割“脑补”运动，仅需0.01%标注，性能媲美监督方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTur8IPrMT4ibM3LyLSw1GMGj9Q94pUmJqL63NGz0Kp6KuIGyTgCv99RsDWyC2w5PPHUDEib8xqmyOPQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天，介绍一篇新出的来自南洋理工大学和商汤科技的研究者们发表在顶级期刊 TPAMI 上的工作。这篇论文 《Weakly and Self-Supervised Class-Agnostic Motio</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635832&amp;idx=1&amp;sn=acf490d444da8c86aced6da215c3dbba&amp;chksm=97b9cdc23da11829e3bac23e3a8f75d789b7d6314f2592bd3184e0846303734d61c4b664e47e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Sep 2025 00:02:00 +0800</pubDate>
    </item>
  </channel>
</rss>