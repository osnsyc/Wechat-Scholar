<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[我爱计算机视觉]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[我爱计算机视觉公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_e07180c244d1.jpg</url>
      <title>gh_e07180c244d1</title>
    </image>
    <item>
      <title><![CDATA[从YOLOv5到YOLO11！改进有多大？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuUlrnticsvjFHSDyYvdXlkcw8zcQptrYMicdw1sAjE00Lm88RqMocl8AyYetY9umv3o13srHmgYplA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在目标检测领域，YOLO（You Only Look Once）一直是一种突破性算法。自YOLO算法问世以来，它已经演变为许多版本，其中最受欢迎的版本是YOLOv5和YOLOv8。这两个版本都有独特的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628972&amp;idx=1&amp;sn=1dbe72f0d6f25c1440d4d8ac8d51ef20&amp;chksm=9700e1e37e065564e4bdd585eeded23803b1eee80b96f1afb38bce23c7d67ccc04c6cfbd1b7b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 04:30:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR2025｜MCA-Ctrl：多方协同注意力控制助力AIGC时代图像精准定制化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvL58Zh0uDXP2yAVCQ8SUzSQpDATjax7XT5icSiaSOWf0JNOJgXsmicPibmia6nQicGBUGeFwQuiaHvIZyLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文由中国科学院计算技术研究所研究团队完成，第一作者为硕士生杨晗，通讯作者为副研究员安竹林，助理研究员杨传广。论文标题：Multi-party Collaborative </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628972&amp;idx=2&amp;sn=e4f6f140691f0a772e70c9b86140bdfe&amp;chksm=9752d7aed0df0ca8171a32a387ce13dacf5718c15363d0d859d0092c8b3f62f071bac10bdca4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 04:30:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动提出Mogao模型：开启 AIGC 从“能写会画”到“边写边画”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuUlrnticsvjFHSDyYvdXlkcgb3MibUcYbaDHjYfBiaCibiaCUpNE6QIRwws0Kez9RPoVP9aiacMGibdfBDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文Mogao: An Omni Foundation Model for Interleaved Multi-Modal Generation，Mogao：让AI</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628967&amp;idx=1&amp;sn=3c5787be4926bf0f9b05e5bc7cedab30&amp;chksm=976c6ef85e7ba557f7470f3255785c4895a723b33d8bb62d539121f3c8964c56b61b1ec1b506&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 14:05:21 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[T-Rex Label 上线 DINO-X 模型预标注，52CV 粉丝专属福利来袭]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuPdI2MhApWYkEN9GlibhH2kGA0UCdghrAptI3ibHUqZFjuRveSfXMQ4zDsTYpJicsHDOQoTrGEVl6gw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美目标检测是计算机视觉的一个核心任务，广泛应用于安全监控、自动驾驶、医学影像分析等多个领域，而高质量的标注数据是训练高效目标检测模型的关键。近两年， AI 辅助标注能力的兴起</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628945&amp;idx=1&amp;sn=3e2a6687f6bbf8c06a8a61047b8bab0b&amp;chksm=973998d1ca6a8548849c705a7307dad253976cee2c322d15702c6f0ab5b755b658b942e921aa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 10:10:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[KuaiMod | 更高准确率、超低举报率的工业级自动化短视频质量判别框架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvXOSvgSST1dNy7aXnjWRgYlKUh64ZGtkkls4soreCfoVvzOkpuLjKEGjmGE6UOck6Ph94VZViauYA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美在短视频成为亿万用户日常生活标配的当下，它不仅是一种娱乐方式，更是人们获取信息、表达观点、构建社交的主要媒介。随着内容量的井喷式增长，平台面临着前所未有的挑战：一方面，需要</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628945&amp;idx=2&amp;sn=0deed8dea6f93a7ed484d8bfd637c2f5&amp;chksm=9764bda4c48fc971462cabfeb9bf9f4224195294924f7026cbfbd0d96146d72004bdf3e8ccd5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 10:10:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[为何说 “在国内做科研，最忌讳踏实”？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYjcMj1Es6LBnic5BBia8KQzzaCc2DvtlNI72Kv641K9WGzENYtiaLdXXoicsHG9icRzsvibskMm0xrdEw/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近经常收到读者的留言 : 抱怨科研真是太难了，竞争压力大，导师不给指导、不开组会，一年见不到导师几次，对于论文初稿、毕业论文毫无建议! 无论什么专业的研究生，面对这样的情况，很有可能都要陷入沉思。万</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628929&amp;idx=1&amp;sn=8a392ac590cb507d855847b76fc91037&amp;chksm=977bdad0720a4fd795bae248869ef4110b9c304432f520d9739849d27753d93248ed599fdf1c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 05:32:03 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | 加州伯克利和 MIT 提出 Sparse VideoGen，挖掘模型稀疏性，加速视频生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuPdI2MhApWYkEN9GlibhH2kbEXiaj4E7g6AnkO6GxneShia7lLMXZKACUnTBdl88zDHgPhBlyvH3JOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文转自机器之心。自 OpenAI 发布 Sora 以来，AI 视频生成技术进入快速爆发阶段。凭借扩散模型强大的生成能力，我们已经可以看到接近现实的视频生成效果。但在模型逼</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628929&amp;idx=2&amp;sn=5b48d61c5f39337e0d8d485dcaf67f23&amp;chksm=97ef52e2fa7171a4a9c5e1d4d05adb759d7c5b7337fd03a89df1c2e867cbf45e1c20bae27fa0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 05:32:03 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | 更快、更灵活的 Transformer图像复原网络]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYjcMj1Es6LBnic5BBia8KQzdEYCVyN9OPsIQgnN73J4HmOS0bIBoTqIJQEFWOCm8bpLAySnnOibK8w/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文MB-TaylorFormer V2: Improved Multi-branch Linear Transformer Expanded by Taylor </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628917&amp;idx=1&amp;sn=a082c1d994fb5ad4e6437cedfde6382b&amp;chksm=97c3f3c4876692e2ccd2049c7257bdcca2e99df7573dd3c447157970f566071c95e6f5d82dfd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 03:47:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Aero-1-Audio: LMMs-Lab发布1.5B音频语言模型，长音频转录直出，性能优异！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLXLtvgvVhYCC48wCJYF80fzzC0EtXvxeI72GH16HfmDXWKazBSe8BIjJCYwoibFfbm7Bm7KcLYkA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美小参数、高性能、长上下文，性能优于Whisper和ElevenLabs。导读：音频大模型领域再迎新星。近日，LMMs-Lab发布了一款轻量级但性能出众的音频大模型——Aer</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247628888&amp;idx=1&amp;sn=86038a5f8f3f0e0f0496542a3f78e0fb&amp;chksm=9745136c241984d1df189cec59ea47503dcf57048276aabe39710913d2225a934dc4027f0e79&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 02 May 2025 12:19:57 +0000</pubDate>
    </item>
  </channel>
</rss>