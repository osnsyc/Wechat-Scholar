<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[我爱计算机视觉]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[我爱计算机视觉公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM6aYkwkiboia6lA9D7ANy49WBe9icxn5NQqJjvn4Pyntzvfw/132</url>
      <title>gh_e07180c244d1</title>
    </image>
    <item>
      <title><![CDATA[AAAI 2026 杰出论文 | 同济&amp;微软等提出 LLM2CLIP：补足 CLIP 难以处理长文本的遗憾]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt31wj7Wz3lTkiciahibeLEliaI8vhEvwGqZKJacuZ0icf6Lo53v8aafkbHG6dUzBpaa5euKFH39WKuQ1g/640?wxtype=jpeg&amp;wxfrom=0"/><p>在多模态大模型（MLLM）和生成式 AI 飞速发展的今天，CLIP 依然是连接视觉与语言的“基石”。然而，随着应用场景的深入，大家逐渐发现 CLIP 的文本编码器（Text Encoder）正成为整个</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655425&amp;idx=1&amp;sn=c7e532098a3cf52818a039e9e08d0678&amp;chksm=9792913a4eaf3eee6b64aa44c281c36ae0edaff0839157e1bf9e0a3aa56cd19af7a0bc1fb2ac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 31 Jan 2026 23:52:39 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IEEE TPAMI 中科院等提出DPSD：无需原始数据，实现高精度隐私模型转录]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt31wj7Wz3lTkiciahibeLEliaIPmJu6LT940YqYfDx1Knq1GLcaicibTFnlXwwacanFWz2nfPqGzS7D6sQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在深度学习大行其道的今天，我们习惯于将训练好的模型部署到各种终端。但你是否想过，这些看似“黑盒”的模型其实并不安全？攻击者可以通过模型反向攻击（Model Inversion Attacks）等手段，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655406&amp;idx=1&amp;sn=d9de088050f51c8d8c43e2f52691c34c&amp;chksm=971e428e0a533139d3a7fa106385d1c53cd9bcecac71fa70ea88436fd124a89a7ec1e5533b5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 Jan 2026 15:01:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2026 | 北大&amp;腾讯开源 GenCompositor：视频素材“拖拽”即合成，生成式视频编辑迈入新阶段]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTspoibFcZLeGeybGBfw9wBFk9cdKWQO4hay3rEjH6yZCcdAYZNZOibmt6iclMhWibrtN6wJXJ8PwpdiaZQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在电影制作和短视频创作中，将一个视频里的动态元素（比如一只飞舞的蝴蝶或一场爆炸特效）无缝嵌入到另一个背景视频中，一直是一项“精细活儿”。这不仅需要剪辑师手动调整位置、缩放和运动轨迹，还要处理光影和谐化</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655382&amp;idx=1&amp;sn=1ef5c8a18091ea4e511fd5c875ace832&amp;chksm=97e7c32bbdc820a9882bb678be7d43e367849d02b767413526e19f28cd00926c3be5bbece71f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 Jan 2026 21:10:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI4RWC@CVPR2026: 人工智能在真实世界中的挑战Workshop征稿中]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTspoibFcZLeGeybGBfw9wBFkbTDxukWxDEKPgKjep1ichWviaqpXtsprNRgh5L67EFnSqicicKnydOLIQA/300?wxtype=jpeg&amp;wxfrom=0"/><p>CVPR 2026 WorkshopAI4RWC: The 2nd International Workshop on Vision Intelligence for Real-world Chall</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655382&amp;idx=2&amp;sn=f1d5ed3230e0028139ad9c1a86a1c2fe&amp;chksm=97f73d1e3cc49ca2137d52fea7e2756c24118c0c2f4fac1efe491c48f96f50dd33869d9df47d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 Jan 2026 21:10:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI 2026 | 山东大学等提出 SAPA-Bench：首个大规模手机智能体隐私意识基准，主流模型普遍不及格]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuDMdIkicaegvfhFjwaen3DJHf6l9ho23EJfZy8OIh5WnHABXzIDB4faUf6RKibodoQhfm4s0uZBc4A/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着多模态大语言模型（Multimodal Large Language Models, MLLMs）的爆发，智能手机智能体（Smartphone Agents）正变得越来越“能干”。从简单的发消息到</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655301&amp;idx=1&amp;sn=10a641c4be2bce0747c4f29d9ac9140c&amp;chksm=977d85a2026401b51ce48fcf1e5fcb7b64cfc3648110984c6a3152ceb99f14b6b677bc9fe112&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 28 Jan 2026 13:27:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NTIRE 2026光场图像超分辨挑战赛正式开赛 | 验证平台已上线！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvvHE3zvianCbjrOxORYIoeqBeCgC7BWPllP2KgDLW82CSZatJZqbm2CqFIYhx38yuqQhjgxsT97sA/300?wxtype=jpeg&amp;wxfrom=0"/><p>光场图像超分辨挑战赛 （Light Field Image Super-Resolution Challenge）将作为NTIRE研讨会的一部分，与CVPR 2026一起举办。NTIRE全称New T</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655301&amp;idx=2&amp;sn=986476d7c4f394c80fdf519085b71018&amp;chksm=97a2d69e5f854900464e140f4dc423810c09656f4742046860949bb496df41fd05cbff46d5ae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 28 Jan 2026 13:27:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[目标检测2026年好发论文的方向！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuJABB18ZECJsJ5V5MRC3tK2BHEYlwyB8ukSvLY6UDrn1TPvl6gn20ib6I1Jnrmib87MmqaBxGp0xfQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>YOLO实在卷不动了，不知道目标检测还有哪些baseline好用？不知道怎么选？实际上DETR系列都是好选择，也一直很火。包括RT-DETR系列、DINO系列、D-FINE系列等，近来更是出现了很多新</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655249&amp;idx=1&amp;sn=218afc083758716157623d61be3560ac&amp;chksm=97a907881d23ecdc833f95055bb020295b8a5238dd31678478f5a77bf9a27f39bf44b038f8c8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 27 Jan 2026 12:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2026 NTIRE 第三届真实场景图像复原（RAIM）挑战赛震撼启动！三大硬核赛道等你来战！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuJABB18ZECJsJ5V5MRC3tKnNyEA8K1ECbxgbaGz1R88MPzZBBIRrYtxXLnMUviaMXibhRXr7ruzBIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>CVPR 2026 NTIRE 第三届真实场景图像复原（RAIM）挑战赛正式拉开帷幕！当“多模态大模型”遇上“专业的画质评价”，当“计算摄影”挑战“动态复杂场景”，谁能定义下一代图像处理的标杆？今年，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655249&amp;idx=2&amp;sn=7b2702e94a4897f390700ac79626bcfa&amp;chksm=97390b7b5113896ab3f824923384319590b8542dc0edd22c44039dca118098af38384d96f930&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 27 Jan 2026 12:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[首届 CVPR 2026 AAVM Workshop 征稿启动：Agentic AI 开启视觉媒体创作新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvvHE3zvianCbjrOxORYIoeqqmy6IduyTXuy6D2wZ26kq1pbVcNwKeCVQiahcdjU5NxZDITeY6WNmGQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着生成式 AI（Generative AI）步入深水区，视觉内容的生产已不再满足于“单点生成”。如何让 AI 从单纯的绘图工具进化为具备思考、规划与行动能力的智能体，已成为计算机视觉与多模态研究的最</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655205&amp;idx=1&amp;sn=632da447efadda60fa65356d781b4db3&amp;chksm=9735deae4cb18f408253832ced632b5ce3c19eb5557189d04ea0faa4a3faade0ddf159cea1a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 26 Jan 2026 21:41:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI 2026 Oral | 北邮提出PBC：告别高分辨率图像“乱码”，内容丰富度飙升！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv3ShrnTyVabuq2H0y19pb3pHkcsSeleKaNLHuHWUyMnqiaBY0tyWDlhadibOiaJFZgtAAzAVUia7p9Fw/640?wxtype=jpeg&amp;wxfrom=0"/><p>文生图大模型现在这么强大，那是否也可以用其做更高分辨的图像生成呢？是可以。但许多研究者发现结果常常边缘模糊不清，或者画面里出现重复的物体，甚至整个构图都“崩坏”了？这就像是给一张小图简单粗暴地放大，细</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655152&amp;idx=1&amp;sn=72eef83e5826d1f17ad6e28dac94a0ce&amp;chksm=97369d71010bd1a88affd60a027180ea966b5846c8cd2bfa553723f7743ac1a1fcb6ce4d9406&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 25 Jan 2026 07:03:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NTIRE 2026 第一届盲计算像差校正挑战赛正式开赛]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv3ShrnTyVabuq2H0y19pb32VMdbHyUk52YzofXHcZO9rZJYOq7IxNmlJoY6TWmjsawNiam4PPSgJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本次挑战赛作为 NTIRE 2026 研讨会的一部分，与 CVPR 2026 一同举办。NTIRE（New Trends in Image Restoration and Enhancement） 是</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655152&amp;idx=2&amp;sn=ae397cfe1ad38f734fd9d212c1deab74&amp;chksm=979aa628a55830993fc6070ca6da79264737044e95aaac510c6e57c2571d148181d0c7b43f0b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 25 Jan 2026 07:03:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI 2026 BuildingWorld：面向 World Models 的全球结构化 3D 建筑数据集]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv3ShrnTyVabuq2H0y19pb36O4ukk7MLr41ibVrpB8n3iajAiculCqFwa0qvcVmTZ7uMOAEo1lTYSR5g/640?wxtype=jpeg&amp;wxfrom=0"/><p>关键词：五百万LoD2建筑物，五大洲，Cyber City项目网站：https://szusic.github.io/BuildingWorld标题：BuildingWorld: A Structur</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655101&amp;idx=1&amp;sn=e14d502ef9456dcc7080e5f9a88ddf2a&amp;chksm=9712f032c92126e4f28379382f7a34f81f79046226babe408d5f80f4e78c8207eb259e6c8630&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 24 Jan 2026 23:03:34 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | 北邮发布T2I可控生成全景综述：从条件到通用，一览模型创新与应用前沿]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvw09RdicP5Uy5Z9glHicgQTMgP1X2aWK8Eh5kbYsgBDYyEe4RFZyTn7x9rBWX1zxFiaM88RibGcI5Jcg/640?wxtype=jpeg&amp;wxfrom=0"/><p>扩散模型（Diffusion Models）的出现，无疑为视觉生成领域带来了革命性的突破。它们以惊人的文本引导生成能力，让“所想即所得”的愿景越来越近。然而，仅仅依靠文本来控制这些模型，在许多复杂和多</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655078&amp;idx=1&amp;sn=e0b876f6ad3e399f45392ff4ce4a9cfc&amp;chksm=97ce36e93e2bfb99071d9bac907880cc103b9793e142938c27521fd0eca2d87b3444f98e9014&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 23 Jan 2026 12:45:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[【3月热门EI会议盘点】多学科覆盖，论文快速发表指南！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvw09RdicP5Uy5Z9glHicgQTM2gCdAibTiciaW6y2xPdDSjQRthk4MsrKiaHl5vCz6I1QWAfXDicHia1ay70A/300?wxtype=jpeg&amp;wxfrom=0"/><p>2026年3月高含金量学术会议日程速览 2026年3月，国内还将迎来多场聚焦前沿科技的国际学术盛会，涵盖人工智能、网络通信、材料、计算机安全等热门领域， 欢迎各位学者下滑查看近期国际会议时间表，并选择</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655078&amp;idx=2&amp;sn=1ed1e0d2965d87bc3a6740567ef9e5b3&amp;chksm=97fa445dbe65a3a41d6cd4006d5b0135c3c2319e0abf41fbbec5835ff776cb17eff3867de030&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 23 Jan 2026 12:45:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[大连理工开源 Think3D：将 3D 重建接入思维链，VLM 空间推理性能显著提升]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvAiaria5x4coTPLhHe72fSfiaUDz1XEMtia4SNF4RlZibHSuNECuwmBVdRbRtzNWWNcw0bN9VIoze5XGg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在视觉大模型（VLM）飞速发展的今天，我们似乎已经习惯了它们在图像识别、文档理解甚至艺术创作上的惊艳表现。然而，当你要求这些模型在 3D 空间里“转个弯”，或者判断几张不同角度照片里的物体相对位置时，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655007&amp;idx=1&amp;sn=2e0f55440b9d36edfe0b96d972da5cad&amp;chksm=97b66c77083880bc60c73ac1f0b86541e88c7b4f2f991f789c829de1a55f472ec3bf3fad875f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 Jan 2026 13:22:34 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[实习 | 启创InnoSpark大模型研发团队招聘实习生(上海)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsctB59lNEDjBVc1AsGSv3E6KG4vTeH9uSBDs4t8DjlBVOyibZUqC9qX3O76MM4SianibicoVG50haJlg/300?wxtype=jpeg&amp;wxfrom=0"/><p>公司介绍启创InnoSpark大模型研发团队由华东师范大学上海智能教育研究院与上海创智学院领导，团队以服务国家及上海市“人工智能+教育”重大战略工程为使命，专注打造具有自主知识产权的中国版教育大模型。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247655007&amp;idx=2&amp;sn=3c5c57149dd4b1301484ee68cdb917f0&amp;chksm=977cadfb31ef5ae5f80f813fa055aa107f61ecc5e9dd15b5399b0fa2e72373604be1899a9c1e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 Jan 2026 13:22:34 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 无标注微调！北邮让大规模扩散模型实现高质量域内生成与可控性]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTslMnibNts6LibW2YLAaaXA2SXyX6wpJ83qorztriaEj0facD4KHlJpialjlqxYr9Y7uNDdicTvJQor4vQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在人工智能生成内容（AIGC）领域，扩散模型（Diffusion Models）已经展现出惊人的创造力。然而，当我们希望这些强大的模型在特定领域（比如生成人脸、动物或特定风格的艺术品）内表现出色时，常</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654982&amp;idx=1&amp;sn=9cbe2e58e38f57ae0e57f32e63c03c06&amp;chksm=970c45368df3ca432181865a847b9fd3855657c3e3e5880f48400c7771f88e5b19b0b51f2e97&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 Jan 2026 21:10:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[YOLO26深度解析：彻底告别NMS，以三大“炼丹神器”定义下一代边缘计算视觉]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTslMnibNts6LibW2YLAaaXA2ScNoamcEicoFV1BLKVxtrnibxQ1tekZS80kVKjB1NxfKVRRcUYoRicXNBg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，YOLO 家族又有新动作Ultralytics YOLO26发布：专为下一代计算机视觉而生，边缘视觉AI的新起点。虽然官方尚未发布论文，但 arXiv 上出现了一篇来自 KIIT Univers</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654982&amp;idx=2&amp;sn=1dc59610f78d977042743055c3e65c0e&amp;chksm=97311ba1bdd1f35be8c3af9ab45c173059a1e99260427f49f4faf24707a891cc1936b037ed25&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 Jan 2026 21:10:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[天控智能招聘，应用数学、计算数学方向]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsctB59lNEDjBVc1AsGSv3EsUbonN1JKicm0XzJOT9791kwd0IgicrKv3KCdHjTheVYkfJaNQUKjr0A/300?wxtype=jpeg&amp;wxfrom=0"/><p>天控智能是国内最大的精密磨床厂家，拥有独立的国产CAD/CAM软件研发部门。现面向应用数学、计算数学方向的硕博学子发出诚挚邀请。（研究生需三年经验）欢迎感兴趣的朋友咨询、投简：[tnca@tncalt</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654982&amp;idx=3&amp;sn=c531b35ef851fa1dd00339bace5322b6&amp;chksm=97dbb1444858a999bb44b79d3deb2992525bc0da10eba702aab01e614c57d789d8114f70dcee&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 Jan 2026 21:10:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI 2026 哈工大提出ITKM：用图文知识统一多场景行人重识别]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuD2aHIiaCRLwia0vn3YfIWiauiarmoVfkWQvRrrFFvYfFNWD16y8MVicTALEmb5NNicTXz24ayy9Gq3FVA/640?wxtype=jpeg&amp;wxfrom=0"/><p>晚上光线不好、监控摄像头分辨率太低、目标换了一身衣服……在现实世界的行人重识别（Person Re-Identification, ReID）任务中，这些复杂多变的场景常常让模型犯了难。传统方法通常是</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654899&amp;idx=1&amp;sn=2782c4858cac43012768e0517963b631&amp;chksm=9740ec941b9c0bee8bd98ba86c302391a4e2c239cf2c0aed52f48424ce977ac634d91f3dfaec&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 Jan 2026 12:37:51 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[计算机视觉方向的CCF-B会议，视觉顶会“地狱赛”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvniaHAqcbxxztJJqD7nibok5xB4Z42oW3ibms6ibH8wQ4qicNZn55KrU4Vjq9thJcCfTsA8M258Ycsdvw/300?wxtype=jpeg&amp;wxfrom=0"/><p>计算机视觉人必盯的 CCF-B 会议来啦！ECCV 2026 投稿倒计时，这场“硬核赛场”等你来战～ECCV 2026（第 19 届欧洲计算机视觉国际会议）是计算机视觉领域公认的旗舰学术会议，与 CV</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654899&amp;idx=2&amp;sn=84491f7fda143512298ae9544b51ee5b&amp;chksm=974012dadcb1eb6c204138b16531be40f3ab8815e499f0c1285a1a2e583aca67fddfc1c053d0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 Jan 2026 12:37:51 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[WACV 2026 | 310万工业图像，444个类别！ICONIC-444数据集发布，专为真实世界OOD检测打造]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsctB59lNEDjBVc1AsGSv3EDEMj3OBu3bKlT51azWibzDqy4KyzyC5sEDS1uSS58otiay1AdDgHibxWg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天想和大家聊聊一个在机器学习安全领域至关重要，却又时常让人头疼的话题——分布外（Out-of-Distribution, OOD）检测。简单来说，就是如何让我们的AI模型在遇到它“没见过”的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654866&amp;idx=1&amp;sn=50c94a8c6e3f1670aa920cf5fef84dda&amp;chksm=97df8b314b5c194d0c06cf9e3ebc714a39aaa3876bd4d15dd00f2e304268c39a250ecec20720&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 Jan 2026 23:02:11 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频分割新SOTA！3AM融合3D感知，大视角场景上IoU大涨15.9点，完胜SAM2]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvml2GMlT9HmbGib584htzCHGw4ichoB1dOw36wjyOv60kDhH3ibG9UY9ZdNoiazN6ygrNTT9ys1GW1HA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天想和大家聊一篇非常有趣的新工作，来自台湾阳明交通大学和英伟达研究院的研究者们联手打造的 3AM。如果你和我一样，一直在关注视频对象分割（VOS）领域，那你一定对 SAM（Segment A</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654803&amp;idx=1&amp;sn=b013f0250e865db93d9bcf58b1945cd5&amp;chksm=9780cd4e90aa024cb921804056d034fa7622a9c5b6c05886250e7cf564c8feb8f87c4d1d9949&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 Jan 2026 22:34:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别视觉瓶颈！蚂蚁集团、同济大学联手提出CLI，让大模型“看”得更准、推理更强]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuuiccwvsUrxbwJuqNJVTQrlVKntSH9HicC42zd0XfeRGDZ0yxgXkKWgBAdEr8AqHmibOZloSLJbqAAQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好！今天想和大家聊聊一个最近在多模态大模型领域很有意思的进展。我们都知道，现在的大模型（VLMs）看图说话越来越溜了，但你有没有想过，它们“看”图的方式可能有点“死板”？目前，像LLaVA这样的主</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654771&amp;idx=1&amp;sn=00bba3cd629e0206fbc4c571be4be679&amp;chksm=97959f6ed04a36ba2052633ec6800d00c349f8cd9115567bee6bea312a1d48b18e64309510d3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 Jan 2026 21:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[2026年截稿的重要CCF会议DDL目录]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuuiccwvsUrxbwJuqNJVTQrlELq63Q1Bv0Na90MBYXVWE7uJfeVmMibpDlbll71n86X0zRVOyB0UbfA/640?wxtype=jpeg&amp;wxfrom=0"/><p>2026年新的一轮CCF刷榜开始了！精准把握计算机方向会议等级分类、截稿日期、rebuttal时间、征稿频次是顶会中稿非常重要的4打因素。时间把握的准确，一年可以4篇A会，把握时机精准转投。反之，一年</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654656&amp;idx=1&amp;sn=588f0382a08b7d21c378d96c6d789486&amp;chksm=9757a87bb7842753819fd4865a437f3bcced594af6049060cb4357f932607bc5a8f3eb3b6467&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 Jan 2026 12:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Ultralytics YOLO26发布：专为下一代计算机视觉而生，边缘视觉AI的新起点]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvriaAodVGM5wWcgesQY9q4UzicMQVTX1kD6efHYEfobv7OUPqaCM2LxibfJSj9eJ8ybQ8xvAoa3HUxw/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，Ultralytics 正式发布 YOLO26，这是迄今为止最先进、同时也是最易于部署的 YOLO 模型。YOLO26 最早在 YOLO Vision 2025（YV25）大会上首次亮相，它标志</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654614&amp;idx=1&amp;sn=ac96d447cc8e7a0233f6877d10e93409&amp;chksm=973258a15ce592572ae1404b065c43d664f0b17a0d5db0a0a0bca7347c5f953331a124636160&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 Jan 2026 21:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦大学推出CME-CAD！异构多专家协同学习刷新CAD代码生成SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuXYQTEQjzWIGicejmH6FeN0LicJqxUEJq1ZHlHGUgyYcaIcMVLdTzogWSfDCwHEbwU5Lzyzr92aqCQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文为粉丝投稿。工业设计领域，计算机辅助设计（CAD）不可或缺，但传统CAD建模的复杂度及流程难以实现自动化生成高精度、可编辑模型的目标。现有技术（如从草图构建3D模型）常产生不可编辑的近似结果，无法</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654431&amp;idx=1&amp;sn=f2d9d0e32b1299121d59a75e735b39a8&amp;chksm=97b8c92bc33d741776163051bb5f5db2a6d345b38d246e225c4e04491cd482d5c62f60f86ccb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 Jan 2026 13:49:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[真实世界3D分割新范式！MVGGT：融合视觉、几何与语言，性能大幅超越传统方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuXYQTEQjzWIGicejmH6FeN02PGCEFhzQ6xVCnIZgcrw7MyynxrsAhia5iaibfh6yIl0licr8X1wMv2bRw/640?wxtype=jpeg&amp;wxfrom=0"/><p>当我们在谈论让机器人或AR设备理解并与三维世界互动时，一个核心任务是“指代性分割”（Referring Expression Segmentation, RES）——即根据一句自然语言描述（如“左边那</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654416&amp;idx=1&amp;sn=2f9e9ec6075561c3d4c2d61ca0026736&amp;chksm=97093fefc2c95ecd13db2bd6fcac2d0c207d21b5edbe293e5babfea220f007b234de784d2719&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 Jan 2026 21:38:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[MLLM想得多也降智？Meta新作VideoAuto-R1：首创“二次作答”机制，推理提速3.3倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6oNAfnlzLEhKj66UsQPnB8Tvcq8f5HbBGWqrs4oorvgPibdgEHhsJ3CTEtz770fl54loguw6dezQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，多模态大模型在视频理解领域可谓是高歌猛进，尤其是“链式思考”（Chain-of-thought, CoT）技术的引入，让模型能够像人一样，通过一步步的分析推理来解决复杂问题。但你有没有想过，我们</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654189&amp;idx=1&amp;sn=41f18de3f62799baa7fd6be54f6add08&amp;chksm=971bafe6725e120f45789f46212474c917f01de76c0904f70eaade105ba5b58c334d85fd0d95&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 Jan 2026 12:46:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[3D场景生成新突破！浙大、字节提出Gen3R：结构高手+美学专家，单图“脑补”完整三维世界]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsicSwwOfhcwCqHGKj45xUgf89ibBP4mx5VdOm0XWiah7NwHhLEPiaauzZgvB35ey7gib8icibGkn6MwyfjQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天想和大家聊一篇非常有趣的新工作——Gen3R，它巧妙地将两个看似独立的领域——强大的3D重建模型和前沿的视频扩散模型——捏合在了一起，实现了1+1>2的效果。过去，我们想要凭空生成一个三维场景，要</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247654005&amp;idx=1&amp;sn=64d1e05bdbc1b7c2a569ecdf2d41bb95&amp;chksm=97874a4c2cb8210c5cb48bb559171fed3bf99aa03d2b9879398b04f43fd15c0000c4b920fa43&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 Jan 2026 12:34:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[2026年1月截稿！AI领域CCFA/B/C会截稿汇总]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvniaHAqcbxxztJJqD7nibok5nIiazzDMlToo6NDTkqxDCBOqkyyjq0k1FE4FmX0FadcwzoFJWZ58VdA/640?wxtype=jpeg&amp;wxfrom=0"/><p>2026年的学术征程已悄然开启！对于人工智能领域的科研人而言，2026年1月堪称关键截稿窗口期——多个CCF A/B/C级权威会议集中收官，既是检验研究成果的黄金赛场，更是链接全球学术资源的重要契机。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247653693&amp;idx=1&amp;sn=3347cb645520f3d9af1f1007927a4f2a&amp;chksm=972451db482904d114560a2cc071d724a83a2f226c09e5a6422473b7a0d9fe0e4aa013ede3a9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 Jan 2026 12:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大、理想汽车联手推出InfiniDepth：用神经隐式场实现任意分辨率深度估计，效果惊艳！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtU3cHtAOp6biaDaQfmHPfzhibicSqXqVk4QVKxktRgaQdMbQc38ofw0lY6dqE7OsxiaKjwHKwW6cMWMQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>AI生成的深度图总是感觉有点“糊”，尤其在面对栏杆、树枝、人物头发丝等复杂场景时，细节总是表现不佳。这背后的一个核心瓶颈，在于长久以来深度学习模型都将深度图视为一个固定的、由像素格子组成的“棋盘”。这</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247653676&amp;idx=1&amp;sn=986f4fb4e8e85019900a6eaa8490a5f7&amp;chksm=974580b4682ae9f333b5730b848530ef6d66e7979fa69d3b13c1a4ebeea18739bb31b3f093bf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 Jan 2026 13:18:12 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 3D目标检测的升维突破：LabelAny3D来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuD30IAxvvSTVMDOMkPbpfuiblMibTMt7xAsr18NdHyHRFIeV5NHe2LLLE493icHsAUZzicInZ7fb6bgQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下，只用一张普通的2D照片，就能精确地框出其中所有物体的三维空间位置和尺寸——这就是单目3D目标检测的魅力。这项技术在机器人、自动驾驶、AR/VR等领域有着巨大潜力。然而，长期以来，它一直被一个</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247653465&amp;idx=1&amp;sn=dac3e7fb884e5cba85ab5927d6c84f23&amp;chksm=97a1ab0926d213069d4b9ec1d2aa1dbb0ebbabef83def0b05cdccc0ac5a08790659208d9da81&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 Jan 2026 15:37:52 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[年度总结｜2025多模态领域前沿技术进展！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtgjuGNqSCXPe7YoOq47icSm0cHDvfcjgZ15oRKxtBGI54AImSLQR4XugaDQQ07G4Q4u5vd1ibFd4MA/640?wxtype=jpeg&amp;wxfrom=0"/><p>多模态可以说是当下最火的领域之一，CV和NLP都在积极拥抱它，VLM和3D文生图更是当红辣子鸡。尤为值得一提的是，其任务场景非常广泛、故事性强、且缺乏统一的理论框架，可发论文的着手点很多，创新空间广阔</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247653157&amp;idx=1&amp;sn=8d21a5cd9f122ec033e7eed0b12763f6&amp;chksm=9712624a94d3a423e827d9a6c611e188d539367e4411667f3caa74a31cab413e560079f97e43&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 Jan 2026 12:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI 2026 Playmate2：开源多角色语音驱动动画新技术，免训练方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtgjuGNqSCXPe7YoOq47icSmwdmwLz3qjgZOicj3jibIVBU2ZCpmc7SAYH6HicvU0QBRc2T5oIAVibE3rA/640?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下，你正在制作一个电影短片，或者设计一个虚拟直播间，你需要多个角色能够自然地根据各自的台词进行表演，他们的口型与声音完美同步，肢体动作流畅自然，而且整个过程无需繁琐的训练或大量的人工调整。这听起</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247653062&amp;idx=1&amp;sn=c8f0e07cf9ebdd51cd604923f7713bb9&amp;chksm=975a53ad3ce55d4ae21c5f4cd4484ed00e5cff3dfbf315e2aaf4666d216d5fa323dc17d618e6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 Jan 2026 21:09:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[哈工大&amp;湖南大学&amp;西电&amp;澳门大学等三个IEEE Fellow发表的余弦网络的图像超分辨方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvniaHAqcbxxztJJqD7nibok5Nc0Y7icYCefCSVo4LfZI83xI6pficS4rSkkFzf9VS5S8eQ0wzkKLUnfg/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇分享的论文《面向图像超分辨的余弦网络》（原英文标题 A Cosine Network for Image Super-Resolution），聚焦于单图像超分辨率任务中结构信息提取不充分、训练过程</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247652835&amp;idx=1&amp;sn=c9724892c59805f25ada7f863258878c&amp;chksm=975b8e72ceb03e1889f42e44a1dc75e0790e7d1410fbe96931de2b16e6dcd157ba17e976196e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 04 Jan 2026 21:09:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[“实时数字人”进入次秒级响应！上交大等开源LiveTalk：20倍加速，多轮对话连贯性超Sora2]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv47jmk350p2rfLmbsqPNE22VEyK68geZroH40BOxD8DniaGKRQiaFfFfOqy2EwRVhTjfzMQEWW84cQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文名称: LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247652671&amp;idx=1&amp;sn=47a955bf5328058458cf6781a66721f9&amp;chksm=97936bfd6cd4f179195ed2afa4ed3b70262fb01ee3b0fcbb034a7514f163219a3dd0666f9f5e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 03 Jan 2026 22:52:14 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[浙江大学、西湖大学与蚂蚁提出OmniAgent：让模型“先听后看”，实现细粒度音视频推理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv47jmk350p2rfLmbsqPNE2ab0ONvNdV61IUfbsbc3bxr3CkVWU5rccZaujHI78D1lnbN4wh9XBaA/640?wxtype=jpeg&amp;wxfrom=0"/><p>你是否也曾对多模态大模型的表现感到困惑？它们看似能“看懂”视频，但一问到需要音视频精确同步的细节问题，就常常“翻车”。比如，视频里的人说了某句话时，旁边牌子上写了什么字？目前的许多模型，要么无法对齐信</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247652644&amp;idx=1&amp;sn=a78154c3956fd690c511a9a9129cfb1c&amp;chksm=979bc644f0cc34d153aa9bc1ffd0e53e393b7897f91a8b3519d62438228a5a587ecedd0e7e6f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 01 Jan 2026 21:14:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[RealDPO：把“真实”当作偏好，让视频生成模型学会自我纠错]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv47jmk350p2rfLmbsqPNE24H1uFW887h9TagYfQBN5SiarYT1DbZfb4riaLUzMXkQKT11gqoJYiaD3A/640?wxtype=jpeg&amp;wxfrom=0"/><p>你可能见过这样的生成视频：第一帧看起来很惊艳，但一旦人物开始运动，肢体就开始“飘”、动作不连贯、互动不自然，甚至出现难以解释的穿模与关节扭曲。复杂动作（尤其是日常人类动作）依然是当前视频生成的硬骨头。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247652592&amp;idx=1&amp;sn=6bb1f2c26165f9d0ffe84c2c08a7cb03&amp;chksm=97d1068833b5e569ecc96e568871736d77e6f3bf8f38b071270ce7550be97e3ee802ebb26004&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 31 Dec 2025 21:04:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | Adobe与JHU提出OmniVCus：前馈式多主体视频定制，多模态控制玩出新花样]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsSTmJMxgdicEupPxfzhweJzmnpgSHso00ibBX6DsScaYzSFka0tmMrPZnVibn3pnrPMV92EmzhXg8Jw/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天想和大家聊一篇非常有料的 NeurIPS 2025 论文，来自 Adobe 研究院、约翰斯·霍普金斯大学、港大、港中文和上海交大的研究者们，共同推出了一个名为 OmniVCus 的新框架。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247652350&amp;idx=1&amp;sn=35dd5fd450216dc78cb0612fcf5f2c14&amp;chksm=97068003242315d1534eac9089e3c0710257bf4f0bf0bf6683abde5ae70e67c9bee421efd36c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Dec 2025 13:51:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[博士招生 | 中国科学院大学光电学院招收类脑视觉方向]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvn2cGNKvjXDZ2kjTlgNaBk0ibM2ibm0NLSb5Rh6S2EDsib92zhGEHeOgca2oQKVt7twJSkuqUkZpyIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>中国科学院大学光电学院孟祥悦教授课题组现招收类脑视觉方向博士生，欢迎具有相关背景的优秀学生加入。团队简介本研究团队在类脑视觉成像芯片领域取得系统性突破，成功实现有机无机杂化离子半导体薄膜的可控制备，并</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247652350&amp;idx=2&amp;sn=e9bde59c6ac9f87fef248f4c4a008995&amp;chksm=97870cd30002679d6d29d0a1d77beb2d8de926b32d1089307e867092233ed744c674abc059de&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Dec 2025 13:51:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[清华&amp;港科大提出MVInverse：前馈式多视角逆向渲染，数秒内分解材质！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuvbfDAokdlb0ibicWtuvjpbUicq3lm0wvkiabBlLSrl8ZSlEzpwRu2TJyZeElAxRTxM7DibsFAbOotpBA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在3D内容创作、增强现实和机器人技术等领域，从2D图像中精确地恢复物体的三维几何、材质与场景光照——即逆向渲染（Inverse Rendering）——是一项至关重要的基础技术。然而，现有的方法往往陷</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247652147&amp;idx=1&amp;sn=d456d25fea62fdf58a2209ded9475ee3&amp;chksm=9746e99a4336dd14d400c9c226b7ab2e8fca77cb4d0609e41a446372083a82dd520ddbac920d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Dec 2025 09:05:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[浸大&amp;腾讯新作Streamo：统一决策与生成，破解流式视频理解难题，性能全面SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuvbfDAokdlb0ibicWtuvjpbUTRWEyzAT6fDeeVQtn34qtYpsYiaYIQ61xLhNQ7S3oLWyZ7CTm7O9bvg/640?wxtype=jpeg&amp;wxfrom=0"/><p>当我们在谈论视频大模型时，我们通常想到的是它能对一段已经录制好的、完整的视频进行总结、问答或打标签。但如果视频是实时、连续不断的直播流呢？传统的视频大模型往往会“傻眼”，因为它们的设计初衷是“事后诸葛</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247652133&amp;idx=1&amp;sn=b62d9a91dd3f05ed828dbe537e69351e&amp;chksm=9764ee4ec8e7dd8d100711ad0a313b02ea8354b86fe40f2ad5153f4ed07b51456206ca703f4c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Dec 2025 22:56:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Overleaf也能Vibe氛围写作了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuvbfDAokdlb0ibicWtuvjpbUE2z7Xx2RvVuOiclK0aIWX3mFsGIibIIRv0rwIrRxSQIX1AgiahJicDAvDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>文智云助手是一款Chrome/Edge浏览器插件，深度集成到Overleaf，提供从氛围Vibe氛围写作、边写边译、自动续写的全流程智能辅助。我测试了以下几个使用场景，发现效果非常好。场景1【氛围写作</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247652112&amp;idx=1&amp;sn=da5b43df45e17d409b3295f48d6fd240&amp;chksm=9717b9ac5c4fee8c60ebd1a851c45d3a2c08a3e1ef9fab5de05695b673960ba602fe6718fdaa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 27 Dec 2025 08:38:54 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[KAIST新研究DiTracker：Video DiT的新妙用，更鲁棒的点跟踪]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsHD9F0pLvDdx6OtFwW0iakGWCov7NR0ibSpmXibn50znyArRoMcelhVXV4kVH6OXqBwa7vyGeoz5iaXQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机构：KAIST AI, Google DeepMind论文地址：https://arxiv.org/abs/2512.20606代码仓库：https://github.com/cvlab-kaist</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247651937&amp;idx=1&amp;sn=1630636eb418edddc8a5109e429f538d&amp;chksm=97390ed69247b1287db135b25b98a1f9124e12efb7b72948432112ba62f219e8eb000dac458c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Dec 2025 08:49:42 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[107倍加速生成！南洋理工&amp;Meta AI等提出HiStream：让高清视频生成摆脱“算力噩梦”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsHD9F0pLvDdx6OtFwW0iakGtNCtIIq5zOjKiaJZ4j5tegdv9f9ibt7GiagtxlhWiba5LmIOYhRxicIgZEw/640?wxtype=jpeg&amp;wxfrom=0"/><p>虽然现在文生视频、图生视频的模型层出不穷，但想要生成真正“高清”（比如1080p）而且“长一点”的视频，实在是太——慢——了！这背后的元凶，就是视频扩散模型那高昂的计算成本，尤其是当时间和空间维度一上</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247651913&amp;idx=1&amp;sn=d68b7dd53e49fe6900860fdb5cf55342&amp;chksm=97b4ebe64d0a4b3a8d1dfd9affa7d025072a55590dc3cb8e4cfb4a645f5a033ba7a12d423f64&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Dec 2025 22:21:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UCSD&amp;Insta360等发布DAP：全景图单目尺度深度估计基座模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuMw0GVbRr4NKcSJatOB1zBhPSlxoPH1nAPtfvbC0OpplpTKaRshs1ib8ItZC9dBjcqj0PEHfD7ruQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，来自 影石Insta360、加利福尼亚大学圣迭戈分校、武汉大学 和 加利福尼亚大学默塞德分校 的研究者们联手，推出了一篇名为 《Depth Any Panoramas: A Foundation</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247651618&amp;idx=1&amp;sn=f4c64c6e9be472626b76fd97f3573b2e&amp;chksm=9790ecae6c9d25efe3ce415715099fb2a27ce272f34fa31934ec6609382a1e3a4195a0ffda40&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Dec 2025 08:15:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[200多篇论文深度梳理！首个通用端到端自动驾驶（GE2E）综述发布，揭秘三大范式演进之路]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuMw0GVbRr4NKcSJatOB1zBr2rhZO2waM28C6bpFOF69z6Lmu3HdZgeMoIGMfsy64HwjslZDcGSZQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>自动驾驶的终极目标是构建一个能够无缝将原始传感器输入映射为驾驶决策的集成系统。为了克服传统模块化管道信息丢失和误差累积的局限性，也是为了追求更接近人类的驾驶智能，学术界和工业界正经历一场从模块化向数据</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247651569&amp;idx=1&amp;sn=c9de49be2440c9ea12d49606ac3694b1&amp;chksm=9756c5bb03904c07045cf3345a22d233cf2140b666c846689edbfe5c4a34fccf27a92ddf9b3c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Dec 2025 18:36:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦、MSRA等提出FlashPortrait：推理速度飙升6倍，高质量“无限长”人像动画成为现实]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTs0oUQFOp3NbuGoq4BerhQZfx4vrib6JNw9G589liaDk5hZHLIhQqm6P9w4euicr1jich9QkIgWZ4It6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天想和大家聊一篇非常有趣的新工作，它来自复旦大学、微软亚洲研究院（MSRA）、西安交通大学、腾讯和阿里通义实验室的学者们。这篇名为 FlashPortrait 的论文，真正解决了当前AI人像</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247651212&amp;idx=1&amp;sn=e98e64468f53a00b45b2b84763da3813&amp;chksm=97cfc2a84093bd705b2d05366254eb14fd2ee7344b4b993046c6aa3bb2bceae04a404342888b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Dec 2025 22:05:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[研究助理教授 | 博后 | 香港中文大学影像及介入放射学系招募]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTs0oUQFOp3NbuGoq4BerhQZDkPKzQdFJU2Ruf7kYXAb42XO55md3q0KZVichoIK7ezV6kJ3qmddjHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>岗位招聘：研究助理教授 (Research Assistant Professor) 与博士后研究员（香港中文大学影像及介入放射学系）入职时间香港中文大学影像及介入放射学系现开始招收计划2026-20</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247651212&amp;idx=2&amp;sn=1509e6d3cc9449685da7667fdb2c1ecb&amp;chksm=97b689e543d16122389c63b85ac2deded7f8a5ae7482d8154c7482347fe38d1b3ce63d494431&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Dec 2025 22:05:00 +0800</pubDate>
    </item>
  </channel>
</rss>