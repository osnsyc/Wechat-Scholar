<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[我爱计算机视觉]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[我爱计算机视觉公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_e07180c244d1.jpg</url>
      

      <title>gh_e07180c244d1</title>
      

    </image>
    


















    <item>
      <title><![CDATA[MME-Finance 破圈：同花顺联合顶尖高校打造中英双语金融多模态基准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTueKG3gcbUfZqia1gywrcyes8lJB4Fuk97qic7JwDGhJyQsz1eWQL3TtA5mXwZ6FdozzgQ6bpvibR7Uw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627199&amp;idx=1&amp;sn=70bc9b18c64729d299b2437701503ba4&amp;chksm=975c0ce84f33c7941301e68c566902183aacec083bbe95a3c76da299113a337c5a659d288535&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 15 Jan 2025 03:30:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[独自一人，怒发顶会]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv0fgt98hCfaibtmHLNKeRn0oT4ibJ9lz2ib3QSnz7sUaBDqP8wYP6VJj6u6tCN7K6ErHL0Sfd3QRUNg/640?wxtype=jpeg&amp;wxfrom=0"/><p>万物皆卷的时代，升学、就业的竞争越来越激烈，想要保研、申博、进大厂，没有高质量论文在手就相当于“裸奔”！尤其是这个人人惶恐又内卷的时代，想要抓住点什么来增强安全感。有一份拿得出手的成绩——发论文的数量</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627198&amp;idx=1&amp;sn=f805fd140d98a877c366574f618fd862&amp;chksm=9782474c8b88f169bd87b088efc9bfa34437fd7a0f7cea669c161533a2ccec098a7f833ee283&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 04:25:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[博后 | 博士 | 硕士 | 访问学生 | 阿联酋大学IEEE Fellow团队招募，人脸和人体的图像和视频生成方向]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv0fgt98hCfaibtmHLNKeRn010TXiasxpicrJ7bABUiajziawj2KoKxibWHRvGI6LwbXDUHQjCdumb0Z3Lw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，获取更多AI领域发展机会阿联酋大学IEEE Fellow团队招收博士后、博士生、硕士生和访问学生导师介绍廖胜才博士是IEEE Fellow和IAPR Fellow，主要从事计算机视觉研究，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627198&amp;idx=2&amp;sn=9170ced2653ebb984059f3e5cbe88cbf&amp;chksm=97eeb1307a28f3f09fb67ff3032c09ca3be944005bfeaac02fcbdd4f6b92f2cf47839aaac01c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 04:25:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[GAN归来：模型大幅简化，训练更稳定，逆袭扩散模型，AI社区疯传]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv0fgt98hCfaibtmHLNKeRn0A6IZRibXeT4HAVlnicumwOFxyPcxYjPnygFiajsAO2Gy0JibNAODibaKmXw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文转自机器之心。GANs are so back!?2025 年了，GAN 能否击败扩散模型？答案是 Yes！本周五，AI 社区开始讨论一种全新极简主义 GAN（生成对抗</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627198&amp;idx=3&amp;sn=41ef4ce49a7128d3c300e019f0140d20&amp;chksm=9746b5bee9db1fac3927fe969ccd735ce0a8fef63856bb331b4c2026bc8fd58c01fae61021af&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 04:25:15 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文绘千里江山！1000万图文数据集Git-10M和生成式基础模型Text2Earth]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTueKG3gcbUfZqia1gywrcyesOaRibrdUtjwp9OSNmy5rZgsgsY2ic5zSqc2UVSogCdibjZMcbnRY6wgqg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文来自遥感与深度学习。分享论文Text2Earth: Unlocking Text-driven Remote Sensing Image Generation with</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627150&amp;idx=1&amp;sn=79f445560426b023a749f53bae2eccd0&amp;chksm=97015cfd5daa718057013f50dd95d6ad5e0a481bd236d95a0fa14e4e93d6ec67a8774b2df526&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 07:05:33 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[VITA-1.5: 迈向GPT-4o级实时视频-语音交互]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtiabwEP5j03iaHOEErowCqvlksnAx2PvwZ7UG5Vhtjltib0RwiaPJVk3AONH8zbCutjQbELZQAT2SmlA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美近年来，多模态大语言模型（MLLMs）主要聚焦在视觉和文本模态的融合上，对语音的关注较少。然而，语音在多模态对话系统中扮演着至关重要的角色。由于视觉和语音模态之间的差异，同</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627101&amp;idx=1&amp;sn=9db81a2cfddb5627182ee3ebeefa7cb0&amp;chksm=97f3f1c6ce25deb376a000c166ef2f002a660093680a7ee38dcb4ab5f0e9e9aad6c781856373&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 14:30:36 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[征稿 | CVPR 2025 Workshop 第一届像素级视觉基础模型研讨会征稿启动]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuUp1ibibQX2ONJmiaSQMNEEib99YhsicWsoB4xvGufHy99qNl8XQSyBgLFHaA8c4ibaTKTewIBuS8WXXZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美近年来，基础模型（Foundation Models）在自然语言处理领域取得了显著进展，其中以 GPT 系列为代表。这些模型规模庞大，通过自监督学习或视觉语言建模训练于多样</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627101&amp;idx=2&amp;sn=86df240119b776bb36190cee0e924b48&amp;chksm=9796cb568f615f4e43dbc326b439542a335c236075b19a5283cb027f338ecdf8b46d49fc124e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 14:30:36 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像美感增强SOTA，拒绝美感焦虑！字节跳动提出VMix：多维度美学控制方法，一键提升图像光影、色彩等]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuUp1ibibQX2ONJmiaSQMNEEib9lCX3wXagiadibdcN6hmEcK0NBjA6V6fk5OtoVQ6NGia5CoWz9SicIwUyHQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美尽管扩散模型在文本到图像生成方面取得了显著成功，它们可能仍然无法生成高度美学的图像。在包括颜色、光照、构图等更细致的维度上，生成的图像与真实世界的美学图像之间仍然存在差距。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247627092&amp;idx=1&amp;sn=0991372edf3c95650d0fcf80e4ff8663&amp;chksm=9797c4930ba72a122e11e0c7dc1d22b0e7a347ae7fbbc15638a4fea8033c717384bd71e8f04d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 04:11:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从文字到视觉：EvalMuse-40K如何评价T2I模型的进化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvial9HZiaPYXB4GqLbrQTxqwictEmCqcwA2FsvTXLN8zFAu5Jov3I1z0cLkKYmbPNLLfbl3mCngQ2OQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文EvalMuse-40K : A Reliable and Fine-Grained Benchmark with Comprehensive Human An</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626967&amp;idx=1&amp;sn=569bb2e5c9d190e8344306e75cc4ed36&amp;chksm=9739558e53eeed1e375e7205038962087488194a6f1eaa1b445dcf13af53357910bbe9119feb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 07:14:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[港大达摩院【视频AI任意门】，向视频无缝传送物体，同时支持准确动作控制]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuKx8Tf0Qh6ibA9zic48lRQib486mMt1mumtzFYBwbsLugRUic0jZYuZWAC1OdaickwuRLvJTqHnRWWDQg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文中，香港大学与阿里达摩院联合提出视频任意门模型，该方法支持将目标准确插入指定视频中。在该过程中，提出的方法可以准确保持参考目标的身份信息，同时根据给定轨迹进行精准动作控</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626925&amp;idx=1&amp;sn=bdfd5a2a33a8e8e720ce68d1ba75b567&amp;chksm=9709ea2b46c820203b066bbf9d106a969a1a3093e8ba7beb8c4c2ae376f14b8428dc5612371b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 04:12:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复旦&amp;字节提出CreatiLayout：基于布局进行可控生成的大规模数据集与新SOTA！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTugscIicNzsZVGSRHIIzKzXibMtxgOUbNA0LSevmIel7sb8Me3MTaoS5ey6vcDy6lNFa1ToNUdO2kxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文CreatiLayout: Siamese Multimodal Diffusion Transformer for Creative Layout-to-Im</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626848&amp;idx=1&amp;sn=8941adfd251296ff6513d31e651b718e&amp;chksm=977adfa6fe5a893c3a3360f0f305f1bd3a8c097e362037d21f7c53c01892c96aa6cb3ce4cfaa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 04:38:16 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NeurIPS 2024 | 基于内联先验引导分数匹配的稀疏视角三维重建]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsib2U1PiaV7JSR2yroGGPvdKBSOZicMM4mOdnyLmAf1HO1405bYbq2L0ZNvicGnRbpmrXBfSGJRRC2sg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享 NeurIPS 2024 论文How to Use Diffusion Priors under Sparse Views?，北京航空航天大学计算机学院李甲教授和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626787&amp;idx=1&amp;sn=3f92e6bdc04acf7f11f0ed6ba0c19913&amp;chksm=97b420830d817f29849e95461c47e84bda00d81e785a1eb29f8c5df76dfcc2cb3c61977e018a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 Jan 2025 06:33:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[顶尖性能，训练成本仅1/10！中国MoE一夜爆火！大模型新王暴打GPT-4o，训练成本仅600万美元]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuSfdo5Vd2libLKcfF59OgJDqyf8JHdcEMicLeC58iam94ZicJm94gdeGhIB3cxoc2nP88JibPX62FhkRg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美一夜之间，来自中国的大模型刷屏全网。DeepSeek-V3，一个拥有671B参数的MoE模型，吞吐量每秒高达60 token，比上一代V2直接飙升3倍。在多项基准测试中，V</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626775&amp;idx=1&amp;sn=c2372b1b3ab8ec18e5bfcfc4bfd7cc0d&amp;chksm=97ff77a8d53a023b7b09dab5476967714ac6582d19b9bf1757ca41a59c31b5f5dd5cfb7d30e1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 10:15:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AAAI2025｜IMAGDressing-v1：南理工提出新的图像生成任务，可定制的虚拟穿衣，数据和代码已经开源]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTupWyR6G0utic3JgefibvLkrwQV6TeXfYXRMic8XF4N2XZJgb4wCmHWOTZJXdD678jq2SDomtkEXmSQg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享 AAAI 2025 论文IMAGDressing-v1: Customizable Virtual Dressing，南理工提出新的图像生成任务，可定制的虚拟穿衣</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626744&amp;idx=1&amp;sn=47f7065d1f1189920f27e4acd3c2b409&amp;chksm=9737a8f7355434a1182df2eb3d89a89f4166e0a48804e7b6af9e86d3914bb68923923d868694&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 13:20:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[3D凸体投影：使用3D平滑凸体的辐射场渲染]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtE51SoPt6aB6W2xQqjXhjEtxiaPvvWAdDEEwQMWTic3jo5ib2a9jM8iaQMJpfibcYmdkIRkHQUSsP7BQg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文3D Convex Splatting: Radiance Field Rendering with 3D Smooth Convexes，3D凸体投影：使用3</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626721&amp;idx=1&amp;sn=9aabbb152938c118d09f0ab0de503d00&amp;chksm=971c04ca1b0b26e8ea114927271e480011b65a3cce1b2c2f24baacf688b7fd0b4d4a10dca750&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 14:11:29 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AAAI 2025 | SparX：一种强化Vision Mamba和Transformer的稀疏跳跃连接机制，性能强大已开源！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsbPTOjZSiaicAOsl7GG4zlZkwY1T5ibr3WYrrEqf2gcUGzsGbl9vIkzlpicmFPujOAicibrrMJNXCEibVDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享 AAAI 2025 论文SparX: A Sparse Cross-Layer Connection Mechanism for Hierarchical Vis</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626692&amp;idx=1&amp;sn=7d22b41dccc06bc22d40db584345fff4&amp;chksm=97aa4f70929199d055ee67d79bb51ab012917feba32b63825ed98b8b82d986f4c8ffc006ef8f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 13:21:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AAAI 2025 | 探索对抗训练的概率分布偏差：DPA 双概率对齐的通用域自适的目标检测方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsbPTOjZSiaicAOsl7GG4zlZknryx5THRGIfcaWTPtMznKN6T0r0vVHJBeIiaDN8RszYxtYp0ocCoc8Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美论文名称: Universal Domain Adaptive Object Detection via Dual Probabilistic Alignment图1. U</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626691&amp;idx=1&amp;sn=bd46cccadd703fe880d20dc4e06a9b50&amp;chksm=9790aa86f22f4b7c89434be7de74c51ff96713fb157b2cfd78f7d8b5f0e801639cdf9bd31ca1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 12:39:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[UniReal登场：用视频架构统一图像生成与编辑，还学到真实世界动态变化规律]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsfWk7cPNcR5Xe3oIfFrIdqmWatPYc4Soyjkmj3VvscvwnRZ7ut316SZd2ef87NIn3W1BMxQSx70g/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文转自机器之心。论文一作陈汐，现为香港大学三年级博士生，在此之前本科硕士毕业于浙江大学，同时获得法国马赛中央理工双硕士学位。主要研究方向为图像视频生成与理解，在领域内顶级</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247626691&amp;idx=2&amp;sn=abb4f1bab3ba3f97cc37fe03a924332b&amp;chksm=97e1702e24636ebb91c63ead02a32cedc2f9e416a0e051570cf37b5c4790abdb61747bc9fb96&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 12:39:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
