<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[我爱计算机视觉]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[我爱计算机视觉公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_e07180c244d1.jpg</url>
      <title>gh_e07180c244d1</title>
    </image>
    <item>
      <title><![CDATA[ICCV 2025 | DiT4SR：融合扩散Transformer的真实图像超分辨率新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLJweSZT8y09sh3cyP3BT7JvLA8jHHUxyZzXT77CRE7Xm9juDJw3jtictmNiaTHcK9LicSupHd365Vw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美预训练扩散模型与Transformer架构的结合在图像生成领域表现出色，但在真实场景图像超分辨率任务（Real-ISR）中的表现仍有待提升。本论文提出了一种名为DiT4SR</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630558&amp;idx=1&amp;sn=962b4089b4000903cf03387e90eae28a&amp;chksm=97442f2e7203a656f1ef8a27dbb68465c3359704fab3c103d775c5fec4fcf899441fffa21bd8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Jul 2025 03:44:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MedIA 2025 | UN-SAM: 域自适应的通用细胞核分割基础模型，自提示生成改善临床效率]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvb7JCRE5zeIC7WV9g7FvE0ZrAupEcOG9IicAm9EZMhobN0SonBbOvmxm88UiaeN8vwruJcDsRgvzTw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美论文名称：UN-SAM: Domain-Adaptive Self-Prompt Segmentation for Universal Nuclei Images期刊名称：</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630544&amp;idx=1&amp;sn=2c10f31702900fa462f0f8848affdd56&amp;chksm=97012f622dae434c424780514f09127472a2767b62fb9702cf90c18c649e0d037300cd435b83&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 07:46:03 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SIGGRAPH 2025|视频超分新范式：双向解耦式生成任意长视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvb7JCRE5zeIC7WV9g7FvE0T60KudC5t1sY1p8EBEbVwTA1xy6CGKgJIje5sErlQ1kiaVDp3uic5TsQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美在短视频爆火的时代，你是否也曾遇到过这样的困扰：手机拍摄的生活片段模糊不清，老电影修复后画面闪烁，AI 生成的虚拟场景细节失真？视频超分辨率（VSR）技术正是解决这些问题的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630543&amp;idx=1&amp;sn=4b1953a38166d2cbc91276b6c64d56bb&amp;chksm=97dc681bbf44413307e2fba3e893769417cfae6f6db459a3246f0fddfa5af86b0068b321ce3c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 03:47:53 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACM MM 2025 | 阿里推出轨迹可控且多主体一致的视频生成模型Tora2]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvt1XmFC5CibEykaiaaic0R9cTl27nlaZkoPZibsBuk573AUjyyyrIHOmmyYvdgS8HkwLzUO980vG552Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美Arxiv链接：https://arxiv.org/abs/2507.05963Project Page链接：https://ali-videoai.github.io/T</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630503&amp;idx=1&amp;sn=f2894a4c1092850ae68d079c80d0332f&amp;chksm=978ba1472710740b57e767be6c859397446810aff47675758a2cbc1d2ca9109fc5e405d3b955&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 09:21:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | DenseVLM，解决“分不清主角和背景”的难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvt1XmFC5CibEykaiaaic0R9cTSgxkZNmAcfDJzRBPBJajICvBcEeHgC5MSpGJlJiaOhUSwTnGm1B9sug/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享ICCV 2025论文 Unbiased Region-Language Alignment for Open-Vocabulary Dense Predictio</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630487&amp;idx=1&amp;sn=e96c17d0033a912dfff348e42531de2a&amp;chksm=974cad374a04784a94cd94e8d17f6d8fa9fac1b6a6ab4e3e0596608e1c2593544f976428d9c5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 04:23:30 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[为何说 “在国内做科研，最忌讳踏实”？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTueQaX6ltgYShFyK1pnuZWVp8IlNvp3qHcncYK2jCYR4BN21qzcaVibjMc7DLMFiaq7JTGmve37f3VQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近经常收到读者的留言 : 抱怨科研真是太难了，竞争压力大，导师不给指导、不开组会，一年见不到导师几次，对于论文初稿、毕业论文毫无建议! 无论什么专业的研究生，面对这样的情况，很有可能都要陷入沉思。万</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630477&amp;idx=1&amp;sn=19ff19f70abab15f74fbdc94820a8e8c&amp;chksm=97552684ad3c247d7f662e543a9b347ea4e7cd4ac0c58d070be21b823feb47d134bcddabc1a1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 05:15:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像生成新基准来了！57 项任务全方位拷问模型生成力，谁能交出最令人满意的图像答卷？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTulGDK1y4dUPQbaHBiaK0P0W4YvicTeAsjxnumIZnASWAFXKOy9Yd0tsoAZibicic6l8zgGW5Da8w94uRA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美“请生成2018年泰坦尼克号的真实状态。”这句看似简单的指令，实则隐含复杂语义。不仅要求模型生成符合“泰坦尼克号”外观的图像，还涉及了对历史事实的把握。2018 年的“泰坦</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630477&amp;idx=2&amp;sn=ce35c4a3f69386e0a6ad189f0296f530&amp;chksm=9753530624307b14138343200a36cef25f32897a499a3112810fc292e7a3949d75db5d472eb8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 05:15:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 武大&amp;通义实验室最新研究SemTalk，首个实现“节奏-语义解耦”生成的共语动作框架，语义与自然性双优]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTueQaX6ltgYShFyK1pnuZWVWIg4KyFh0myA4PIz1smVUJjdIInO4kIsZaIFgoc4TVQVqaekPKt31A/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文介绍了武汉大学及阿里巴巴通义实验室的最新研究成SemTalk(SemTalk: Holistic Co-speech Motion Generation with Fr</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630476&amp;idx=1&amp;sn=1f84226969308688a4e44c0952564b68&amp;chksm=974b03778dda8dd3eb2b30eea08718e7538513909cf6509994f5e3b3e417303f2a3e9a806849&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 03:22:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 局部对齐的CLIP零样本学习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTulGDK1y4dUPQbaHBiaK0P0WAydDxxxTQWyiajoGuMEIEJE2J0KQXyKmVHZwgXGIhYSoKxaEjc4HNsg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享ICCV25论文Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Mode</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630456&amp;idx=1&amp;sn=30889c7cdd50fb8399ee0b1a9c5f079f&amp;chksm=973ecfe800035df7c435e237fa4505bc0ce7fb32252a94bff43da2eb0dcffebe6e86b53cb7c8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 08:39:25 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 零样本、无需训练的交互式运动编辑算法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTulGDK1y4dUPQbaHBiaK0P0WCLErsEFEPmZmvia7PEWFudDjcGd6KRyXu6C8XzgeicxojYCrPOXCom3g/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美导读：论文《MotionDiff: Training-free Zero-shot Interactive Motion Editing via Flow-assisted</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630455&amp;idx=1&amp;sn=4cd0a6dfcb6a0177944a368caaed92c4&amp;chksm=974f2a8271f7944b72ac7bc3210eec9871340046bd3a3b1391ca546431b098eaf98e19d3151a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 05:56:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | SewingLDM：一句话+一张草图，3分钟生成合身数字华服]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTud5P6XujwO9OMcTfySQrKkPD953bmP8fTyhgZicSJbbFsp7LyHkQibicsc9q4E9cZwpOmQbic38vF3eg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美论文题目：Multimodal Latent Diffusion Model for Complex Sewing Pattern Generation论文地址：https</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630404&amp;idx=1&amp;sn=d7fec65aa2e589a31dbe165e00a5527b&amp;chksm=97bffc064a55c8803cd2d25ef61270274802f54ff2b195fad13c018e22524cfbec0703d05b1d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Jul 2025 10:42:09 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV2025 | Skip-Vision，为视觉-语言模型打造通用加速框架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvtVreNnrZ9HWPrwmPNyWSJuoqFuOZicDq8sLTpHwH2sCwxsxZMfld2NpYYfqu6ia4vlpxsPnznbAsg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美近日，上海交通大学人工智能研究院晏轶超副教授联合蚂蚁集团的研究团队创新性地提出一种通用的视觉-语言模型加速框架Skip-Vision，论文Skip-Vision: Effi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630371&amp;idx=1&amp;sn=311722c740f7663e54fada455cd66aa5&amp;chksm=9720e63e271599f3085b1a22e47dcf8fef1f5ff8cd9f773a4eb6acedfa44465a3f7cb68655e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 06:27:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南开等提出REG方法，直接、高效地利用判别性信息，几十倍加速扩散模型训练！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvtVreNnrZ9HWPrwmPNyWSJ23hPOxiaYTqsG1dgqy0EfeoPPUniaq9Mqoc9CiciaIF2TcAeJXXmoERuKg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文Representation Entanglement for Generation:Training Diffusion Transformers Is Mu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630360&amp;idx=1&amp;sn=a8b77285c57e14ee1a56f7447616a4e2&amp;chksm=97a9492c114fe95f36e375b61d6830f4f3d85b900691724d171fb7cb426bf767d702e22366d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 03:32:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 南开等提出REG方法，直接、高效地利用判别性信息，几十倍加速扩散模型训练！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsXzdJ3vib1r7VpK7ibttmfUtINiaXmnNXbwItdl0pAdliaFbdF7QupRybRycapORNR5fdUujo1v6YROA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本篇分享论文Representation Entanglement for Generation:Training Diffusion Transformers Is Mu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630349&amp;idx=1&amp;sn=663effe1c12adc3bf65ef672c0702dbc&amp;chksm=97a9d9d344f06035dcf67b2640d96f03fcd3f433025859da9ed8016b55d5de1ffc8321364fb9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 01:09:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 武大等提出TurboReg：超高速高精度点云配准方法，比现有SOTA方法快200多倍的速度！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsXzdJ3vib1r7VpK7ibttmfUtwCxicZrY8CEiaFO3tONftmu24Bcfd6XXd84vF7Sx0C7QxM2eCTvnNPCw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文分享最新公布的一篇ICCV 2025论文TurboReg: TurboClique for Robust and Efficient Point Cloud Regis</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630339&amp;idx=1&amp;sn=0587adbb8dc3916c3d694088790aab73&amp;chksm=97a51dcfd90f414d128612ed7567399ea74b313b5f64192cd3aeaa3434d2bd45a8aaafaace28&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 00:20:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[上海交大提出FixTalk：告别“恐怖谷”，让数字人灵动又逼真]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsXzdJ3vib1r7VpK7ibttmfUtCDI8mJGuvLO3cFO2Eha7iaaac5VeLibgOicvP7B8oe4ibcDBCkOMM55c8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美向大家介绍一篇数字人相关的“说话人脸生成”（talking head generation ）的最新工作，来自论文FixTalk: Taming Identity Leak</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630327&amp;idx=1&amp;sn=aa97a911cd6f53447daf778aba070a40&amp;chksm=979df9ca156230744ea33026ce1e3aef24c37e30a4f21ff5e04c2415ccb320ba847dd8490825&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 14:56:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[新疆大学等提出DiffMark扩散水印算法：为数字身份打造对抗Deepfake的“隐形盾牌”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsXzdJ3vib1r7VpK7ibttmfUtApKGgUIqFSYNnpjibPf1jyHJiaZDYFSBpx9KnXcF6BdCYkHxPGnkmalA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美本文分享今天新出的论文DiffMark: Diffusion-based Robust Watermark Against Deepfakes，该文提出一种名为DiffMa</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630316&amp;idx=1&amp;sn=de9d87b9ae8dce217f34edfa4480dabb&amp;chksm=97883b33146ff672cd2c609caef8dfcab74079953a2161533862a77da7148360d52e3d5f0924&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 11:22:49 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[助力汉字识别与文化传承！首个覆盖近十万类汉字的超大规模数据集正式发布！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvzcUgz6hIJtTupvOsrtXdZdFSKflibVAdtdnjoNKD2RYaKNTaFBYDCHvCr3nQQJtBSBY2A5u9CQicw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美导读：  随着汉字数字化、古籍保护和智能应用的兴起，如何精准识别海量、稀有、甚至生僻的汉字，成为人工智能领域的一大挑战。现有数据集受限于类别数量和样本分布，远远无法满足对“</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247630303&amp;idx=1&amp;sn=0d14f46427ab1730f816398ea2172eee&amp;chksm=970326a700a3ab24637c54a6007e8fd5829dfd63e1edd949bd44aa9018a94e83ab3cc42b6687&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 07:15:00 +0000</pubDate>
    </item>
  </channel>
</rss>