<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[我爱计算机视觉]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[我爱计算机视觉公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM6aYkwkiboia6lA9D7ANy49WBe9icxn5NQqJjvn4Pyntzvfw/132</url>
      <title>gh_e07180c244d1</title>
    </image>
    <item>
      <title><![CDATA[苹果发布Manzano：一种简单可扩展的统一多模态大模型，其混合视觉Tokenizer统一了理解与生成任务，性能SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wIsoRYib0JKCUlhhrHugkWBCIibAVOqCbcCGOoAanyatS0tJw0IrKyoWYg/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍来自苹果今天发布的 Manzano 模型，这是一个简单且可扩展的统一多模态框架。它通过创新的 混合视觉Tokenizer ，成功地缓解了多模态大语言模型（LLM）在同时执行视觉理解和生成任务时</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636580&amp;idx=1&amp;sn=654a4b72ba9c5ea364df032e95511d27&amp;chksm=97dd8540121a6d773a01155baa9910d2ff41e24fd2e099c910c61e07d3cc421901318363e298&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Sep 2025 11:50:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动SAIL-VL2登顶OpenCompass，开源高效多模态新标杆]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wIIplATVwRYAckyibx8HDnCKfzOHSnEcEg88ZwOJe7icPYTJCUplDVps7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，字节跳动 Douyin SAIL 团队与新加坡国立大学 LV-NUS 实验室联合发布了其最新的开源视觉语言基础模型（LVM）—— SAIL-VL2。作为其前代 SAIL-VL 的强力续作，SAI</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636580&amp;idx=2&amp;sn=63cb646ee1a1422fa467d1c2f577cd35&amp;chksm=97abc06b0feaeb11e64f19a10ce6f77679ebfa962b96e6fe9015d8a6678663055c7cd53041b1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Sep 2025 11:50:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[博后年薪40万到90万 | 东方理工朱文韬课题组招聘AI方向博士后、研究助理教授、访问学生、实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wI8Ix01Ul0N8yz049posJFuicvJwlBGF3EecvwU7F9AHlEl8PlTFpwpgA/300?wxtype=jpeg&amp;wxfrom=0"/><p>【博后年薪40万到90万】东方理工朱文韬课题组招聘AI方向博士后、研究助理教授、访问学生、实习生宁波东方理工大学宁波东方理工大学是一所由社会力量举办、国家重点支持、省市共同建设的小而精、高起点、高水平</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636580&amp;idx=3&amp;sn=6c065d6c8461c14d1374e535506b6e8a&amp;chksm=972a64a1df7373873ef181f04bde6e07eca9ee23ced8e0b32eb08586aa2747a38d602a01f4e0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Sep 2025 11:50:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别视频“抽帧”理解，美国东北大学新算法GRT算法实现高效可扩展的高帧率密集视频理解]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOQ1iaMicr3QclWE27SVl7NOMMz3zWBicFS5W0fQezetW2hMVsvrFemXltA/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前的视频大语言模型（VLLMs）在处理视频时，普遍面临一个核心瓶颈：为了节省巨大的计算成本，它们不得不“抽帧”处理，即只对视频中稀疏的几个关键帧进行分析，而丢弃了绝大部分的密集时序信息。这种做法在处</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636505&amp;idx=1&amp;sn=4e4978faf6a8b3d85bc374f54498901d&amp;chksm=97d12b2cfbc4b6d428f4c2acaa5262ef70e52ede85cd96fe0a88f865abe607147a759fcd17fa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 21 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[【招生招聘】阿卜杜拉国王科技大学孟彦达博士组全奖博士、博后、实习、交流生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvrpy6G01cVWkU3z9NrpIzs5QkM0mpswQVncWyg4DEqFSFgG2cCicJUWxXeWALBrWu6hvoicRje85AA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在英国求学与工作八年后，孟彦达博士将于 2025 年 10/11 月 加入阿卜杜拉国王科技大学（KAUST，US News 世界排名112） 生物工程系，担任助理教授（独立 PI）同时挂职于计算机科学</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636505&amp;idx=2&amp;sn=831ebaa40cf75cd61781e65f1c165c92&amp;chksm=97a96b547cf1efd520bc6ca45b39139a5372ddd3817e763273a93c6d9f382932a43e45e1c8ea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 21 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | DiffMVS/CasDiffMVS：一种置信度感知的扩散模型，实现轻量且准确的多视图立体三维重建]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOict6ibia8kPFOGPcFAXKgpO5fbEEtKE4D2XYfuc8Qb9kfhaVCeKGEXTHg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天要介绍的论文是来自苏黎世联邦理工学院、南洋理工大学等机构的研究者们发表在 IEEE TPAMI 2025 上的工作。该研究创新性地将近期在生成任务中大放异彩的 扩散模型（Diffusion Mod</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636472&amp;idx=1&amp;sn=2f08b9ffe438978def1d931f45ffdd17&amp;chksm=97cecac4a02d9ceb551d4f9e893e360a3de418c9db93647032f2b7dd13c604779792924cca8c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 20 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[北大等提出BEVUDA++，首次解决BEV感知跨域难题，夜间检测性能提升12.9%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOPuPs6P4zu7iacibbSq8yHOc359ianFcCiccWBxlY7DP5L52omg1DS2GIbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在自动驾驶技术中，以视觉为中心的鸟瞰图（Bird's Eye View, BEV）感知方案正变得越来越重要。然而，现有BEV模型的一个致命弱点是“水土不服”：在一个地方（如晴天的波士顿）训练好的模型，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636472&amp;idx=2&amp;sn=0a7874fbf6512d86f1573a350bdb2ff8&amp;chksm=97acdc94888b9fe33a9eb689d29c53068ebb89f6bda04298bcffa671281cec42caa01e349f9e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 20 Sep 2025 11:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta新作SyncSeal：用深度学习“封印”同步信息，让数字水印不再怕裁剪和旋转]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOIyQ3vgMAwXXM7fKe50y3qK39q17C0N1q4frMOQqDRKFQAaBiaHH07Nw/640?wxtype=jpeg&amp;wxfrom=0"/><p>数字水印是保护图像版权、验证内容真实性的重要技术。然而，传统的水印技术非常脆弱，一张带水印的图片，只要经过简单的裁剪、旋转、缩放等几何变换，水印信息就可能“失之毫厘，谬以千里”，导致无法被正确提取。这</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636428&amp;idx=1&amp;sn=5f34ca69ea54fb2f10530fe0b8f03dda&amp;chksm=970e32cf5613e6ad1845a0f3f68da6465482080fa2cc7707016de4f7de24e149d9f9b1d0dad7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 19 Sep 2025 17:00:08 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿联酋大学CVLab IEEE Fellow团队招收2026春季/秋季全奖博士生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuYdz0aIspu7uSag2Jx2xsOZx5z5YrfwtbNRR1NL4QjnD3Ubb6D81gric0WujqEAt4281AoLlrPywQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿联酋大学信息学院计算机视觉实验室（CVLab）IEEE Fellow廖胜才博士团队招收多名2026春季或秋季入学的全奖博士生。现开始报名2026春季博士，2025年10月8日截止报名。这一批次的学生</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247636428&amp;idx=2&amp;sn=2d47ad2395a42d37c30c6aaa4a78ed0e&amp;chksm=97118fd278cf026b878c84a984c2c1c70b08ab22afc1d6e4fb0268cd3f94a508f5b1d370a142&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 19 Sep 2025 17:00:08 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | 弱监督与自监督引领自动驾驶运动预测新范式，用场景分割“脑补”运动，仅需0.01%标注，性能媲美监督方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTur8IPrMT4ibM3LyLSw1GMGj9Q94pUmJqL63NGz0Kp6KuIGyTgCv99RsDWyC2w5PPHUDEib8xqmyOPQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天，介绍一篇新出的来自南洋理工大学和商汤科技的研究者们发表在顶级期刊 TPAMI 上的工作。这篇论文 《Weakly and Self-Supervised Class-Agnostic Motio</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635832&amp;idx=1&amp;sn=acf490d444da8c86aced6da215c3dbba&amp;chksm=97b9cdc23da11829e3bac23e3a8f75d789b7d6314f2592bd3184e0846303734d61c4b664e47e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Sep 2025 00:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南开大学等提出RAM++：从关注“降质”到关注“内容”，实现鲁棒的全能图像恢复]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTur8IPrMT4ibM3LyLSw1GMGjBcZ6S46LfmHOQiajE2jtiaoKTPIuU2AmZicyTzc94rE6l1hMJtmibMBWOQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>当AI模型面对一张雨天、雾天或充满噪点的模糊照片时，它应该先“识别”这是什么类型的降质，再去修复它？还是应该直接“想象”出这块区域原本清晰的样子？来自南开大学等机构的研究者们在一篇名为《RAM++:</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635832&amp;idx=2&amp;sn=f302f17c2a71911780d8de6d8c27dd8a&amp;chksm=976ba803640a211f63217447f194f0f90292983a09e9349add9a6e807d24a19e8de6430f10dd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Sep 2025 00:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯、复旦、上海创智学院提出SwiftVideo：首个Continuous-time视频蒸馏加速框架，实现业界最快最高清视频生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTur8IPrMT4ibM3LyLSw1GMGjRYtYs8Ozbjrkbliapib6gPrWHmiaSDwwibibhJNAgdAWzxUZARKrOf8M04Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇分享论文SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635762&amp;idx=1&amp;sn=9bcf9c12c921cd70c07fbd69020f731a&amp;chksm=9743f0e2723a0d668d6753137e1781126f3d2ec15039584bb5bf1995f8f3785e12c0d7b46bbc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 17 Sep 2025 11:03:10 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[斯坦福大学提出PSI：一种通过概率结构集成，从数据中学习可控、可灵活提示的世界模型的新系统]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuVUGiajwiaF5fKpXGW3qjkdib5kDaM5wxxM1HbqpP58wcNagcCfSFzX9c25SxuwjibUkEBBmq7zv6GFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文将为大家介绍一篇来自斯坦福大学的最新研究，该研究提出了一种名为 概率结构集成（Probabilistic Structure Integration, PSI） 的新系统。简单来说，PSI是一个可</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635570&amp;idx=1&amp;sn=790cb09aaf9244cf72289af560e04e1d&amp;chksm=97e4f2d7bdf1b7637424350c6340b5c5769c8f67601a2a26b0926fcbe81082ddddc85110a59b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 16 Sep 2025 13:37:44 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[BMVC 2025 | 无需源数据，Grad-CL如何利用梯度引导实现精准的眼底图像分割？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuVUGiajwiaF5fKpXGW3qjkdibLg0YKXl55ictFKVRolOu14G9qztglADeicPQWR0HdYfvNUWZRewwvBOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在眼科疾病诊断，尤其是青光眼的早期筛查中，对眼底图像中的视盘（Optic Disc, OD）和视杯（Optic Cup, OC）进行准确分割至关重要。然而，深度学习分割模型面临一个严峻的挑战：在一个数</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635570&amp;idx=2&amp;sn=f1506bbde99ed12911f604b596379c63&amp;chksm=9755578ceb76beb585f5a0ed27defe59db5af0f523adf6664fc2242c3516a36f63ebd021b7f6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 16 Sep 2025 13:37:44 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[超越GPT-4o，蚂蚁集团与南洋理工大学提出LaV-CoT：首个语言感知的视觉思维链]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsia3cw9WQic7PGxiatsic0iayOB4gFRXn5ZMNQgX22GFs31X0Ra3HffTQzrZIDpxBrtZwpa80d8rK37iag/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大型视觉语言模型（VLM）的飞速发展，它们在处理复杂的视觉问答任务时展现出惊人的能力。其中，思维链（Chain-of-Thought, CoT）技术通过模拟人类一步一步的思考过程，极大地增强了模型</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635405&amp;idx=1&amp;sn=3862a4306a3b99bc4bacdd0da7befbd0&amp;chksm=977b42a9d0ba212af98cb0fa58b736a031c41f6fdd2a1c6b499f33dcb9b32cd0940d2785fcbe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 15 Sep 2025 14:55:25 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepMind与牛津大学提出LayerLock：用渐进式层冻结实现高效、无崩溃的自监督视觉表征学习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsia3cw9WQic7PGxiatsic0iayOBUh8IGt7MZg6PgT3hwmYoZNHunNZ55zIkr1rQcP1hVFMYXPRQUv399A/300?wxtype=jpeg&amp;wxfrom=0"/><p>在自监督学习领域，如何让模型在没有标签的情况下学到有用的视觉表征，一直是核心挑战。其中，掩码自编码（MAE）是一个明星方法，但它依赖于繁重的像素重建任务。另一条路是预测网络自身的“潜在特征”，这更高效</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635405&amp;idx=2&amp;sn=50dcc6f4c0a98de0d85c59048d76a703&amp;chksm=97c30588ff71ea3074b66790adfa5f0fb1bfa0ce59c2580d47097f3acc43676edfeb1560fd75&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 15 Sep 2025 14:55:25 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[耗资15000个A100 GPU日！港中文、阿里等发布600万规模T2I推理数据集与基准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLlCzQhzYhGQU5wVYAguiaD9ckc0E6PFslOrsSZwrFVuTs5uicPSOqicjEt69MicXhDfaULmkzBOGcbA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，文生图（Text-to-Image, T2I）技术取得了飞速发展，但开源模型在处理需要复杂推理能力的提示词时，其性能仍与顶尖的闭源系统存在差距。这背后的核心挑战在于，社区缺乏大规模、以推理为中</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635294&amp;idx=1&amp;sn=1b1de9160c5b724c6deb2a9a124614bc&amp;chksm=97920d961a0f8eb89b4983977ac2944a488b4574ee09830a16fdf303dfa51f07ccb18023a043&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 14 Sep 2025 11:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[INFFUS 25 | FS-Diff：一步到位，用扩散模型同时实现多模态图像融合与超分辨率]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLlCzQhzYhGQU5wVYAguiaDHp3iaLcCO4Cb5T0nJ2usE46MWggnzHgwgb3pJsqgd7ibqfzJH3XChuJg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在许多现实场景中，例如无人机侦察、自动驾驶和医学诊断，常常需要将来自不同传感器的图像（如可见光和红外图像）进行融合，以获得比单一图像更丰富、更全面的信息。然而，这些原始图像往往分辨率较低，甚至可能因为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635294&amp;idx=2&amp;sn=7edf94571b2b13a04b516caa4979b351&amp;chksm=97271fa039e10ded81735ea3f724a0b280815bd1737101d379bbc373c8394456592251e5881d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 14 Sep 2025 11:30:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[让机器人“大脑”更轻更快：SQAP-VLA首次实现VLA模型量化与剪枝协同加速]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLlCzQhzYhGQU5wVYAguiaDJt04XYn18bvDia07bCzR1sSE6H5e9U16vn2ZzrBX5wRPqUJiaEfGN6jA/640?wxtype=jpeg&amp;wxfrom=0"/><p>视觉-语言-动作（Vision-Language-Action, VLA）大模型被誉为具身智能的“大脑”，它让机器人能够理解人类指令并与物理世界交互，展现了惊人的潜力。然而，这些模型巨大的计算和内存开</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635226&amp;idx=1&amp;sn=cdf3e866b16789ac1676a0aca13141b9&amp;chksm=972f0d0f81c4ecfaf4227e156149c25ef85169424afae4635cc2f2ec7872da71dd1e0d74c78b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 13 Sep 2025 18:14:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[成本不足60美元！开源U-ARM：让机器人模仿学习更亲民的通用遥操作界面]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsLlCzQhzYhGQU5wVYAguiaDEoJBl9l65LlZibvoYdm2NWF1falibicZwpDsicicBnsc3mpacoIRDtvsIug/300?wxtype=jpeg&amp;wxfrom=0"/><p>在机器人学习领域，通过人类演示来教导机器人（即模仿学习）是最有效的数据收集方式之一。而“主从遥操作”（leader-follower teleoperation）系统，即操作员通过一个主端控制器（le</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635226&amp;idx=2&amp;sn=1903f9aa58a75293eb2b9ff708f0ec63&amp;chksm=970ff3272319c3366b57c644e55d59b1a3d4e01ec4239fcc395480997e819b8c33f2b050e6c6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 13 Sep 2025 18:14:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICRA 2025 | TANGO：机器人告别3D地图，仅靠RGB摄像头实现零样本长距离导航]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTumkrJXfuQ7kKHWJbDdY86YcfewhQeBWXJSZvHXx87RqpX8kYysDCRiaeTzEkBevt2an7t236fUv7Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>让机器人在复杂、陌生的环境中自主导航，是机器人学的核心挑战之一。传统方法通常依赖于预先构建的、全局一致的三维几何地图，或是通过大量数据训练得到的端到端控制器。前者构建和维护成本高昂，难以适应动态变化的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247635082&amp;idx=1&amp;sn=79151da724bb8475292b6c3ee56e56f9&amp;chksm=9730613a6ce1ac82c716613fe07649608d7771ad3895e8cc373878fb0af7c9d51af9582820d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 12 Sep 2025 12:24:19 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[RewardDance：字节跳动提出视觉生成奖励扩展新范式，破解“奖励劫持”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsVASZWLEjOlVNSX15mdb0RWBRk5eAQsA4ASAjQr6iapiaUTxbFqFEAAzVaCHRw6O6dicIBRwxkg672w/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，来自字节跳动 Seed 团队的研究者们发布了一篇名为《RewardDance: Reward Scaling in Visual Generation》的技术报告，提出了一种名为 RewardD</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634818&amp;idx=1&amp;sn=c51b82bbf92da1cccdc3224c2a4d9ea4&amp;chksm=9713fb5e2aa924d21114266ba03e85f693dcae8ffa91bb800f5be229895fab2fce77cb069884&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 11 Sep 2025 12:28:40 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | H2OT：分层沙漏型Tokenizer，重塑高效视频姿态Transformer]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtbvdOZNia0MkibzpTSGFBAibEjMcibKxGCOGPMAg8F3fca2X29XRSzRlNTr0qsgj8o6icxIhMeeZpu6gw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天要介绍的论文是“HOT: Hierarchical Hourglass Tokenizer for Efficient Video Pose Transformers”，它提出了一种名为 H2OT</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634586&amp;idx=1&amp;sn=201d9822f56f1d3b157eb7058f06f3b6&amp;chksm=97355fc54bce42f0736baac6164f3310f72c7b9eff2e2facab1d3c821bc7890e546a5bd71458&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 10 Sep 2025 11:35:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | IGEV++：迭代多范围几何编码，刷新立体匹配技术新高度]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtbvdOZNia0MkibzpTSGFBAibENqibdGYfJQibTib5icvibAkP71OH2Fm8fhYf0odEnw9NcicOvvR8gfFMKGyA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍一篇在立体匹配领域取得突破性进展的论文 IGEV++ 。该研究通过一种新颖的深度网络架构，有效解决了在病态区域（ill-posed regions）和巨大视差范围下的匹配模糊性问题，在多个主流</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634531&amp;idx=1&amp;sn=25ff5f0ef28510ed05d133067dff3707&amp;chksm=97bff079b90b5b30acd585100cea7284294f3c458cb5ff259356ba2706831d745bb843c7fd0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 09 Sep 2025 11:42:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IEEE TPAMI | M²Diffuser: 让机器人学会“脑补”，在复杂3D场景中实现精准移动操作]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuiaTyIcQwIMYwpfs83LJGEVjnvpHheVBkOibsrgrETR0d79Kia3tq8Ot5hFgS98iaSu4iansPTSlpqSnw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍一篇来自华中科技大学、北京通用人工智能研究院（BIGAI）等机构的研究者们共同发表的论文。该研究提出了一种名为 M²Diffuser 的新型运动规划框架，它创新性地将扩散模型（Diffusio</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634377&amp;idx=1&amp;sn=d481379d05769662a22a046f9276e507&amp;chksm=97169738ef61af8895d3d01651c279e54eab6ac532c83c920a1628f5511e21ef91c2611479bc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 08 Sep 2025 11:52:05 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大提出SSGaussian：注入语义与结构灵魂的3D风格迁移，让高斯溅射场景化身艺术品]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuhicr1RmNKvfaBOz7pGmBlbdkZ6obr9pqj18yBjKIeUp9iclMy21Eg2gc0M6ZiafEa596rxOQBEhuCA/640?wxtype=jpeg&amp;wxfrom=0"/><p>将梵高的《星夜》“画”在一个三维场景上，是一种怎样的体验？近年来，随着NeRF和3D高斯溅射（3D Gaussian Splatting）等三维神经表示技术的兴起，3D风格迁移成为了一个热门研究方向。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634228&amp;idx=1&amp;sn=7bdb6a3c4e2cea18bff1d9dae9831fbd&amp;chksm=970031411962fcd1bc6b0bfd1079c6cb89837b705b64912f9f562f8738191f42460870598d23&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 07 Sep 2025 11:40:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IEEE TPAMI 2025｜ PointGST：参数量仅0.67%，精度首破99%，三维点云处理迎来谱域新范式！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtdiaupEC6STNZCqDcbBao0ia5E1AcwD9Kt2icdT2fyVJlTHicZaDtYibiap7Fr07nnVPZibVxLfDpcV4ffA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大规模点云预训练模型已成为3D视觉领域的基石，但其巨大的模型体积和高昂的微调成本，正逐渐成为研究和应用落地的一大瓶颈。如何在保持卓越性能的同时，将微调的“开销”降到最低？近日，一项已被计算机视</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634178&amp;idx=1&amp;sn=46e7eb7c8f618d4c1e6a106407a7b1a3&amp;chksm=975520b55930a4bb26b3e0a8d67d44424dab8c40c27f4f5ec16a88c6fe28ab6b9900ccaac268&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 06 Sep 2025 11:38:30 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | MOSEv2 全新亮相，第七届 LSVOS 挑战赛正式开启！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuhicr1RmNKvfaBOz7pGmBlbiaQpMhdpVriaJnKNlQUic4I8bsEGLCnQgYJGMq0oohnNribrmZSpLArloQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大赛简介第七届 长时视频目标分割挑战赛（Large-Scale Video Object Segmentation Challenge, LSVOS） 将于 ICCV 2025 期间在美国夏威夷举办！</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634178&amp;idx=2&amp;sn=2ee5b982dc7ab850f78e84bad171db77&amp;chksm=97649dee662133dbf540538561b0d30d4fda363b56770afe19ab635d50df89b0c7224c19e2f1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 06 Sep 2025 11:38:30 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI重磅综述：一文读懂人类动作视频生成的五大阶段与三大多模态技术]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtdiaupEC6STNZCqDcbBao0iarB6rhE7ehYozzeJzr4byqgF4CLXia7vibTfto3Y8e2mQYU1DwTrDXjPw/640?wxtype=jpeg&amp;wxfrom=0"/><p>从能歌善舞的虚拟偶像到高保真的数字人主播，人类动作视频生成技术正以前所未有的速度渗透到我们生活的方方面面，展现出巨大的应用潜力。然而，该领域的快速发展也带来了技术上的碎片化，现有的综述往往只关注某一特</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634124&amp;idx=1&amp;sn=29db2279758b7c226c748fcb652a5738&amp;chksm=97eb23d3b2b0fec791db6721a58417df13f6137dd3068cd3f3b30882840ba0cc15a0d9524931&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 05 Sep 2025 12:31:48 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯 ARC Lab 开源 IC-Custom ：一个强大且灵活的图像定制化工具！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtrgmDwRqjuAJ99YVQtTtz8S1wUIicDCj1ibQiaxOEJ3qJQyPCIbQnEgwa3owkhlOBCgg7klW6Fqb4ng/640?wxtype=jpeg&amp;wxfrom=0"/><p>如何让AI根据我们提供的一张（或几张）图片，生成具有相同主体、但场景和风格各异的新图片？这就是“图像定制”技术，它在虚拟试衣、产品展示、IP创作等领域拥有巨大潜力。然而，现有方法通常需要为每个新主体进</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247634002&amp;idx=1&amp;sn=c26d3a3f4f424aac851ef51046350f5f&amp;chksm=97b1b4726175bdd9115803faca1fd61ec5b3ae0c414678cf32b314388616143f3ebab59b651d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 04 Sep 2025 13:29:42 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[USO：鱼与熊掌亦可兼得，字节跳动提出统一框架，完美融合主体与风格生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTs85VAeryJxCcyrib6LNAMEr2VHua9PQRU4u500wqGBwuCSmibOT5Uh3GFIHWzBIJe5V1EIDzna7uzw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在AIGC图像生成领域，有两个非常主流且看似“对立”的需求：主体驱动生成（Subject-driven）和风格驱动生成（Style-driven）。主体驱动：类似于制作“数字分身”，追求的是让特定的人</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633916&amp;idx=1&amp;sn=9210a6a9acc38dd3a4c518830b833955&amp;chksm=976d1003f9a620b2bc826d0c35e2a41585da28a50b35a5778fcfbfe5f2785b7db3b4af1be645&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 03 Sep 2025 12:29:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | InterVLA：聚焦第一视角感知决策，大规模通用人-物-人交互数据集与评测基准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTulRzNUialC9ibhCibFVZKHpo0KTcSRr5MIL1eadz9iaU4tRqhz7hR9icAQ0C9gjo9QU823ibibztql7qfwg/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，上海交通大学联合宁波东方理工大学、南京航空航天大学以及联想的一篇关于第一视角人-物-人交互的研究工作被计算机视觉顶级会议ICCV 2025录用，论文、代码、数据均将开源。论文标题：Perceiv</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633894&amp;idx=1&amp;sn=f88acedca2541a4ce4fb16a902946b4a&amp;chksm=973a51487824826a2e51a9eb879c7e03f54eace0f37750bb808067bf72bf48b1ccde02389291&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 02 Sep 2025 12:56:47 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动提出OneReward：一个奖励模型统一多任务图像生成，效果全面超越PS！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt2PiaYXouHjtyW6XDmZibGGGzqPojEfR49iaffKTC1QdD5fxN4EQmibetqjRfwvSWAqencb6CBSNkZpA/640?wxtype=jpeg&amp;wxfrom=0"/><p>图像修复、内容扩写、无痕移除、文字生成……这些强大的图像编辑功能，我们通常需要在不同的软件或模型中切换使用。有没有可能用一个统一的模型，同时精通所有这些任务，并且在各项指标上都做到顶尖水平？来自字节跳</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633779&amp;idx=1&amp;sn=3054505fa255a575def5cf950e11c767&amp;chksm=97b4a1c6a25cd22f38e839b2febc015303b431160e2b26171b1242768a54f97b363d31e2edaa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 01 Sep 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[POSE：100倍加速视频生成，腾讯混元提出单步对抗平衡蒸馏框架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt2PiaYXouHjtyW6XDmZibGGGFkD8juPmWXib5fJunWD1c1SXL0lpjTmSeE32X09R52S0WWOeicAIiaogA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，视频生成领域迎来一项重要突破。来自腾讯混元与加州大学洛杉矶分校的研究团队，共同发布了一种名为 POSE (Phased One-Step Adversarial Equilibrium) 的创新</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633735&amp;idx=1&amp;sn=f61f6f6dc7e7b4ce5bd56b101848759b&amp;chksm=97bec8cd2190e0505e9c95811cee056219c0933e6ded98e16c53ec9c287871ee205776e6c6eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 31 Aug 2025 22:14:15 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 AnimateAnyMesh：文本驱动通用网格动画新范式，实现高效高质量4D内容生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtf4XRHF89ZKb7IaWicpIgnlpr3cFDwPt7mxicuSy0odJvuSPzzjAAxScMqDcw7gqVt9rgKjGCf895w/640?wxtype=jpeg&amp;wxfrom=0"/><p>引言4D 内容生成，即包含时间维度信息的 3D 内容创建，在 VR/AR、游戏等领域具有广阔的应用前景。然而，由于时空建模的复杂性和高质量 4D 训练数据的稀缺性，创建高质量的动画 3D 模型仍然充满</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633723&amp;idx=1&amp;sn=e9eed6bd3d71d18fc2f4ef4271397346&amp;chksm=974c0ab5778df91a535dd00aabcc759509a17a4ae78d453f44d943aa5b687a9bf27548b3b600&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 30 Aug 2025 19:31:27 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[苹果发布MobileCLIP2：最强移动端CLIP，开源数据生成代码！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsV3X5r4e4W1QyOVr4sdCwhlp2tUmWk4JA2LP3aTpqb1clJGzEfznTo6KYialQoeXvic1ODDxoT1XFA/640?wxtype=jpeg&amp;wxfrom=0"/><p>苹果公司的研究人员最近推出了 MobileCLIP2，这是其高效端侧多模态模型家族的最新成员。作为MobileCLIP的继任者，MobileCLIP2通过改进多模态增强训练方法，在低延迟、轻量级的模型</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633708&amp;idx=1&amp;sn=81e077d6e670ebc110ae66b8b37ef534&amp;chksm=9701a82ebefd6be64032fc51850a3ba3f3b315b6adac1743ebcf0db0ece7547386dd2ad84774&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 29 Aug 2025 11:04:03 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 3D-MOOD：让单目3D检测走向开放世界]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu2PK9BkDZJyWAXPibRSfGVL8QV18ZKZr4nZIvYWk9MrTtYR6O1ia4axvg8aicedUgeWibIeA5eAxfkcA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文解读一篇在3D视觉领域具有开创性意义的论文：“3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection”。这篇论文首次系统</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633597&amp;idx=1&amp;sn=f722dd8026a1e274102c9542e68a6c78&amp;chksm=97d42f254f1b7a58aabd0086d8a267a8f43355d8a6964a3baa388fd96f41657b34f44343e23b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 28 Aug 2025 12:15:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[FoCa：将特征缓存视为常微分方程求解，实现DiT模型高达6.45倍无损加速]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsial8c09EMEdWDjvMmIbl70vmoLT3mDribISPLOVKwDmqyrI4vopkgCS6cmgvb78N4vdbYD1JEib6ZA/640?wxtype=jpeg&amp;wxfrom=0"/><p>扩散变换器（Diffusion Transformers, DiT）在图像和视频生成方面取得了卓越的成就，但其巨大的计算成本限制了其在实际应用中的部署。为了解决这一问题，研究者们提出了特征缓存（fea</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633517&amp;idx=1&amp;sn=377375b08e6e58196737eaac1e530a4b&amp;chksm=9799ed89ddfde7360a9962680def7003a53d76267d5df0ea29462b5a3917bdb940f4506af3ab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 27 Aug 2025 12:13:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[量子压缩思想启发，Squeezed Diffusion Models让噪声更有“方向感”，FID提升15%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuUVdDBvsQZLaicF1MPTSE6gzNbpCfVHUyUPFycftxwpnYZmwZZuewGRKtM3mI50nElVtxicezkQZkQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍的论文是来自斯坦福大学的研究者们发表的《Squeezed Diffusion Models》。这篇论文受到量子物理中“压缩态（Squeezed States）”概念的启发，为扩散模型提出了一种</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633425&amp;idx=1&amp;sn=e5c92ad44f3a44aa033c362394cc0a3d&amp;chksm=97fbe5da70ea5ce4c09b82e5dbb0faf3b54d1a78b8446897a9915797374276976afb20ba2461&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 26 Aug 2025 13:52:37 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[站在巨人肩上：索尼AI提出“模型驱动”新范式，“继承知识”铸就强大视觉基础模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsN8tSl7eUibu5QwKXibyspU390qS8SpdsNMmkiaQ1eJeicvmFlPdT6o17nEXgLgWicfuXEzsgib0vg1SOA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，来自 Sony AI 的研究者们发表了一篇题为《Seeing Further on the Shoulders of Giants: Knowledge Inheritance for Visi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633349&amp;idx=1&amp;sn=3ca52dac1178d9d59b98421523d64ec5&amp;chksm=97d780b2e8428113e1993656c641155ac40cfece1524ef7f8b8c4292dc762a4b27ad230d103b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 25 Aug 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[挑战扩散模型基石：T-space解耦，实现4-6倍速分布式训练]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsN8tSl7eUibu5QwKXibyspU3L3vvnNYRGxBSbUshaib6ictkVHm3ibbViaqC721G79riaEXMsaAPLWpEnVA/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自亚马逊的研究团队近日发表了一篇引人深思的论文，题为《Disentanglement in T-space for Faster and Distributed Training of Diffus</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633309&amp;idx=1&amp;sn=f1f5019e447e0b2749661eef00cfba32&amp;chksm=97d9dc534aa45103d1fb4004e12e03a6a3a21b58e02be35e512b363a93d75e77d1f1fc25ee97&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 24 Aug 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UniUGG：首个统一3D理解与生成框架，让AI同时看懂、问答、还能创造3D世界]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsSFpmHojpWNgflep1DniccbXfqoZE3Q4ibqCP9cy1CM5GgVGNvmfBBjuamMicUKbetKPXdmCVW71SSQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文要探讨一篇来自复旦大学和华为诺亚方舟实验室的最新研究 《UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633289&amp;idx=1&amp;sn=0ce3c60822428be321b7a32404fe0116&amp;chksm=97eef93475f2a81e9f188b28eef224ea9ff2becb2066f053e062ba495528805753d1daa14bf5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 23 Aug 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工&amp;Netflix提出CineScale：解锁8K图像和4K视频的电影级高清生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuoONxWl1tle4ebDvwbicKRepCamic1XnhssCZao3oKfeRicup4n2nRX0qtxBOR5NjXiagOZqribFgAm4w/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍一篇由南洋理工大学S-Lab和Netflix Eyeline Studios的研究者们共同完成的重磅新作，论文标题为《CineScale: Free Lunch in High-Resolut</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633287&amp;idx=1&amp;sn=320b4ee326ae86063548c3d22efc0cf6&amp;chksm=978e613f960c89a69c4575a6936804643cee3c230e95bc7dc645a4e53508efd6f6e1cfca7bb2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 22 Aug 2025 14:07:20 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[GSFix3D：当高斯溅射遇上扩散模型，解锁新视角修复神技]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsSFpmHojpWNgflep1Dniccbxiaxh8bBB8DRmrbOrmhWcLxrlKXKH6IuyNEjML7mCRzzTvcgCibWQkGQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>3D高斯溅射（3D Gaussian Splatting, 3DGS）技术以其闪电般的渲染速度和逼真的画质，在三维重建领域掀起了一场革命。然而，这项技术并非完美无瑕。当面对训练时未曾见过的新奇视角，或</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633159&amp;idx=1&amp;sn=1b884c07209011f8db476d1b3763b4e8&amp;chksm=9789414707c158c17d877585f0e070915339585b42296a966678c56569fb92ac6ade3dd77c5c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 21 Aug 2025 14:43:47 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里提出Vivid-VR：概念蒸馏，教T2V大模型学会视频修复]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsSFpmHojpWNgflep1DniccbZnMhorYvsKXej7g8dxBPrqX0eFKUfzJjiaViacq0gjH6avEKfRo9xsRA/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，以Sora、Latte为代表的文生视频（T2V）大模型，凭借其惊人的生成能力，展示了AI在理解和创造动态世界方面的巨大潜力。一个自然而然的想法是：能否利用这些强大的预训练模型来“修复”那些画质</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633159&amp;idx=2&amp;sn=3676697c38e073426ae55b2274d47041&amp;chksm=974e00db976be1f04a32d0e127dd83809f58cdba86a56a53c29c8aa93d972f4c2bbd0ceda912&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 21 Aug 2025 14:43:47 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | 骨架动作理解大一统：东南大学等提出USDRL，一个面向密集表征学习的基础模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu4O9kFJBDQUZekEBeHHzlEQfLYCNqI3hpY0Rz1iaKXH0gibM0mM9dnXoBFDRoqNc0D6MKLymZdRUoA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天，介绍一篇已被TPAMI接收的论文，该研究由东南大学、西北工业大学、南京大学、南京理工大学以及中国科学院的学者共同完成。论文针对当前基于骨架的人体动作理解领域缺乏一个能够处理多样化任务、具备良好扩</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633107&amp;idx=1&amp;sn=2255e5bd2c7dadc9f478a011f25161ae&amp;chksm=979bde120f9312bbd9238cfe6cbd7966932120986a0fbd06bf89e00d82895e65ceac34d41d3c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 20 Aug 2025 18:14:06 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[为长视频生成减负！浙大与华为提出Compact Attention，挖掘结构化稀疏加速2.5倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu4O9kFJBDQUZekEBeHHzlEMHhUVFGWicXqKslialKzNicpM8FFxDk35uSfsdLkWMQAibsEbzFaAgbNkw/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着Sora、可灵等模型的涌现，AI视频生成技术正以前所未有的速度发展。然而，在通往更高清、更长时视频的道路上，一个巨大的计算瓶颈始终存在——自注意力机制（Self-Attention）。对于基于Tr</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247633107&amp;idx=2&amp;sn=51b70ffa00a7eec0bdf1a6389276477d&amp;chksm=971fe76111dd9ea77c92c3f0b65190cf7a30ad61c32ffab68c93f0be7373dabf725090054b94&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 20 Aug 2025 18:14:06 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | DeCLIP：解耦CLIP注意力，哈工大（深圳）、港大提出通用开放词汇密集感知新框架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvK01rRpuicx4giaYhB58UysUDD2oMLyrW8rvxSKN5D8u8wyicxwqnj66dIFXGpuveyficDJTcY6No7dg/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前，目标检测、实例分割等密集视觉感知任务，大多仍受限于一个“预定义”的封闭类别集，这极大地限制了它们在视觉概念无界的真实世界中的应用。尽管像CLIP这样的视觉语言模型（VLM）在开放词汇（Open-</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247632981&amp;idx=1&amp;sn=3350d3ae0803418e30755ed646536f0f&amp;chksm=9765fb1fa8bdaee007b7d3a1ab18f44975ca170007e13662ac541ac3a47957d0a03322703926&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 19 Aug 2025 21:43:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[英伟达ViPE：任意视频一键转为3D几何数据，开源引擎与亿级帧数据集重磅发布！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvK01rRpuicx4giaYhB58UysUsqFRomLZpDuzXqhZjV6N8MC1DGnd8RR8BViaone4CkkM8iatOlLND6iag/300?wxtype=jpeg&amp;wxfrom=0"/><p>精确的三维几何感知是机器人、VR/AR、自动驾驶等众多空间AI系统的基石。然而，当前最先进的方法大多依赖于大规模、高质量的标注数据，但从真实世界的视频中获取一致且精确的3D标注（如相机位姿、深度图）却</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247632981&amp;idx=2&amp;sn=a9f6060acf1661657e9a2967acaa3c90&amp;chksm=971ec81d2a42aeb159d15371aeaf54c3b4da47961c0bcc5d133a241ecc5ddf6c34709224f9f8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 19 Aug 2025 21:43:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | MobileViCLIP：快55倍！南大等提出首个高效“视频-文本模型，让多模态AI在手机可运行！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuubFXJFggHLr698gpo7hFHN4ibg6d6bQJjt0ibWxqZZRweW0GFqKpYWB5ENC08AzQ0yNeclP13daQg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注公众号，发现CV技术之美视频-文本预训练模型（如Video-CLIP）在视频搜索、分类和理解等任务上取得了巨大成功，但这些强大的模型几乎无一例外地基于庞大而高延迟的Vision Transform</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247632945&amp;idx=1&amp;sn=0bb02ebde8548f2314c63e178d5a3aef&amp;chksm=97978837025935c4034cc33753ca307909aa5eac88afbc68e43bd7b45b2a02b51e72846377d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 18 Aug 2025 13:17:06 +0800</pubDate>
    </item>
  </channel>
</rss>