<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[我爱计算机视觉]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[我爱计算机视觉公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM6aYkwkiboia6lA9D7ANy49WBe9icxn5NQqJjvn4Pyntzvfw/132</url>
      <title>gh_e07180c244d1</title>
    </image>
    <item>
      <title><![CDATA[Identity-GRPO：阿里开源多人物定制化视频生成的后训练优化算法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtNaxWwYdt7L2LJCIicpZicMtpyWtKCr9qpFn6YjNpPVzhMYvuibvlTszzvEWKib6LdujBLg4eMCj3G1Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇分享论文 Identity-GRPO: Optimizing Multi-Human Identity-preserving Video Generation via Reinforcement</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247642099&amp;idx=1&amp;sn=612ac4d3ef32ac086a5959bee407d50a&amp;chksm=97653382c8a0e795854c9ff186fd3ad63197428a9e84e009e3eedb87fad1da4467d65512b0ec&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 17 Oct 2025 16:17:44 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Real-world Video Super-Resolution | VSR的十字路口]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtNaxWwYdt7L2LJCIicpZicMtSvUkMOwE6HukYiciaWBOjQeRrR6DPx6AuDROtMd1tFNJG7rtXeURSGTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文为粉丝投稿，原文链接：https://zhuanlan.zhihu.com/p/1959430260706744130。本文距离上一篇文章Real-world Super-Resolution |</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247642099&amp;idx=2&amp;sn=c64dad72dfe4e13e850bf3f8ae3fcfe0&amp;chksm=9702a2e0bbf133f949ef64fba2fb9b94d4001844e43f3418082cf4cfdb75bf28798329ba7684&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 17 Oct 2025 16:17:44 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 为Sora视频加上“隐形身份证”：清华大学等提出Safe-Sora，时空频率感知水印新框架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuwUbsFGXicqLs3cmiaVghtCYibMdQgbWYfFXAuKs4Rpn9LELUSdqAfJcO7bMq0WrLiaQZu9xVHNLU7ibw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着Sora等视频生成模型的爆发式增长，如何为AI生成内容进行版权溯源和认证，成了一个亟待解决的问题。在图片生成领域，隐形水印已经是一种常见的技术，但在视频生成中，相关的探索还比较少。最近，来自清华大</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247641670&amp;idx=1&amp;sn=f918f03aa34204a808782889c6a19205&amp;chksm=97b608a41142c83b71d6e5461c0ba2a8e906fef473da0f9d6c969e7fa0b02ba3c31717db1a7c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 12:46:52 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从DNN到MLLM的异常之旅：视频异常检测（VAD）范式大迁徙]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsSN8GjDGQ0icCYibOAaVHskWviazjdl9xxYbC1YaicYaICXzPGjPZbTsNsYRLlE9wHwM7UyycUBq8Tsw/300?wxtype=jpeg&amp;wxfrom=0"/><p>如果你还在纠结视频异常检测任务如何预测/重建，如何设计MIL框架，那你可能错过了一次正在发生的范式迁徙：研究从视觉空间的边界学习，悄然转向语义空间的理解与推理。从深度神经网络（DNN）到多模态/大语言</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247641670&amp;idx=2&amp;sn=6c3ef3b1adca48fbbfc758b298d4e681&amp;chksm=970709789dc7ca6214bc1d64c3d5f0b02f5f477f3ed540d5d8d75fe2eefc9be0665bf9527399&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 12:46:52 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IDEA提出Rex-Omni：将目标检测变为“下一个点预测”，零样本性能超越DINO]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTs1le1vXqvbN9Ors1hmQF4yzQOnwzPLiaOy3MxzuKic5o41khbwNauhtQPZW1ibolR49NWBPCMFm8pHw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天和大家分享一篇来自IDEA 研究院的最新研究成果。这篇名为《Detect Anything via Next Point Prediction》的论文，介绍了一个名为 Rex-Omni 的3B参数</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247641473&amp;idx=1&amp;sn=102d135e1c3ffa85196a2ef1292f9ffa&amp;chksm=978b08ab1072479e4da148cf91b77a6167bb5c4fc29eef669e836df1e42358c86c3d08cfcad2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 15:44:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | 华中科大与大疆等提出LLF-LUT++：4K照片增强仅需13ms，PSNR提升2.64dB！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsSN8GjDGQ0icCYibOAaVHskWk9o4kSo5kHyIhTaUE4ibicv88S1QxHXJ4zDCktxMwjpECdLTs0Vzu0zw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，来自华中科技大学、大疆和香港理工大学的研究者们，为我们带来了一项非常酷的工作。他们提出了一种名为 LLF-LUT++ 的新型金字塔网络，完美解决了高分辨率照片增强中“效果”与“效率”难以兼得的痛</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247641473&amp;idx=2&amp;sn=56b84fa5047c0ec8877b2324e0cb681e&amp;chksm=975f137570e649e51e867604903859f8aedde9decb079bcac436168d9b81f1960a02a167a348&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 15:44:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 让AIGC视频变为可探索场景：Instant4D实现单目动态场景的分钟级重建]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsSN8GjDGQ0icCYibOAaVHskWbsSqxndocKuCLicKQ0GkwNr1nSJCXnYia2WJDOzLUZTURiaXiaFMQibMEmg/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，视频生成生成模型例如 Sora, Veo3 得到了社区的关注。 这些模型能够生成具有视觉吸引力，高度逼真，天马行空的视频。 在这个工作中，我们希望能够重建任意视频，并且实现新视角渲染，把AIGC</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247641003&amp;idx=1&amp;sn=ed5802038986826f42f9c7ee4eeb4bf1&amp;chksm=973b2edb48cdc800160470488cd6cc33e707dcc79d1fbd3d387adb288ce16df4ddaa81186d83&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 12:36:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | PPFN：渐进式提示融合，让红外图像增强在复杂场景下性能提升8.76%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsSN8GjDGQ0icCYibOAaVHskWOygvr2E2ySxx7ObJ0LlQNsyL2u2W7kdrzV5sAu0Jfdzgwe4ZkI5cqg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，来自大连理工大学和大连海事大学的研究者们，为我们带来了一项关于热红外图像增强的新研究。这项工作已被机器学习顶会 NeurIPS 2025 接收。不同于我们常见的RGB图像，热红外图像的“视界”里</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247641003&amp;idx=2&amp;sn=d8de02f86d5d5ecda3a0ff96b6f5d84f&amp;chksm=97cb39382571ad921506488b5eee2857b746724246dc328ebf2c684cd8f3f343880c482d64d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 12:36:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[SAM 3揭开面纱：不止分割万物，更能理解概念，交互式分割迎来新篇章！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuwUbsFGXicqLs3cmiaVghtCYvnLqUIzicibLUv1aicEqFelbHFFhkuicAD3IhvfJ8n93QGvEp6LXMfNicYA/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，Segment Anything Model (SAM) 系列迎来了第三代——SAM 3。如果说第一代 SAM 教会了模型“分割万物”，那么 SAM 3 则让模型更进了一步，开始“理解万物”。它</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640604&amp;idx=1&amp;sn=9640e887d893f35182914fdf11b5f359&amp;chksm=974eba97d851764a7e06788547b8af17340e13720c386db9a4423f55ab8359cc670f97fa3af3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 12:32:58 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ACM MM2025 Oral | MoSEAR:为多模态情感推理补齐“冲突场景”的短板]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTuwUbsFGXicqLs3cmiaVghtCYL8kjA0AA2HbrliacnudnCH8UlsNic0l9WZxB9ia5jiah1Wd1zxAwvhkmVw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在电影“流浪地球2”中，尽管刘培强用冷静的语气掩盖内心的不安，但是人工智能MOSS还是通过他微表情识破了其隐藏的秘密。类似的，当一个人嘴上说“没事”，但表情却写满了失望，如今的多模态大模型能读懂这其中</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640604&amp;idx=2&amp;sn=69aa2a9ffc8231fa07249a99ff38f5ed&amp;chksm=97dabc6305743aa37094d2b3dbe55e142ca8c98b98ae062b0d94254e9fc0fbf5ec8caeb8bd35&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 12:32:58 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | Latent Harmony：潜空间和谐共生，实现UHD图像修复新SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv9so0J5tAxMejTVmE0zXQ3kjIia5p9ib2dRl6ibncuM0cLSFClbEiaWxv4nDa5F5gSRKpLPd1xz0af3g/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天CV君想和大家聊一篇非常有意思的新工作，它来自中国科学技术大学和上海人工智能实验室，并被 NeurIPS 2025 接收。这项研究聚焦于超高清（UHD）图像修复，提出了一个名为 Laten</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640508&amp;idx=1&amp;sn=3dacde954621ad9d05bf44aa978ef92c&amp;chksm=976dbd7335fb8e8b6c95376b4b2632cdb82c561f4ebe44c584b4eb0790b6d20ae0ee50e501e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | NTN-Diff：一石二鸟，利用空文本与频率感知破解图像修复难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvfxUxmBxdrd76bga45zN0PjSCpuibg1iabVCZo1TJicc1ic1YIvF9Y9XKpSRuE2HC295u8r351orVZ8A/300?wxtype=jpeg&amp;wxfrom=0"/><p>在文本引导的图像修复（Text-Guided Image Inpainting）领域，一个老大难问题始终困扰着研究者们：如何在根据文本描述填充缺失区域的同时，完美保留图像中未被遮挡的部分？很多时候，模</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640508&amp;idx=2&amp;sn=82febf7dd7a41eb6d45e09a1d49cebbe&amp;chksm=97945ce9883274478c098776ac6b2988491686bd1f17b89895875577207cd72ff1c478334954&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IROS 2025 Oral | RAG-6Dpose：三大创新模块，利用 CAD 作为知识库进行检索增强 6D 姿态估计]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTv9so0J5tAxMejTVmE0zXQ3GZCJody1RAaHCmUKAQW8uOhM9VObicRkc8IDq6qqrKGc4k8rWnwia7xQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>准确的 6D 姿态估计对机器人操作至关重要，可实现像抓取这样任务中精确的物体定位。单目 6D 姿态估计旨在从一张 RGB 图像中准确预测物体的三维位置和朝向，这对机器人抓取与交互等任务非常关键。然而，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640313&amp;idx=1&amp;sn=c519aa8196af4d49206fa798d035556f&amp;chksm=97918e585542ab3945026d0af22c75e079f756c272c52db215ed5c0b5eb468dd7ec88c415b45&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 13:07:17 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IROS 2025 | 速度飙升24倍！巴黎萨克雷大学等提出HARP-NeXt：实时3D激光雷达分割新标杆]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvBzrQOREVzKT4UfnMW9TcYRAYo3o3gCyqGviag1YKN6F0ShAm68DHWQX7kw1WqompahKb4Vc2Ik2g/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是CV君。今天想和大家聊聊3D激光雷达（LiDAR）语义分割这个领域。对于自动驾驶和移动机器人来说，能实时、准确地理解周围环境至关重要，而LiDAR语义分割就是实现这一目标的关键技术。然而，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247640313&amp;idx=2&amp;sn=319b1068b23b5356ac62edd9351f29b2&amp;chksm=97c210fccb6b11764e5b2224370236a42767527120138dfe92cadc28f8a6693337f3550f64c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 13:07:17 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[U-Bench：U-Net十年“大乱斗”终结者，100个变体、28个数据集的终极对决]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvfxUxmBxdrd76bga45zN0PEgmXkx2ib7t1TKtE0kepoBNl2fzaHIdhzUtzFGqIkb7sickMJcjvaPGw/640?wxtype=jpeg&amp;wxfrom=0"/><p>自2015年诞生以来，U-Net无疑是医学图像分割领域的“王者”，其优雅的U形结构和出色的性能，催生了数以千计的“变体”模型。然而，这个繁荣的生态也带来了一个问题：新模型层出不穷，但我们真的知道哪个更</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639919&amp;idx=1&amp;sn=fd4f39a9c066c69a8a6df5434ddf7441&amp;chksm=9717827550435ad86b4303aec44e5135361b1b2e9f164772c85bcaf78363f2f655e9a553d720&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 14:50:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[东京大学、牛津大学等联合发布VLA万字综述：机器人迈向通用智能的全栈指南]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvBzrQOREVzKT4UfnMW9TcYWx9R79CiaFc5atUIdzk4RJx7hmghuOn18Q3Nxd7icVU5kEFetrTtjkzA/300?wxtype=jpeg&amp;wxfrom=0"/><p>当大语言模型（LLM）和视觉语言模型（VLM）的能力不断溢出到机器人领域，一个激动人心的新方向——视觉-语言-动作（Vision-Language-Action, VLA）模型，正成为通往通用机器人之</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639919&amp;idx=2&amp;sn=df224c69de268ba102ff25427433177e&amp;chksm=977b2bb4d5371e0f0e9e70170d62cb719395a10560b439db4226fcec62f8361cfe70c657d63f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 14:50:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Diffusion²来袭：威斯康星大学&amp;华盛顿大学等提出双扩散模型，“回溯历史-预测未来”，破解自动驾驶“鬼探头”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtmWEI9nicjxnJ8zanDyuJwHdibhsxNxXaxnB7MokNcibhIE0V1mcRo6RKlzXYkc5eAJCo0r17icnicx1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>朋友们，今天我们来聊一篇非常有意思的论文，来自威斯康星大学麦迪逊分校、华盛顿大学和同济大学的研究者们，题为《Diffusion²: Dual Diffusion Model with Uncertai</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639615&amp;idx=1&amp;sn=f3ee6bc7c6c291c7f628ecd6f62f1b00&amp;chksm=977eb6ea4aafd9b2ca14efac20f310480c24d7831987b8a4ef3dddfc4b5c152e833ce8dd820b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 14:46:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[北大等提出TrackVLA++：赋予机器人推理与记忆，跟踪成功率飙升12%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvBzrQOREVzKT4UfnMW9TcYw2OW72DlER4zICD1QCpoBMv3VL0ceHb7ynQVDCIgdqe3GEBetq1Lug/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，具身智能领域又迎来一个非常有意思的工作。我们知道，让机器人像人一样在复杂的环境里持续跟住一个移动目标，其实非常困难，尤其是在目标被遮挡或者周围有长得很像的“路人甲”干扰时，机器人一不留神可能就“</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639615&amp;idx=2&amp;sn=91b87ca4a7ae75111f0888ae1c9957c2&amp;chksm=97c1c081e74cfef40141f3155f5012517489ffeab79b3b7eac52b8bade073f62d3d19b4b3d06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 14:46:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IROS 2025 | Waymo与谷歌DeepMind联手提出Drive&amp;Gen：用生成视频评估自动驾驶，虚拟测试更逼真]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtmWEI9nicjxnJ8zanDyuJwHDIPswGkuicpYYOiaNnlq1u1KAtIuwVfFwLNhEibPVeYDmlGTiapflXPNYw/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，自动驾驶领域迎来了两位“新玩家”：端到端（End-to-End, E2E）驾驶模型和视频生成模型。E2E模型试图用一个“大模型”直接从传感器输入预测驾驶操作，大大简化了传统复杂的模块化系统；而视</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639304&amp;idx=1&amp;sn=550ba355d4167df876744480c285f2f9&amp;chksm=979d4aad72ea38a473d2873e06feb22b8f5b584134c8d30f652a82ec9dd551c49172298fbb42&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 08 Oct 2025 12:09:23 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别深度传感器！慕尼黑工业大学提出DropD-SLAM：仅用单目RGB即可实现RGB-D级的SLAM精度]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtmWEI9nicjxnJ8zanDyuJwHgcKHOMPuNl54cWFLfc9e0IicWkatEwVqUTBzKhAhTicuhWXDPaB2Ocsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天，我们来聊一篇非常有意思的SLAM领域新工作，来自慕尼黑工业大学和3Dwe.ai的研究者们。他们提出了一个名为DropD-SLAM的系统，这个名字很直白，意思就是“扔掉深度（Dropping th</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639304&amp;idx=2&amp;sn=78ab7f916ec4433d758a363c4431eef2&amp;chksm=9735940e075bb713cb1faca2acbf0025537ee51c98453b4d8b55dcc8991aefa0c8c9f89c0f63&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 08 Oct 2025 12:09:23 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI 2025 | 电子科大等提出EEMFlow：从事件相机学习高效Meshflow与光流，速度提升30倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsTeSh4RLoXLA8MMC9VPRNzqiad4NpfYTp2KkicXcSAo2WicLUlu7hydx3FLwXuEnpuDnSiceRfoOtTDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天想和大家聊一篇非常有意思的新工作，来自电子科技大学、香港科技大学和西南交通大学的研究者们，他们关注的是一个越来越火的领域——事件相机（Event Camera）。这篇被 TPAMI 202</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639120&amp;idx=1&amp;sn=75539d0808a7384c22a05b01ebcaf2bb&amp;chksm=975c5f1a84e6b583f424ade2ecac593d58b533a0619dbe10b63aa48e866c40543874bae5dea5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 07 Oct 2025 15:31:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[MICCAI 2025 | 莱斯大学提出MetaSeg：参数减少90%，元学习隐式网络重塑医学图像分割]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsTeSh4RLoXLA8MMC9VPRNzPgLv2qG6MCFvnIjQZibGfbeQ8njkzDK1tIS3za0xSszaoQicIV8IyVrQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，来自莱斯大学的研究者们在医学图像分割领域投下了一颗“重磅炸弹”。他们提出了一种名为 MetaSeg 的新框架，巧妙地将元学习（Meta-learning）和隐式神经表示（Implicit Neu</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247639120&amp;idx=2&amp;sn=893a4e1f9ab2fe7893e98bd324f0c598&amp;chksm=974b3b801bfcc4e3a2b65beaa90cb79305f56da2cfe19cd283755c10ff218c32488d849444c6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 07 Oct 2025 15:31:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 慕尼黑工业大学提出SIM(3)等变网络：让3D形状补全告别“姿态偏见”，实现跨域泛化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsWzQRzR8ECqLgEf8Jbe1jOFpwy6j4OcCYQuoZcxSQApyqr36UsRgV0kyeXnNh4CicgBfM1wbkfSJw/640?wxtype=jpeg&amp;wxfrom=0"/><p>聊一篇关于3D形状补全的顶会论文。我们先简单聊聊为什么需要3D形状补全。在现实世界中，我们通过激光雷达（LiDAR）、深度相机等设备获取的3D数据几乎总是残缺不全的。这可能是因为物体被遮挡、传感器视角</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638848&amp;idx=1&amp;sn=8ed516b291a968b84634cc377d303bea&amp;chksm=97f750c087556e5fd03b962e8d621e5bbe37164a4be9fee4011e89b3d8d47c291e5432630920&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 06 Oct 2025 12:47:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 高通提出GCL：无需额外数据，通用多模态检索迎来“一统江湖”新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTsWzQRzR8ECqLgEf8Jbe1jOOxEqdcrtgb23vZQD3LFt9E8DfAEhFfbibqPxnycvcPGvZEl0WNgvCEg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是CV君。今天想和大家聊一篇非常实用的论文，它来自高通AI研究院，并已被NeurIPS 2025接收。这篇工作聚焦于一个很现实的问题：我们如何让机器在面对图、文、甚至图文混合的内容时，都能“</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638848&amp;idx=2&amp;sn=79950ef2e3a274622482b51856321171&amp;chksm=97356856157b0d08df03b8c9539b9a78af241bdb96f9b26ce93d8fa29b4c63e4a2a0666746fd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 06 Oct 2025 12:47:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[宾大提出F³：事件相机迎来“预测性”表征新范式，光流、分割、深度全SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtB0ib5icMePhR4iblOq43vhSj3XKH1ia8W8esTYPSqCgaC0x7zIKNQryRkDgeV0ChGRnlQ9wE1RLYqcg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天想和大家聊聊一种非常酷的传感器——事件相机（Event Camera），以及一篇来自宾夕法尼亚大学的最新研究，它为处理这类独特数据提出了一种极具启发性的新方法。事件相机和我们手机、相机里常见的传统</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638707&amp;idx=1&amp;sn=a5b88345beb4a0643f1c73764e87fffe&amp;chksm=97fde72e866df8f2d8cf3e221de24091ba5c9588e36b45781e2c41dea803f5a4cf6a6775623d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 05 Oct 2025 22:41:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南理工提出FMC-DETR：巧用“频率解耦”，航拍小目标检测精度飙升8.2% AP50]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtQJO9jUpDtyicfwaZshibtGvwshxJZFwyGB4vVFkLrGuE0eYkLEZ5FwUWXm2csiaqpccicjygeP4zyrw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在广阔的航拍图像中，要准确地找出那些只占了几个像素点的微小目标，比如远处的车辆、行人，无疑是一项极具挑战性的任务。这就像是在一幅巨大的画卷中“找茬”，不仅考验眼力，更考验对整个画面的理解能力。这项技术</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638660&amp;idx=1&amp;sn=ee5206c4ed4f83f1b28d3ed5a06b865d&amp;chksm=97bc5fedb9a4211c5ef60413bf695e3d3b8b2245513a5f910189b8f43a1655219b27d9d40fc9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 04 Oct 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | RAD：基于大规模3DGS孪生数字世界的端到端强化学习训练策略]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtQJO9jUpDtyicfwaZshibtGvSjygyicBPlJfAzIXYVBtWPxibcaMRFvVOElibeY8lJLS4S0bIEjXpiaPjw/640?wxtype=jpeg&amp;wxfrom=0"/><p>一、论文基本信息类别详情论文标题RAD: Training an End-to-End Driving Policy via Large-Scale 3DGS-based Reinforcement</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638621&amp;idx=1&amp;sn=53094d3e8f3baf73ea1d713c8f0c996d&amp;chksm=972e1021d09a24c30fb6c2410ea42525f189dec2ba4ef7df80b39931592d5cb5863c467af469&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 03 Oct 2025 12:41:49 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[武大新作MASt3R-Fusion：融合IMU与GNSS，为新一代视觉SLAM注入“多感官”智慧]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8ouFWiaGSZBaLpmDzz0yQPEInQ2lcoiatwWr2ayLsS6qdiayiazrsfiaTuwA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，今天CV君想和大家聊一个机器人和自动驾驶领域的核心技术——SLAM。简单来说，SLAM（即时定位与地图构建）就是要解决一个根本问题：一个机器人在未知环境中，如何知道“我在哪？”以及“周围长啥样</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638597&amp;idx=1&amp;sn=9d2668a10edb9ec779f97d7a0c992731&amp;chksm=97221ac64e4c07357ef3cd0db7207f32615c6b1fe38e08d87655c3e52ab131ba2eb0fb6b3104&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 02 Oct 2025 13:21:40 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[中科大、清华、快手等发布OpenGPT-4o-Image：为多模态AI打造的“超级燃料”，图像编辑性能提升18%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBgRTg3KmUVicQLS2RiaTlfkxvkeSLBrNDRkbuJIN9dsh8dadban7TNYYg/300?wxtype=jpeg&amp;wxfrom=0"/><p>如今，我们都对GPT-4o这类强大的多模态模型的威力惊叹不已，它们能看、能听、能说，还能生成和编辑图片。但一个灵魂拷问随之而来：要让这些模型变得更强，下一个突破口在哪里？答案可能出乎很多人的意料——</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638597&amp;idx=2&amp;sn=74ca0b987665c0e63e2a0e4f6fa8b92d&amp;chksm=9796344e1ac9055dfd25878676b863bf6bf3e94c4c6aa7902ccc5b2b7a4579e70afac547ddc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 02 Oct 2025 13:21:40 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工联合商汤提出Visual Jigsaw：像玩拼图一样，显著提升多模态大模型的视觉理解力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDB9LvkFxyVM30CmqicXwODg5vh6zO6dQFpypTsdpLV5XtQg5ibHm5aYIDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，多模态大语言模型（MLLM）的发展日新月异，但大家有没有发现，很多模型似乎更偏爱处理文字，而在“看图说话”的“看”这个环节，总感觉还差那么点意思。它们或许能识别出图像里的物体，但对于更精细的视觉</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638569&amp;idx=1&amp;sn=b54044764004f56e5d49e5a90ab89ab6&amp;chksm=97332836b25f56abffe9fe8b50b9f347d407f2641c815bd4ce86dc33909a0545582a255451f2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 14:13:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[天津大学联合腾讯提出Wan-Alpha：一键生成高质量透明视频，发丝级抠图不再是梦]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBibaCsGibCJlhicfEYXkRgNNIOwjkfz0h1e5XVBViakhoAoGEdBC4yFsqLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>对于视频创作者和设计师来说，获取带透明背景的视频素材（也就是RGBA视频）一直是个头疼的问题。无论是繁琐的手动抠图，还是效果不尽人意的自动工具，都耗费了大量时间和精力。随着AI视频生成技术的飞速发展，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638569&amp;idx=2&amp;sn=5d6ea97371bbd1a523b6fe308c425277&amp;chksm=97018df3d0a7403c6884598684fdf5d5fb637827bbbdf1b029cc16c0ef39048eaed5fb6bcf9b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 14:13:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 清华大学与华为等提出全新正则化方法，破解稀疏视图3DGS“协同适应”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBufibxKqprqSfLsGepluFSQvYxibUgicT18hUNR14POgFfIQVAmdKC6TdQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年，3D高斯溅射（3D Gaussian Splatting, 3DGS）技术因其出色的渲染质量和实时性能，在三维重建领域掀起了一股热潮。然而，这项技术在密集视图下表现优异，一旦训练数据变得稀疏（即</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638453&amp;idx=1&amp;sn=526fd0a7a4c6fa9a41f77a9bca5f7d9e&amp;chksm=97227d6c01511fd5dc75ab8e807a6455d919599271151572c010d3ca5ad9ef379077f7c7a999&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 16:04:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DeFacto：用强化学习治愈AI幻觉，让多模态模型“有据可查”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTttDVCqQ9gFaBE2oxXtrPErItXvjagPrYXTJ6zG0dGZ9dOdzicOfAe8NMMc7FQQI4NplPRXZV5VSWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：DeFacto: Counterfactual Thinking with Images for Enforcing Evidence-Grounded and Faithful Reaso</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638453&amp;idx=2&amp;sn=1d3171800ea06cf16cc83a1970a4cfb5&amp;chksm=978f2c79bd5a9543eb8cee832aa6eeffd0e65a381fc5b30d59b9572ee0b780194eb7f6062c4c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 16:04:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[YOLO26首份学界评论：端到端无NMS，目标成为边缘设备实时目标检测新标杆]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTvaJj8L54WLMsIRqx2X6zDBCUAQMymGbNmUUzia9ju037B4WI501WdweD06MquW2P5bibKufXwzNHzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Ranjan Sapkota, Rahul Harsha Cheppally, Ajay Sharda, Manoj Karkee机构：康奈尔大学、堪萨斯州立大学论文地址：https://arx</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638453&amp;idx=3&amp;sn=41bf331d478908c376f3e5d47b4b9a2e&amp;chksm=97731a6c9fadf3b9c940633b324581f7532738d9bb59224ba98bb88979433849e63b8120f0e1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 16:04:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | Seg4Diff：无需分割头，揭示并放大扩散Transformer中的涌现分割能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8WZDXdYhkxWtzAtXCEDVtrOqE3gbOam6yPfzr1Ud23xhDJ8j2yicxjJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自韩国科学技术院（KAIST）、高丽大学和苏黎世联邦理工学院等机构的研究者们，共同发表了一篇题为 「Seg4Diff: Unveiling Open-Vocabulary Segmentation</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638378&amp;idx=1&amp;sn=b0575c3fc7c477f08574970aa7b50f2c&amp;chksm=97dbb6d3d7a38d13dad379f456a5fe39ce104681e0ef40decb4bcc65e01c0ef92b33d712beab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 12:11:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | UniPixel：首个统一对象指代与分割的像素级推理框架，让大模型看懂每一个像素]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8L4aVbyibeA6DTujfVHJBIZYB1moB9Tsjz9pV8mNMo71icU9vKEOrAqMw/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大型多模态模型（LMM）在作为通用多模态助手方面取得了巨大成功，尤其是在宏观的图像和视频语言理解上。然而，这些模型往往“观其大略”，对于深入到像素级别的细粒度理解能力却关注较少。为了弥补这一差</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638378&amp;idx=2&amp;sn=2d357f26972dbc498d99b5357da70e4c&amp;chksm=97c3e1edc32aab8f66b57ad73777aa5a83006fb77af28e1212e6b77d06490b6076b5a4481a5e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 12:11:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 北大等提出C²PPrompt：解耦类内与类间知识，破解联邦持续学习“双重遗忘”难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8aKPBbxXmbaD1gesQk8JMg6kw6QKq3eKBv3lib7BEJlpXwELfhYyaKZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天想跟大家聊一篇来自北京大学、中国科学院大学和内蒙古工业大学的最新研究成果，这篇论文已经被 NeurIPS 2025 接收。想象一下，我们有很多智能设备（比如手机），它们各自在本地学习新知识，同时又</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638246&amp;idx=1&amp;sn=2e7a435ad3e62177ac5405b4583b83b2&amp;chksm=97b7162c252fce5b0fd9d7ef0203150bab4ea5c71d1030ae23d5e4992ac18ca245709b83f8d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Sep 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[InterDigital开源CompressAI-Vision：为“AI看”的视频压缩，打造一个“通用跑分平台”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8CoN1WhLH6gxY4Ft1s7SPxDP3cAuxicKDKByhxRRMjHmuylroecpljNg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好！如今，从自动驾驶到安防监控，AI摄像头无处不在。一个随之而来的问题是：海量的视频数据，如果都原封不动地传到云端分析，带宽和成本谁顶得住？于是，一个新领域应运而生——面向机器的视频压缩（Vide</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638246&amp;idx=2&amp;sn=ef3bbdd1fb667da892d97e0feb5c0053&amp;chksm=97273a1f748ddb681fb287fe4f61db955e692aab1d6fcd419055aeb0126018b8c6c8037d6563&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Sep 2025 12:12:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦等揭秘机器人“大脑”安全漏洞：一张图就能让它“宕机”，攻击成功率76.2%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8QxzSgoBliadjOxGAc4tlCVLn4q7VO8mm5iaL6FIIKDpGIBM1L4YIEsJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天，来聊一个让人细思极恐的话题：当机器人的“数字大脑”被一张图片“冻结”，会发生什么？来自复旦大学、上海人工智能实验室和Sea AI Lab的研究者们，最近就揭示了这样一个严重的安全漏洞。他们提出了</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638237&amp;idx=1&amp;sn=233708a1dd10fe31d65c7b62eb5dd46c&amp;chksm=9726168b71f46e2bd72219a9342a133d21a1978fbc17206c7eeb42fed0885d8a68c2b14ca7eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 27 Sep 2025 11:14:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DASFAA 2025 | 湖大等提出SCRA-VQA：给LLM一份“精装修”的图像描述，无需训练提升VQA性能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6a5InlLvyzricJC1dNwgL8kR5VObDnvbvRNWJPicSiaIl9oqpNJOB448uqFwDdbwR401kHKGicicia3mg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家好！如今，大语言模型（LLM）已经成了AI领域的“万能钥匙”，研究者们都想用它来解决各种任务，其中就包括视觉问答（VQA）。一个很自然的想法是：能不能直接“冻结”一个强大的LLM，不重新训练它，只</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247638237&amp;idx=2&amp;sn=d22ffff7def78153a8f16c7d12f09a40&amp;chksm=97291f27e0b09f723311f65966bb74bc7a8d431bfe0e76b10979f901c682a45865354e35a8b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 27 Sep 2025 11:14:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[斯坦福推出VisualMimic：让机器人“眼观六路”，零样本完成复杂任务]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt7q7P0SJ2ogSq0RpXaS4wic6zicSO90ibB0NClibZwfcbEMoiaIw0E5LoyePYROCDHwvCUibBmnoXrO5tw/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近，机器人领域的一项新进展吸引了我的注意。来自斯坦福大学研究者们，带来了一个名为 VisualMimic 的全新框架，让机器人只通过视觉模仿，就能完成一系列复杂的移动和操作任务。想象一下，一个机器人</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637958&amp;idx=1&amp;sn=7b107313e482e95c686389341f4968f5&amp;chksm=971cc97d99791050cbd1df03938c76041c88a5bc1f050f8d6127e40641be00958c3778c0706e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Sep 2025 11:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大发布RS3DBench：让遥感AI看懂3D世界，首个像素级对齐的大规模基准来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTt7q7P0SJ2ogSq0RpXaS4wic0icQ3a93UqWicXnEkKLZxTEQZEiaE5G8hK9ZwjCSeiaIkziaujpYSyRA6pw/300?wxtype=jpeg&amp;wxfrom=0"/><p>分享一个来自浙江大学和杭州城市学院的硬核工作，它为遥感（Remote Sensing）领域的AI研究，补上了一块至关重要的拼图——真正的3D空间感知能力。我们都知道，AI在解读卫星图、航拍图这些遥感影</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637958&amp;idx=2&amp;sn=9bf5d36f8370196ada8c6732cd3ffa26&amp;chksm=97ea37a2cff4148d220e1acf8984605431614b50e3ed108d646328cd755beb0cf3be323e4f3b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Sep 2025 11:02:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[OCRBench v2 25年9月最新榜单发布！揭示多模态大模型文档智能真实水平]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd2kiayZvjkHY5IsW7lVgfBQADZEJM5KiclSZdTCzo0lHhAibD7rDmIA4Eicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>导读：现有多模态大模型（LMMs）在复杂多样的OCR任务中表现如何？华中科技大学白翔团队联合华南理工大学、阿德莱德大学和字节跳动联合推出新一代OCR评测基准OCRBench v2，并发布最新私有数据榜</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637510&amp;idx=1&amp;sn=ad33f7e477e2e8a9029c8b384a9f15cd&amp;chksm=975925e491d0e72ae3f30a25ed4d64a959cb0bee9956fdc803818049f179eb80dda3d086235e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Sep 2025 00:01:02 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[恶劣天气下的图像修复：南理工等提出LCDiff，让AI在雨雪雾天也能看得清]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd2Nf7yNoDkqqeyELvyrkX4f7ibVeSLoKm8u0dqQEjxVQB4PakicXNcFhaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>如何让AI在狂风暴雨、大雪纷飞、浓雾弥漫的天气里，也能“看”得清清楚楚。这不仅仅是听起来酷，对于自动驾驶、户外监控这些应用来说，简直是刚需中的刚需。恶劣天气下的图像修复（Adverse Weather</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637510&amp;idx=2&amp;sn=8b541444da5351b1617b76bf72ba7703&amp;chksm=976c8359a787be5d286150431f64faa5a0afd93a4c9a8306b37ee62a0c4564d9733bf8e141ff&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Sep 2025 00:01:02 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ContextFlow：无需训练的视频编辑新范式，实现电影级魔改！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd20ibQaNjXkl0S7ibHefQDRkRk16XeuIpovOrS4pRoNK5iazgfwND2YpQtg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家聊一个好玩又实用的技术，来自北大和港科大的朋友们提出来的一个叫 ContextFlow 的新模型。简单说，它能让你像P图一样轻松编辑视频里的物体，比如凭空加个东西、把A换成B，或者直接让某个</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637418&amp;idx=1&amp;sn=7be6207fc1e1f503dba15e1aade164b3&amp;chksm=973e9657631c69403a3168861d060709b293b2caf22ecbaeee6200fc36ad08cbcbb595b36e6b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Sep 2025 17:32:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动OmniInsert炸场：无需掩码，任意物体“贴”进视频，效果碾压闭源SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTticmUibSps35gmNvnJevgdd2HdoGYvNichpFrl7RHvp709g24GCjjYekHDicaIzkL2ECJCMPXcLj54Vw/300?wxtype=jpeg&amp;wxfrom=0"/><p>搞视频编辑的朋友们，是不是经常觉得，想往视频里加个东西，这过程简直比登天还难？又要抠图，又要搞蒙版（mask），效果还经常不咋地，光影对不上，动起来也假假的。今天，咱就来聊个“王炸”级别的技术，它可能</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637418&amp;idx=2&amp;sn=6303fd2446ca057452c59326733d3788&amp;chksm=9780016665502454e9975aa1a29042d18fbc6adb994794ae7902ec80488d44561a6889f49a8a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Sep 2025 17:32:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Point-SSM：一种用于点云分析的极简状态空间模型，在医学点云任务上表现SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtnmoicO3a5Ipkbun74mk2wI1nyHcPESG7hdfRDdvtcXNvBReWCutYYZ8250lTAjiblEccAWTaJHzRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文提出了一种名为 Point-SSM 的新型点云分析框架，它创新地将最近在序列建模领域大放异彩的状态空间模型（SSM，如Mamba）应用于无序的点云数据。通过引入多种 扫描策略 将点云序列化，Poi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637418&amp;idx=3&amp;sn=15fb8ef51f1521f9a4a0a9be936c5efc&amp;chksm=97fc3ac00102ead592d9d6fa561d768fd203aef596ee92a4ef2223247cfdcedc505ac87d4802&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Sep 2025 17:32:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TPAMI | 数据增强还在“盲操”？南大提出IPF-RDA，让模型训练告别信息丢失]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8r8pVhGicxSwwZDBiaw8TEdoqKB8gZN4x7nIDjNXh5qBNhXSLyTTuBb6A/640?wxtype=jpeg&amp;wxfrom=0"/><p>各位炼丹师们，大家好！今天CV君想和大家聊一个咱们训练模型时几乎天天在用，但又可能没那么在意的“常规操作”——数据增强（Data Augmentation）。简单说，数据增强就是通过对原始图片做些“小</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637025&amp;idx=1&amp;sn=6ec8f5aad63d31240f66561870523389&amp;chksm=974523e271af3e3e14d54cebaca5ed2c34007d32efe9d4f82d3cb36e10de2cb7be11cce7af76&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Sep 2025 16:08:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[SilentStriker：无声击溃大模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8Rl4Tlq2HibSialp7aGElrFhzJasKiaJ4OooLiaXlAYanqnkC7ZZII5Cvwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着大语言模型在各种关键领域的广泛应用，激发了大量关于其安全问题的相关研究。相较于已被广泛研究的输入操纵攻击（如提示注入，prompt injection），针对大语言模型的比特翻转攻击（Bit-Fl</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637025&amp;idx=2&amp;sn=da009e971c31dcf8c003af98b19535ff&amp;chksm=971240bdc23bc2523ff837a0554edb47ea172e21d13d2d7417d1af8a5b4b8ee5780621bdeb9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Sep 2025 16:08:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Yann LeCun团队新作LLM-JEPA：结合联合嵌入预测架构，显著提升大模型微调性能与效率，在代码生成任务上表现卓越]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtibgWM1iae9P2Ox4YSPtndib8T6WK5v6f09MOy6FNbQ9HPyC4R3s8tQJicP4HwsBrl58BBXVY7TlSKEA/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前，大型语言模型（LLM）的训练和微调几乎完全依赖于“下一个词元预测”（Next Token Prediction）这一自回归的生成式任务。然而，在计算机视觉领域，一个名为 联合嵌入预测架构（Joi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTE1NjQxMQ==&amp;mid=2247637025&amp;idx=3&amp;sn=f3dd386a5c4bdc3b8984fe0416cc6727&amp;chksm=97b243bf5e79c3f2699d100352d3ceb01076e79317cc5823b405d8d66102c877d7e807deba70&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Sep 2025 16:08:35 +0800</pubDate>
    </item>
  </channel>
</rss>