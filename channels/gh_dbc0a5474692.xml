<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[机器之心]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[机器之心公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_dbc0a5474692.jpg</url>
      <title>gh_dbc0a5474692</title>
    </image>
    <item>
      <title><![CDATA[魔改AlphaZero后，《我的世界》AI老玩家问世，干活不用下指令]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiclpKp5iaMh8iahEt7aBwB7DEAd9cJot8gohjyhDJT2JfrDYt8hv17uZaRo6GPng7zNjD0xlJTaMS7A/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：泽南、杨文人和智能体共享奖励参数，这才是强化学习正确的方向？大模型驱动的 AI 助手又升级了。本周五，科技圈正在围观一个陪你一起玩《我的世界》的 AI。它话不多说，就是埋头干活。一起</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964349&amp;idx=1&amp;sn=10d1402c376d01963509c0f04a20d5e8&amp;chksm=8559299f0a1d3ad8a549a938387c5ebabd48a3b2230da956aa2181f438de8ecbd19eb2e0bbe5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 04:57:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[算法不重要，AI的下一个范式突破，「解锁」新数据源才是关键]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiclpKp5iaMh8iahEt7aBwB7DEAbKMOllq0Bo33bVfeIBBSAktiajqtUnbwdpWmFfaN7AicrMickRbicrvHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：蛋酱众所周知，人工智能在过去十五年里取得了令人难以置信的进步，尤其是在最近五年。回顾一下人工智能的「四大发明」吧：深度神经网络→Transformer 语言模型→RLHF→推理，基本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964349&amp;idx=2&amp;sn=5018ddc4d4d9d5e8c46ad70bb3ba858e&amp;chksm=851c70428fce952374fd05543e5845e66bb04ef3da5173ee1bd457ec7c7fce9e58478d62ab91&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 04:57:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[苹果发现原生多模态模型Scaling Laws：早融合优于后融合，MoE优于密集模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUeuUFttHabDy8YoMcibZlzYYGSa2jzn49zCkZxEqlZRcXrLD9Cm6vRTA/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：泽南、Panda让大模型进入多模态模式，从而能够有效感知世界，是最近 AI 领域里人们一直的探索目标。目前我们见到的很多多模态大模型应用是「组合式」的：其中集成了数个单独预训练的组件</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964349&amp;idx=3&amp;sn=00799602fe371fde27c50c60ee91c0c4&amp;chksm=85f3b87f2142cbff80daa00b199ea6398c5f78fd4eb57d09ef9d9c197b30916de9923970fea8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 04:57:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[面对杂乱场景，灵巧手也能从容应对！NUS邵林团队发布DexSinGrasp基于强化学习实现物体分离与抓取统一策略]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IK4aPsf7fQee1Mq0BoTv36k1BmbZNBvX3CXqyV3493DiavTiauUL1uB9hg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文的作者均来自新加坡国立大学 LinS Lab。本文的共同第一作者为新加坡国立大学实习生许立昕和博士生刘子轩，主要研究方向为机器人学习和灵巧操纵，其余作者分别为硕士生桂哲玮、实习生郭京翔、江泽宇以及</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964349&amp;idx=4&amp;sn=cca34ab5e5e9508fd542b8300324727a&amp;chksm=85a2d0d86c352c65b78f43f8a066edf8a73b806290cb621d49e4372a8f446deeda945d5fe5db&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 04:57:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Anthropic 首席科学家的 AI「视界」如何判别 AGI 进程？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUxTRlVoMRqa1cH3KnZWWShGHmKLEKVJFSMgNGymyKjKqKjezFBtYqhA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文来自PRO会员通讯内容，文末关注「机器之心PRO会员」，查看更多专题解读。Anthropic 联创兼首席科学家 Jared Kaplan 在一场 AGI 主题的访谈中用 AI「视界」衡量了模型的能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964317&amp;idx=1&amp;sn=9d8037b8c2d3349fe276c20484b386c1&amp;chksm=859a89e50857d37fde6920a099dacb3cdabdf51244b68fd24f41d8204b0839b36cd61075e4bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 01:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[原生多模态大模型也能强化学习，思维链长达几万字，商汤日日新V6来了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUahr9vCibRg7qpBuviaT3YFKzuZ01XPXxX6INSBGuf0URHRm6K5NT9HSg/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部拥有行业最强多模态推理与交互能力的商汤「日日新 SenseNova V6」来了。如果让大模型像人一样聪明，应该是什么样的？你可能会回答，我们生活的世界纷繁复杂，常常涉及多模态</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964307&amp;idx=1&amp;sn=3424270589b36050fc7d5c39ebedfdf8&amp;chksm=85142250bdbe310ea574df53a5f88a9e96eb9fd848c0481febd512303e525f2c777df50651fe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 13:07:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ChatGPT重大更新，能翻出所有历史对话，网友被AI聊破防了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yU03Cmic2J0gm99BtjibHHW2JeYSfCQLbc2kV8w0W2zRFibH7aea9piaPtDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：泽南终极个人 AI 助理初现雏形。今天凌晨，OpenAI 的 CEO 山姆・奥特曼突然发推说自己睡不着了，因为有重要新功能要推出。很快，OpenAI 就正式发布了一个令人期待的新功能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964307&amp;idx=2&amp;sn=12a892705706f5abb8f203fdcfc5143c&amp;chksm=852825dc1ed9c363ad07d654ce0c2226c18b85c5c66d0665aecbae18555f9eb9ec80c07b63ba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 13:07:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[传统预训练正走向终结，推理优化与后训练提升有限，大模型今后如何突破发展瓶颈？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFENcGM8m7g3pC5zJ2JhNWriby0icfRDzte8wichanvww4dYW8espRz9E4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>高质量数据枯竭，传统预训练走向终点，大模型如何突破瓶颈？当前（多模态）大模型正深陷「数据饥渴」困境：其性能高度依赖预训练阶段大量高质量（图文对齐）数据的支撑。然而，现实世界中这类高价值数据资源正在迅速</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964307&amp;idx=3&amp;sn=f037d36333c3a2fb987a286126087f25&amp;chksm=856f8ede218b05636875b44648d315853126383aa73a70cb0688426fd7ba0aeb20736d2bd37e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 13:07:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[200B参数击败满血DeepSeek-R1，字节豆包推理模型Seed-Thinking-v1.5要来了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUwMjvCgrsqbBKt8UeDklZcPtqWt4fA6OWUsXUWcRIjIicEj7TQ6gCBUw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Panda、+0字节跳动豆包团队今天发布了自家新推理模型 Seed-Thinking-v1.5 的技术报告。从报告中可以看到，这是一个拥有 200B 总参数的 MoE 模型，每次工作</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964188&amp;idx=1&amp;sn=7e9e92163a81d1e3fbeabf96ff6c8c41&amp;chksm=85679e38e8a438d9e01f3042930fe276ea6b8256005894c8464f5e2d7443a57a48d960ac39ba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 03:02:11 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IC-Light的视频版本来了，RelightVid：强光动态环境下的视频光照编辑神器]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFw6AM84e5ziabyYey0HGL0zTicN32VH9AT0N2LsmEnnaicTGMSpUtTs7icw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家还记得那个 ICLR 2025 首次满分接收、彻底颠覆静态图像光照编辑的工作 IC-Light 吗？今天，来自复旦大学、上海交通大学、浙江大学、斯坦福大学等机构的学者们正式宣布：IC-Light </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964188&amp;idx=2&amp;sn=662fa2a1d768b8f9ece7ff2b00a88ae4&amp;chksm=856797124c3257154fa2c62454e40fea7da2d28255e961e0391d3586e85b6e1aba07167f910e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 03:02:11 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MoE模型已成新风口，AI基础设施竞速升级]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IKOXsnYL7Vx02HM9gSls5Oh1bhvhkdeT33ibia7PclicUciaKibTFKyplEEUg/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Panda因为基准测试成绩与实际表现相差较大，近期开源的 Llama 4 系列模型正陷入争议的漩涡之中，但有一点却毫无疑问：MoE（混合专家）定然是未来 AI 大模型的主流范式之一。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964063&amp;idx=1&amp;sn=91a4f9e74086b5897b5812b51a183b32&amp;chksm=85ed4567f0aff9e8253583de80232d827eda08f0c4d95252014d7807a5870579245085426eab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:31:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[42.5 Exaflops：谷歌新TPU性能超越最强超算24倍，智能体协作协议A2A出炉]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IK40BLl2qnBpAcibzictq1Eib3UOlOibfjosGAx4Z96kHiahLlvvK7FqUAFVw/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：泽南、+0第七代 TPU 来了。AI 算力又迎来了新的标杆。本周三，谷歌正式发布了旗下第七代张量处理单元（TPU）Ironwood。谷歌称，在大规模部署的情况下，这款 AI 加速器的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964063&amp;idx=2&amp;sn=fae1953e7bd488ebb976b91c51ba334b&amp;chksm=856b35ed379e315457ec5133c091910aaa4b7f8daaec5b0b85589f2b4ea748ad04db519fa9f6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:31:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 2D 大模型赋能3D Affordance 预测，GEAL助力可泛化的3D场景可交互区域识别]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vTAu7DCxGQFpWic1fzYsq7ic7EgACGj9mOC1icibsiawlwPKrPImiaNHIqFFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>GEAL 由新加坡国立大学的研究团队开展，第一作者为博士生鲁东岳，通讯作者为该校副教授 Gim Hee Lee，团队其他成员还包括孔令东与黄田鑫博士。主页：https://dylanorange.gi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964063&amp;idx=3&amp;sn=9c318f83edaeb4b3771e4fc47eb78240&amp;chksm=85c57dcf01703fdca7c087b80365101356a1a06255135b487e0c00f1b6561e5f58f3079d5b35&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:31:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[闭环端到端精度暴涨19.61%！华科&amp;小米汽车联手打造自动驾驶框架ORION，代码将开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8HXJJMEnKicFIibEic39ngdq4vEhWcLpzswMK5XPpN818WWQakWOq3f014Dju2RFoVMto92b2FjS6Og/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，端到端（End-to-End，E2E）自动驾驶技术不断进步，但在复杂的闭环交互环境中，由于其因果推理能力有限，仍然难以做出准确决策。虽然视觉 - 语言大模型（Vision-Language M</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964063&amp;idx=4&amp;sn=13eeb7cceae559108fee593e1c96cb24&amp;chksm=8539e4ceb31879682f88c8b46d2599a3a78421814fbd6325076e8e69892e93fcb993b88b7834&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:31:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[因研发FPGA工具，丛京生院士获得ACM计算突破奖]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IKSn5UxraJ23Gv29Ohn8jfV2wkgrlwaicfQKPqwnUDNKmxjF43oxnC5gQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Panda今天凌晨，国际计算机学会（ACM）宣布了今年的 ACM 计算突破奖获奖者。丛京生（Jason Cong）「因其在现场可编程系统和可定制计算的设计和自动化方面做出的奠基性贡献</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963965&amp;idx=1&amp;sn=4e71a1fc84e67f6f444286cae3053364&amp;chksm=85f9f1ba39a9ef8e2006bb9848acc96e6d77ac15a50f9321bcd0cc2f5530c0d48e0f84326a60&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 02:59:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型推理无损加速6.5倍！EAGLE-3碾压一切、延续Scaling Law能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vSD7GHOAbyYoK1bmkhgmftL1V6RoiaLhqVqrV0SHZd1aibHSEicZ7GLjCQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>自回归解码已然成为大语言模型的推理标准。大语言模型每次前向计算需要访问它全部的参数，但只能得到一个 token，导致其生成昂贵且缓慢。近日，EAGLE 团队的新作《EAGLE-3: Scaling u</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963965&amp;idx=2&amp;sn=4bcca8e1a43e6b39e8052c050c56c876&amp;chksm=85d3c19c716f783923848bbdb506e4573dfe500b8897a45ea5e5eb540a970edf250e48b853c2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 02:59:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI封神了！无剪辑一次直出60秒《猫和老鼠》片段，全网百万人围观]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFWl0Yy1q1dKzrohxtxwKYteTgGVxRopKfibeIP4AyNwBmRWpkDicBibjyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：杜伟、蛋酱AI 圈永远不缺「新活」。这两天，加州大学伯克利分校、斯坦福大学、英伟达等机构联合制作的《猫和老鼠》AI短片火了。论文共同一作 Karan Dalal 的帖子收获百万观看。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=1&amp;sn=4cee55a6aeccd0cc7f49f1c8cb9c5b51&amp;chksm=850190452c09516c791ea56747ea4f0f57fd0e94ad74835f05dad92a361dd7275020499b3445&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文党狂喜！alphaXiv推出Deep Research一秒搜遍arXiv，研究效率直接爆表]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFibxFjazPrpgrSaV4L1X9EJic63SDEQVXicdkmpKUMO75ZCE57I6D28DcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：+0刚刚，alphaXiv 推出了新功能「Deep Research for arXiv」，该功能可协助研究人员更高效地在 arXiv 平台上进行学术论文的检索与阅读，显著提升文献检</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=2&amp;sn=16bf30502a94f71585daaaeeb6d6dd50&amp;chksm=85ba9416ff321350c64b9d7e695e01ec10a060b0493b5039c57e190913ba1b3049fb0ad85dce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 HighLight｜打通视频到3D的最后一公里，清华团队推出一键式视频扩散模型VideoScene]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v25jWmX6S2LQEOJn6Bu0ohVa4gibm4sv3BFJkxQQSPNoxC6y3853O80Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文有两位共同一作。汪晗阳，清华大学计算机系本科四年级，研究方向为三维视觉、生成模型，已在CVPR、ECCV、NeurIPS等会议发表论文。刘芳甫，清华大学电子工程系直博二年级，研究方向为生成模型 (</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=3&amp;sn=7a51f00a00c37ecdcb8b8c59acaa937b&amp;chksm=85f212898c3c50f72f75fdffbc2c5efb9970a9a3e76255aabcd4dceb2ad4c3fbda4289c2ecdc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工&amp;普渡大学提出CFG-Zero*：在Flow Matching模型中实现更稳健的无分类器引导方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v14PDgVbUiccicNicxCbflmicYxVD9ybHWUYuY8eRRIQvrW02oymIKDJAhw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇论文是由南洋理工大学 S-Lab 与普渡大学提出的无分类引导新范式，支持所有 Flow Matching 的生成模型。目前已被集成至 Diffusers 与 ComfyUI。论文标题：CFG-Ze</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=4&amp;sn=6b81be1904d11911dede2f2e5d77ff22&amp;chksm=85b3c3109ffc4bfd65916c391715c0dc1cedf02654a6115f74aef16e4234f4ff3e595f07fe0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[全日程揭晓！ICLR 2025论文分享会我们北京见]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vd68IxfialZjbGfxY7icYgobzWDlsE2d8xUP2NLzbibEFZZAlxNyXMm7Ww/640?wxtype=jpeg&amp;wxfrom=0"/><p>从 OpenAI o1 到 DeepSeek R1，推理模型进入到了全新的发展阶段，展现出来的「慢思考、强推理」能力正在加速从语言智能到认知智能的进程，并构筑起未来 AGI 的重要基石。同时，学界对大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963889&amp;idx=1&amp;sn=f3d5234b73b3e593ab8c41e591b97133&amp;chksm=85e36fc2bf6a01cc6797c3eaadbe946a9275a9e4c8bfec9b135e9ad9c4a894a9a8015ceabeac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 03:07:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从零搭一套可复现、可教学、可观察的RL for VLM训练流程，我们试了试]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v3cln5A4ZJISoIDSwa2d5YSC0rKqhUq71PsXZACXwDc9VvmwvrAArZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>自 Deepseek-R1 发布以来，研究社区迅速响应，纷纷在各自任务中复现 R1-moment。在过去的几个月中，越来越多的研究尝试将 RL Scaling 的成功应用扩展到视觉语言模型（VLM）领</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963889&amp;idx=2&amp;sn=19b8cd5cb8193c9e5f58a537d7eeadc8&amp;chksm=85119ccec38778e2a54a790ed60b63418f161eba36b7fdad6489a79242f2c8f5b96c1685eb36&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 03:07:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[迈向机器人领域ImageNet，大牛Pieter Abbeel领衔国内外高校共建RoboVerse，统一仿真平台、数据集和基准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vWuVpicSspZb9GLR5NKZHSapjCEcZvM9fibtGrk6SPIquJTtMJhOLUhDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大规模数据集和标准化评估基准显著促进了自然语言处理和计算机视觉领域的发展。然而，机器人领域在如何构建大规模数据集并建立可靠的评估体系方面仍面临巨大挑战。一方面，采集真实世界的机器人数据需要消耗大量资源</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963868&amp;idx=1&amp;sn=b12ca51e5cf5a8b758b7eaaa02405f85&amp;chksm=85e542e994e8954c0962b223f09ceaf36497d9de4d816eec298dffa3728cdbb55277e887973c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 09:31:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[UI-R1|仅136张截图，vivo开源DeepSeek R1式强化学习，提升GUI智能体动作预测]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0veCxC6rJic4u0whicN9XhBnJIkWZyo9d7iburE5VCHN6a1icKicSE0buws9A/300?wxtype=jpeg&amp;wxfrom=0"/><p>基于规则的强化学习（RL/RFT）已成为替代 SFT 的高效方案，仅需少量样本即可提升模型在特定任务中的表现。该方法通过预定义奖励函数规避人工标注成本，如 DeepSeek-R1 在数学求解中的成功应</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963868&amp;idx=2&amp;sn=062f4cbd883871ffbd8c4c28b944e5f5&amp;chksm=853f5311141a93107bdbabd8e7cc09d8bd8cc11673b4287d4c09e238c1c33a5098b872e87b2c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 09:31:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Llama 4在测试集上训练？内部员工、官方下场澄清，LeCun转发]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vKau0WmXsaLGyB2sWKPcHpPGMicokXldJZrybVcY3uqMh0CvvZAOj7LQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：张倩、泽南大家翘首以盼的 Llama 4，用起来为什么那么拉跨？Llama 4 这么大的节奏，Meta 终于绷不住了。本周二凌晨，Meta Gen AI 团队负责人发表了一份澄清说明</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=1&amp;sn=2e63fcbf091cef43ae9fbf61aecc15a2&amp;chksm=857ef0a28c02af5d1b3ad8c36bd4c2141186f450f3052aad0c86b3ea9d3e47270427856106d2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 04:48:40 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[斯坦福2025 AI Index报告来了：DeepSeek在全文中被提到45次]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vaXhNlH1uqzEHTql5equsuSPAiaLe0tYk4Oibjm2bvbSJvVbUice6B7Yicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：蛋酱、+0刚刚，斯坦福大学正式发布了《2025 AI Index》报告。在过去的一段时间里，人工智能领域经历了一场蓬勃的发展，但与此同时，也有人说「人工智能是一个泡沫」。其他的讨论话</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=2&amp;sn=9843c5010e27941cd6a9cc09bb2ef96f&amp;chksm=8559d5f21da721c9e2ddbeb61eb74999a52b0f50db55cf6ccca09e7df353af7a2e2dcd33e091&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 04:48:40 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[类R1强化学习迁移到视觉定位！全开源Vision-R1将图文大模型性能提升50％]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v9gz8L8icas71pyGtYfs26Vl5exCdu2J2gcHrtJoW6hmpWgcKuiam1L0A/300?wxtype=jpeg&amp;wxfrom=0"/><p>图文大模型通常采用「预训练 + 监督微调」的两阶段范式进行训练，以强化其指令跟随能力。受语言领域的启发，多模态偏好优化技术凭借其在数据效率和性能增益方面的优势，被广泛用于对齐人类偏好。目前，该技术主要</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=3&amp;sn=7c62398a729785a7d02da7b9d47fab3a&amp;chksm=8525221905860a7ee31228d160e4f9c43b94d60c8acde57393a69b9a129332cc7c29446bba77&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 04:48:40 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[颠覆传统信息搜索，效果是之前SOTA的三倍？UIUC韩家炜、孙冀萌团队开源DeepRetrieval，让模型端到端地学会搜索！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXNUMFw5WKdZ2wK23QFWTia30IKE9E7p9aj8Za1nX2493SObukR3YsrYQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在信息检索系统中，搜索引擎的能力只是影响结果的一个方面，真正的瓶颈往往在于：用户的原始 query 本身不够好。尤其在专业搜索场景（如文献、数据库查询）中，用户往往无法用精确、完整的表达描述他们的需求</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=4&amp;sn=28f1d2a68c5b9f23f435f7aa66335473&amp;chksm=8593ba76d088c1c15fa73b18bb65dd1a3248edc9f61f7ff321f751bebb6b8a4ad40e1d126749&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 04:48:40 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[首次引入强化学习！火山引擎Q-Insight让画质理解迈向深度思考]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWib8gGIFStdWwr8FW74SYGPibDBvTHcz7b3m0DAdZw0FP9FxoGSsVRIqkjiag3JFEndX5ibfQ1rMlISsA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部Q-Insight不再简单地让模型拟合人眼打分，而是将评分视作一种引导信号，促使模型深度思考图像质量的本质原因。有了会思考的“大脑”，视频云技术栈不仅得以重塑也让用户体验有了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963640&amp;idx=1&amp;sn=4627a1366e9482e9dbcc99cf8a2dff57&amp;chksm=85057ce70579f2f48039a611aad647fe2cce5456418c04fbeb96f84b5aaddd9b9b76c4af7bcc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 01:00:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文读得慢，可能是工具的锅，一手实测科研专用版「DeepSeek」]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibdvRMoAz5RN4AEUMO2Rbn4Srp4zg4Wa1TH4T0iawtEnibLiax3dbuqes20aCwich9XAqnjFlvzEyib6CA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心原创作者：张倩「未来，99% 的 attention 将是大模型 attention，而不是人类 attention。」这是 AI 大牛 Andrej Karpathy 前段时间的一个预言。这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963638&amp;idx=1&amp;sn=5d68f81fb9a2d77a2856f1ddb0a735ef&amp;chksm=85fea7d948c96c5befcd07e97e4a84ff690b8f4afb73112e180e38867fd98fd34d5cab52e52a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:33:34 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[反向传播、前向传播都不要，这种无梯度学习方法是Hinton想要的吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8apWjQibSDGflicVKV7CAsLLz7Jtmib4z1Ru1mnWCHNLnMWR8VQiay2xzOMOq2o6V5RM2NpgXhPQRG6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：张倩、+0Noprop：没有反向传播或前向传播，也能训练神经网络。「我们应该抛弃反向传播并重新开始。」早在几年前，使反向传播成为深度学习核心技术之一的 Geoffrey Hinton</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963638&amp;idx=2&amp;sn=ec44861a4abc6cfb93b9cd8cdc179d26&amp;chksm=85d47b008b5dd45424d986fc6b0b49413153f3e3ceff668fd1a843395c657ccb35117b5a5f72&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:33:34 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MoCha：开启自动化多轮对话电影生成新时代]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiciaTmTso3bEKnrl9RXg2LfibZCnfBUHloJkPt7iaOzC7teQCeB6XuKHf6CJZBLiaiaOVLzqNibyLgKKcVw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文由加拿大滑铁卢大学魏聪、陈文虎教授团队与 Meta GenAI 共同完成。第一作者魏聪为加拿大滑铁卢大学计算机科学系二年级博士生，导师为陈文虎教授，陈文虎教授为通讯作者。近年来，视频生成技术在动作</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963638&amp;idx=3&amp;sn=87b688d624d02b929f51ff8eee12d16f&amp;chksm=859b52ab4b7fe051670dafcf2dc40327dc13aa9e12c34e3f028e450680020a45982e459de647&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:33:34 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[铰链物体的通用世界模型，超越扩散方法，入选CVPR 2025]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXL9ia5mstx7BWZibFR6sRQ4RBqcOW6zib8nia5NB1xFjzZLoEdibxCQavt0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>基于当前观察，预测铰链物体的的运动，尤其是 part-level 级别的运动，是实现世界模型的关键一步。尽管现在基于 diffusion 的方法取得了很多进展，但是这些方法存在处理效率低，同时缺乏三维</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963638&amp;idx=4&amp;sn=3b9a244025311b21c645a0b3448fe7dd&amp;chksm=851bce195bc572682080834bb080c1fbc68be9de5127fe9ea0a8a75a78b264a37bec567f2911&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:33:34 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta Llama 4被疑考试「作弊」：在竞技场刷高分，但实战中频频翻车]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8apWjQibSDGflicVKV7CAsLL0WSOQ86BlribYMjXEER57pnBt7BDHMJOBLGyr2womJt9IYJqK3tnfKA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部Meta 翻车来得猝不及防。上周六，Meta 发布了最新 AI 模型系列 ——Llama 4，并一口气出了三个款，分别是 Llama 4 Scout、Llama 4 Mave</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963634&amp;idx=1&amp;sn=4935ed3758561c8ee8366adce6b3be1f&amp;chksm=85f03fd34e34f6e5719c23a45f8d47247e86f80a480c2b9c39c60d07d9c49edb035e2eeb7eb3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 03:51:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ILLUME+：华为诺亚探索新GPT-4o架构，理解生成一体模型，昇腾可训！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWib8gGIFStdWwr8FW74SYGPibyx3Hb3r0lRZmIuUtZvfVjicgD1ib4xQG4FdpjreNT4ibqKDZCjQIian8og/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，基于大语言模型（LLM）的多模态任务处理能力取得了显著进展，特别是在将视觉信息融入语言模型方面。像 QwenVL 和 InternVL 这样的模型已经展示了在视觉理解方面的卓越表现，而以扩散模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963634&amp;idx=2&amp;sn=0891fee849bb90b2c6a9335f22df3410&amp;chksm=85ac296db33ccf116569187dd8421932df88b0307a95ccb35fd6d5d2f5a94b0aba5c984d84c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 03:51:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[解构多模态，GPT-4o 的自回归路线真的走通了吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8FelbdsTQvaNCN5mPann8gWL1wwXc7ZGsh7ibTKENyYluYoUEjkicgQzmhm90MzNrHTW6YT8p2E1ow/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心PRO · 会员通讯 Week 14--- 本周为您解读 ② 个值得细品的 AI &amp; Robotics 业内要事 ---1. 解构多模态，GPT-4o 的自回归路线真的走通了吗？GPT-4o </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963545&amp;idx=1&amp;sn=ccc34a1cca1533c7d0ff716d36e8bdcd&amp;chksm=853bb25e4db3fa82c2480ffa0fe0ed63d1e10252f87184cac59709fd3c481a130ae3642aa3b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 06:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta深夜开源Llama 4！首次采用MoE，惊人千万token上下文，竞技场超越DeepSeek]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWib8gGIFStdWwr8FW74SYGPib5RoP6oKXxibxLJX6iaAr8YEayqGhP1osbfTlibwgt9ia8qJBjLKuSPvwmA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部万万没想到。Meta 选择在周六日，发布了最新 AI 模型系列 ——Llama 4，这是其 Llama 家族的最新成员。该系列包括 Llama 4 Scout、Llama 4</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963546&amp;idx=1&amp;sn=9b93063a0f272ed5a2e4d56725328e32&amp;chksm=857055ff35264f4c30fc939bf069ecbfdf6e762dfe3dab1347a26759d1e08886e28f6f7732f3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 00:40:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从0到1玩转MCP：AI的「万能插头」，代码手把手教你！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibdvRMoAz5RN4AEUMO2Rbn4TFJo7wV2Fbb1pfib3tkVu9PTIeSFDePSy8F99eoohGfZ9PIm2QzPdBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>选自Towards Data Science作者：Sandi Besen机器之心编译在人工智能飞速发展的今天，LLM 的能力令人叹为观止，但其局限性也日益凸显 —— 它们往往被困于训练数据的「孤岛」，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963546&amp;idx=2&amp;sn=9853970a59b52ed72b16a10fedc99c19&amp;chksm=8575ab8cc0716700c7e1daa7237340ad780b9700974d093b590f92b0a0488bdc48185af9f3cf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 00:40:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR满分论文 | 英伟达开源双目深度估计大模型FoundationStereo]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXuV5FXZuBicHAQd9dH6t38WLicpcvxG8icVy1ic1aoiaAUUkaUcggic9IFlsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍了 FoundationStereo，一种用于立体深度估计的基础模型，旨在实现强大的零样本泛化能力。通过构建大规模（100 万立体图像对）合成训练数据集，结合自动自筛选流程去除模糊样本，并设计</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963546&amp;idx=3&amp;sn=8f7ee6579f70d6378c7ef130e330b423&amp;chksm=859556efbe6bb79792ea46911459a64c444a8d41ad0eedd578d0b85da9cad4df4120c6b638b9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 00:40:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大语言模型变身软体机器人设计「自然选择器」，GPT、Gemini、Grok争做最佳]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJX0UGDqZCXT8FOiaajbpBcbuSYd5ibfQccCYEBbMMpbEpHics0wSXwnaPow/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型 (LLM) 在软体机器人设计领域展现出了令人振奋的应用潜力。密歇根大学安娜堡分校的研究团队开发了一个名为「RoboCrafter-QA」的基准测试，用于评估 LLM 在软体机器人设计中的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963546&amp;idx=4&amp;sn=09a315d3e78f6b190224df55f1d4c9d4&amp;chksm=853b6bdf80d42ec6d748904c97445413cfd42f1aa0b131f6f0cd11ca20fd92b5fecb6cd86e8c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 00:40:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[全网都在猜，这些视频是不是字节AI生成的：该跟动捕说再见了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8vAMiaOQhhApSnSPJ3lFJiaIvescCqUjSV1SevGEFiaMlOCJx1IKLeAewXHicNxzB3MAXLy1fMCTrGsA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：梓文动作捕捉，刚刚发生了革命。在 GPT-4o 的风到处吹时，X 平台（原推特）上有好多带视频的帖子爆了。到底是什么引来了一百万的浏览量？没错，是玛丽莲・梦露「活了过来」。她不仅能够</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963521&amp;idx=1&amp;sn=3020279603bac4495bf8245709230ec4&amp;chksm=8593acb187df2f0cff386ef1d054f8e865c60d45df56f932bc1deb84a74eb136da23d175f2ee&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Apr 2025 08:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 Oral | 多模态交互新基准OpenING，新版GPT-4o杀疯了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnN1eCBU3ByDnZeicjHeia65MygsKjVpYEVUqB1Jibpibuy6qvQicR4yZ7GX5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>文生图 or 图生文？不必纠结了！人类大脑天然具备同时理解和创造视觉与语言信息的能力。一个通用的多模态大语言模型（MLLM）理应复刻人类的理解和生成能力，即能够自如地同时处理与生成各种模态内容，实现多</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963521&amp;idx=2&amp;sn=412f932c14796e8672e3786f87a793ff&amp;chksm=85ec11f7befb3694f17f415e41bb64fbe9d332455d98ea33aee7013a8c256056e513edd493d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Apr 2025 08:10:00 +0000</pubDate>
    </item>
  </channel>
</rss>