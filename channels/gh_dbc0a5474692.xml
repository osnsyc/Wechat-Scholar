<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[机器之心]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[机器之心公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_dbc0a5474692.jpg</url>
      <title>gh_dbc0a5474692</title>
    </image>
    <item>
      <title><![CDATA[从 VLM 到 VLA，智驾距离跨过「L2.9999」还有多远？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8FelbdsTQvaNCN5mPann8gWL1wwXc7ZGsh7ibTKENyYluYoUEjkicgQzmhm90MzNrHTW6YT8p2E1ow/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心PRO · 会员通讯 Week 20--- 本周为您解读 ② 个值得细品的 AI &amp; Robotics 业内要事 ---1. 从 VLM 到 VLA，智驾距离跨过「L2.9999」还有多远？各</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969499&amp;idx=1&amp;sn=83b4979aa0d5a668156a1a38fdc551be&amp;chksm=85b4d40a9569b409fcfba238f448f27e14f2cdbdcdd155bcac6e0a94a5bdcedd0e79470fc8fd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 02:38:44 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像分词器造反了！华为 Selftok：自回归内核完美统一扩散模型，触发像素自主推理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibEbsia9Ynuctvv0LXvYlEibMArsfgFDEZOYdpdIg8VkczH1ibjWa0nv5xkPyAAwh6GLbibYvfSQ7u4lA/640?wxtype=jpeg&amp;wxfrom=0"/><p>自回归（AR）范式凭借将语言转化为离散 token 的核心技术，在大语言模型领域大获成功 —— 从 GPT-3 到 GPT-4o，「next-token prediction」以简单粗暴的因果建模横扫</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969496&amp;idx=1&amp;sn=4f6b0a878fa953093dddb4cff3453829&amp;chksm=8563d355f9660592213e5ae30cf5f3b5e6bd107844d59b85de77ef2fac327b9867e0b43acfd7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 06:00:01 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | SketchVideo让手绘动起来，视频生成进入线稿时代]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicSKRC1lyVXiagUyrpWXrxynt3MOvpaLoHNECGQZs9rFNxKQNA3WQ3yX9sIwDAmlaCmmEVHDaTWRlw/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，生成式人工智能的快速发展，在文本和图像生成领域都取得了很大的成功。视频生成作为 AIGC 的重要研究内容，在影视制作、短视频合成和虚拟仿真等方面都有应用价值。现有的商用和开源的视频生成模型，都</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969496&amp;idx=2&amp;sn=dae047eb531c57e52e0b73ac23aae92a&amp;chksm=8584a4a1a3168ae0422841bc03f16b20e8b3af61dd2149a5dd5bca9c7bb940df4af9b5838cf4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 06:00:01 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[争夺 Agent 市场，微软的押宝点竟是「情商」？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicSKRC1lyVXiagUyrpWXrxynibN5Zn1vLEkklM6RUFlicibOuPLAgUiaYKjL6gIyy2iaF9oUxUbUwnEPEgA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文来自PRO会员通讯内容，文末关注「机器之心PRO会员」，查看更多专题解读。微软 AI CEO Mustafa Suleyman 近日接受了海外播客 AI Applied 的访谈，分享了他对 AI </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969459&amp;idx=1&amp;sn=29aed308c68f936fdd560651dc87bce5&amp;chksm=85a2abfe4d67e06c21270e99cb2a75570aca1e6aec761b718e70bac563da819575484af1d1f9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 02:20:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刚刚，OpenAI最强编程智能体上线ChatGPT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicSKRC1lyVXiagUyrpWXrxynTPwhZdeHwmLCYnNeocQCLRQoy4HvNXoa5xAptiaQ9Tppsep5GmvCoVA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部从编程开始，今年智能体要卷飞了！！！昨天，OpenAI CEO 奥特曼预告了一项新研究，吊足了所有人的胃口。就在刚刚，谜底揭晓！OpenAI 宣布，在 ChatGPT 中引入</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969451&amp;idx=1&amp;sn=adb07a6587841af3f07af1301dedee94&amp;chksm=85104ca18e0be39f11d69a5cc6071b64493e77d573240758283a41178e2a77e2eb385068d556&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:31:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[85倍速度碾压：苹果开源FastVLM，能在iphone直接运行的视觉语言模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8hpZtcxlGwk419nJeqVZEc3icOsL1gAiaAWfKwWtDS99RWhicPNOHA50kXiaJ2DsgR6iaicGLbxl3Ee1gQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道作者：+0、刘欣FastVLM—— 让苹果手机拥有极速视觉理解能力当你用苹果手机随手拍图问 AI：「这是什么？」，背后的 FastVLM 模型正在默默解码。最近，苹果开源了一个能在 iPh</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969451&amp;idx=2&amp;sn=52a014a7559c2e13a361e3823ecb8259&amp;chksm=856f45da20d4a05d249d252936104bc39d89768111152297ebf8d4a5adef235f056a5a06da8f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:31:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 Spotlight｜南洋理工陶大程教授团队等提出基于RAG的高分辨率图像感知框架，准确率提高20%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicSKRC1lyVXiagUyrpWXrxynxiaRvUWB0fGu0Ntnic5GEfXexfibhbpAUtJ3WhmKyO76gyVVWsyyk5zfQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>该工作由南洋理工大学陶大程教授团队与武汉大学罗勇教授、杜博教授团队等合作完成。近些年，多模态大语言模型（MLLMs）在视觉问答、推理以及 OCR 等任务上取得了显著的成功。然而，早期的 MLLMs 通</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969451&amp;idx=3&amp;sn=6df190541926ed328aa8187b726f90a9&amp;chksm=85a111ecc4c37ffe5fdffdfa80671a92685d4bf650f8ae11a176b9eead66e52b7e71d6e3b8a7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:31:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刚刚，Manus生图功能强势登场！从设计到搭建网站一站式搞定，1000积分免费薅]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicSKRC1lyVXiagUyrpWXrxynRrs1xIKjtLGibNAibZ4XkLN6swdRgxA6aFxLUnkcvqL7ibibvdmpMviacCA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：陈陈、杜伟那个曾经一码难求的 Manus 已经可以全面注册了。从此以后，到处求购邀请码的时代一去不复回。首次注册就送「1000 积分」让你尝尝鲜！不得不说，Manus 这次真是豪气了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969247&amp;idx=1&amp;sn=e6bcbb9fade4ec3d656f0d9b46a4bde9&amp;chksm=855e253a40e16afe63c82b7b2bdd8d8e62a3adef9117f337f0916f0d869f2068841479d27048&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 04:39:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一键开关灯！谷歌用扩散模型，将电影级光影控制玩到极致]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicSKRC1lyVXiagUyrpWXrxynd9icPvYzfIN8ZOz1iczdTl0xTGsPp0Pd0VhKXjvrqecCRfnDPtbU46bw/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：刘欣、+0最近，Google 推出了一个可以精准控制画面中光影的项目 —— LightLab。 它让用户能够从单张图像实现对光源的细粒度参数化控制， 可以改变可见光源的强度和颜色、环</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969247&amp;idx=2&amp;sn=95db6f376ea0c8ac1699ce4b4b99a15a&amp;chksm=852b56ea201144b7ad345a31142d69130a166359c1f18241fa36c096131d1744586c006ab9cb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 04:39:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[泛化性暴涨47%！首个意图检测奖励范式，AI工具爆炸时代意图识别新解法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicAcAVcbKtrGM6xQsSB2dTNjWdJrY7QkFx7hgcIqeprt81ibSJmibz8yCCEuBQkrPuWoJ3ehYiadSJJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型（LLMs）的快速发展和可集成工具的爆炸增长，AI 智能助手在日常生活中可提供的便利越来越多，不仅包括传统任务型对话中订机票、查询天气等助理能力，还增加了无以计数的 AI 能力，如 AI 画</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969247&amp;idx=3&amp;sn=c71de2d50606770177263ece5681dcc1&amp;chksm=85372434e75569b2c2b7657634900c0dcf9ff242dc343bcfbd876b0f1d5fd79a5f7ab98a82b6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 04:39:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阶跃星辰×光影焕像联合打造超强3D生成引擎Step1X-3D！还开源全链路训练代码]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicSKRC1lyVXiagUyrpWXrxynE5ZDJYJp2iaY09iahhdqcNn3WLhCPiboZiaffFb3GebEWzIYRVPcOQXTNg/640?wxtype=jpeg&amp;wxfrom=0"/><p>阶跃星辰携手光影焕像发布并开源 3D 大模型 ——Step1X-3D。Step1X-3D 模型总参数量达 4.8B（几何模块 1.3B，纹理模块 3.5B），凭借坚实的数据基础与先进的 3D 原生架构</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969178&amp;idx=1&amp;sn=eedee5023a31d88de8b95dbb3b44b0d8&amp;chksm=85b24609b889526e9df46c8057ff124e13fe49267f2f4c8f3f81a8bb3b3da524fcfc668b4940&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 02:42:44 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DiffMoE：动态Token选择助力扩散模型性能飞跃，快手&amp;清华团队打造视觉生成新标杆！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibssf2sy58y26bgaWibGrnLjvxYTgQwibZgYY4wNSatg5tAqVLxPmzQROPR9VzZcoHYYKHZmPfLx9gg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文由清华大学和快手可灵团队共同完成。第一作者是清华大学智能视觉实验室在读本科生史明磊。在生成式 AI 领域，扩散模型（Diffusion Models）已成为图像生成任务的主流架构。然而，传统扩散模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969178&amp;idx=2&amp;sn=d8f282e5dc3eb8a5f9265b1d23599e5f&amp;chksm=85b9bfc0f557259a58ffe13015928e7004108a4b64ad4c073283ac84b62098604ca0ab6958b6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 02:42:44 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek-V3再发论文，梁文锋署名，低成本训练大模型的秘密揭开了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicAcAVcbKtrGM6xQsSB2dTNn2jN87S0aar9DyaSFFcXv6jBgApyPsAfMm2hr3icJDR2mVcCia8lPfyA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部关于 DeepSeek-V3，你需要了解的一切。虽然此前 DeepSeek 已经发布了 V3 模型的技术报告，但刚刚，他们又悄然发布了另一篇围绕 DeepSeek-V3 的技</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969136&amp;idx=1&amp;sn=2e72aaaed79b18eb64bde52d2f453ce8&amp;chksm=854b9028028829745394a02857dde1b3d420e1b1d263fc44976f48f5ab9b175d01b49a78c213&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 08:40:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[「边思考、边搜索、边写作」WebThinker开启AI搜索&amp;研究新纪元！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibssf2sy58y26bgaWibGrnLjYEAl1usHib2akJgolPIXTPWe7RW86TiaXvibkibibPydPInUBHlblnuNqng/300?wxtype=jpeg&amp;wxfrom=0"/><p>李晓熙目前就读于中国人民大学高瓴人工智能学院，博士二年级，导师为窦志成教授，研究方向主要包括检索增强生成、大语言模型推理等。在国际顶级会议和期刊如 AAAI，SIGIR，TOIS 等发表多篇论文，代表</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969136&amp;idx=2&amp;sn=8256cb11f77b163281c1539280c4f0b6&amp;chksm=85964e62ee4ea5606d60f1e35aa5bcccb22ae9581d2d370250d222a026ae8ce38d958010d3fd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 08:40:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超越OpenAI、ElevenLabs，MiniMax新一代语音模型屠榜！人格化语音时代来了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicAcAVcbKtrGM6xQsSB2dTNtN06TkEoDbCwSsSHV0gZwsKeeZcdXTUsmMugHQsHM6D9DgUtvmQ51g/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：杜伟、陈陈国产大模型进步的速度早已大大超出了人们的预期。年初 DeepSeek-R1 爆火，以超低的成本实现了部分超越 OpenAI o1 的表现，一定程度上让人不再过度「迷信」国外</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969047&amp;idx=1&amp;sn=eb22c8f510c369709bb1a503ace7f132&amp;chksm=856a1031fbc569f88c78625a770579c1ed7eeadfabfae350a803b61a912f9a4baa7903340071&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 06:04:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刚刚，DeepMind通用科学智能体AlphaEvolve突破数学极限，陶哲轩合作参与]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicAcAVcbKtrGM6xQsSB2dTNRSoLibgLhYg4booVgiasBNc0gaJ1kZcbzO76WtZD5sSnnefvnX7mEFjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：+0、刘欣今天，DeepMind 正式发布了 AlphaEvolve —— 一个由 LLMs 驱动的革命性进化编码智能体。它不仅仅是一个代码生成工具，更是一个能够演化整个代码库，用于</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969047&amp;idx=2&amp;sn=ef0aadc0ffa79ae0bea4266da98f2bc0&amp;chksm=85cd5dee7125fc7ad9e295a48895f9e0af69488fb219447af76a0610f094801dbafed3cd82e4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 06:04:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | 大模型深度思考新范式：交替「推理-擦除」解决所有可计算问题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8hpZtcxlGwk419nJeqVZEcbtxOVe4QZTCM5O6Dw9gzdUT6icic2PKHgbsEwFqmRdm51cDmqmMSoRFA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者介绍：本文第一作者是丰田工业大学芝加哥 PhD 学生杨晨晓，研究兴趣是机器学习理论和大模型推理，在 ICML，NeurIPS，ICLR 等顶级会议上发表过论文。本文提出一个交替「推理 - 擦除」的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650969047&amp;idx=3&amp;sn=de3572fe4cbfc8b1391bb4fa4bcf9fdc&amp;chksm=85e28a34bd927d7ef3845c9abeea9cc4de97a2cbf9c46b6a88e34ffb1e697cec52f050d915cb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 06:04:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DanceGRPO：首个统一视觉生成的强化学习框架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibssf2sy58y26bgaWibGrnLj722QlO746nNXabicILn0sPb8SUHT4AqekpbYicRNb09d3Fp5OUzPym3Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文由字节跳动 Seed 和香港大学联合完成。第一作者薛泽岳为香港大学 MMLab@HKU 在读博士生，在 CVPR、NeurIPS 等国际顶级会议上发表多篇研究成果。项目通讯作者为黄伟林博士和罗平教</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968990&amp;idx=1&amp;sn=b971ea59a3c3b0c422ac7eaf8cbff2b6&amp;chksm=857c5b4c8bf6d6a3c14ecaeef6c22ca2d5880f6f9407e66702ed2d8ae01b5bc6593e75beb8a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 May 2025 08:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[线下仅200名额！CVPR 2025北京论文分享会报名开启]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibssf2sy58y26bgaWibGrnLj1beiacHEKmZia0VvBzowWRtU6cCxANbTobffY9KvDicILaESNurZLU4fg/300?wxtype=jpeg&amp;wxfrom=0"/><p>2025 尚未过半，人工智能领域的新进展已经令人应接不暇。在计算机视觉领域，生成式 AI、多模态基础模型及实际应用落地等方向都取得了显著进展。这个领域正从单一任务模型转向通用化、多模态的基础架构，同时</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968990&amp;idx=2&amp;sn=60caf48630a3dd35d663902c4ca3e49a&amp;chksm=85e4d7dfb7fdef00df9c25d2ba1bee8a151d09477d8c5d8a40d53fe5a514fcb18b2b615d045b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 May 2025 08:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节最强多模态模型登陆火山引擎！Seed1.5-VL靠20B激活参数狂揽38项SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8hpZtcxlGwk419nJeqVZEcCD6ZcPvM7eJF59en540OuHC4O0kEIBxPjTMDylkXVzlSKuuH4hRnzw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：杨文字节拿出了国际顶尖水平的视觉–语言多模态大模型。5 月 13 日，火山引擎在上海搞了场 FORCE LINK AI 创新巡展，一股脑发布了 5 款模型和产品，包括豆包・视频生成模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968948&amp;idx=1&amp;sn=41a6ee98a833fd2ac6529fd3fc97b807&amp;chksm=85f2688be611e6fa0fb71f6d1a057c7878e5a5cfb8ab461c5aa48ac95f52cd79123f2a37932c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 May 2025 04:36:17 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[叶子豪、陈天奇等人开源项目FlashInfer入选，MLSys2025最佳论文奖公布]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibssf2sy58y26bgaWibGrnLjzXNpic4vicOVPEDQ9zAmAv2fiaF57vkFhbPaA9VRXTkTfBl4zCichLDBFA/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：泽南、+0今年的两篇最佳论文一作均为华人。近日，国际系统领域顶会 MLSys 2025 公布了最佳论文奖。今年的大奖颁发给了来自华盛顿大学、英伟达、Perplexity AI、卡耐基</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968948&amp;idx=2&amp;sn=93a475e6e09054fc83620bbff88a8d65&amp;chksm=85507430425d421b2930733153ca8be42d512dbb1a580bf887120238bd1e02d46ee29eded82f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 May 2025 04:36:17 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | 如何在合成文本数据时避免模型崩溃？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUicicWZ284pwqKB9PJFPSwMnvPOPC5Ff1nibicsaSZ5TgDRKD3ahc083tzKQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着生成式人工智能技术的飞速发展，合成数据正日益成为大模型训练的重要组成部分。未来的 GPT 系列语言模型不可避免地将依赖于由人工数据和合成数据混合构成的大规模语料。然而，这一趋势也带来了严峻挑战：合</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968948&amp;idx=3&amp;sn=6d52bea8a6e159ad6a7e03e956a10124&amp;chksm=85d0decf4ae69c27984067e2f5bbcfdca582bc78e06a265b1f2e4a68ad711f08abd5f0676286&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 May 2025 04:36:17 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[线下仅200名额！CVPR 2025北京论文分享会报名开启]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8hpZtcxlGwk419nJeqVZEc7EIRPiaias9WS9icibgJ4HMLzNd5ztrYofOykeHMBQ0p5VrJ7aYu8iasH3Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025 尚未过半，人工智能领域的新进展已经令人应接不暇。在计算机视觉领域，生成式 AI、多模态基础模型及实际应用落地等方向都取得了显著进展。这个领域正从单一任务模型转向通用化、多模态的基础架构，同时</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968899&amp;idx=1&amp;sn=d446f3cc3de6066a3ae2e5346adc5052&amp;chksm=858d15d53a25a6ff56cb4f87aeb0e06082e60a311d3322bd3234ca31515d76a2f2999d8b4883&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 09:30:17 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[首个多模态统一CoT奖励模型来了，模型、数据集、训练脚本全开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW94vNLlLdhff0PD5eykgRtazKFoADvPIPmd2q5daf6cskVPnzI1uibQEkTcnRzcrF4HeVRkI14xGog/300?wxtype=jpeg&amp;wxfrom=0"/><p>在多模态大模型快速发展的当下，如何精准评估其生成内容的质量，正成为多模态大模型与人类偏好对齐的核心挑战。然而，当前主流多模态奖励模型往往只能直接给出评分决策，或仅具备浅层推理能力，缺乏对复杂奖励任务的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968899&amp;idx=2&amp;sn=73311752ac3ac5c31c41ad6ebf04ae0e&amp;chksm=853e4a5ebf5741448f5ddd76c5ffb6f8dfa18cd0a29e35330cd0c0ff6cc14d538581bb7a6402&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 09:30:17 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[首次！流匹配模型引入GRPO，GenEval几近满分，组合生图能力远超GPT-4o]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8hpZtcxlGwk419nJeqVZEcaV4gcEHiaZOOKXPVXfNYWVgCaee0xObicbFSfvp6IwjlABU27DoSOPHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文由香港中文大学与快手可灵等团队联合完成。第一作者为香港中文大学 MMLab 博士生刘杰，他的研究方向为强化学习和生成模型，曾获 ACL Outstanding Paper Award。流匹配模型因</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968851&amp;idx=1&amp;sn=34daaab8a502a7c003546bf08e3ee3ee&amp;chksm=85127ab5a2711f48a44e93d370c181ac926c9038bbc16abf74872e60d8ea13e12a561b6e3573&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 07:08:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML Spotlight | MCU：全球首个生成式开放世界基准，革新通用AI评测范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUicGPGaQQfjtJZsibaxcKtNaK37LI7Cpdt7fHn3LclbzK4uhibBiaqLvDJlA/300?wxtype=jpeg&amp;wxfrom=0"/><p>该工作由通用人工智能研究院 × 北京大学联手打造。第一作者郑欣悦为通用人工智能研究院研究员，共同一作为北京大学人工智能研究院博士生林昊苇，通讯作者为北京大学助理教授梁一韬和通用人工智能研究院研究员郑子</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968851&amp;idx=2&amp;sn=ae2484492ecc7be9750ad016b460cbab&amp;chksm=8567654eb8e1d758ec6d048f4263cacca0002a96422bef1c29b1bdd83f88d33b3456fd6fb052&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 07:08:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[生成视频好看还不够，还要能自由探索！昆仑万维开源Matrix-Game，单图打造游戏世界]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUic3x5QakvpZctISpKAVjIQYy9lQsKznicHoxK7ubUgUEWAwVicqpRnQVSQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道作者：张倩、泽南世界模型的进度条，最近坐上了火箭。去年 11 月，两家创业公司打造的 Oasis，首次在开源世界模型中实现了实时、可玩、可交互。生成的虚拟环境不仅包含画面，也体现出了对物理</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968805&amp;idx=1&amp;sn=7233b87aa89c3e19841f57c502674645&amp;chksm=8580b4420e7ce02392b36ed288101adec66c0e95f00c8deaf564ae743731bc54d2f4b224d96d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 02:37:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NYU教授公布2025机器学习课程大纲：所有人都在追LLM，高校为何死磕基础理论？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUicH0dgnynRwaCRr6R4oiaGU1U2Tt33WxqPuQ76L1icgdlE24gxMMfNZmNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：+0最近，Meta 公司首席 AI 科学家、图灵奖得主 LeCun 转发了他在纽约大学的同事 Kyunghyun Cho 的一篇帖子：内容是关于这位教授 2025 学年机器学习研究生</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968805&amp;idx=2&amp;sn=6bb95856195246761ab016a68fd44e03&amp;chksm=852bae3018b6a8926f2d5d82432c92d761ebfaf75b1898df174f57f8cb1d62ce6a491050aafb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 02:37:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[突破大模型推理瓶颈！首篇「Test-Time Scaling」全景综述，深入剖析AI深思之道]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUicT16OpTic0cpFreMAaib751NPKFmEVQXn9A89GiapJFhgZWkiblFw7DKcLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文由来自香港城市大学、麦吉尔大学（McGill）、蒙特利尔人工智能实验室（MILA）、人大高瓴人工智能学院、Salesforce AI Research、斯坦福大学、UCSB、香港中文大学等机构的多</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968805&amp;idx=3&amp;sn=ccd2461488dda016766ca2837a5b60f1&amp;chksm=850343ac932fb3d1405d12f2d367256fce1a13559251fe36485bf78039b4b9461eeb541ee47a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 02:37:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[连续思维机器来了！Transformer八子之一创企推出，让AI不再「一步到位」拍脑袋做决定]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUicEGNYC24qh30A4FvuF7NM7ibf1TNQj8Bzu71qmzkS6zxdAArQz47h5uQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：杜伟、蛋酱开启「分步思考」新范式。科学界的一个共识是：即使是最复杂的现代人工智能，也难以媲美人类大脑的表现和效率。研究者经常从大自然中寻找灵感，了解如何在人工智能领域取得进步，例如利</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968794&amp;idx=1&amp;sn=d02911f8ef6ef9889f46bf2122de717a&amp;chksm=855bcb12e436eff9033e8a4d4169fc16d1e7dd8366af921707b45ae8a4637fdb183e8c4b2dbb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 09:06:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | 长视频理解新SOTA！蚂蚁&amp;人大开源ViLAMP-7B，单卡可处理3小时视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUicsGxa5ib6QMvajf7GnnBzcyMgvC8u8ZIicGc9NrojibKTwUw1x74nD6uFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>该工作第一作者为中国人民大学高瓴人工智能学院硕士生程传奇，目前于蚂蚁技术研究院实习，其主要研究领域为多模态大模型，蚂蚁技术研究院副研究员关健为共同第一作者。在视觉语言模型（Vision-Languag</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968794&amp;idx=2&amp;sn=6a5e2853cf7b17b497e58d018a08cc5c&amp;chksm=850f4af20712c87905e9a7cf17fdb87a57e41c959b1deb71794a3b9875408807818f110a0df2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 09:06:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[强迫模型自我争论，递归思考版CoT热度飙升！网友：这不就是大多数推理模型的套路吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUicOTUhuVZia4vJnial1EdDodImRSardZLWz8CiaavtOR9QWkKtMpL32EoeQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：杜伟递归思考 + 自我批判，CoRT 能带来 LLM 推理力的飞跃吗？CoT（Chain-of-thought）大家都很熟悉了，通过模仿「人类解题思路」，进而大幅提升语言模型的推理能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968670&amp;idx=1&amp;sn=cc60f8ae9877549d672e1f3533453a63&amp;chksm=85d1972e9d3ececc43dce3cf60d036bc5dace7f6744d520eadfc198e58af9d87a84b27053d84&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 04:31:47 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[RL训练总崩溃？R1-Reward稳定解锁奖励模型Long-Cot推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUicot31EfzCgF2NIWdianDbR9Hf8kqVPpVfDOKbwaKdxnfRm1w6ujxdqNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心发布机器之心编辑部多模态奖励模型（MRMs）在提升多模态大语言模型（MLLMs）的表现中起着至关重要的作用，在训练阶段可以提供稳定的 reward，评估阶段可以选择更好的 sample 结果，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968670&amp;idx=2&amp;sn=43af2ad356e908557c975ce2ffb9f1e6&amp;chksm=85445d55d5e66c7f092b7501f02eb05716581ae329711f6dba38945082dd4226803289eb1ec1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 04:31:47 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CMU朱俊彦等上新LEGOGPT，一句话就能搭乐高，网友：复杂零件行不行？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiceOLg1Fj6QY5fWMEKLrjUicibwgpf0Kiaz97EFR8qe8gExumyGdD8uNQSMy9491GicM3SRibj8LTzrd1Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部AI 不允许有人不会搭乐高。近日，CMU 助理教授朱俊彦团队带来了新研究 —— 基于文本生成 3D 乐高的大模型。这款大模型有多强呢？比如输入文本「基本款沙发」，一眨眼的功夫</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968670&amp;idx=3&amp;sn=1fd1270d00e0b2e6f8a6a7fc3a816af5&amp;chksm=85d605d280e366d391a9c2974ff792740c09f575527bbe079897b49a06cf9ea3345d8e6a0ad6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 04:31:47 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR2025｜MCA-Ctrl：多方协同注意力控制助力AIGC时代图像精准定制化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW94vNLlLdhff0PD5eykgRtaOicLF2ybciamRAx5MVuE80yVOicKzcuDiaWANUpUgltAPZjmzFCv7nXrKw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文由中国科学院计算技术研究所研究团队完成，第一作者为硕士生杨晗，通讯作者为副研究员安竹林，助理研究员杨传广。论文标题：Multi-party Collaborative Attention Cont</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968670&amp;idx=4&amp;sn=80faadc900918a0ea129397755b7452f&amp;chksm=8568aae1721fba8b29d2fe3f78fbd61a9021322c54949a8dde9d8c39484881d950eee043f815&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 04:31:47 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Copilot上大分，仅数天，陶哲轩的估计验证工具卷到2.0！刚刚又发数学形式化证明视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic9zSic7ruicQlCH4iccfGYxficf8E1jmmUyibAHLiajFE4o97Qo0H8u2xRfgjkAOk0OpZ7VZqXmowYWIzQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：杜伟、大盘鸡本周二，我们报道了菲尔兹奖得主陶哲轩的一个开源项目 —— 在大模型的协助下编写了一个概念验证软件工具，来验证涉及任意正参数的给定估计是否成立（在常数因子范围内）。在项目中</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968588&amp;idx=1&amp;sn=6662d3f64c647b1a9af4f9aa4d27d63b&amp;chksm=853c8a08b3ce729a09a2e8464f4780024a673d428a1d8a1ac49e602cbc930071334757ae00b6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 03:20:53 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[现在的大学生，不用大模型才是异类]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic9XyDIFDk5o9xkXDxmdyIvrSpOsLNJ9sib65n2beuYK9Fo3sOOWO2I3MOn4ljMrB5jxgqg9YYkCmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>选自New York Magazine机器之心编译作者：James D. Walsh「大学现在学的就是掌握 ChatGPT 的程度了。」在北美的顶尖大学校园里，人工智能完成作业、写论文已经成为一种常态</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968588&amp;idx=2&amp;sn=0d2ece2e4e3e8ea56c62d2a29da05f0c&amp;chksm=85914cfe08640bbef496347a23b327fbd093bdf9bf3d544467b98eec98e11306501180f636c0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 03:20:53 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[转身世界就变样？WorldMem用记忆让AI生成的世界拥有了一致性]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic9XyDIFDk5o9xkXDxmdyIv7W1esIPJCUQBiaQ39YFz5ELn2aqWHuXG5Yy6J5y8LNXw0xooOpp9FibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文一作为肖泽琪，本科毕业于浙江大学，现为南洋理工大学博士生，研究方向是基于视频生成模型的世界生成和模拟，导师为潘新钢。个人主页：https://xizaoqu.github.io近年来，基于视频生成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968588&amp;idx=3&amp;sn=c39f85ad59253c1a1ac5910c96e28b3e&amp;chksm=8563538d83df25a333543d4f11f07c9da8c2dba2d653b2a94e493243e9eaee347c19e09235b3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 03:20:53 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SIGGRAPH 2025 | 快手可灵团队提出3D感知的可控电影级视频生成工作CineMaster！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic9XyDIFDk5o9xkXDxmdyIvMJSRzxTZ5eeBg60Kb64ZOrr3BdtvZnlRbstJ2ibMsRG0I6FlpPs2QFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Sora、可灵等视频生成模型令人惊艳的性能表现使得创作者仅依靠文本输入就能够创作出高质量的视频内容。然而，我们常见的电影片段通常是由导演在一个场景中精心布置多个目标的运动、摄像机拍摄角度后再剪辑而成的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650968588&amp;idx=4&amp;sn=422ba2eee8e9da120442deead9fa6523&amp;chksm=855fe2b7e74caf56fe8e18a72cc23a57c77c0485ed6cf0ba5adac62d6e83016476a8dc3d6863&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 03:20:53 +0000</pubDate>
    </item>
  </channel>
</rss>