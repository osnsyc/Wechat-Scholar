<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[机器之心]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[机器之心公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_dbc0a5474692.jpg</url>
      <title>gh_dbc0a5474692</title>
    </image>
    <item>
      <title><![CDATA[因研发FPGA工具，丛京生院士获得ACM计算突破奖]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IKSn5UxraJ23Gv29Ohn8jfV2wkgrlwaicfQKPqwnUDNKmxjF43oxnC5gQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Panda今天凌晨，国际计算机学会（ACM）宣布了今年的 ACM 计算突破奖获奖者。丛京生（Jason Cong）「因其在现场可编程系统和可定制计算的设计和自动化方面做出的奠基性贡献</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963965&amp;idx=1&amp;sn=4e71a1fc84e67f6f444286cae3053364&amp;chksm=85f9f1ba39a9ef8e2006bb9848acc96e6d77ac15a50f9321bcd0cc2f5530c0d48e0f84326a60&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 02:59:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型推理无损加速6.5倍！EAGLE-3碾压一切、延续Scaling Law能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vSD7GHOAbyYoK1bmkhgmftL1V6RoiaLhqVqrV0SHZd1aibHSEicZ7GLjCQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>自回归解码已然成为大语言模型的推理标准。大语言模型每次前向计算需要访问它全部的参数，但只能得到一个 token，导致其生成昂贵且缓慢。近日，EAGLE 团队的新作《EAGLE-3: Scaling u</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963965&amp;idx=2&amp;sn=4bcca8e1a43e6b39e8052c050c56c876&amp;chksm=85d3c19c716f783923848bbdb506e4573dfe500b8897a45ea5e5eb540a970edf250e48b853c2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 02:59:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI封神了！无剪辑一次直出60秒《猫和老鼠》片段，全网百万人围观]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFWl0Yy1q1dKzrohxtxwKYteTgGVxRopKfibeIP4AyNwBmRWpkDicBibjyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：杜伟、蛋酱AI 圈永远不缺「新活」。这两天，加州大学伯克利分校、斯坦福大学、英伟达等机构联合制作的《猫和老鼠》AI短片火了。论文共同一作 Karan Dalal 的帖子收获百万观看。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=1&amp;sn=4cee55a6aeccd0cc7f49f1c8cb9c5b51&amp;chksm=850190452c09516c791ea56747ea4f0f57fd0e94ad74835f05dad92a361dd7275020499b3445&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文党狂喜！alphaXiv推出Deep Research一秒搜遍arXiv，研究效率直接爆表]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFibxFjazPrpgrSaV4L1X9EJic63SDEQVXicdkmpKUMO75ZCE57I6D28DcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：+0刚刚，alphaXiv 推出了新功能「Deep Research for arXiv」，该功能可协助研究人员更高效地在 arXiv 平台上进行学术论文的检索与阅读，显著提升文献检</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=2&amp;sn=16bf30502a94f71585daaaeeb6d6dd50&amp;chksm=85ba9416ff321350c64b9d7e695e01ec10a060b0493b5039c57e190913ba1b3049fb0ad85dce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 HighLight｜打通视频到3D的最后一公里，清华团队推出一键式视频扩散模型VideoScene]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v25jWmX6S2LQEOJn6Bu0ohVa4gibm4sv3BFJkxQQSPNoxC6y3853O80Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文有两位共同一作。汪晗阳，清华大学计算机系本科四年级，研究方向为三维视觉、生成模型，已在CVPR、ECCV、NeurIPS等会议发表论文。刘芳甫，清华大学电子工程系直博二年级，研究方向为生成模型 (</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=3&amp;sn=7a51f00a00c37ecdcb8b8c59acaa937b&amp;chksm=85f212898c3c50f72f75fdffbc2c5efb9970a9a3e76255aabcd4dceb2ad4c3fbda4289c2ecdc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工&amp;普渡大学提出CFG-Zero*：在Flow Matching模型中实现更稳健的无分类器引导方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v14PDgVbUiccicNicxCbflmicYxVD9ybHWUYuY8eRRIQvrW02oymIKDJAhw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇论文是由南洋理工大学 S-Lab 与普渡大学提出的无分类引导新范式，支持所有 Flow Matching 的生成模型。目前已被集成至 Diffusers 与 ComfyUI。论文标题：CFG-Ze</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=4&amp;sn=6b81be1904d11911dede2f2e5d77ff22&amp;chksm=85b3c3109ffc4bfd65916c391715c0dc1cedf02654a6115f74aef16e4234f4ff3e595f07fe0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[全日程揭晓！ICLR 2025论文分享会我们北京见]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vd68IxfialZjbGfxY7icYgobzWDlsE2d8xUP2NLzbibEFZZAlxNyXMm7Ww/640?wxtype=jpeg&amp;wxfrom=0"/><p>从 OpenAI o1 到 DeepSeek R1，推理模型进入到了全新的发展阶段，展现出来的「慢思考、强推理」能力正在加速从语言智能到认知智能的进程，并构筑起未来 AGI 的重要基石。同时，学界对大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963889&amp;idx=1&amp;sn=f3d5234b73b3e593ab8c41e591b97133&amp;chksm=85e36fc2bf6a01cc6797c3eaadbe946a9275a9e4c8bfec9b135e9ad9c4a894a9a8015ceabeac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 03:07:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从零搭一套可复现、可教学、可观察的RL for VLM训练流程，我们试了试]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v3cln5A4ZJISoIDSwa2d5YSC0rKqhUq71PsXZACXwDc9VvmwvrAArZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>自 Deepseek-R1 发布以来，研究社区迅速响应，纷纷在各自任务中复现 R1-moment。在过去的几个月中，越来越多的研究尝试将 RL Scaling 的成功应用扩展到视觉语言模型（VLM）领</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963889&amp;idx=2&amp;sn=19b8cd5cb8193c9e5f58a537d7eeadc8&amp;chksm=85119ccec38778e2a54a790ed60b63418f161eba36b7fdad6489a79242f2c8f5b96c1685eb36&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 03:07:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[迈向机器人领域ImageNet，大牛Pieter Abbeel领衔国内外高校共建RoboVerse，统一仿真平台、数据集和基准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vWuVpicSspZb9GLR5NKZHSapjCEcZvM9fibtGrk6SPIquJTtMJhOLUhDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大规模数据集和标准化评估基准显著促进了自然语言处理和计算机视觉领域的发展。然而，机器人领域在如何构建大规模数据集并建立可靠的评估体系方面仍面临巨大挑战。一方面，采集真实世界的机器人数据需要消耗大量资源</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963868&amp;idx=1&amp;sn=b12ca51e5cf5a8b758b7eaaa02405f85&amp;chksm=85e542e994e8954c0962b223f09ceaf36497d9de4d816eec298dffa3728cdbb55277e887973c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 09:31:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[UI-R1|仅136张截图，vivo开源DeepSeek R1式强化学习，提升GUI智能体动作预测]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0veCxC6rJic4u0whicN9XhBnJIkWZyo9d7iburE5VCHN6a1icKicSE0buws9A/300?wxtype=jpeg&amp;wxfrom=0"/><p>基于规则的强化学习（RL/RFT）已成为替代 SFT 的高效方案，仅需少量样本即可提升模型在特定任务中的表现。该方法通过预定义奖励函数规避人工标注成本，如 DeepSeek-R1 在数学求解中的成功应</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963868&amp;idx=2&amp;sn=062f4cbd883871ffbd8c4c28b944e5f5&amp;chksm=853f5311141a93107bdbabd8e7cc09d8bd8cc11673b4287d4c09e238c1c33a5098b872e87b2c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 09:31:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Llama 4在测试集上训练？内部员工、官方下场澄清，LeCun转发]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vKau0WmXsaLGyB2sWKPcHpPGMicokXldJZrybVcY3uqMh0CvvZAOj7LQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：张倩、泽南大家翘首以盼的 Llama 4，用起来为什么那么拉跨？Llama 4 这么大的节奏，Meta 终于绷不住了。本周二凌晨，Meta Gen AI 团队负责人发表了一份澄清说明</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=1&amp;sn=2e63fcbf091cef43ae9fbf61aecc15a2&amp;chksm=857ef0a28c02af5d1b3ad8c36bd4c2141186f450f3052aad0c86b3ea9d3e47270427856106d2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 04:48:40 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[斯坦福2025 AI Index报告来了：DeepSeek在全文中被提到45次]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vaXhNlH1uqzEHTql5equsuSPAiaLe0tYk4Oibjm2bvbSJvVbUice6B7Yicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：蛋酱、+0刚刚，斯坦福大学正式发布了《2025 AI Index》报告。在过去的一段时间里，人工智能领域经历了一场蓬勃的发展，但与此同时，也有人说「人工智能是一个泡沫」。其他的讨论话</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=2&amp;sn=9843c5010e27941cd6a9cc09bb2ef96f&amp;chksm=8559d5f21da721c9e2ddbeb61eb74999a52b0f50db55cf6ccca09e7df353af7a2e2dcd33e091&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 04:48:40 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[类R1强化学习迁移到视觉定位！全开源Vision-R1将图文大模型性能提升50％]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v9gz8L8icas71pyGtYfs26Vl5exCdu2J2gcHrtJoW6hmpWgcKuiam1L0A/300?wxtype=jpeg&amp;wxfrom=0"/><p>图文大模型通常采用「预训练 + 监督微调」的两阶段范式进行训练，以强化其指令跟随能力。受语言领域的启发，多模态偏好优化技术凭借其在数据效率和性能增益方面的优势，被广泛用于对齐人类偏好。目前，该技术主要</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=3&amp;sn=7c62398a729785a7d02da7b9d47fab3a&amp;chksm=8525221905860a7ee31228d160e4f9c43b94d60c8acde57393a69b9a129332cc7c29446bba77&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 04:48:40 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[颠覆传统信息搜索，效果是之前SOTA的三倍？UIUC韩家炜、孙冀萌团队开源DeepRetrieval，让模型端到端地学会搜索！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXNUMFw5WKdZ2wK23QFWTia30IKE9E7p9aj8Za1nX2493SObukR3YsrYQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在信息检索系统中，搜索引擎的能力只是影响结果的一个方面，真正的瓶颈往往在于：用户的原始 query 本身不够好。尤其在专业搜索场景（如文献、数据库查询）中，用户往往无法用精确、完整的表达描述他们的需求</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963731&amp;idx=4&amp;sn=28f1d2a68c5b9f23f435f7aa66335473&amp;chksm=8593ba76d088c1c15fa73b18bb65dd1a3248edc9f61f7ff321f751bebb6b8a4ad40e1d126749&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 04:48:40 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[首次引入强化学习！火山引擎Q-Insight让画质理解迈向深度思考]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWib8gGIFStdWwr8FW74SYGPibDBvTHcz7b3m0DAdZw0FP9FxoGSsVRIqkjiag3JFEndX5ibfQ1rMlISsA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部Q-Insight不再简单地让模型拟合人眼打分，而是将评分视作一种引导信号，促使模型深度思考图像质量的本质原因。有了会思考的“大脑”，视频云技术栈不仅得以重塑也让用户体验有了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963640&amp;idx=1&amp;sn=4627a1366e9482e9dbcc99cf8a2dff57&amp;chksm=85057ce70579f2f48039a611aad647fe2cce5456418c04fbeb96f84b5aaddd9b9b76c4af7bcc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 01:00:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文读得慢，可能是工具的锅，一手实测科研专用版「DeepSeek」]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibdvRMoAz5RN4AEUMO2Rbn4Srp4zg4Wa1TH4T0iawtEnibLiax3dbuqes20aCwich9XAqnjFlvzEyib6CA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心原创作者：张倩「未来，99% 的 attention 将是大模型 attention，而不是人类 attention。」这是 AI 大牛 Andrej Karpathy 前段时间的一个预言。这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963638&amp;idx=1&amp;sn=5d68f81fb9a2d77a2856f1ddb0a735ef&amp;chksm=85fea7d948c96c5befcd07e97e4a84ff690b8f4afb73112e180e38867fd98fd34d5cab52e52a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:33:34 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[反向传播、前向传播都不要，这种无梯度学习方法是Hinton想要的吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8apWjQibSDGflicVKV7CAsLLz7Jtmib4z1Ru1mnWCHNLnMWR8VQiay2xzOMOq2o6V5RM2NpgXhPQRG6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：张倩、+0Noprop：没有反向传播或前向传播，也能训练神经网络。「我们应该抛弃反向传播并重新开始。」早在几年前，使反向传播成为深度学习核心技术之一的 Geoffrey Hinton</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963638&amp;idx=2&amp;sn=ec44861a4abc6cfb93b9cd8cdc179d26&amp;chksm=85d47b008b5dd45424d986fc6b0b49413153f3e3ceff668fd1a843395c657ccb35117b5a5f72&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:33:34 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MoCha：开启自动化多轮对话电影生成新时代]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiciaTmTso3bEKnrl9RXg2LfibZCnfBUHloJkPt7iaOzC7teQCeB6XuKHf6CJZBLiaiaOVLzqNibyLgKKcVw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文由加拿大滑铁卢大学魏聪、陈文虎教授团队与 Meta GenAI 共同完成。第一作者魏聪为加拿大滑铁卢大学计算机科学系二年级博士生，导师为陈文虎教授，陈文虎教授为通讯作者。近年来，视频生成技术在动作</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963638&amp;idx=3&amp;sn=87b688d624d02b929f51ff8eee12d16f&amp;chksm=859b52ab4b7fe051670dafcf2dc40327dc13aa9e12c34e3f028e450680020a45982e459de647&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:33:34 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[铰链物体的通用世界模型，超越扩散方法，入选CVPR 2025]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXL9ia5mstx7BWZibFR6sRQ4RBqcOW6zib8nia5NB1xFjzZLoEdibxCQavt0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>基于当前观察，预测铰链物体的的运动，尤其是 part-level 级别的运动，是实现世界模型的关键一步。尽管现在基于 diffusion 的方法取得了很多进展，但是这些方法存在处理效率低，同时缺乏三维</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963638&amp;idx=4&amp;sn=3b9a244025311b21c645a0b3448fe7dd&amp;chksm=851bce195bc572682080834bb080c1fbc68be9de5127fe9ea0a8a75a78b264a37bec567f2911&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:33:34 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta Llama 4被疑考试「作弊」：在竞技场刷高分，但实战中频频翻车]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8apWjQibSDGflicVKV7CAsLL0WSOQ86BlribYMjXEER57pnBt7BDHMJOBLGyr2womJt9IYJqK3tnfKA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部Meta 翻车来得猝不及防。上周六，Meta 发布了最新 AI 模型系列 ——Llama 4，并一口气出了三个款，分别是 Llama 4 Scout、Llama 4 Mave</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963634&amp;idx=1&amp;sn=4935ed3758561c8ee8366adce6b3be1f&amp;chksm=85f03fd34e34f6e5719c23a45f8d47247e86f80a480c2b9c39c60d07d9c49edb035e2eeb7eb3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 03:51:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ILLUME+：华为诺亚探索新GPT-4o架构，理解生成一体模型，昇腾可训！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWib8gGIFStdWwr8FW74SYGPibyx3Hb3r0lRZmIuUtZvfVjicgD1ib4xQG4FdpjreNT4ibqKDZCjQIian8og/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，基于大语言模型（LLM）的多模态任务处理能力取得了显著进展，特别是在将视觉信息融入语言模型方面。像 QwenVL 和 InternVL 这样的模型已经展示了在视觉理解方面的卓越表现，而以扩散模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963634&amp;idx=2&amp;sn=0891fee849bb90b2c6a9335f22df3410&amp;chksm=85ac296db33ccf116569187dd8421932df88b0307a95ccb35fd6d5d2f5a94b0aba5c984d84c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 03:51:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[解构多模态，GPT-4o 的自回归路线真的走通了吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8FelbdsTQvaNCN5mPann8gWL1wwXc7ZGsh7ibTKENyYluYoUEjkicgQzmhm90MzNrHTW6YT8p2E1ow/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心PRO · 会员通讯 Week 14--- 本周为您解读 ② 个值得细品的 AI &amp; Robotics 业内要事 ---1. 解构多模态，GPT-4o 的自回归路线真的走通了吗？GPT-4o </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963545&amp;idx=1&amp;sn=ccc34a1cca1533c7d0ff716d36e8bdcd&amp;chksm=853bb25e4db3fa82c2480ffa0fe0ed63d1e10252f87184cac59709fd3c481a130ae3642aa3b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 06:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta深夜开源Llama 4！首次采用MoE，惊人千万token上下文，竞技场超越DeepSeek]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWib8gGIFStdWwr8FW74SYGPib5RoP6oKXxibxLJX6iaAr8YEayqGhP1osbfTlibwgt9ia8qJBjLKuSPvwmA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部万万没想到。Meta 选择在周六日，发布了最新 AI 模型系列 ——Llama 4，这是其 Llama 家族的最新成员。该系列包括 Llama 4 Scout、Llama 4</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963546&amp;idx=1&amp;sn=9b93063a0f272ed5a2e4d56725328e32&amp;chksm=857055ff35264f4c30fc939bf069ecbfdf6e762dfe3dab1347a26759d1e08886e28f6f7732f3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 00:40:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从0到1玩转MCP：AI的「万能插头」，代码手把手教你！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibdvRMoAz5RN4AEUMO2Rbn4TFJo7wV2Fbb1pfib3tkVu9PTIeSFDePSy8F99eoohGfZ9PIm2QzPdBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>选自Towards Data Science作者：Sandi Besen机器之心编译在人工智能飞速发展的今天，LLM 的能力令人叹为观止，但其局限性也日益凸显 —— 它们往往被困于训练数据的「孤岛」，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963546&amp;idx=2&amp;sn=9853970a59b52ed72b16a10fedc99c19&amp;chksm=8575ab8cc0716700c7e1daa7237340ad780b9700974d093b590f92b0a0488bdc48185af9f3cf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 00:40:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR满分论文 | 英伟达开源双目深度估计大模型FoundationStereo]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXuV5FXZuBicHAQd9dH6t38WLicpcvxG8icVy1ic1aoiaAUUkaUcggic9IFlsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文介绍了 FoundationStereo，一种用于立体深度估计的基础模型，旨在实现强大的零样本泛化能力。通过构建大规模（100 万立体图像对）合成训练数据集，结合自动自筛选流程去除模糊样本，并设计</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963546&amp;idx=3&amp;sn=8f7ee6579f70d6378c7ef130e330b423&amp;chksm=859556efbe6bb79792ea46911459a64c444a8d41ad0eedd578d0b85da9cad4df4120c6b638b9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 00:40:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大语言模型变身软体机器人设计「自然选择器」，GPT、Gemini、Grok争做最佳]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJX0UGDqZCXT8FOiaajbpBcbuSYd5ibfQccCYEBbMMpbEpHics0wSXwnaPow/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型 (LLM) 在软体机器人设计领域展现出了令人振奋的应用潜力。密歇根大学安娜堡分校的研究团队开发了一个名为「RoboCrafter-QA」的基准测试，用于评估 LLM 在软体机器人设计中的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963546&amp;idx=4&amp;sn=09a315d3e78f6b190224df55f1d4c9d4&amp;chksm=853b6bdf80d42ec6d748904c97445413cfd42f1aa0b131f6f0cd11ca20fd92b5fecb6cd86e8c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 00:40:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[全网都在猜，这些视频是不是字节AI生成的：该跟动捕说再见了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8vAMiaOQhhApSnSPJ3lFJiaIvescCqUjSV1SevGEFiaMlOCJx1IKLeAewXHicNxzB3MAXLy1fMCTrGsA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：梓文动作捕捉，刚刚发生了革命。在 GPT-4o 的风到处吹时，X 平台（原推特）上有好多带视频的帖子爆了。到底是什么引来了一百万的浏览量？没错，是玛丽莲・梦露「活了过来」。她不仅能够</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963521&amp;idx=1&amp;sn=3020279603bac4495bf8245709230ec4&amp;chksm=8593acb187df2f0cff386ef1d054f8e865c60d45df56f932bc1deb84a74eb136da23d175f2ee&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Apr 2025 08:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 Oral | 多模态交互新基准OpenING，新版GPT-4o杀疯了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnN1eCBU3ByDnZeicjHeia65MygsKjVpYEVUqB1Jibpibuy6qvQicR4yZ7GX5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>文生图 or 图生文？不必纠结了！人类大脑天然具备同时理解和创造视觉与语言信息的能力。一个通用的多模态大语言模型（MLLM）理应复刻人类的理解和生成能力，即能够自如地同时处理与生成各种模态内容，实现多</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963521&amp;idx=2&amp;sn=412f932c14796e8672e3786f87a793ff&amp;chksm=85ec11f7befb3694f17f415e41bb64fbe9d332455d98ea33aee7013a8c256056e513edd493d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Apr 2025 08:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[7B扩散LLM，居然能跟671B的DeepSeek V3掰手腕，扩散vs自回归，谁才是未来？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXZ5iaDodqic8r0uzanjsF4ExCUE7Y7YNfrRgrcqQkxRbsdemRReSiaXWEA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：张倩语言是离散的，所以适合用自回归模型来生成；而图像是连续的，所以适合用扩散模型来生成。在生成模型发展早期，这种刻板印象广泛存在于很多研究者的脑海中。但最近，这种印象正被打破。更多的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963520&amp;idx=1&amp;sn=4e604b812a4587be4139ee244d15cd6a&amp;chksm=855b022550276ec5e9a70b7630604142ca239e3865931dd144339b8061c69dc8d10a45c1f260&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Apr 2025 04:10:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[微软诞生50周年，比尔・盖茨撰文忆往昔，并发布了Altair BASIC源代码]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiciaTmTso3bEKnrl9RXg2Lfib5YxhtY3mfFAMFybsBpAHHfw91T4IDzVCFwhxt8tN1N0xbUXYOF9v6Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>选自 Gates Notes作者：Bill Gates机器之心编辑部1975 年 4 月 4 日，比尔・盖茨和保罗・艾伦在美国新墨西哥州阿尔伯克基市创立了微软公司。到今天，半个世纪过去了，微软早已成长</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963520&amp;idx=2&amp;sn=c6e890ea8fd2f342ef9799a600281bc7&amp;chksm=85b06ba532024417d486ed1f1749c9650aba5e3bc1d6bb54093b9fc45a6ed764324b7346c2da&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Apr 2025 04:10:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[三思而后行，让大模型推理更强的秘密是「THINK TWICE」？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9dTqibU1aRyjLam46FtAyNO96eRQM081AtN1s6c2TXYRvyMib3pytC5iaTdSzR3qXD5jtWM9Y9m5wPw/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大语言模型（LLM）的性能提升逐渐从训练时规模扩展转向推理阶段的优化，这一趋势催生了「测试时扩展（test-time scaling）」的研究热潮。OpenAI 的 o1 系列与 DeepSe</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963520&amp;idx=3&amp;sn=f3e8168cfe732ad314711f3893efbe11&amp;chksm=85f9fd43c5673942ca6c82fdad4475ec077b9f9faeca7cd97f92d8be445561db5afdfee9c6f6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Apr 2025 04:10:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | GaussianCity: 60倍加速，让3D城市瞬间生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibdvRMoAz5RN4AEUMO2Rbn4TaadpM2sObiczoibsMiadxdtngfLkkwoQSA3qQhcS1po1tazmicibodQ5hw/300?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下，一座生机勃勃的 3D 城市在你眼前瞬间成型 —— 没有漫长的计算，没有庞大的存储需求，只有极速的生成和惊人的细节。然而，现实却远非如此。现有的 3D 城市生成方法，如基于 NeRF 的 Ci</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963520&amp;idx=4&amp;sn=a746d1d656e1f5dbe516d402ff78ba9b&amp;chksm=8575b3087fa523f779290addfbd1c710e8bcf290354078c571b4061b4f2f539327f6b1fb4d2d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Apr 2025 04:10:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[高估值对 AI 公司没有好处？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8vAMiaOQhhApSnSPJ3lFJiaIRpgIlTs1KuBgFAWPfxApWV4zQibsrgPkTRc0AAoU8ibib2qDSRDnSEYyA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文来自PRO会员通讯内容，文末关注「机器之心PRO会员」，查看更多专题解读。Upfront Ventures 近期在美国加州英格尔伍德的 Intuit Dome 举办了 2025 Upfront S</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963502&amp;idx=1&amp;sn=c9ccb45efcc6c7abecae25e89b252a26&amp;chksm=853771434a3848dd8f29d75bfeb522693378e6aef903d1e1099c56ec6687ff19f3382979688f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Apr 2025 01:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刚刚，DeepSeek公布推理时Scaling新论文，R2要来了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8vAMiaOQhhApSnSPJ3lFJiaIGaFFR79F7U60lY17hN9NMpd9CDdYZy6wwdSyVWUMrfSzFYtiboXcFOQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部一种全新的学习方法。这会是 DeepSeek R2 的雏形吗？本周五，DeepSeek 提交到 arXiv 上的最新论文正在 AI 社区逐渐升温。当前，强化学习（RL）已广泛</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963496&amp;idx=1&amp;sn=a8805d7936ad730682640c44eb6c5fdb&amp;chksm=8591196fc210bad22f265a187bd3a39873d87eccd8cad0e6cd1b37468163e7cd9fbd8879f006&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Apr 2025 05:06:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[思维链不可靠：Anthropic曝出大模型「诚信」问题，说一套做一套]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8vAMiaOQhhApSnSPJ3lFJiaIialheuicAMqGIicN7giaZUXUibb00XNgZSXWpgeicPT2cNCqzg9GErZka64g/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：蛋酱AI 可能「借鉴」了什么参考内容，但压根不提。自去年以来，我们已经习惯了把复杂问题交给大模型。它们通常会陷入「深度思考」，有条不紊地展示思维链过程，并最终输出一份近乎完美的答案。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963496&amp;idx=2&amp;sn=ef3293e62479dc5083dd4fce77cb2bf4&amp;chksm=859363a31195e77075370d46cfbeb99e25172545a2bb32a3b222e69bf731c375729cab4fbe02&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Apr 2025 05:06:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[250多篇论文，上海AI Lab综述推理大模型高效思考]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnNkGXB9t7NVdO5gkDcVaa2Leg5Jic3JXjp0sT2tibic1ApRKWic2TdArDwhg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，像 OpenAI o1/o3、DeepSeek-R1 这样的大型推理模型（Large Reasoning Models，LRMs）通过加长「思考链」（Chain-of-Thought，CoT）在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963496&amp;idx=3&amp;sn=9de16b392d13c8c9a8eedd441b674670&amp;chksm=85be30db3d6d3eb102c539850f55a0761eeccea4c8d012202008314fd74c3d14a8d2602f1e98&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Apr 2025 05:06:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多榜单登顶！华为 &amp; 哈工深团队提出 AdaReTaKe，突破长视频理解极限]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnNHIL6IafuOdMT6EGiaC1LRZenHkRUlwW5b5TT1PEkgEWzDHOQNqMEczA/300?wxtype=jpeg&amp;wxfrom=0"/><p>第一作者为哈尔滨工业大学（深圳）博士生王霄和华为大模型研究员佀庆一，该工作完成于王霄在华为实习期间。王霄的研究方向为多模态视频理解和生成，佀庆一的研究方向为多模态理解、LLM post-trainin</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963496&amp;idx=4&amp;sn=0514bf1819bf1516c5fbb4cde60a769d&amp;chksm=85a44c02e16e094c887539c8d923a2312235e535fcaa493fd37a37bd5b694257fb564afbabf5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Apr 2025 05:06:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ChatGPT会员北美大学生全免费，持续一个月，AI帮你过期末考试]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8vAMiaOQhhApSnSPJ3lFJiaIhBC9x41RuXoDnPicxcOsmHz1f2ZknhOmqAsvssic3ebPHQ1hd5whJwlw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部「下一代默认 AI 大模型工具」的竞争开始了。本周五凌晨，OpenAI CEO 山姆・奥特曼宣布了一个令人兴奋的消息。从现在开始，ChatGPT Plus（原价每月 20 美</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963426&amp;idx=1&amp;sn=dcf7e4f22c1442cf81edbf442880b87a&amp;chksm=85fe4215d4e71b4b3b2c09b12f9ff55735fa9214f9451398d28cfe3dd7ac290cbc434724f644&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Apr 2025 02:12:20 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Multi-Token突破注意力机制瓶颈，Meta发明了一种很新的Transformer]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXxiczUbNzoUHRvryXjuanZuv2IZeDDsJ0C2dsU0ia8VhEibKYqNRygvstw/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：蛋酱、杜伟Attention 还在卷自己。当上下文包含大量 Token 时，如何在忽略干扰因素的同时关注到相关部分，是一个至关重要的问题。然而，大量研究表明，标准注意力在这种情况下可</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963426&amp;idx=2&amp;sn=4cb5432a3b547f12136a50fdebbb19f8&amp;chksm=85606e908a517c8b2841c4ceb570a97a38df885b3d42053f40f522a576a33ca0da31e1a2a348&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Apr 2025 02:12:20 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[速来！机器之心ICLR 2025新加坡现场人才晚宴开启报名]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnNOUnn1wUYFsw444ztSdI8bp6icPt6D0BtCZUld4Urqj8z7Kov0L2Xv7Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025 年开年，以 DeepSeek R1 为代表的推理大模型开启炸场模式。在短短数月内，DeepSeek 凭借其卓越的性能和广泛的适用性，迅速在人工智能领域掀起了一场技术革新的浪潮。而后，国内外各</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963391&amp;idx=1&amp;sn=23762eb7cc9a9211a3af902f58c8fc61&amp;chksm=85e6712313f34dba6deb9b3e44e788d2ac50a4e43c16e722e06699c0fe9f3677052b476cba6b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 09:00:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepResearcher：交大、SII发布首个真实环境强化学习「AI研究者」模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXrPWiaFUl0G50asCF934pxr9zCDKbb5rXcef2F1Rv5NGcqClcy5qiadGw/300?wxtype=jpeg&amp;wxfrom=0"/><p>上海交通大学与 SII 联合发布了 DeepResearcher，代码训练框架完全开源。这是首个在真实网络环境中通过强化学习训练的 AI 研究模型。随着大型语言模型（LLMs）推理能力的飞速发展，Op</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963391&amp;idx=2&amp;sn=823c021fb6b4d9bb73857253b832e353&amp;chksm=85a660745929ede43c1b5b1fbcf69f274eeb479ef4e79add6a0ae0355cdb2691de7659215eb2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 09:00:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[为今年最火的机器人来场全球挑战赛：150万高额奖金，还有顶级硬件支持]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnNh8A6ud6SvIGX5hibl9JlYtPDK2IegndTsUel30JFjy83o4kHVOqCvXQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>ATEC2025 科技精英赛是由 ATEC 前沿科技探索社区主办，清华大学、浙江大学、西安交通大学、上海交通大学发起。本届赛事由香港中文大学、北京大学、北京师范大学顶尖学府联合蚂蚁集团共同承办的全球性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963181&amp;idx=1&amp;sn=148d6cc8024af2e87a36a633d8709cbe&amp;chksm=85ebabd2ef5780e23be3927ef13e7f0cd9296b913b07d2b879783ae3da43ba32da2419146463&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 04:01:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OpenAI的AI复现论文新基准，Claude拿了第一名]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXj51cFd0txtLFH9TeJqbInRzlnibcQAHiaibeOQHQoe5LvhXslIdawUO3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：+0、泽南大模型能写出 ICML Spotlight 论文吗？近年来，AI 正从科研辅助工具蜕变为创新引擎：从 DeepMind 破解蛋白质折叠难题的 AlphaFold，到 GPT</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963181&amp;idx=2&amp;sn=df8451d62cda949c87a1550ca755f780&amp;chksm=85e953e77f1aae470ca5b126bc1f82c4d1a1b8bd95a326e7b7dfa825cf87ff7268ff2b2a8bc7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 04:01:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 Spotlight | 参数高效微调新范式！上海交大联合上海AI Lab推出参数冗余微调算法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic4qxCCBDwsURwYQxQzqtnNUFibGaWh57nkDGbaNVwaxE5HG0bOT9rrQlibh3MKiaZYPmIoQYJfibmeVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文作者来自复旦大学、上海交通大学和上海人工智能实验室。一作江书洋为复旦大学和实验室联培的博二学生，目前是实验室见习研究员，师从上海交通大学人工智能学院王钰教授。本文通讯作者为王钰教授与张娅教授。低秩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963181&amp;idx=3&amp;sn=cddb2e0fa9edfa9cb10b1e96daa48b6e&amp;chksm=85c03634fd01ed380a2804870ead1c5bbe039d3102d7d07ed2c5c8a2db876737cc4fa4db068d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 04:01:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[视觉SSL终于追上了CLIP！Yann LeCun、谢赛宁等新作，逆转VQA任务固有认知]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJX4CraD5Hicjp0PqKg668OUNCXsY1HWJCicZPc2al0COhwfNIfvdFH3ZTw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：蛋酱、杜伟扩展无语言的视觉表征学习。在视觉问题解答（VQA）等多模态环境中，当前视觉自监督学习（SSL）的表现还比不上语言图像预训练（CLIP）。这种差距通常归因于语言监督引入的语义</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963176&amp;idx=1&amp;sn=9947e10c0d2d98a1ac274ec9d3159e4a&amp;chksm=85f1abc9c402e86574a4e60d92b6b8065421904027c35480b43dbeda7e92618090b1b880692a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 03:06:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[让AI替码农卷复杂任务，贾佳亚团队提出MoTCoder，准确率刷新SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibdvRMoAz5RN4AEUMO2Rbn44d63Jv0vsRj2mwLyjZkGJn1Yn2iaicHcYeg0W4boCW63tjK6iajg5XJBw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文一作李靖瑶，香港中文大学博士生（DV Lab），师从贾佳亚教授。主要研究方向是大语言模型，包括模型预训练、后训练、推理优化。作者陈鹏光、夏彬等均为 DV Lab 成员。大模型写代码早就是基操了，但</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963176&amp;idx=2&amp;sn=10f7ec40183096a60100c9261ece4be3&amp;chksm=854476ce5dd31c8507c87d4bb12253e53dfde226de98b3c3f007be4f32db6e66729f48fa8a12&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 03:06:19 +0000</pubDate>
    </item>
  </channel>
</rss>