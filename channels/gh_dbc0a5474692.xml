<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[机器之心]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[机器之心公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_dbc0a5474692.jpg</url>
      <title>gh_dbc0a5474692</title>
    </image>
    <item>
      <title><![CDATA[继VAE之后，Adam也拿到了ICLR 时间检验奖，OpenAI联创两次获奖]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiboBGfzicV4NS6MxFiaqEVGx7LXoNkhlaDWgnMZM0Q3ZobyOmpRRUdT8fSY07r2ic5jMPCEuoDHXoKPg/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：张倩刚刚，ICLR 2025 宣布了今年的时间检验奖获奖论文。这个奖项旨在表彰十年前在 ICLR 2015 上发表的对该领域产生持久影响的论文。经久不衰的「Adam 算法」拿到了冠军</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650965021&amp;idx=1&amp;sn=7c1a362b1fe39cd7eef3d20b4bbb51ea&amp;chksm=85feda18a5ee8260518ef9a1cdcd27ea31d879ecdd3ad0dcd411e686908ed6bfa45e3eefe4a2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 11:05:03 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 | 一行代码！FreDF频域损失稳定提升时间序列预测精度]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGekia8DZP2n1siaqykECLJk0eVvSKSKS2Ihvne1RNn1hxRqVGY3YkKpDCmw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文由浙江大学、中南大学、上海交通大学、Tiktok、北京大学、南洋理工大学联合完成。第一作者王浩为浙江大学硕博连读生，发表NeurIPS、ICLR、KDD、WWW、TOIS等顶级会议和期刊十余篇。通</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650965021&amp;idx=2&amp;sn=88d0baa1628763a48bcb10794a3733a2&amp;chksm=85a73ba7f95cda4323639bcca0f5c3de291fd48a3a1d252129b6ba8882d5eddedade40a0af6a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 11:05:03 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[「开源版GPT-4o」来了！这个17B国产模型生图效果比肩4o，还可商用]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGekqD3a8ssbENwjnNGiarwsZTkH8WPLCcyibj6fA3ecEyAFzgzqZT5dY7LQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心原创作者：张倩前段时间，GPT-4o 火出了圈，其断崖式提升的生图、改图能力让每个人都想尝试一下。虽然 OpenAI 后来宣布免费用户也可以用，但出图慢、次数受限仍然困扰着没有订阅 ChatG</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964917&amp;idx=1&amp;sn=52b926f8a1fe7661c32aa5a845b8d81a&amp;chksm=8585fbc02c7eff5634ebabba085f52595385baa5afc75c90995b6d74d733961a1810513ebb6a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 05:07:23 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[免费用！阿里通义大模型上新，超逼真音视频生成SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGekxzMjibZbz62Fxk79VoBXWwEvzGPibTVqKfaHCfD5IDXvKNcHc04nfm7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心发布机器之心编辑部近日，阿里通义实验室推出了全新数字人视频生成大模型 OmniTalker，只需上传一段参考视频，不仅能学会视频中人物的表情和声音，还能模仿说话风格。相比传统的数字人生产流程，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964917&amp;idx=2&amp;sn=57394dee841ea7db7d20b27d01aac1b5&amp;chksm=85265fef3d655ff2b30ce43e4dcf58b9bf83415837fa84379aacbf0f9104463fd78e2c860dd6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 05:07:23 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[30年悬案告破，平均曲率流的奇点真相曝光，揭晓「冰块融化」的数学秘密]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibMueEjyHDqYKxbqEv4lJJXeouB4bFDjobQnDvgXxEZaTibTJCuIzn9OdlMqwiaaoXGa0yicd7yBSenQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>选自quantamagazine作者：Steve Nadis机器之心编译一块冰块漂浮在水中，随着时间推移，它会逐渐融化成一个微小的冰粒，最终完全消失。在这个过程中，冰块表面变得越来越光滑，所有不规则形</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964917&amp;idx=3&amp;sn=5e3cafe637ec1d3e85cb2d9426f0be66&amp;chksm=852f92c6d75b57026f55ba34d1971609efb84ceb125ec4325ebfbf9ba49b6f2c200749c5f9dc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 05:07:23 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[智谱深夜开源新一代GLM模型，推理速度快DeepSeek-R1八倍，还启用了全新域名Z.ai]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiboBGfzicV4NS6MxFiaqEVGx7gAnlO1iaFQ6KDEZd8gH9RGU1IqjQDhd8BzcqJCqIvx6pJlMeThnhbxw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Sia好消息！还记得「AutoGLM 沉思」吗？短短 14 天、孵化出一个 5000 多个粉丝的小红书账号，还接到了商单！相比 OpenAI 的 Deep Research ， 「A</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964908&amp;idx=1&amp;sn=530979e2da0e4bc78901c1e4e1fc7cc6&amp;chksm=85596d3e808bb07e6de9d0ff8bfe91d007c73cb94f97aef5b04ac7ec045301edac173c15f277&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 03:39:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[「交交」媲美GPT-4o！上海交大推出口语对话情感大模型，首个纯学术界自研！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGekuM5R8sHttTibWibv2YHUgObdpiacHxnzG7sOZPJ1X95NyibibEBdBODQEQQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>智能语音交互领域，学术研究也能如此酷炫。全球首个纯学术界自研的支持多人实时口语对话的语音情感大模型 ——“交交”，正式推出！“交交” 由上海交通大学听觉认知与计算声学实验室倾力打造，它不仅是一个智能语</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964908&amp;idx=2&amp;sn=f1e3910bbd8c1c8da2bbb740fdc40cb8&amp;chksm=857b486285d1659eca7a9d495ba88e06ee4c39dcd55d36527b2f460875674da995490a511c6e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 03:39:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刚刚，OpenAI发布GPT-4.1！全系支持百万token上下文，全方位碾压GPT-4o并且价格更低]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGekOicIz4EaTjBJCff4JYdXwIZhgcicgGB5MxQYHM5ldY0eC26xnrgUTrYQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：杜伟今天凌晨，OpenAI 的新系列模型 GPT-4.1 如约而至。该系列包含了三个模型，分别是 GPT-4.1、GPT-4.1 mini 和 GPT-4.1 nano，它们仅通过 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964787&amp;idx=1&amp;sn=873b1300f554f03c1f65de0041ca4008&amp;chksm=85fd6f38b90ec3293c99cb04c994e80b301eb8a74d248a1b8cbd2c4c86c5135a3e26e32cd400&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 23:19:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[什么样的偏好，才叫好的偏好？——揭秘偏好对齐数据的「三驾马车」]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGekRdFl0vxPzHECN32bd3GyN15BiclGccJD1CHYDOFdz5vse5WgGccTPsw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文有两位共同一作。何秉翔，清华大学博士一年级，研究方向为大语言模型对齐、强化学习。张文斌，哈尔滨工业大学博士一年级，研究方向为自然语言处理。近年来，大语言模型（LLMs）的对齐研究成为人工智能领域的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964787&amp;idx=2&amp;sn=f08b06a7e8654866e4f19d6f1b227ce2&amp;chksm=8529b57bec931dc2ecd85bba41d22e2f6aea21d939624aeba5ecedc53b62e667b98ab7c8f339&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 23:19:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刚刚，DeepSeek公布了推理引擎开源路径，OpenAI也将开始连续一周发布]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGekIDbDyCx18FM0XCl6IflCU0VialVv1ugwwWCwffMeLe4nicHtJmXR3Yibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Panda今天下午，DeepSeek 默默地在自己的 open-infra-index 库中发布了一份题为「开源 DeepSeek 推理引擎的路径」的文档，宣布将开源自己的内部推理引</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964761&amp;idx=1&amp;sn=ca2d57751ce5a76110fd6dee13a8a2ca&amp;chksm=8560e6036c136692ea011445b18af28696fa3cfd2085242afa704cc778dc2df880d4fb0843e8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 09:31:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[合成数据助力视频生成提速8.5倍，上海AI Lab开源AccVideo]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGekJgYLu0r0hXZdeEMRm7Cj4HsZyLcsxUSx2FRHaaknYicKddUfMjMW6ng/300?wxtype=jpeg&amp;wxfrom=0"/><p>虽然扩散模型在视频生成领域展现出了卓越的性能，但是视频扩散模型通常需要大量的推理步骤对高斯噪声进行去噪才能生成一个视频。这个过程既耗时又耗计算资源。例如，HunyuanVideo [1] 需要 323</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964761&amp;idx=2&amp;sn=9086ca2116993c1b3f6eafd45c17e5a5&amp;chksm=853113df6fc1a63afcb165e93d4f0401747da907b2f1b2f214cdd182e36c1639d705f2b5cf14&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 09:31:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[10万奖金×认知升级！OceanBase首届AI黑客松广发英雄帖，你敢来么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGeksSPUd9HJQiaTXsw7Q2xgKdnwjc1BiaxfpmiaOWvjkauC677VuDOuJjflg/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心发布机器之心编辑部从 ChatGPT 引发认知革命到 GPT-4o 实现多模态跨越，AI 技术的每次跃迁都在印证一个底层逻辑 —— 数据质量决定智能高度。而今，这场 AI 浪潮正在反哺数据库领</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964601&amp;idx=1&amp;sn=3312e30d3d806429e07b18a8af26119e&amp;chksm=85cff880950894610da898cd0c3e3fec83b3dc022d0364ac7dab44e684e8b457b3b3a3ad08ef&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 04:26:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[更长思维并不等于更强推理性能，强化学习可以很简洁]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibVg6ic9AFBfLjEK65uewGek3DfiaialOEkx0YItVSQibianF3KYIGfSD7tlvZyom69vaYC8dvH0YuajDQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Panda今天早些时候，著名研究者和技术作家 Sebastian Raschka 发布了一条推文，解读了一篇来自 Wand AI 的强化学习研究，其中分析了推理模型生成较长响应的原因</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964601&amp;idx=2&amp;sn=54693ad66d4d8a324fc155f1a3b26db8&amp;chksm=851c356895eb9034829e88c1377fcf60be9cf580afc8eacd7ea67fff3f1f583dfd6a28080360&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 04:26:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[过程奖励模型也可以测试时扩展？清华、上海AI Lab 23K数据让1.5B小模型逆袭GPT-4o]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUx61RJkU4qpYs2icQicQNsO1aG0xZErQUCSuRnrWL8mr81yr7ODhErgyQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>赵俭，北京邮电大学本科三年级，研究方向为大语言模型。刘润泽，清华大学硕士二年级，师从李秀教授，研究方向为大语言模型与强化学习，特别关注大模型推理能力增强与测试时间扩展，在 NeurIPS、ICML、I</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964601&amp;idx=3&amp;sn=0d02277cafede72c5697edc5cb1d28c3&amp;chksm=8577016ff8eade7265a229262aed04581605f1227db6d0958b2df6ed0b7c8b5cecb77e5e01c5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 04:26:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[中科大、中兴提出新后训练范式：小尺寸多模态模型，成功复现R1推理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yU7WL8uU6AfPhyXOLJmH8DnKf7gsmGnfREo85KhJb8X3VHyHSCLtMT6w/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文第一作者为邓慧琳，中国科学技术大学硕博连读四年级，研究方向为多模态模型视觉理解、推理增强（R1强化学习）、异常检测。在TAI、TASE、ICCV等期刊和顶会发表论文。近年来，随着大型语言模型（LL</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964601&amp;idx=4&amp;sn=648ce8159dbd92df300df8219d346842&amp;chksm=850b6e638fb296207ac1df2fb39512b51c7728dc7c5c593395f6a158ffa2d48c8f740cc62043&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 04:26:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D领域「源神」又开了两个新项目：三维部件编辑与自动绑定框架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWictE1YgQrTd5kDznuNAIrfib0ZbIqkS0I9BuMF8c96TWY6r2eGTgnNPrUFbb36JIqL4RAbiaw2Xicf7g/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心发布机器之心编辑部在不久之前机器之心报道文章《3D领域DeepSeek「源神」启动！国产明星创业公司，一口气开源八大项目》中，我们曾介绍到，国内专注于构建通用 3D 大模型的创业公司 VAST</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964448&amp;idx=1&amp;sn=c41d00536695ec7430bd28c1d58a196d&amp;chksm=856f980deafdcd380fddeb27291419fe5ac6908773665309d51ded0b735582247a81cc83e9b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 09:12:47 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[不用英伟达GPU！华为盘古Ultra来了：昇腾原生、135B稠密通用大模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiclpKp5iaMh8iahEt7aBwB7DE1L8JEpzBOqDrKGVG4kUibOviag0DT4ficA80yzniaRuXBfptx0tA2d4TJw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部终于，华为盘古大模型系列上新了，而且是昇腾原生的通用千亿级语言大模型。我们知道，如今各大科技公司纷纷发布百亿、千亿级模型。但这些大部分模型训练主要依赖英伟达的 GPU。而现在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964411&amp;idx=1&amp;sn=d0b59fa8c5df9bc1c0e944e16168bcfb&amp;chksm=855213e1c04e871adde3489235f3ebe900a34bb5fb86528437d3ae7aa9b30c576eecc8913b02&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 04:39:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[强化学习带来的改进只是「噪音」？最新研究预警：冷静看待推理模型的进展]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWictE1YgQrTd5kDznuNAIrfibCmkplmMelMadtIxs1aOJ832N401ib0KwH4ibq6eEUduYLbVHZXtMM8cw/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：蛋酱、+0「推理」已成为语言模型的下一个主要前沿领域，近期学术界和工业界都取得了突飞猛进的进展。在探索的过程中，一个核心的议题是：对于模型推理性能的提升来说，什么有效？什么无效？De</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964411&amp;idx=2&amp;sn=576a00bdbc19b0a4790417afc29c9e82&amp;chksm=85b5ee2b5a4a0f68a116566819674328cd5aeb12e0c4a230193a36605b3e3524cb286dbfd2de&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 04:39:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3710亿数学tokens，全面开放！史上最大高质量开源数学预训练数据集MegaMath发布]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUXXWsys2RqE72GULzNexiaXZukH7qOLaoVk4zgQpKA4mLJNPmhJLTpng/300?wxtype=jpeg&amp;wxfrom=0"/><p>在大模型迈向推理时代的当下，数学推理能力已成为衡量语言模型智能上限的关键指标。近日，LLM360 推出了 MegaMath：全球目前最大的开源数学推理预训练数据集，共计 3710 亿（371B）tok</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964411&amp;idx=3&amp;sn=10f61c70b9d7bb14a4f7867f6d4aa070&amp;chksm=8502797b78153fc0ffbe55971401726a97d7c106ada4bf9d0a5f59a1e24f154002fdd481ec95&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 04:39:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[扩散模型奖励微调新突破：Nabla-GFlowNet让多样性与效率兼得]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IKLPSHUbia1KCiaqpOmzrib2PyDABR2h0Cr1XK66ZA8qCib5Um44NBlJW77Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文作者刘圳是香港中文大学（深圳）数据科学学院的助理教授，肖镇中是德国马克思普朗克-智能系统研究所和图宾根大学的博士生，刘威杨是德国马克思普朗克-智能系统研究所的研究员，Yoshua Bengio 是</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964411&amp;idx=4&amp;sn=483b0f94053ec333faed6d74a0b3923d&amp;chksm=8599467edd5ab8641309cf56e58d228fcdca81012f7910c7cd5ea6111dec9921214e18856d03&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 04:39:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[RL for LLMs，强化学习的 Scaling Law 才刚刚起步？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8FelbdsTQvaNCN5mPann8gWL1wwXc7ZGsh7ibTKENyYluYoUEjkicgQzmhm90MzNrHTW6YT8p2E1ow/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心PRO · 会员通讯 Week 15--- 本周为您解读 ② 个值得细品的 AI &amp; Robotics 业内要事 ---1. RL for LLMs，强化学习的 Scaling Law 才刚刚</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964395&amp;idx=1&amp;sn=1895fccacefd3325449a64d7ddbf5bd0&amp;chksm=8547e76281ecf9735f630a10aba256d880426b99ab79224b790ce4668e425ea6fd35fcf608d1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 01:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[魔改AlphaZero后，《我的世界》AI老玩家问世，干活不用下指令]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiclpKp5iaMh8iahEt7aBwB7DEAd9cJot8gohjyhDJT2JfrDYt8hv17uZaRo6GPng7zNjD0xlJTaMS7A/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：泽南、杨文人和智能体共享奖励参数，这才是强化学习正确的方向？大模型驱动的 AI 助手又升级了。本周五，科技圈正在围观一个陪你一起玩《我的世界》的 AI。它话不多说，就是埋头干活。一起</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964349&amp;idx=1&amp;sn=10d1402c376d01963509c0f04a20d5e8&amp;chksm=8559299f0a1d3ad8a549a938387c5ebabd48a3b2230da956aa2181f438de8ecbd19eb2e0bbe5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 04:57:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[算法不重要，AI的下一个范式突破，「解锁」新数据源才是关键]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWiclpKp5iaMh8iahEt7aBwB7DEAbKMOllq0Bo33bVfeIBBSAktiajqtUnbwdpWmFfaN7AicrMickRbicrvHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：蛋酱众所周知，人工智能在过去十五年里取得了令人难以置信的进步，尤其是在最近五年。回顾一下人工智能的「四大发明」吧：深度神经网络→Transformer 语言模型→RLHF→推理，基本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964349&amp;idx=2&amp;sn=5018ddc4d4d9d5e8c46ad70bb3ba858e&amp;chksm=851c70428fce952374fd05543e5845e66bb04ef3da5173ee1bd457ec7c7fce9e58478d62ab91&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 04:57:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[苹果发现原生多模态模型Scaling Laws：早融合优于后融合，MoE优于密集模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUeuUFttHabDy8YoMcibZlzYYGSa2jzn49zCkZxEqlZRcXrLD9Cm6vRTA/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：泽南、Panda让大模型进入多模态模式，从而能够有效感知世界，是最近 AI 领域里人们一直的探索目标。目前我们见到的很多多模态大模型应用是「组合式」的：其中集成了数个单独预训练的组件</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964349&amp;idx=3&amp;sn=00799602fe371fde27c50c60ee91c0c4&amp;chksm=85f3b87f2142cbff80daa00b199ea6398c5f78fd4eb57d09ef9d9c197b30916de9923970fea8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 04:57:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[面对杂乱场景，灵巧手也能从容应对！NUS邵林团队发布DexSinGrasp基于强化学习实现物体分离与抓取统一策略]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IK4aPsf7fQee1Mq0BoTv36k1BmbZNBvX3CXqyV3493DiavTiauUL1uB9hg/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文的作者均来自新加坡国立大学 LinS Lab。本文的共同第一作者为新加坡国立大学实习生许立昕和博士生刘子轩，主要研究方向为机器人学习和灵巧操纵，其余作者分别为硕士生桂哲玮、实习生郭京翔、江泽宇以及</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964349&amp;idx=4&amp;sn=cca34ab5e5e9508fd542b8300324727a&amp;chksm=85a2d0d86c352c65b78f43f8a066edf8a73b806290cb621d49e4372a8f446deeda945d5fe5db&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 04:57:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Anthropic 首席科学家的 AI「视界」如何判别 AGI 进程？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUxTRlVoMRqa1cH3KnZWWShGHmKLEKVJFSMgNGymyKjKqKjezFBtYqhA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文来自PRO会员通讯内容，文末关注「机器之心PRO会员」，查看更多专题解读。Anthropic 联创兼首席科学家 Jared Kaplan 在一场 AGI 主题的访谈中用 AI「视界」衡量了模型的能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964317&amp;idx=1&amp;sn=9d8037b8c2d3349fe276c20484b386c1&amp;chksm=859a89e50857d37fde6920a099dacb3cdabdf51244b68fd24f41d8204b0839b36cd61075e4bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 01:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[原生多模态大模型也能强化学习，思维链长达几万字，商汤日日新V6来了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUahr9vCibRg7qpBuviaT3YFKzuZ01XPXxX6INSBGuf0URHRm6K5NT9HSg/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道机器之心编辑部拥有行业最强多模态推理与交互能力的商汤「日日新 SenseNova V6」来了。如果让大模型像人一样聪明，应该是什么样的？你可能会回答，我们生活的世界纷繁复杂，常常涉及多模态</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964307&amp;idx=1&amp;sn=3424270589b36050fc7d5c39ebedfdf8&amp;chksm=85142250bdbe310ea574df53a5f88a9e96eb9fd848c0481febd512303e525f2c777df50651fe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 13:07:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ChatGPT重大更新，能翻出所有历史对话，网友被AI聊破防了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yU03Cmic2J0gm99BtjibHHW2JeYSfCQLbc2kV8w0W2zRFibH7aea9piaPtDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：泽南终极个人 AI 助理初现雏形。今天凌晨，OpenAI 的 CEO 山姆・奥特曼突然发推说自己睡不着了，因为有重要新功能要推出。很快，OpenAI 就正式发布了一个令人期待的新功能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964307&amp;idx=2&amp;sn=12a892705706f5abb8f203fdcfc5143c&amp;chksm=852825dc1ed9c363ad07d654ce0c2226c18b85c5c66d0665aecbae18555f9eb9ec80c07b63ba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 13:07:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[传统预训练正走向终结，推理优化与后训练提升有限，大模型今后如何突破发展瓶颈？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFENcGM8m7g3pC5zJ2JhNWriby0icfRDzte8wichanvww4dYW8espRz9E4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>高质量数据枯竭，传统预训练走向终点，大模型如何突破瓶颈？当前（多模态）大模型正深陷「数据饥渴」困境：其性能高度依赖预训练阶段大量高质量（图文对齐）数据的支撑。然而，现实世界中这类高价值数据资源正在迅速</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964307&amp;idx=3&amp;sn=f037d36333c3a2fb987a286126087f25&amp;chksm=856f8ede218b05636875b44648d315853126383aa73a70cb0688426fd7ba0aeb20736d2bd37e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 13:07:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[200B参数击败满血DeepSeek-R1，字节豆包推理模型Seed-Thinking-v1.5要来了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicUrVBTVESicaKBy5JFMz8yUwMjvCgrsqbBKt8UeDklZcPtqWt4fA6OWUsXUWcRIjIicEj7TQ6gCBUw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Panda、+0字节跳动豆包团队今天发布了自家新推理模型 Seed-Thinking-v1.5 的技术报告。从报告中可以看到，这是一个拥有 200B 总参数的 MoE 模型，每次工作</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964188&amp;idx=1&amp;sn=7e9e92163a81d1e3fbeabf96ff6c8c41&amp;chksm=85679e38e8a438d9e01f3042930fe276ea6b8256005894c8464f5e2d7443a57a48d960ac39ba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 03:02:11 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IC-Light的视频版本来了，RelightVid：强光动态环境下的视频光照编辑神器]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFw6AM84e5ziabyYey0HGL0zTicN32VH9AT0N2LsmEnnaicTGMSpUtTs7icw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家还记得那个 ICLR 2025 首次满分接收、彻底颠覆静态图像光照编辑的工作 IC-Light 吗？今天，来自复旦大学、上海交通大学、浙江大学、斯坦福大学等机构的学者们正式宣布：IC-Light </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964188&amp;idx=2&amp;sn=662fa2a1d768b8f9ece7ff2b00a88ae4&amp;chksm=856797124c3257154fa2c62454e40fea7da2d28255e961e0391d3586e85b6e1aba07167f910e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 03:02:11 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MoE模型已成新风口，AI基础设施竞速升级]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IKOXsnYL7Vx02HM9gSls5Oh1bhvhkdeT33ibia7PclicUciaKibTFKyplEEUg/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Panda因为基准测试成绩与实际表现相差较大，近期开源的 Llama 4 系列模型正陷入争议的漩涡之中，但有一点却毫无疑问：MoE（混合专家）定然是未来 AI 大模型的主流范式之一。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964063&amp;idx=1&amp;sn=91a4f9e74086b5897b5812b51a183b32&amp;chksm=85ed4567f0aff9e8253583de80232d827eda08f0c4d95252014d7807a5870579245085426eab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:31:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[42.5 Exaflops：谷歌新TPU性能超越最强超算24倍，智能体协作协议A2A出炉]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IK40BLl2qnBpAcibzictq1Eib3UOlOibfjosGAx4Z96kHiahLlvvK7FqUAFVw/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：泽南、+0第七代 TPU 来了。AI 算力又迎来了新的标杆。本周三，谷歌正式发布了旗下第七代张量处理单元（TPU）Ironwood。谷歌称，在大规模部署的情况下，这款 AI 加速器的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964063&amp;idx=2&amp;sn=fae1953e7bd488ebb976b91c51ba334b&amp;chksm=856b35ed379e315457ec5133c091910aaa4b7f8daaec5b0b85589f2b4ea748ad04db519fa9f6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:31:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 2D 大模型赋能3D Affordance 预测，GEAL助力可泛化的3D场景可交互区域识别]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vTAu7DCxGQFpWic1fzYsq7ic7EgACGj9mOC1icibsiawlwPKrPImiaNHIqFFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>GEAL 由新加坡国立大学的研究团队开展，第一作者为博士生鲁东岳，通讯作者为该校副教授 Gim Hee Lee，团队其他成员还包括孔令东与黄田鑫博士。主页：https://dylanorange.gi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964063&amp;idx=3&amp;sn=9c318f83edaeb4b3771e4fc47eb78240&amp;chksm=85c57dcf01703fdca7c087b80365101356a1a06255135b487e0c00f1b6561e5f58f3079d5b35&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:31:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[闭环端到端精度暴涨19.61%！华科&amp;小米汽车联手打造自动驾驶框架ORION，代码将开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8HXJJMEnKicFIibEic39ngdq4vEhWcLpzswMK5XPpN818WWQakWOq3f014Dju2RFoVMto92b2FjS6Og/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，端到端（End-to-End，E2E）自动驾驶技术不断进步，但在复杂的闭环交互环境中，由于其因果推理能力有限，仍然难以做出准确决策。虽然视觉 - 语言大模型（Vision-Language M</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650964063&amp;idx=4&amp;sn=13eeb7cceae559108fee593e1c96cb24&amp;chksm=8539e4ceb31879682f88c8b46d2599a3a78421814fbd6325076e8e69892e93fcb993b88b7834&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:31:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[因研发FPGA工具，丛京生院士获得ACM计算突破奖]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8oqguYh3T85w6pSNKPC7IKSn5UxraJ23Gv29Ohn8jfV2wkgrlwaicfQKPqwnUDNKmxjF43oxnC5gQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：Panda今天凌晨，国际计算机学会（ACM）宣布了今年的 ACM 计算突破奖获奖者。丛京生（Jason Cong）「因其在现场可编程系统和可定制计算的设计和自动化方面做出的奠基性贡献</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963965&amp;idx=1&amp;sn=4e71a1fc84e67f6f444286cae3053364&amp;chksm=85f9f1ba39a9ef8e2006bb9848acc96e6d77ac15a50f9321bcd0cc2f5530c0d48e0f84326a60&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 02:59:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型推理无损加速6.5倍！EAGLE-3碾压一切、延续Scaling Law能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vSD7GHOAbyYoK1bmkhgmftL1V6RoiaLhqVqrV0SHZd1aibHSEicZ7GLjCQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>自回归解码已然成为大语言模型的推理标准。大语言模型每次前向计算需要访问它全部的参数，但只能得到一个 token，导致其生成昂贵且缓慢。近日，EAGLE 团队的新作《EAGLE-3: Scaling u</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963965&amp;idx=2&amp;sn=4bcca8e1a43e6b39e8052c050c56c876&amp;chksm=85d3c19c716f783923848bbdb506e4573dfe500b8897a45ea5e5eb540a970edf250e48b853c2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 02:59:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI封神了！无剪辑一次直出60秒《猫和老鼠》片段，全网百万人围观]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFWl0Yy1q1dKzrohxtxwKYteTgGVxRopKfibeIP4AyNwBmRWpkDicBibjyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：杜伟、蛋酱AI 圈永远不缺「新活」。这两天，加州大学伯克利分校、斯坦福大学、英伟达等机构联合制作的《猫和老鼠》AI短片火了。论文共同一作 Karan Dalal 的帖子收获百万观看。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=1&amp;sn=4cee55a6aeccd0cc7f49f1c8cb9c5b51&amp;chksm=850190452c09516c791ea56747ea4f0f57fd0e94ad74835f05dad92a361dd7275020499b3445&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文党狂喜！alphaXiv推出Deep Research一秒搜遍arXiv，研究效率直接爆表]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW8M4rGiaLyHRZmTGNm5r4CuFibxFjazPrpgrSaV4L1X9EJic63SDEQVXicdkmpKUMO75ZCE57I6D28DcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：+0刚刚，alphaXiv 推出了新功能「Deep Research for arXiv」，该功能可协助研究人员更高效地在 arXiv 平台上进行学术论文的检索与阅读，显著提升文献检</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=2&amp;sn=16bf30502a94f71585daaaeeb6d6dd50&amp;chksm=85ba9416ff321350c64b9d7e695e01ec10a060b0493b5039c57e190913ba1b3049fb0ad85dce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 HighLight｜打通视频到3D的最后一公里，清华团队推出一键式视频扩散模型VideoScene]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v25jWmX6S2LQEOJn6Bu0ohVa4gibm4sv3BFJkxQQSPNoxC6y3853O80Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文有两位共同一作。汪晗阳，清华大学计算机系本科四年级，研究方向为三维视觉、生成模型，已在CVPR、ECCV、NeurIPS等会议发表论文。刘芳甫，清华大学电子工程系直博二年级，研究方向为生成模型 (</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=3&amp;sn=7a51f00a00c37ecdcb8b8c59acaa937b&amp;chksm=85f212898c3c50f72f75fdffbc2c5efb9970a9a3e76255aabcd4dceb2ad4c3fbda4289c2ecdc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工&amp;普渡大学提出CFG-Zero*：在Flow Matching模型中实现更稳健的无分类器引导方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v14PDgVbUiccicNicxCbflmicYxVD9ybHWUYuY8eRRIQvrW02oymIKDJAhw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇论文是由南洋理工大学 S-Lab 与普渡大学提出的无分类引导新范式，支持所有 Flow Matching 的生成模型。目前已被集成至 Diffusers 与 ComfyUI。论文标题：CFG-Ze</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963927&amp;idx=4&amp;sn=6b81be1904d11911dede2f2e5d77ff22&amp;chksm=85b3c3109ffc4bfd65916c391715c0dc1cedf02654a6115f74aef16e4234f4ff3e595f07fe0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 04:23:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[全日程揭晓！ICLR 2025论文分享会我们北京见]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0vd68IxfialZjbGfxY7icYgobzWDlsE2d8xUP2NLzbibEFZZAlxNyXMm7Ww/640?wxtype=jpeg&amp;wxfrom=0"/><p>从 OpenAI o1 到 DeepSeek R1，推理模型进入到了全新的发展阶段，展现出来的「慢思考、强推理」能力正在加速从语言智能到认知智能的进程，并构筑起未来 AGI 的重要基石。同时，学界对大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963889&amp;idx=1&amp;sn=f3d5234b73b3e593ab8c41e591b97133&amp;chksm=85e36fc2bf6a01cc6797c3eaadbe946a9275a9e4c8bfec9b135e9ad9c4a894a9a8015ceabeac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 03:07:46 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从零搭一套可复现、可教学、可观察的RL for VLM训练流程，我们试了试]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWic2wU9U1GRVLkvhjU96IK0v3cln5A4ZJISoIDSwa2d5YSC0rKqhUq71PsXZACXwDc9VvmwvrAArZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>自 Deepseek-R1 发布以来，研究社区迅速响应，纷纷在各自任务中复现 R1-moment。在过去的几个月中，越来越多的研究尝试将 RL Scaling 的成功应用扩展到视觉语言模型（VLM）领</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650963889&amp;idx=2&amp;sn=19b8cd5cb8193c9e5f58a537d7eeadc8&amp;chksm=85119ccec38778e2a54a790ed60b63418f161eba36b7fdad6489a79242f2c8f5b96c1685eb36&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 03:07:46 +0000</pubDate>
    </item>
  </channel>
</rss>