<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[学术头条]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[学术头条公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM6paafH0azzlKicqfUJvZkmEwhWbkEDrRTKSKvLRIiciaofw/132</url>
      <title>gh_790ee301453b</title>
    </image>
    <item>
      <title><![CDATA[击败99%人类玩家！智谱开源GLM-4.5V，拿下41个SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9CC213psSbRT2QctGib8oh9m8HscpmEECRbPqD0vZ6UmXOhhewtuGiaIuiaJOKBGlBk3C2ibkCm9DerBA/640?wxtype=jpeg&amp;wxfrom=0"/><p>多模态推理被视为通向通用人工智能（AGI）的关键能力之一，让 AI 能够像人类一样综合感知、理解与决策。其中，视觉-语言模型（VLM）是实现多模态推理的核心基础。今年 7 月，智谱发布并开源了全球 1</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598556&amp;idx=1&amp;sn=bad59618f2f02af7b3dfa3d175aaaa94&amp;chksm=cedc5ba89f4ece2c84ff82ba58e1801dbcffed4888e5614fa874b1f8963df44119036fc95050&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 12 Aug 2025 11:55:13 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[今日第一！智谱发布GLM-4.5技术报告，技术细节大公开]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9D7CLSiccub8zIJvSd7gKwR1dqxOcgvIfWsL1IWL8zjMb7FI189eb2myoURbGQr8UOGuWAlt3VuRsg/640?wxtype=jpeg&amp;wxfrom=0"/><p>内容来自：机器之心就在上个月底，智谱放出重磅炸弹 —— 开源新一代旗舰模型 GLM-4.5 以及轻量版 GLM-4.5-Air。其不仅首次突破性地在单个模型中实现了推理、编码和智能体能力的原生融合，还</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598548&amp;idx=1&amp;sn=c4488c3ba3f5ec63cd924d6e7be79ba7&amp;chksm=ceb1f1fd837425d1dfce9de37da8d97b56589300b0f8f8cf40dd650d33991490bfe0f0159684&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 11 Aug 2025 09:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[俺「代理编码」来也！｜漫谈AI]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9DH9n4b3fUrrZfkIsL4fO2xFuJLFK3Hh5IeJPuLGLoUEYLDZB8JSq24c9vWYvuzVSDNjZhxQRDzWw/640?wxtype=jpeg&amp;wxfrom=0"/><p>参考：https://arxiv.org/pdf/2505.19443作者：小羊文案：ChatGPT如需转载或投稿，请直接在公众号内留言</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598528&amp;idx=1&amp;sn=d28907ecefa2ccc15966c52ce6b5292e&amp;chksm=ce5b2fe74855439148b9d850ec91fbaa81cb126adb9bb61d6d42b1f2c7c726a6aebb0c7c5016&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 10 Aug 2025 04:18:50 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[王梦迪团队「自我进化agent」综述：从静态LLM到超级智能ASI]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9Dic3Q5sN0vI3Dd67ZWvrKd37LOaVBm00beZOXvWcgbEOvmH9IicuPVgjxc0Fw1sMpRianicDEsT4O8nw/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前的大语言模型（LLM）存在严重的缺陷：其本质上是静态的，无法根据新任务、不断发展的知识领域或动态交互环境，调整内部参数。如今，随着 LLM 越来越多地被部署在开放、交互环境中，这种静态缺陷愈发凸显</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598526&amp;idx=1&amp;sn=a775fe907018da6704f4901df0702ea9&amp;chksm=ce0ba49bde85ac6c1eb27bc0049666b539a968aaf2d30eb1d5b295de0c2e5c3e1016bf6d6c60&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 02:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刚刚，GPT-5正式发布，奥特曼：所有亮点都在这里了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9DH9n4b3fUrrZfkIsL4fO2x6uaHdHqDI8QnmJxtPlMPkvSYHuHw6tmUONpfrPh3HGqZias2auGEeiaA/640?wxtype=jpeg&amp;wxfrom=0"/><p></p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598506&amp;idx=1&amp;sn=78a517e08d537ab5841f421f68046945&amp;chksm=ceb1efaca802c6970f8fae578d63d8e4173fa55b1e38dff1ced78332af4cf8f099bbe8235e13&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 18:26:53 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Nature最新封面：AI“造”水凝胶，粘连一切！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9Do0Q32xQ4DndEgC4nL0ojcqZia7LSI2ErOVEAyHC8onRgwmibwJniaqlIJkuXlZgFicSbUNj4lsmibECg/640?wxtype=jpeg&amp;wxfrom=0"/><p>一只橡胶小鸭，经受住连续数日的海浪拍打，依然纹丝不动；一根破洞达 2 厘米、注满水的管子，只需随手打个“补丁”，便可瞬间止水并防漏 5 个月之久。以上，全归功于刚刚登上最新一期 Nature 封面的「</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598436&amp;idx=1&amp;sn=b3459ce0edd6533b837eb983070d7c0a&amp;chksm=ce63da2d3cffaa08abd7e30c920d2912197ab7fae11cd3636ac467ca842253ec030974e8d395&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepMind 世界模型再升级：一句话「创造」多样化交互世界！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9Do0Q32xQ4DndEgC4nL0ojcHPTj7VtlRcDFTvMLhWJZCAnE3lmLdbM34TrhrDyaY9Rm71U5iaaicbmw/640?wxtype=jpeg&amp;wxfrom=0"/><p>继去年发布 Genie 1、Genie 2 之后，Google DeepMind 昨日深夜推出了他们的新一代世界模型 Genie 3。据介绍，这一通用世界模型能够生成前所未有的多样化交互式环境。基于文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598404&amp;idx=1&amp;sn=21a21e346bb1b88f9fca7a5a9dcc4c43&amp;chksm=ce36daae28372ca84d52ad82bdbb67d1f68243ae3e0b36dc95dabaed903b1a28ae8c50ce12a6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 04:06:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[深夜突发！Claude Opus 4.1发布：智能体、代码、推理能力全面提升]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9DaSpTXVxzUfVpfTD0qNCC7tDicXp8hNlicibjicianfVTic1Wny3ptBWmyU9daPStk0OmPpIT9SIkX3TOw/640?wxtype=jpeg&amp;wxfrom=0"/><p></p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598339&amp;idx=1&amp;sn=87dc724ae5a8cdccb7a281397aaae7f3&amp;chksm=ce4c2206db17973f4e6b6071512441c9c4bfc2fca64ce13ac38686a0405228c7336aac848533&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 18:58:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刚刚，OpenAI再次“open”：发布两款开源模型，性能逼近o4/o3-mini]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9DaSpTXVxzUfVpfTD0qNCC7TuC7McibCzr7Jnuz6IucglRsCNicvSTqgfl5pTT0VEhMfeUdpT9T6IOQ/640?wxtype=jpeg&amp;wxfrom=0"/><p></p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598302&amp;idx=1&amp;sn=dfb1ac06d23754400abe575eb290976d&amp;chksm=ce5523a83285574f3fc3dab1ce87daf02739dff1359b66737990eea5c131a80f586fe81cbb96&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 18:22:43 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[清华00后校友推出「分层推理」模型，仅2700万参数，击败o3-mini-high]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9DaSpTXVxzUfVpfTD0qNCC7oBC8b41IthKxGhic4BWF2Oibe2gzpg0kKYnaH3nD5OfSBHnibRiarljQ6Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>尽管大语言模型（LLM）在内容（文本、图像、视频、音频等）生成、对话交互等任务中“大放异彩”，但在实现“真正推理”方面依然存在局限性。思维链（CoT）并非一个理想的长期方案：它依赖于脆弱的人工预定义分</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598252&amp;idx=1&amp;sn=1fa7be074fa099f42063aea9676235ba&amp;chksm=ce7766e67440e1f3a6b9bb1e374208c6c42ea44d2366abbc0894cf3fbc1f055c0d13430d2ddc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 10:11:49 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[scaling law再遭质疑：“退化式AI”竟成终局？大模型的“大”错了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5qv5QsBmI9AT0VmvLAfE6dw6OicdV4qkjc4qiaFJCjmNgbV6sDzjEYVvgazk8IoXCFaV7AIwbJ1bvuSKRgiaNZedA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大模型行业正在掀起一场“scaling law”热潮，科技公司与研究机构纷纷投入巨额资源，试图以“更大”的数据规模实现“更好”的模型性能。然而，这种暴力的数据扩展能否带来预期中的模型性能提升？不断扩展</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247598240&amp;idx=1&amp;sn=51fd65348ac360233ad1f7fdd27622d8&amp;chksm=ceb966294e7f80e08ca47ddc1b93529e73eff54b3e2f81095691b616242815a4f2333a270c78&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 09:57:11 +0000</pubDate>
    </item>
  </channel>
</rss>