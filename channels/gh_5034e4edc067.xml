<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    



































    <item>
      <title><![CDATA[特供版RTX 5090D被曝不能「炼丹」！AI算力3秒锁死，不支持多GPU配置]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIGibpwicp5dlniaLuclBz3aZg9LaMSkoN0TXXA5YjYiaxRXajuaqW0PN7YHW1FmaqOZae6ZP6WI4RYmg/640?wxtype=jpeg&amp;wxfrom=0"/><p> 新智元报道，编辑：泽正 好困【导读】英伟达针对中国市场即将发售的RTX 5090D被曝出无法「炼丹」，3秒即可自动锁死算力。而且也不再支持多卡服务器配置与超频。该显卡或成「笼中金雀」，只能供游戏党细</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447216&amp;idx=1&amp;sn=84412edbe684e3dac905812d0c2e8193&amp;chksm=bf041b128e211e8ff16410ce4b1d75724b69c398c35c44592bd5c9093abb1150b63a5cdcc114&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 17 Jan 2025 10:25:25 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[文末赠书！“西瓜书”《机器学习》官方配套习题集重磅出版]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIGibpwicp5dlniaLuclBz3aZgD8wtIOY9wA6jI1up65ia67nibrKv2Z2lZzvtZFmZB1FSgJlBovXhewbg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作为人工智能领域（AI）中文教材扛鼎之作，南京大学周志华教授所著的《机器学习》帮助无数AI从业者理清了机器学习的基本原理。在书中，周志华解释机器学习基本术语和问题时，贯穿全书用西瓜进行比喻讲解，因此该</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447216&amp;idx=2&amp;sn=c5061414e4159bbbecd770d904d26ecb&amp;chksm=bf63790f5276f2150209ee6dbe5e06ca48812061c558c3890e6ab15b1f7b11365d6d624564a3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 17 Jan 2025 10:25:25 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[多模态入门--CogVLM,VILA,MM1,MM1.5和Pixtral-12B]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW466ttLDYX3XVSHSHVeNIJiahEphHJKVuribEv04FLqKvqg5FY7BOl83cXoAZA4cicypc2csdKVPHH7ukg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇主要包括CogVLM，VILA，MM1，MM1.5和Pixtral-12B。1.CogVLM论文：《CogVLM: Visual Expert for Pretrained Language Mo</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447216&amp;idx=3&amp;sn=976ccb8b77d664671a7358e0bb5ff7ec&amp;chksm=bf354041f5c317009030bf57bceee7668fd8de906a061173adef3caac3c02a48d5b6672f1c96&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 17 Jan 2025 10:25:25 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【多模态&amp;LLM】Reyes：一个从0到1开始训练的多模态大模型（技术报告）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGDN0QSHsP0HQ4HWrQELzDZiajvKvGRDBBQraUWl8RyibCUic3uaeChcyMM5DRvGfRibJosEibx9icWPuasQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，笔者系统的看了下一些比较经典的多模态大模型实现思路，本着动手实践的态度，从零到一实现了一个多模态大模型，并命名为Reyes（睿视），R：睿，eyes：眼。Reyes的参数量为8B，视觉编码器使用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447216&amp;idx=4&amp;sn=073697b5e1728b8079f5ae5868cc420d&amp;chksm=bf6dbb8a615d0a53c42e888588d29c504dc9098fff28f453c61eddcc0b2ae81f4072cadbfcf7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 17 Jan 2025 10:25:25 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[从“说”到“做”：大语言模型为何会进化成智能体]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGzMIibOvgkr2oYsH0DY4JxxokkUDdjzKJAPhVD0KWJtSPMicqiaOcOicXpvUutrkIAlLG1XNTxMXyWuRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>    媒体上有关智能体的文章如同天上的繁星，这些文章大多数是从商业角度进行的概念炒作，有深度的文章却很少，尤其是从技术原理角度阐述的文章更是少之又少。我决定从技术原理角度展开对智能体的讨论，力求通俗</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447216&amp;idx=5&amp;sn=8f0bc185b489f18820de432114f3c3cd&amp;chksm=bf22f58b84da398ab1bf39f5d1a55f83908544c55cdbda94c57fc3961dcf853ea367b046e57d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 17 Jan 2025 10:25:25 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[刚刚，智谱被美国列入实体清单]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ9bGiayDjPsCUsxYBM37bHpndM0bH2Sp2hKFo01RBeUxW31HOycHLrNdTZCaTWoKIWE3WwSaTxOibw/640?wxtype=jpeg&amp;wxfrom=0"/><p></p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447197&amp;idx=1&amp;sn=56d2edf4293ecf431921faf458b3722e&amp;chksm=bf2e987b4dba92deb47c81a48272b66e2d17e1a7b577ec0797158bf628a3487e7408fb862854&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 16 Jan 2025 02:10:38 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[中科院化学所宋延林组火了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLibaSjLXGjC8Io1e9fz1K7M9AdsHubgIGY8xFQ2juv7ekgA9GrWBx9hFvLseXNovAHSm5vYR3JicCg/640?wxtype=jpeg&amp;wxfrom=0"/><p>转载自：募格学术 ｜来源：知乎@阿黄sweetgirl、公众号清风寻迹前情提要：吃瓜系列的第一次“好瓜”，好导宣传和赞扬！！！（我大概看了三遍，每看一次都有不同的感受，初看：比较快速的浏览，初始的印象</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447191&amp;idx=1&amp;sn=6d601088ebcb0d1144aba0ff59cb4284&amp;chksm=bf65d27b75ba78951f07abe13ad487553038090ec4fb232356bc20ed41b3dddaae54c2eb0482&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 Jan 2025 14:39:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024 年度总结 LLM System Research：过去半年的科研心路历程]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLibaSjLXGjC8Io1e9fz1K7McdhEhOmOJdjt1jX2bS2FokiaXWW4B6z5MJT1ibyPdlqSVIKg7oFC39eg/300?wxtype=jpeg&amp;wxfrom=0"/><p>飞往SFO的沿途风景，Shot on IPhone恰逢年末年度总结盛行，回国无心科研，我便强迫自己分享一下自己的过去半年的科研心路历程。目的有二：1. 继往开来，学有所思。2.受东川路第一伊蕾娜：年度</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447191&amp;idx=2&amp;sn=da91fb1e0ec89ea15c49577074a0a7f0&amp;chksm=bff76163fbd865177ce07b4b74def5655b281d246893411e913d628b454d4f90280f94112a29&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 Jan 2025 14:39:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[你的RAG出错了？快来Get这份改进秘籍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVcmYqQTLYyYeiaolevofFSacHfYwI30X9KeiajVRnAdNicYXfDzYyC0AxHGQAdRwKl3C5rPRFeN2TVlw/300?wxtype=jpeg&amp;wxfrom=0"/><p>原始 RAG 框架在提升检索和生成答案质量方面，还有一些关键问题没解决：找出来的文档真的跟用户问题相关吗？有时候可能找偏了。找到的内容够不够回答用户的问题？会不会信息量不足？会不会有一堆没用的信息混进</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447191&amp;idx=3&amp;sn=c7048a9148c99eb290ae429139ad5f84&amp;chksm=bfbcad83a91c8a83403920cf86e42d22a7b015dc3b516b00d931deb746ae376656d9b53723f7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 Jan 2025 14:39:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[实测书生系列开源的最新模型-InternLM3-8B]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5njIImn6qOTniceqMic3LIXOg8iaasian6mAQhQSILEF5TIKdUuNBZApNT4L4Cb6FZqI6z0r83rJsO2ew/300?wxtype=jpeg&amp;wxfrom=0"/><p>2025年才过了半个月，开源社区持续躁动，这两天已经有4家又开源了新模型，千问开源了过程奖励模型-Qwen2.5-Math-PRM、面壁开源了MiniCPM-o 2.6全模态模型、MiniMax开源了</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447191&amp;idx=4&amp;sn=9922fbcef13b0cb317f92445334d1d5b&amp;chksm=bf5de4b137a1a6286514fd3145c46a2393867cf4b13744afccb10e17c429d48fe849953bd345&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 Jan 2025 14:39:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文档智能】轻量级级表格识别算法模型-SLANet]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGANHHpjGsDfaqeZvcxmNMqSaWEBnRyaC301HkKPUjKlxt3dxZdf3eBbIKZrKicVppz1rq8hicWzoNlQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言前面文档介绍了文档智能上多种思路及核心技术实现《【文档智能 &amp; RAG】RAG增强之路：增强PDF解析并结构化技术路线方案及思路》，表格识别作为文档智能的重要组成部分，面临着复杂结构和多样化格式的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447191&amp;idx=5&amp;sn=adbc2287c876d319780b1729be7bf558&amp;chksm=bfddfc7d23b1a898c7926c9afb51fb798b9a9388f8215be0890bf9808210f7e97cde4a296129&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 Jan 2025 14:39:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[用LLM做文本分类，微调选base还是chat]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuxH9CdgII5ZJeF82icj9d5CkOr9FGOEEAMYEV0iarU2aKLj7xNxQQPEcsw2EbDTkSm4QMW9CHCxWBKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：LeonYi链接：https://www.zhihu.com/question/632473480/answer/75664255663使用Qwen2ForSequenceClassificat</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447166&amp;idx=1&amp;sn=d618fbc37763a29f63ca251725fe0727&amp;chksm=bf5a76355a620bda473fea219c4952e1d039fa0ac4894cc3dab718c61eb18138e61f014dbfd5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 14:40:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek-V3：开源模型的里程碑 - 从671B参数到全面领先的实力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic2lqVoRq7DwynLb5ibg3kw8DichZ1Gzfg5bXMCEuwicibKMeqO2G91cMtGtFNP2CGIvq3NSsDzY6774ug/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言近日，人工智能领域再次迎来重大突破！DeepSeek-AI发布了其最新一代大语言模型DeepSeek-V3（简称DSV3）的技术报告，在AI圈引起了广泛关注。作为一个开源的大规模混合专家（MoE）</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447166&amp;idx=2&amp;sn=c2ff548731065b5d1fe8c64674adb7a0&amp;chksm=bf814e84c8ed95c91a51b679fdf0273624dc45f6a42c0353b8bbfce07cb65ae8efd7bf29a96d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 14:40:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问又开源啦，开源过程奖励模型-Qwen2.5-Math-PRM]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nVX1dGicfJ5CuiciaMUqB28wT3Yvu54ZXYeibShEBT18T41CicR43r0afrWT9dB93h5U4KicguJanMKqqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>刚刚刷了一下Qwen的Repo，发现又有新模型了。喜欢开源是吧，就爱这样的你~~这次是数学推理的过程奖励模型，共有3个，分别是，Qwen2.5-Math-7B-PRM800K、Qwen2.5-Math</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447166&amp;idx=3&amp;sn=af7fd680b760b87a3fb81516274fe4d8&amp;chksm=bf10d8272ca492051ded2f22731a24de7fc4fa71c37633e75e275fdea706b49cab131f132b29&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 14:40:28 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[免费下载|火爆AI圈的深度学习 “四大名著”]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLBzsPjhKMEAW88t6H3OYdGohNVW6rpjqYh0AHNCAYJjAqGtuxX8N4jczzCMWyu9lZvyXIK1lzZUg/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍人工智能的四大名著，今天来给大家介绍一下 √ 西瓜书《机器学习》周志华。讲述了机器学习核心数学理论知识和算法。适合作为学校的教材或者中阶读者自学使用，对于没有基础的初学者入门来说还是有点难度的，可</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447148&amp;idx=1&amp;sn=c77c5cb4734b014283e6a8be92aac480&amp;chksm=bfdec0b2244fef8c8936131ebb748cbc763a947a179e4525c6deffb979c519932977862a9435&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RLHF 常见的思维误区]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5k1kicYLWLFuw9VOrveqacQhlxq2thMbiajFxiccEdHWqK7h4MgNmHAibmozdSmNhfzib7GuEkh8kHzLIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：https://zhuanlan.zhihu.com/p/17657567877本文分享下我在学习和实践 RLHF 时，曾经陷入过的一些思维误区。这些误区的产生大多和我的强化基础知识理解不到位有</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447148&amp;idx=2&amp;sn=69cd66d8f70184e34821e7f57711d625&amp;chksm=bf05dd38586ec1fecd69a7113dd5ca8cd77710b3aefa11824f068c5b939da471a452f3383d0d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LoRA 的原理和用 PyTorch 从零到一的代码实现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BrtBjG6XSzIRRlEmT6EQbvFKoBEib0eu40ehVJ3Qc2sGIhveZnqI8e20bJswSUxXkWZC7VPgbon2ZYhbe80xibcA/300?wxtype=jpeg&amp;wxfrom=0"/><p> 背景无论是火热的大模型（LLM）还是文生图模型（Stable Diffusion）微调的时候，都需要大量的GPU显存，个人的显卡上很难实现，因此各种参数高效（Parameter-Efficient）</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447148&amp;idx=3&amp;sn=e18af15e2f3bb41453bd0a4b77b813fc&amp;chksm=bf57a7c9e33cc29ebdc54c59d64d8968abb4462a77a76dfd117e51e4710e9278f8fe10c6e325&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文档智能 &amp; RAG】RAG增强之路：增强PDF解析并结构化技术路线方案及思路]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGASKcfJtp9G00sykMjuXXExSOpjZgibV3nZA4WCaUibGI3tHUPdT9HVibyMxXCrlaPOejUcdOticjOWIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言 现阶段，尽管大模型在生成式问答上取得了很大的成功，但由于大部分的数据都是私有数据，大模型的训练及微调成本非常高，RAG的方式逐渐成为落地应用的一种重要的选择方式。然而，如何准确的对文档进行划分c</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447148&amp;idx=4&amp;sn=f94dfead6fae825f899e5cecb9389cd4&amp;chksm=bf112e9b486c36f1e0e1d4e7a2333b6471397617c873fe5d805629bd42a2a9e8592f1bc5b64a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CCF对话式检索增强生成Top1赛后方案]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVfjkpOqq17vlwcmkE41dAqlVUe08MjzdSOcvgWzjW6YsXV7aibriahGEzEBq908NGbULwfIaOYOBN7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言❝作者    Winnie; 马千里说在前面    不知不觉已经坚持大模型比赛逾半年，期间学习和收获了很多。非常幸运，在最近的CCF BDCI中荣获全赛道特等奖。遂将方案分享，期望能和大家共同进步</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447148&amp;idx=5&amp;sn=52d396b80598fabfe2505c7cf46a08fa&amp;chksm=bfea99d97f203650ddd2bf5ff9d738c3184d1a69be313e0f105347a2020a94ca5dc19cd30314&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复旦首发“AI禁令”：禁止在论文关键环节使用AI工具]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLBzsPjhKMEAW88t6H3OYdGq1vFcMk6P4VEw6chv7EbCtkZjic00icCJkDXN3RInlxEHaPAeOoLGg2g/640?wxtype=jpeg&amp;wxfrom=0"/><p>期末已至！在高校读书的同学们正忙着完成各种论文、报告。很多学生会选择利用AI来当帮手。相比翻阅厚重的书籍资料或者利用互联网搜索引擎查找资料，借助AI完成作业更加方便、实用但也出现了滥用AI的情况5分钟</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447133&amp;idx=1&amp;sn=fdacd4c22f357e58cf8a03250b65fba7&amp;chksm=bf9547520ed0433cc41f163815b73b8704c36b992e8cd302aa7ea0369d494f61cdbf0fae4519&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 12 Jan 2025 13:35:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【文末赠书】大模型在生产制造场景的3个实际落地方案]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLBzsPjhKMEAW88t6H3OYdGrS6u4oryiaicfVye8P7ibfwuBdeogicScByUEuCmYfCBaEhgDHIAiaibQKHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>生产制造环节蕴含有大量工业知识和工业数据，这些过去都只存在于老工程师、老专家的头脑和电脑里，并没有及时转化为企业知识资产，这其实阻碍了智能制造的发展。伴随着大模型技术在工业制造领域的快速渗透，在生产计</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447133&amp;idx=2&amp;sn=ee917edf8faaa04f0206636d954c671f&amp;chksm=bf2a8c3abea8538abb6e362bd1ebe41cfff8f846e7e9ae37171e58bfada68886b014b6588b45&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 12 Jan 2025 13:35:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[5万字长文全面解读GUI Agent的前世今生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib4F5QibhvUYtB9XXECryd8CtIl9reTLdictkaicz0VMmtPvK0DJMHD6bbZI7yibqXtV5ZAdLqOUD0rwPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言今天的主题聚焦于一个激动人心的领域——大型语言模型（LLM）驱动的图形用户界面（GUI）智能体（Agent）。这一领域融合了人工智能、人机交互和软件工程的跨学科知识，是当前AI领域最活跃的方向之一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447133&amp;idx=3&amp;sn=f60e28f1072a08e75576ebaea820dda4&amp;chksm=bf6d39b7c1e75d3d131ff8746969ddc5e8e59a11de17d351409db2c455b90ebe06c8713f68a5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 12 Jan 2025 13:35:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【多模态&amp;LLM】LLaVA系列算法架构演进：LLaVA（1.0->1.5->Next(1.6)->NeXT(Video)）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGA0Abicsiaz1wZ9BWzkfUdQFZrvbHz0AOkHFWfw4eMhO2ABjBfX4jNWZiaW7keqgv4rqrzVDic2aiaBHAg/300?wxtype=jpeg&amp;wxfrom=0"/><p>LLaVA模型架构目标是结合预训练LLM和视觉模型的能力，llava使用Vicuna作为的LLM （语言解码器），CLIP作为视觉编码器。视觉编码器：使用预训练的CLIP视觉编码器ViT-L/14来提</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447133&amp;idx=4&amp;sn=a1d7c3299b01926feaba8d10fb6c6fd8&amp;chksm=bfa447df96eef85f8d2bbface7a7cd92f0f7b70b47b90601131ae3e6becda855babf0c5b51a9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 12 Jan 2025 13:35:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[手写 transformer decoder（Causal LM）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BrtBjG6XSzJoo7gHm1BSPsDGh8UWtbJrJQ7Dd8UKCOtptdCTibwWdU4uZ9ly6gWlcf1tlNkibmQd7WovG2V9CGrA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阅读须知面试过程中让写 transformers Decoder 一定要沟通清楚是写一个 CausalLM decoder 还是原版的，原版的比较复杂，一般也不会让写。这里的 Decoder 一般指的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447133&amp;idx=5&amp;sn=38ac03deb8dcf42f4932ac6df93c5aa7&amp;chksm=bfd188767c226f830ee86a8b938e7e7227dc59a7ac89ec95c8122b90d55cd202ae3423b533fe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 12 Jan 2025 13:35:21 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Corex: 通过多模型协作增强推理能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJvjcAz7IqwFQ1CNPLMrEaTUwf4oUAiaf7YToOpMnVoUicOPGTZOFPy0TskbA0vj223VMPuaXdqnM3g/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文题目：Corex: Pushing the Boundaries of Complex Reasoning through Multi-Model Collaboration论文地址：https:</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447095&amp;idx=1&amp;sn=6298b4d438fac0769886ed1dd5456276&amp;chksm=bf8e674d47ec72a2d1357caa1925e7af0af75c2a34ed9bbbfdaf14590c7a06c4f1105f254a14&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 13:39:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[分块的艺术：提升 RAG 效果的关键]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVdZj9wBAKsp4a6emxwyuQC9icyOgmYAc0GUTs4iaZnfdaouPibZuicpHEcbId4UM7jG0sRaKlRbao0Ntw/300?wxtype=jpeg&amp;wxfrom=0"/><p>聪明人往往很“懒”，但这种“懒”其实是高效的体现。他们总能找到解决复杂问题的最佳路径，用最少的力气获得最大的成果。在RAG系统中，这种高效的实现往往是通过“分块”来实现的。你可以把它想象成把一本厚书分</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447095&amp;idx=2&amp;sn=f8340e650db6475b9a3131208c4b80db&amp;chksm=bf2926bd0008f7f47f8ff8532beea227820b6633f559914ce07e9fc1042651cd759b0f5361e3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 13:39:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[o1类大模型的过度思考: 2+3=？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagcf3kfqIMv2aF3dJOvKWIb6SBznv5kN3Y4Yt9ZvD4hLMS4bgMNxQdow7guaK58nvCl9EI26cbJYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯AI Lab和上交发现在面对一个基本的算术问题“2+3=？”时，o1类LLMs为何会表现出过度思考的现象。这个问题虽然简单，但它揭示了当在处理复杂任务时，这些模型是否真正高效和智能。下面一起深入剖</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447095&amp;idx=3&amp;sn=fd570d9ca37bdbdf0f3f7f21d2512754&amp;chksm=bffaa10ff660f0c92643c5ad723a9dec0840388ac428d15d9ff8cdbc4a2c87affaa215c1d0ba&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 13:39:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[生成式推荐最新进展]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0Or4ugWRYXw819LYsAyk9C3xTyUFNaU4wkmQtIRmPcYDn8uPLFYDPQonOzssSIPldaAGpibYk6RqEWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜刘恩泽机构｜中国人民大学研究方向｜推荐系统随着大语言模型的迅速发展，生成式推荐作为一种有前景的新范式备受关注，因此本文聚焦生成式推荐领域挑选了十篇最新的相关工作。文章也同步发布在 AI Bo</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447095&amp;idx=4&amp;sn=1d4bf35561f128fcd419126cfa00e975&amp;chksm=bf4057004a9095319db2801bd13df052942cafcdf6d5a2da7dee7ab0ee4aea3365b8477b2628&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 13:39:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[PyTorch 实现 Multi-Head Self-Attention]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BrtBjG6XSzJoo7gHm1BSPsDGh8UWtbJrTbvDJF0EagJs3eUhpQ569rZYPVqCoGhr94zyiaQvxDPVcSoibTdHUQ8Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>背景在 AI 相关的面试中，经常会有面试官让写 self-attention，但是因为 transformer 这篇文章其实包含很多的细节，因此可能面试官对于 self-attention 实现到什么</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447095&amp;idx=5&amp;sn=e491094c34c0abef4a7a2343f173a53b&amp;chksm=bf51add8d5da3b6a2b7dbb94f6ade5413986fe38e08c8e56b11e5452ad0fb9afa6eb0a7d731b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 13:39:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[突发！美国AI芯片限制最后一刀！英伟达AMD全球禁运，只配5万块]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIpua4V2lSLMSBgqfibRptP7w0bv7zOPkyaNkOAkQISzzRTz5HHaoaL4CBxjWSGPOsJtcZt2vc1jzA/640?wxtype=jpeg&amp;wxfrom=0"/><p>转载自 | 新智元编辑 |Aeneas 好困就在离任前几天，拜登政府再次决定，对英伟达AMD等AI芯片的出口，进一步实施限制。而这也是他为了防止美国技术落入中国手中的最后一搏。知情人士透露，美国希望在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=1&amp;sn=515f4805e8938874b16f561e15506c75&amp;chksm=bf7ba2a7d10386507459905caf0c384008a451217923d18ad19cb1a84db7df80e4add07516e6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[老婆饼里没有老婆，RLHF里也没有真正的RL]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIpua4V2lSLMSBgqfibRptP7oiasnfnO1hCdiajV7lRNaOrkmBw2cOK1LclVNDiboxyjMdgjrJXcsQ0pQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 作者：Atlas Wang，编辑：机器之心分析这个问题是为了弄清楚LLM能做什么、不能做什么，以及为什么。老婆饼里没有老婆，夫妻肺片里没有夫妻，RLHF 里也没有真正的 RL。在最近的一篇博客中，德</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=2&amp;sn=732e7998615b88470a89325b7288e4dc&amp;chksm=bf3bbcf823191d45eb9c507b92da6578a921596e1d999254f5579bb061fdd8c3cd7e6ddd2f49&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[关于RAG你不得不了解的17个技巧]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVcof43sE3D2aNwmW0qpNY9HUQlENO6AHG8Eiak0qxYTxKAWOLysgicrRq8CDu3hjhXV18y8ibbaibSRyg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近在写文章，想补上去年RAG（Retrieval-Augmented Generation）遗留的一些坑，希望能分享一些RAG的技巧帮到大家。还是那句老话：构建一个大模型的原型很容易，但把它变成一个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=3&amp;sn=b93bc92c23f44cd0f784711bd53c8d75&amp;chksm=bf31ad64a6ff21449068ab191944b09c5ac7c5b406b5dd2c7205c940913d70ab243ab849b0a2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Search-o1：赋予推理模型主动搜索的能力]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lBNd8z3tqaZ7b5iagMRyWtTJIfOcfWqMXO84yJL10ANx61aY4REXCfPKCjseGOv2nhMfwn5SzeHRQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：https://zhuanlan.zhihu.com/p/17527068532 Paper: https://arxiv.org/abs/2501.05366Github: https://g</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=4&amp;sn=306de5ab7dd936d5599eca8d66d1839f&amp;chksm=bfe19ff86611193dbe6454a2857a79e2aa29fc3476146b214d3cd1764c52ab88088e1e2a4a73&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[增强大模型的推理能力：从思维链到连续思维链（中）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGwyKFY6DOxInK5rqfAsOggeOLW1hheGREicbcLv5jImYfdrCI4gzib1zZwzEzKTvmkiboa0QAgYnKibyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>接续上文《增强大模型的推理能力：从思维链到连续思维链（上）》    5语言模型进行推理的底层逻辑    前面我们提到，大模型回答问题有两种场景：一种是提示词上下文中没有“解题思路”的提示，也没有“让我</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=5&amp;sn=773790c9e306eb41ef8a6e921a6f0c40&amp;chksm=bf1b29fc9de18bd4dd2ed90c63eba65866c22b8e1f99e969b8a8f7c6d945b4898f2662ba1ab2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
