<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    






















    <item>
      <title><![CDATA[突发！美国AI芯片限制最后一刀！英伟达AMD全球禁运，只配5万块]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIpua4V2lSLMSBgqfibRptP7w0bv7zOPkyaNkOAkQISzzRTz5HHaoaL4CBxjWSGPOsJtcZt2vc1jzA/640?wxtype=jpeg&amp;wxfrom=0"/><p>转载自 | 新智元编辑 |Aeneas 好困就在离任前几天，拜登政府再次决定，对英伟达AMD等AI芯片的出口，进一步实施限制。而这也是他为了防止美国技术落入中国手中的最后一搏。知情人士透露，美国希望在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=1&amp;sn=515f4805e8938874b16f561e15506c75&amp;chksm=bf7ba2a7d10386507459905caf0c384008a451217923d18ad19cb1a84db7df80e4add07516e6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[老婆饼里没有老婆，RLHF里也没有真正的RL]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIpua4V2lSLMSBgqfibRptP7oiasnfnO1hCdiajV7lRNaOrkmBw2cOK1LclVNDiboxyjMdgjrJXcsQ0pQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 作者：Atlas Wang，编辑：机器之心分析这个问题是为了弄清楚LLM能做什么、不能做什么，以及为什么。老婆饼里没有老婆，夫妻肺片里没有夫妻，RLHF 里也没有真正的 RL。在最近的一篇博客中，德</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=2&amp;sn=732e7998615b88470a89325b7288e4dc&amp;chksm=bf3bbcf823191d45eb9c507b92da6578a921596e1d999254f5579bb061fdd8c3cd7e6ddd2f49&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[关于RAG你不得不了解的17个技巧]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVcof43sE3D2aNwmW0qpNY9HUQlENO6AHG8Eiak0qxYTxKAWOLysgicrRq8CDu3hjhXV18y8ibbaibSRyg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近在写文章，想补上去年RAG（Retrieval-Augmented Generation）遗留的一些坑，希望能分享一些RAG的技巧帮到大家。还是那句老话：构建一个大模型的原型很容易，但把它变成一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=3&amp;sn=b93bc92c23f44cd0f784711bd53c8d75&amp;chksm=bf31ad64a6ff21449068ab191944b09c5ac7c5b406b5dd2c7205c940913d70ab243ab849b0a2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Search-o1：赋予推理模型主动搜索的能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lBNd8z3tqaZ7b5iagMRyWtTJIfOcfWqMXO84yJL10ANx61aY4REXCfPKCjseGOv2nhMfwn5SzeHRQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：https://zhuanlan.zhihu.com/p/17527068532 Paper: https://arxiv.org/abs/2501.05366Github: https://g</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=4&amp;sn=306de5ab7dd936d5599eca8d66d1839f&amp;chksm=bfe19ff86611193dbe6454a2857a79e2aa29fc3476146b214d3cd1764c52ab88088e1e2a4a73&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[增强大模型的推理能力：从思维链到连续思维链（中）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGwyKFY6DOxInK5rqfAsOggeOLW1hheGREicbcLv5jImYfdrCI4gzib1zZwzEzKTvmkiboa0QAgYnKibyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>接续上文《增强大模型的推理能力：从思维链到连续思维链（上）》    5语言模型进行推理的底层逻辑    前面我们提到，大模型回答问题有两种场景：一种是提示词上下文中没有“解题思路”的提示，也没有“让我</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447058&amp;idx=5&amp;sn=773790c9e306eb41ef8a6e921a6f0c40&amp;chksm=bf1b29fc9de18bd4dd2ed90c63eba65866c22b8e1f99e969b8a8f7c6d945b4898f2662ba1ab2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 10 Jan 2025 15:34:03 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[阿里通义等提出Chronos：搜索智能体技术助力新闻时间线总结]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL0YiateoMHIf1ohJPa3DCibHe0q3ia5hBXianaH3BrJy513Z3Yo7icC76XBO3CC86YNMkx4OvPq0jVwXA/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文：https://arxiv.org/abs/2501.00888Github: https://github.com/Alibaba-NLP/CHRONOSDemo: https://model</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447034&amp;idx=1&amp;sn=75a9396087c29832a74fe9e046151ad1&amp;chksm=bf9b74765ab792fdc2601c06c0cb6867869330c767529ce6b7cfc9c7a4c9c05d09fa817353c6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 14:35:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Github揽获1.6K星！南大、腾讯发布VITA-1.5: 迈向GPT-4o级实时视频-语音交互]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkic3tucibERrwhaNEALEHxWPz51SdzyQNokwicNoclLibYOpHYvVGnkyic7RTQLGwwuyUb2VtgoicypRtw/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，多模态大语言模型（MLLMs）主要聚焦在视觉和文本模态的融合上，对语音的关注较少。然而，语音在多模态对话系统中扮演着至关重要的角色。由于视觉和语音模态之间的差异，同时在视觉和语音任务上取得高性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447034&amp;idx=2&amp;sn=4e136b74d341b65c515b473979614d7e&amp;chksm=bf9b70d183748e6eb0ce7cb880b295c841ecceec394dd0bb6cefb84ac3b481017e87be0fc5a4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 14:35:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从ROPE到Yarn, 一条通用公式速通长文本大模型中的位置编码]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nLRr470LSaujrHibR4EwTzwTM8kKPSKAYNS4oYLPHXTMhYreKPJC7eGGfIt1cquSWTJibh3BD0Yxqw/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：https://zhuanlan.zhihu.com/p/15311461897 从Qwen2.5到Deepseek V3, Yarn几乎已经是各家LLM做长文本外推的标配组件 （相比Pretr</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447034&amp;idx=3&amp;sn=8eefd26d0a6250de8811f1f77df88f25&amp;chksm=bfa5c1bf8ff1158904344920a4facf4f0e0908eaac41486890e7963adc074c10a3d5c16e8036&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 14:35:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[增强大模型的推理能力：从思维链到连续思维链（上）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGxupMV8abS0In5hbApdsOu9k53ekyTuQ2rnxtEY4I9uYHDBJYxO2j8PMccdRz8X3s5UELMWdvaenQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>1    为什么要写此文？    收到许多朋友的建议，说现在Agent智能体很火，公众号需要赶紧写几篇有关智能体的文章，蹭蹭热度。但我一直觉得要做好智能体，大模型的推理能力必须足够靠谱才行，否则Age</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447034&amp;idx=4&amp;sn=aad8f98e7b3d439dd56f18df0752b7f2&amp;chksm=bf2e522443f107b1a0615a83cad0cb554c199247671eff25091334ea04f16c2df78d445faef8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 14:35:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：在家也能养“大脑”：本地运行大型语言模型的奇妙之旅]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>做LLM，如果没有亲自实践过，就不能说懂它。之前在本地部署LLM很困难，一）是开源的模型都很大，么有GPU跑不起来，二）是，部署起来太复杂，需要手动准备很多，解决很多包依赖的问题。经过很多人的努力并且</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650447034&amp;idx=5&amp;sn=971c78c6bfa4b0860320baca7cbe5438&amp;chksm=bfd1d345eda42b105666ea5bb7fe4558708cf5d62ee55411b06490c3e9a04142a0a985141908&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 14:35:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[1999美元！RTX5090发布]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJb0yKNr3WtLwSohOzheFUSbrK8Cgw0NLAk0lEcnfxYwXtf3OVqf2mY7t5zEM6JJTX82WdJoPonCw/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：EETOP1月7日，英伟达在2025年CES 并发布了RTX 50系列GPU。英伟达首先发布了RTX 5070 GPU，售价仅549美元。据英伟达称，该GPU将通过多种方式利用AI技术，提供RT</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446990&amp;idx=1&amp;sn=ec5cd5331b0192e0e718d5a3bf7cc445&amp;chksm=bf4fa927f9439a553a3f937da793931f8dea0bb17ae4718bb15b46b4ae2bb91ce121daf0a144&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 06:39:26 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年RAG：回顾与展望]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVcGjx2ic29DVDUJxlFBHPA9aajp6j2tFIYfWg5xSuiaQV6X2EDvWwe3wCXHSezBaF0OpogLTq4WqiaLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>2024年，RAG（Retrieval-Augmented Generation）技术经历了从狂热到理性的蜕变，成为大模型应用领域不可忽视的关键力量。年初，AI的“无所不能”让市场充满乐观情绪，RAG</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=1&amp;sn=0040aeeaf34a5cd592e93c8593f3f452&amp;chksm=bfb612ac1a9f56e624ba632ab2fc1e2e46e0b3b3de33b14fff57836eccf8e4e2a76deff4f016&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Baichuan Alignment Technical Report 论文精读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxtDLTHYN5ws5MjBgVsDwsz13OU98oYy4CAQ2ot4yqm8q21P15U2hXQR5icxSCsOnWo6PzhIMicZWicVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言最近在研究如果更好的制备通用 SFT 数据，baichuan 这篇文章对通用 SFT和 RLHF 两大技术进行了全面，个人认为非常具有参考意义。Baichuan 将对齐划分为三个阶段： Promp</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=2&amp;sn=c450004b05635a0feceb8d30c3ec2386&amp;chksm=bf052f44777904ef508a4512faa19f9642a258a5733f0ec4dfb4b33238484e259b897b82ad31&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[工作近五年，谈谈各类公司和部门的区别]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDAykAXrsvPIPrLDsOtkpxv2Lb1Xyr1La7ibiarAwALhguhbaKhqH6eORzNRSsKMPvSMpiagboICR0eNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>从实习到工作这些年，我曾在两家外企、两家国内互联网、一家初创公司和一家券商工作过。其中包括Top外企和Top国内互联网。整体下来感触还是很多的，以后可以多分享给大家。国内互联网 VS 外企 VS 金融</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=3&amp;sn=8b121dc43d2536bec13b530ab79de9da&amp;chksm=bfc1ba6143963c3b1a5ebe49d481ebe5e8e817a9795671b0769136e785f1a1b399784700d08e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[[vLLM vs TensorRT-LLM] ：系统调度schedule比较]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLL41WHgwWVzraBAS0f5nGfQYLbUbF6ZTZk2hbkUHricxWTx9EnWPPIiaiaEgKgibdB8cuH8fzhZcarOA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源：oldpan原文：https://medium.com/squeezebits-team-blog/vllm-vs-tensorrt-llm-4-which-scheduler-wins-2dc</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=4&amp;sn=f424c12ac6984dc8573a03553f3bacfa&amp;chksm=bfd0a720b85c8745f5105b96cf606432d2fb1db48eb5c21c5993f269a0854fa6c26bff42e30f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM之LLM的特工行动：工具召唤功能实战案例？Agent 到底是什么？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>智能体Agent新鲜吗？并不新鲜，因为我们之前处理LLM的输出的时候，代码中也会有一些判断是否可以采用LLM的输出，还是需要调用别的信息。不过Agent把之前hardcode部分的调用变为自动决定调用</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=5&amp;sn=1efe337727fabff388538f202ca643c3&amp;chksm=bf75488760c6dd81cf85431826b6c4b1de30495a9c8f5bf88c0e0ad6e62453485fc954e5a4c7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从infra的视角聊聊DeepSeek-V3]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKFPuSXXOqRGlq1EfNkNMBDBYJtXnibOFH13QDg4Yb7Nar0t8m32Jic5EaDhlAv6WQvvSnEdfqMDicnw/640?wxtype=jpeg&amp;wxfrom=0"/><p>看完技术报告，从infra的视角分享一些个人看法，供大家讨论。首先，训练超大号的MoE模型，仅使用两千张H800加两个月的时间，就能达到如此好的效果，这点实在是太强了。只能说实践出先知，从DeepSe</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=1&amp;sn=bd9d7b796f7fc6b60e92d9b0b38c6e2f&amp;chksm=bf34b1f360fa2a9d480c398fee7e01000d06e709885fe631a20869dd7b08104b0e2b2b330bc6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文末赠书 | 技术人的年末书单，这10本最受欢迎！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKFPuSXXOqRGlq1EfNkNMBDEZAfJicBOdh5fXG4TbSiaWiaw6KClDGtFm2YyNQuYG3axNhLCvtlia3Ohg/300?wxtype=jpeg&amp;wxfrom=0"/><p>一年过去，我们如何勾勒自己的2024？这里借用一位相熟多年书友的回答，“认真阅读，好好践行。”这种对阅读最朴素的认知，不失为抵抗现实焦虑的一剂良药。我们结合销量、口碑，阅读趋势，精选出最受欢迎的10本</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=2&amp;sn=f879024a5dc3adaa09e9304da8311b92&amp;chksm=bfc4a980017d614334f1b2a1fe13197f97b56a4fd4a21845817084f031fc8605fc4b012bc06a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解Megatron TP中的计算通信overlap]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkMbLJgBKf7TGLiazdyylqtZemA2Wdgkq4UL3L5GnDtspUWacNbT6EiaAkWrTARBTc2EyIqu2k5WDkyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章想来探索Megatron中实现计算通信overlap的方法。具体来说，Megatron的dp、tp和pp部分，都有可以做overlap的地方，本文探索的是tp部分（更准确地说是megatron</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=3&amp;sn=65f3f848aa069cacd01e79539d498a16&amp;chksm=bf793bf53bd90f68bca95259fad07a6da881e9d997e19b2ad77b39ea3797f0982798824c1c46&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[曾经火热的Graph Embedding和GNN在推荐系统上还有前途吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/7YJVBU9FXkV9af0b3e7IG34IZkiaINIwkBr1CIHw9AlZfgtclYugpiaWSLUKIwSiatorG0YqxdHSEuvElNUg5wKyQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>曾经火热的Graph Embedding和GNN在推荐系统上还有前途吗？前段时间回答了一个问题 为什么最近几年，没人在推荐系统里去玩 GNN 模型，GNN 是凉透了吗？ 感觉大家还挺感兴趣，这次专门开</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=4&amp;sn=fa134c2331fb054b217310dadaa66d00&amp;chksm=bf2047190bab9716998bc38ecc3451d85135c90be4dbfae48fd7e76837a172783458593178f2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：什么是 Sharding? 之ZeRO 优化（Zero Redundancy Optimizer）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>还记得小时候第一次看到《西游记》中孙悟空遇到一堆妖怪的时候，都是拔出一根毫毛变成成千上万个小猴子，把小妖怪都分给每个小猴子，这样大大缓解了美猴王的压力，但是也可能会增加孙悟空赢得胜利的时间，需要等这些</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=5&amp;sn=a6b326f587bf900a7b6e771ef2ea83c5&amp;chksm=bfe889c5c50a1f5e839fc052e93b89380fa9efc0322254fd722ad44d9e58c1f31876aafb6d1c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
