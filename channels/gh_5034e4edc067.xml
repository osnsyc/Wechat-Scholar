<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    






























    <item>
      <title><![CDATA[DeepSeekV3带火大模型infra，入门看这篇就够了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLROkF38B0FVOMyI1kL03FOU7UPR8PkcicVPy8xUhpTWScyHt6xbibeIzykWXpt4tkkRnaTJsog4UPw/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：真中合欢地址：https://zhuanlan.zhihu.com/p/10091011992整理：包包算法笔记为什么会有这篇文章：虽然工作内容不是infra，但是我比较喜欢研究训练方法，魔改训</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=1&amp;sn=85fd17af9ca8ebb9c4d7fd1a880b255b&amp;chksm=bf9a6b504fa03159ea1a34fcf7b00366176d8ce6a0c5cab021084a8b1988d29eba8db16fd336&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[《大语言模型》：人工智能时代的知识盛宴，大模型中文书籍震撼发售！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLROkF38B0FVOMyI1kL03FORDTOtpGv8DRqKWxvqBzZKaj32eHdUgib4ibCMSO5uWj0y4QibZkyShGWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>为了推动大模型技术的普及与传播，经过数月的大量修订，由中国人民大学师生联手撰写的《大语言模型》中文书籍正式出版。作为该领域全面解析大模型技术的中文著作，该书将提供大模型技术的权威介绍，注重为大模型技术</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=2&amp;sn=99959fe43ac0508fcb2ba71e7d6cadab&amp;chksm=bf391d2031aa800c0d4ffa510097a9cad683223443f17909c81117a2a205539a616a016a0338&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[5个开源RAG框架对比]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVdb8ibypmfibEag2TgJcQNA1vcgSkfGMIRPbVJVZ0nMzJ00fX58a3j9AFqGwQ1MplQVgCr1GxwfjibKQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>还在为RAG应用开发头疼吗？别急，今天给大家推荐五款完全开源免费的RAG框架，覆盖自动优化、多模态处理、本地部署、生产环境支持等多种场景，助你轻松搞定RAG开发！👇1. AutoRAG：自动优化，省心</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=3&amp;sn=eb957a44db82b53d98b06cebf1a9469b&amp;chksm=bf07be84220dbf39a6e58c4c4b5d6390325573257a747bb2b29bd99266466c9866e09e9abae9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【多模态&amp;文档智能】OCR-free感知多模态大模型技术链路及训练数据细节]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGAtwHQ0Csm6ibvCBXW3M9nDbxzWuVPznMceOiaDPZiblC7M5jJ7rPurKOCtG69RsN4RBDSd6Sevnf4Bg/300?wxtype=jpeg&amp;wxfrom=0"/><p>目前的一些多模态大模型的工作倾向于使用MLLM进行推理任务，然而，纯OCR任务偏向于模型的感知能力，对于文档场景，由于文字密度较高，现有方法往往通过增加图像token的数量来提升性能。这种策略在增加新</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=4&amp;sn=80c2b79008a032b943561d8679753321&amp;chksm=bfd159beb89bedc03eeb29b6c52fa295a98e206f51fa72b504defeff1b15c92a1121cc7a64db&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[千问LLM：什么是 Sharding? 之数据并行（Data Parallelism）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这次我们详细介绍一下 LLM 中的 Sharding 技术，中文叫分片技术。为什么需要分片？因为想要加速训练或者因为LLM参数过多导致不得不分片。那么参数过多的数量级是多大，我来给大家简单算一算。假如</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=5&amp;sn=13b9888bcf2f8afb209c4250f4f9dc44&amp;chksm=bf6c43278dd0377169d15ad131bb1067aa2c3b9e047535649f072e2c9372e277a1ca2bb7342d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[硬核！实现千亿模型训推全流程的LLM开发利器！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLR0wpDWC4mwRhDr9hFWrqSoj1uLSNEJsVJfZNb35S9vK22f3pM1zR4MJMUFziby5nq22Fciacaiaecg/640?wxtype=jpeg&amp;wxfrom=0"/><p>背景与简介大语言模型的快速发展对训练和推理技术带来了更⾼的要求，基于飞桨框架3.0版本打造的PaddleNLP大语言模型套件，通过极致的全流程优化，为开发者提供从组网开发、预训练、精调对⻬、模型压缩以</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446832&amp;idx=1&amp;sn=bdc05dc7f2ed832eb2c95fa24727fdd9&amp;chksm=bf0a7fd66ced4e9a9768ff8059559fe9059f83f8c5bd314f06accea21fa468932b3bf1106f36&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 30 Dec 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[我与vLLM的2024：清华大佬的vLLM开发之路]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLR0wpDWC4mwRhDr9hFWrqSmRCW8kqICx8StlkO9DbMlpCkqofan4lEhgxFKk4orCsxBicpzQrnceg/300?wxtype=jpeg&amp;wxfrom=0"/><p>我与vLLM的2024,作者游凯超https://zhuanlan.zhihu.com/p/14430956145编辑：ChallengeHub楔子我与 vLLM 的缘分，还得从五年前的那个暑假说起。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446832&amp;idx=2&amp;sn=9df093155533ed2a468bef7825648ada&amp;chksm=bffd5da451fdcbef5b411cb83b0ea2d09e2382628713a4770a93934b05f7f19d2997b583d2bf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 30 Dec 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2.5技术报告解读：18万亿token训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic0bEWUiaNibqDMxj3ibC8q4WDrAgVHXgbcYZVCM9EqVyH0ia49qBibdjGhIMu8j5BFxwflj5EctawlqH5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言大语言模型（LLMs）的发展日新月异，每一次重大更新都可能带来性能的显著提升和应用场景的拓展。在这个背景下，阿里巴巴院最新发布的Qwen2.5系列模型引起了广泛关注。这篇技术报告详细介绍了Qwen</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446832&amp;idx=3&amp;sn=0ad5fbc44e90611f4f45affc9eea8e9c&amp;chksm=bf255a85e7681af55fd1d492a354fd4e04bc45045c6b6de659cfc30bf4318f7836930f4ff680&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 30 Dec 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[精读DeepSeek v3技术文档的Tech&amp;Soul Seek]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/yToxjhYT5ibazsnejGIKQYMS0klsX5yVt6LpL9BRFrZFMXAx78xibIialjpFpOQRyZ0BtTB40iaic0OcMhTPDbF9HUg/300?wxtype=jpeg&amp;wxfrom=0"/><p>2024年12月26日，DeepSeek AI正式发布了其最新的大型语言模型——DeepSeek-V3，直接在外网刷屏…每秒处理 60 个token，比V2快3倍！MoE架构，6710亿参数，激活37</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446832&amp;idx=4&amp;sn=52430883c6c7c0f84d1de14179854347&amp;chksm=bf4453da567ea231eaa3926ff7c324214e0ec584b42d2d70dc78281470c3cffa206616a1b438&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 30 Dec 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Building effective agents笔记]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/QLDSy3Cx3YKyUY7toUQSEYMbASsgib1lmmnwI1bvPjud8QnvRJrwZD2fmkU9OdXlkmLYlxIu8ZTHFwWKm8PE14Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近阅读了 Anthropic 发表于12月20号的一篇文章《Building effective agents》（https://www.anthropic.com/research/buildin</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446832&amp;idx=5&amp;sn=b89ea361a159254fa7f5d73d5e783327&amp;chksm=bff2e1c1b6c424adffac265343e71191ba2d557c57860f4893edc6ce09978bb60290ab8d8b0d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 30 Dec 2024 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RAG最新进展FlashRag! 复杂场景下高效开发与评测RAG框架FlashRAG-Paddle]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLR0wpDWC4mwRhDr9hFWrqSUO1b9ia5Yw6gsS31a0W0C9CEzgrSPRWZUcywksRiaKC5icOyu6z6XxnTg/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research作者机构：中国人⺠大学高瓴人</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446820&amp;idx=1&amp;sn=f72b64a679321fa5017630eb50b708e9&amp;chksm=bfe3f02610f871f3858c895fad29ad016db38956016cb06ccca0728e4acbbb69e178a14f362b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Dec 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[雷军挖了个95后AI天才少女做大模型，开出千万年薪！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIBz0g3En3bx5zQg8MQojp6Isn7Iw8vEZobPibZs3aoKgdt2yeL7G4UVHxsfLbMCKeaQghygqgbgmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源：51CTO官微、科技每日推送、第一财经雷军，亲自挖人了。知情人士称，雷军认为小米在大模型领域发力太晚，于是亲自挖人，重金招募能够领军小米大模型的人才。而且雷总已经初战告捷——帮小米赢得了 Dee</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446820&amp;idx=2&amp;sn=da17d7ae78273ecd5c9e747126bc0267&amp;chksm=bf86170c298e5f0dd2009653efcd81fadc6dae782e1947cbbd3f6f179cf6aa178633ac97a0b4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Dec 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[万字长文梳理 2024 年的 RAG]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/tfic1yF9PPI87NpcpWGkSJZWxpDicQeaicFue24dvpfsGO547VmaXW0aBpsnVDcctrK1LibDYpQJhJicOyTesCmo96g/300?wxtype=jpeg&amp;wxfrom=0"/><p>在已经过去的 2024 年，RAG 的发展可以称得上是风起云涌，我们回顾全年，从多个角度对全年的发展进行总结。首先用下图镇楼：对于 2024 年的 RAG 来说，有一系列标志性事件：关于 RAG 的争</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446820&amp;idx=3&amp;sn=7352659c16db623d7d8c99bcd139fd37&amp;chksm=bf5c61a04c618ef33bf79dfa92470e0716bff9c41665724b7ca0e430c37e7f850d3bb9c7d809&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Dec 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文带你全面了解 RAG 核心组件]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVc6RsobsfWDlTAK4GYysQtWqy6OSkaHJibiclt056fNj8ZKpY8RrFibwEuwslP6PA0M2ib1GibjtsU4dgw/300?wxtype=jpeg&amp;wxfrom=0"/><p>检索增强生成 (RAG) 流程正在彻底改变我们与大型语言模型 (LLM) 的交互方式。RAG 不再仅仅依赖这些模型中预先训练的知识，而是让 LLM 能够实时访问和利用外部知识源，从而产生更准确、更相关</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446820&amp;idx=4&amp;sn=8d1b0a4322552a6500618c6d262fc85d&amp;chksm=bf2052c146e4482785e5a2fed092ec991528cd5e9af2263acaac8ab721370326529525ea05e4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Dec 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：AI界的“节食”计划]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>01—什么是Dropout?先从概念上理解Dropout, 想象一下，你正在参加一个宴会，面前从左到右摆满了各种美食，目标是吃到尽量多的全部美食。你会怎么做？你肯定不会一直吃一种美食，停留在那里不走，</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446820&amp;idx=5&amp;sn=1c33faaa8d54560e0cdc7310b8a41072&amp;chksm=bfb5caa370d6e8984647c99d94126a05f9b45586b08fbabb56b1a358c4ccd6ab572704f28456&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 29 Dec 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型存储效率太低，占用空间太大？推荐一个开源神器！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK3PjYicVI3JQYOBSjAtTKntOEYPawUQd3EZTvlGKfH5xibDGfJ0O5mHEANOENkaEsoN9uTCU9E3iauw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型工程技术的迅猛进步，提升大模型训练效率已成为推动其发展的关键要素。训练效率 = 训练吞吐 × 训练有效率 × 收敛效率，其中，训练有效率的保障离不开灵活且强大的模型恢复机制。据悉，Meta的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446801&amp;idx=1&amp;sn=41423b6c42f29553ab4f34fc30b01eb9&amp;chksm=bfb65510c5415600c44be762334e08051de5bd404515280e7a7e45ae73ec76a6ef10194fa9d8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 28 Dec 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型的基本功]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIURkEnvhgvAZACdIicTK4TtOUC093l7xjQrpru5GeT0uQ9298wUghH1jmZtPBgXCs5ffl4lyO0DoA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Author: [ybq]Link: [https://zhuanlan.zhihu.com/p/716344766]这篇文章给大家推荐几个大模型的练手程序，也就是所谓的“基本功”。先问个问题，除了 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446801&amp;idx=2&amp;sn=79c44d2a883d48beee7b29857d1becad&amp;chksm=bfdf0110465b4713b7fe29128e978b72b1907fcb4cb98daa3b247ed3ce8c9f95fd112405c847&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 28 Dec 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[深度学习工作：从追求 SoTA 到揭示新现象]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLR0wpDWC4mwRhDr9hFWrqSJFjgIpKXKrhIAhLMaLGqAseREMibsZT8SduEJLLwLNRL8GN6azbuYfg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨黄哲威 hzwer@知乎来源丨https://zhuanlan.zhihu.com/p/14170281797编辑丨极市平台导读 本文主要讨论了从追求模型 SoTA 到揭示新现象的转变。通过几个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446801&amp;idx=3&amp;sn=0415d20d347eb29cae9bc7de5621dc16&amp;chksm=bf63476997deb6df0c1a993fcc4c88d397345295d78533a4a24b77ee72acfa5fccf79a679bad&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 28 Dec 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM模型微调】LLMs-PEFT[微调]-QLoRA总结笔记v6.0]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdAGjG6CTCktBa8hUfec1MISxXE7Yvktanp4iaCxgnnEBA0OBfxjop6WPvprmxm29mDJy9nbNAAbxzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型微调第六篇，分享论文QLoRA: Efficient Finetuning of Quantized LLMs的解读。主要内容有论文解读(提出背景、技术原理，细节补充...)</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446801&amp;idx=4&amp;sn=20b3b45033ca29d0fc6cf31d330119d9&amp;chksm=bf439bb3bf853c9393bc3d578c0e01d179d74abbe07f8e27c25d0451da67849e956894624325&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 28 Dec 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[75k，确实可以封神了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK3PjYicVI3JQYOBSjAtTKnt3Nic3CIVCJY9a6e79AlHmWxfqUz7coAfNHXQjJo6Ch8z4iba2330zJow/640?wxtype=jpeg&amp;wxfrom=0"/><p>因ChatGPT爆火许多行业未来发展不明朗，技术人纷纷想转行、跳槽到前景光明又高薪的算法岗位。（算法工程师的薪资在各个技术岗位中显然是最高的，更多技术岗位平均薪资详请见下图）事实上，哪怕算法团队申请和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=1&amp;sn=ca6044b328b761f40f44a4187892fd08&amp;chksm=bf9eadc839693c4ddf1d6c26a8aeaaa6f0e2d4a517950957156af39215dc1dd57360e6142ca6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek-V3发布：编程能力超过 Claude Sonnet 3.5！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVdqqjI6LdvcdNQiadVe47oVS7fqG5Voyor5j72RQdJMnwCvJc25pY48Ue4exUpK0ALI1B8Wun6SibicA/300?wxtype=jpeg&amp;wxfrom=0"/><p>备受期待的Deepseek V3终于开源!这款全新的AI模型在多语言编程能力上取得了重大突破，其在aider多语言编程测评中的表现，甚至超越了Claude3.5 Sonnet V2等竞争对手，引发了业</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=2&amp;sn=69d411ac35b88bccad70201bff04f95d&amp;chksm=bf59696621843a30fd51317a3a8a71d2be0a6f35a1a48544c0295474bb0ddd51873e466335e9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年大模型总结与展望（技术上篇）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGy058d86CodWtNHyhMPrDabq3Mguv2jvfgCDyqiaaEOM0ibIjzOs1LAwMEEjdHLPTcoiaTFG1aXGBKxA/300?wxtype=jpeg&amp;wxfrom=0"/><p>   本文参考了信通院、智源研究院等众多机构、AI行业大佬的观点，再结合本人自己的观察体会总结而成。    2024年是AI时代迈向一个新阶段的开局之年。身处变革的洪流之中，我们见证了许多激动人心的技</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=3&amp;sn=cac20f9af8626b7c58b990645128761f&amp;chksm=bf48e449f581672916f3de3c43ec6adfd8767f10d21648ac543e788083a36f28b2173cd78b8f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[让Agent"少说废话"！打造高效的LLM多智能体系统]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah1aGlib8oybp7QdEiaHpnVytEDsHv5dA5HrWFprcbXybOhQhdvK625YQ68cXkiaF4mmVO5ZGrLoOX6A/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期，大语言模型（LLM）驱动的智能体（MA）取得了显著进展，集体智能表现出超越单个智能体能力的优势，主要归功于精心设计的智能体间通信拓扑。然而，现有的多智能体系统在性能上的提升是以大量的token开</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=4&amp;sn=ff4c3f405a130c3b56b021c766534d39&amp;chksm=bf23f271f89d9ad3c90080d7d8bad26ce0eecd5346e91ac554464c408d051407a34ec136da73&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Scaling Test-Time Compute：向量模型上的思维链]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/3EjVEqjYF3IjMoyELZt7ZKRTgsuY0geiaCjt1NrPNUzeicM9m4CJVGf1h6F7SwI5BIl5XWia0gevsDOWoyRAia5nnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>自从 OpenAI 发布了 o1 模型后，Scaling Test-Time Compute（扩展推理时计算）就成了 AI 圈子里最火爆的话题之一。简单来说，与其在预训练或后训练阶段疯狂堆算力，不如在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=5&amp;sn=d869619ec291338bff4b650a8b64c63e&amp;chksm=bf6ff4d796a2654df6dd501430cf086e93734b8c74f8d1b8d153e77fb9dd634d084be9730ea0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[全是细节｜大模型SFT的100个关键点]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK3PjYicVI3JQYOBSjAtTKntw85EHFia7QUmgicOMe8C7KF8wAV9Unb2bicJkYvnj094z97icxcVY77NCA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：ybq链接：https://zhuanlan.zhihu.com/p/809229182点击底部访问原文直达这篇文章介绍一下大模型的 sft 如何去做。相比较于上一篇文章介绍的 pretrain</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446728&amp;idx=1&amp;sn=370bbcd9d2e49aa3e60447af176eaf20&amp;chksm=bf91d38ce13b4e1e1ac5b58833775e13c125aef438f389b98d35557d433af4f8d8de5ea07aa0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:28:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2.5 论文精读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxvOklibm1qAjC9rChOcqwYvMJqAR4phFsQ9PTzcfMiaEqib7VZknyL5Fyic9NwESa8wGBDRO2oUR28WSw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言不得不说，Qwen真的是太卷了，目前看来其基座能力已经稳居开源大哥大的宝座，并且与大多数闭源比也丝毫不逊色，估计很多公司的基座团队已经在被 judge 训基座的意义了。Qwen的开源架势一如既往的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446728&amp;idx=2&amp;sn=3b75039f3fd0352ea4ce41857c7d8fbb&amp;chksm=bf9775b5936590442b4ad0a5a61c02c861bc12a21a49b7898cab45cf985a3f526709f9d68556&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:28:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[技术人该积累什么，才能避免被AI淘汰？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5l8uuaWFH5xbhu792Ne2uhKvh3IncadZ7JAoicvBicy6P9iboQSD2536fRNxxuOaGZSOjAkyE5KWk1iaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：https://www.zhihu.com/question/7440697804/answer/61212648228即使没有 o3，大部分的技术人也一定会被淘汰，这就是当下程序员圈不可避免的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446728&amp;idx=3&amp;sn=e72c46c8023b088158e45b2fd0520f3d&amp;chksm=bfaaf7c63adeef69e3206671b4f9f881f06f8d7eb16b2b8ce63291ed1782f9e67f493c4b4e0e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:28:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[右脑科技招聘AIGC算法实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK3PjYicVI3JQYOBSjAtTKntnsNiaFBNJP9xIJkhE1YCL5Zsqvgu99Q2iawkpL7qUD250JVF8os7hkog/300?wxtype=jpeg&amp;wxfrom=0"/><p>     【岗位名称】AIGC算法实习生【薪资】350-400/天【工作地址】海淀区中关村SOHO大厦【投递方式】careers@rightbrainai.cn，备注实习时长+到岗时间  Hr电话&amp;微</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446728&amp;idx=4&amp;sn=799617b0250de9b4fdc1000c1662b67c&amp;chksm=bf8ecb0e06e4f83f8d70ea954b8823fab90e97f26ca8de67674372be6efba2917f09f4c71f8f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:28:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态RAG杀疯了！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIZdlVnsVqPVqcScxQRkwBnm3WFSWKp7ZGrvUDFtfOxzGFaCEj1Wib2K5sN98ohbh8DVBdHGYOdzHQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>2024上半年是大模型的时代，但随着训练推理的深入，大模型也逐渐暴露出幻觉问题，
一些回复与事实知识不符，研究落地面临极大挑战。于是，多模态检索增强生成（mRAG）技术应运而生。近年顶会更是激增了一批</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446582&amp;idx=1&amp;sn=88d5342db4c5da3ceb1f30f60222a20b&amp;chksm=bfd7dbf1a5b95fbe634cc65071f0dbfb634d15c46d7430a80151112e6f7765ef04c2550837f3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 02:20:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM 又一年！！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lDrFs3QsIxrEGeoC2uqZbJXIrsmOD6TXVFLbkHjsBiaTDoVOIVgefdBZJ1NEDqo8ImicaPDvpMaL3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>LLM 的第二年就要结束了，如果 2023 年的主题叫“从零到一”，那么 2024 年的主题无疑是“颠覆认知”。知乎：https://zhuanlan.zhihu.com/p/13803218651过</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446582&amp;idx=2&amp;sn=aad0525599c3b5b340adc8cb728d2e53&amp;chksm=bf99cd22204f7ddf73c9003cbbad7e82b2c62de9aed8c62fe25cdd05f445d3bfdb48b3cbc626&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 02:20:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLAMA3 论文精读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxutIeo0mRMymBic1ke0rHeJfj1fnCGvRiayscrjx3ktP0a014LyNERLeXc509OARs7xkJp9HzEzZn4Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言最近对之前精读的论文进行梳理，发现一些笔记还是非常有价值的，稍微改改发布出来给大家看看。LLama3是几个月前的论文了，但是每次精读还是有所收获，本文将一些重点的内容加一些自己的思考和实践进去，对</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446582&amp;idx=3&amp;sn=430f50e147371cfa181b31d50555352f&amp;chksm=bf8a21994e40080788d1eb028ada26f4d0eef5c60ede4b370111d3e0142e9ff4d38f43bcaad6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 02:20:40 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
