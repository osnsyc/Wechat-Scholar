<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AINLP]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AINLP公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM67GK57pic5p6OCgaEI1EzCbicqVCKRibvxxIvF2Nic3mxJMw/132</url>
      <title>gh_5034e4edc067</title>
    </image>
    <item>
      <title><![CDATA[2396部黄片，一片罚15万，Meta用BT偷黄片训练AI，遭天价索赔]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5fknb41ib9qFqia0ibXumtQcnIK0j99iahYhEgcjAn9L5c5SIz3s7lMW3MMjwSxyP51L0icRW7reRWzXCcUruJjOHVg/640?wxtype=jpeg&amp;wxfrom=0"/><p>你有没有想过，Meta 训练 AI 用的数据里，有可能不只是维基百科、小说、YouTube 视频……而是你在某个晚上偷偷下载的成人电影？你没听错。是色情片。而且不是三两个，而是 2396 部！就连提起</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449837&amp;idx=1&amp;sn=a3dead2637abb068fc825522812d4d1a&amp;chksm=bf9e51fcfcdc27e06fc721fd2fa0173e433d5d4946826b74e09d64ad4d57e5a5691637221362&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 19 Aug 2025 18:25:09 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Multi-Agent 多智能体架构解析--DeerFlow]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/3o3xicT0qOibuqWibn9llhF1rnBlWzFgSicoX0ydX22WqVgzSlgBloRsICPQ6wRkY9bC6biaecTz84eotwVnWFAMcAg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在人工智能技术快速演进的当下，Multi-Agent（多智能体） 架构因其对 复杂任务 的高效协作能力，正成为驱动 AI 应用突破的核心引擎。这一技术的爆发式增长与大语言模型的局限性密切相关 ——</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449837&amp;idx=2&amp;sn=6a485c57c926843d04bcecb604d82b1b&amp;chksm=bf29954f6d89978c4bf3310ce28046925fd38a1e4afa8b69312efba54513c5e8cc500c95548a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 19 Aug 2025 18:25:09 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[13小时速成多模态大模型！附教程]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKLMlyddyQVDPCTicSrGCszMQ9eSBeLZOvEGpeRPwVpFoN7WsM7eDUt6sPArZr7TPvIMf4gCjdfibEw/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近AI圈只能说是神仙打架，太卷了！某书两个月内接连开源三款模型！最新开源的首个多模态大模型dots.vlm1，性能直追SOTA！牛哇牛哇！想进入这AI最卷的领域，没篇拿得出手的论文可能连实习都找不到</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449835&amp;idx=1&amp;sn=3e7f2a8e9ed8e6741e4135b2e5fdbdb7&amp;chksm=bf5175a6dea75cf7caaac805b25e3f1721edd74a57a1d5cefdeead6eebcd8309c3ad843706bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 18 Aug 2025 10:06:20 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[几行代码改个reward，让RL效果起飞]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuwxNQo9z6icmNXwibPQ15aWWIMlR2ahYNQdUQGObzAYLA4hUQmHpF4UicEmCYtk1hqfBlHUJcVfQfkEA/300?wxtype=jpeg&amp;wxfrom=0"/><p>把“Pass@1”换成“Pass@k”，几行 reward 函数，7B 模型就能在数学推理任务上反超 GPT-4o。听起来像标题党？今天带你 15 分钟复现这篇刚刚出炉的 ACL 2025 论文。💡论</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449835&amp;idx=2&amp;sn=b6c4c5a195af603cd063ca0a7d30d4a2&amp;chksm=bf63e27dbff62bb6dd9c3e4f8a80d27fc0b9ba93c977a37522d2fb661f5b44a5237c97e0829b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 18 Aug 2025 10:06:20 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[纯干货！关于SFT的22条经验分享]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSI1f8xMChIjpbCq8hX62Qu9UarVVgwjTKq4wgKI5ZRJ2cicjIt88JFsrMW1icxspPVgxY4o47j1ib1vA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：王宸原文：https://zhuanlan.zhihu.com/p/49398269658 （1）为什么会有SFT？预训练、SFT、RLHF是大模型的标配。预训练让大模型获得了通用能力，SF</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449834&amp;idx=1&amp;sn=6ff9c2598f8aa6a48970c6ba98fde51b&amp;chksm=bfd936220464bd0cd3ef555596d62aea2dbf38bf440d46d00d9b9f1f3efd7cfc57fe22065ee3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 17 Aug 2025 21:18:16 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[聊聊AgenticRL的算法设计以及工程化问题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSImRNOz2XXZvibzNGyFh433ItibLUVX1ZJubrBuA3yakXfp9CUaXnbR8MOthLC0rFcoePJwcLteEl0w/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：紫气东来https://zhuanlan.zhihu.com/p/1913905349284591240 在前几期中，笔者重点介绍了通过蒙特卡洛树搜索、过程监督与结果监督、强化学习来提高 LLM</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449817&amp;idx=1&amp;sn=4c838b2445e3f79093bfe81475ed62b0&amp;chksm=bf537de5e65bd59dc29cbc7a7f2587060205878fd08017e5aa15db20f84a43ad2e0cfd8e05a7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 17:23:30 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[REINFORCE++-baseline is all you need in RLVR]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSImRNOz2XXZvibzNGyFh433I62affl2s2o6gtQB2icibahB9MSslJQiafCULZEMticzpYqF7DkWsHOVN1Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者: 初七123334链接: https://zhuanlan.zhihu.com/p/1938824375903183527英文版 https://medium.com/@janhu9527/re</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449817&amp;idx=2&amp;sn=94a9e7ac67507e2a023fb819373d3f4f&amp;chksm=bf561fcedb857507a8bc5cc101e1e57128a464075f6a2c00dfd3cf4aa18bf15308f7f6c75005&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 17:23:30 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[GPT-5波折超乎想象！奥特曼连夜回应一切：4o重新上阵，团队紧急补救]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJty5hBic6rg0lxhPEkAk6IWGMDTNpSbnPadPT3PJmmc7Sgia5V0uQPHF5xsqBOoLPqUic0eDoeXTLsw/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源 | 新智元编辑 | 定慧 好困GPT-5发布会，大家都看了吧～感觉现在整个世界，都在讨论GPT-5。网友们都吵翻了天，直播的时候跑分图都能画错，这也算AGI？更有网友哭着喊着：还我GPT-4o！</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449801&amp;idx=1&amp;sn=d3bc76ff1b1d71acdef8927f33ca9714&amp;chksm=bfba7ae2062fa7594e7446ffd63beaba47b9ef9987cd44e643ccfda6adcaeb55d17dbb20a9fc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 22:54:42 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[深扒RL叠的一堆trick，到底哪个有用？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuyVGGkYzXp4iaRFOYBddw0tn9DIOyGpbX50QbwgCLvo03kROyqOL5bKqJPjR1n9VExELIs1uZ6q8PQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>原文：ROLL Future Life Lab《Tricks or Traps? A Deep Dive into RL for LLM Reasoning》地址：https://arxiv.org/</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449801&amp;idx=2&amp;sn=280aac1879a79759fd0c122d0f11b40b&amp;chksm=bff61279b746a59db1ed25dd643217e44707db2211f03ecefe760f754a42127b987556c3bdae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 22:54:42 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[训练时显存占用估计（上)：你的卡玩得动7B模型吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/OG6cPvxbL6yWdsm6iaa66rRic3ngsyWLvyCNPpY1I6eoXHibrk6Cbtj3sf29mFRPh5qAxmFPOqoLxJpP1xF8icrPqw/300?wxtype=jpeg&amp;wxfrom=0"/><p>1.基础知识模型参数数量：提到大模型时，我们常说的7B，14B，32B中的B是Billion即十亿()的意思，表示模型的参数量。比如qwen-7B意思是有70亿个参数，qwen-32B意思是有32</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449801&amp;idx=3&amp;sn=e0f6a01b2f32591e67cd75002ddf9952&amp;chksm=bf2e2f109e2ffd43f5ce97c8421a33251863f82926f9b5bc939015bf7733284e7f294d63117f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 22:54:42 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[GLM-4.5：三体合一的开源智能体大模型，附GLM4.5技术报告英中对照版]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIibsj6PkGuDdWNGicnwkHIibfew5F61HlumhtFlEXN3yPa7G0dQ0bwjsdfxojL4FLI1sHy2eJXXUImg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在追求通用人工智能（AGI）的道路上，智能体能力（Agentic）、复杂推理（Reasoning） 和编程能力（Coding） 是衡量大模型综合实力的“黄金三角”。而最新开源的 GLM-4.5 系列，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449796&amp;idx=1&amp;sn=1455cfdbae8bdfeeb451758aa3cd1204&amp;chksm=bf6ddbb950205cc3e9dafd2507a184f485ae99adc933348a436d6b74069eb137dbea856d141e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 12 Aug 2025 14:46:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[在LLM中使用sageattention]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/OLqd64H6CmYg1jjhRJgiawzHW4wV8rAiceM4aFafxhHV9oegOT7ia1NE3k7Wwnlful3gELSoibyHuzxpnc4Aoz2LhA/300?wxtype=jpeg&amp;wxfrom=0"/><p>基础介绍SageAttention 是一种专门针对 Transformer 注意力机制进行低比特量化（如 8-bit、4-bit）优化的算法库，目的在于以更低的计算资源、更小的模型延迟，同时保持精度与</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449796&amp;idx=2&amp;sn=8269d60dfcac3b06c042434b218f4b07&amp;chksm=bf627b74c213acc7ee3ce307d2e0238aa81dab658e4583bdb0ea41ba21997589c22c62cdcdf9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 12 Aug 2025 14:46:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一文搞懂模型性能瓶颈之计算瓶颈与带宽瓶颈]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/OG6cPvxbL6zjH5hUTajqibONqs7jQoMRIFySp2AiakBEicIDdYZfkTaYJnIu8qcibvoZhhuoXFuc23v2QC7UXMnEkA/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面上周在投机解码之EAGLE：轻量级草稿模型实现3-4倍推理加速一文中，我们提到了LLM在推理阶段是受内存带宽限制的，即所谓的Memory-bandwith bound，带宽瓶颈。今天我们就一起</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449796&amp;idx=3&amp;sn=7eae0f18c7a4c2b669dfb616d3dad782&amp;chksm=bff0495898bfa6e47a2c4748a605e9a66786455081db2284a75d24c6e65a8dc377cb808ffed3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 12 Aug 2025 14:46:36 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[熬夜整理！!《LLM》.pdf]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLEyJic3l6pe5SdQhIqibEBDVzwuFMY7yYQNrkSwLPayjHe9WBNjCMEdsK36tKlQQ3WcwpE7lcdh0TA/640?wxtype=jpeg&amp;wxfrom=0"/><p>北航计算机硕士，收到3份大模型offer，薪资86~94W...？家人们，大模型方向这么火爆的吗？是真的，不少人还说这个薪资肯定少了……具备大模型技术的专业人才在市场上稀缺的狠，人手几个SCI一区二区</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449782&amp;idx=1&amp;sn=3caac1543f331b50ffa79a9eca1c6138&amp;chksm=bf45c726897ab5426048f30bb0c42bc9d9bcc6115897c73dbd467e210d756eaf3fcd12d31c0b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 11 Aug 2025 02:18:49 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从推理轨迹反推：gpt-oss背后的训练策略]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsHIHXFumLcVpEZic1FIGP3rOoqpAOnbXMj2wNicE9sh3BGeJEtLBUibV0U26lJj47ljnA9lhplSyecNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：王振凯、宋志学OpenAI 在 8 月 6 号的凌晨开源了两个 MoE 模型：gpt-oss-120b 和 gpt-oss-20b，并且原生支持 MXFP4 训练和推理，gpt-oss-20b </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449782&amp;idx=2&amp;sn=c2d7db93b745e766573703a8a2ff3db4&amp;chksm=bf53dbcd4823b35c21dff179641e051284ddb04a1865ae35097864e17e517f081d311b520bf2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 11 Aug 2025 02:18:49 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ReSearch: 用强化学习让LLM 学会边推理边搜索]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpvQVATbR4yuvY0qlYKS8VeE8ickcJlGZQu9KcbyTZJtaUUMH43Bql1ic7REiaWSxtWfMhplLibvR9pImg/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 背景3 Research    3.1 强化学习    3.2 推理链设计    3.3 奖励机制4 实验5 讨论参考文献1 简介    在大语言模型（LLM）飞速发展的今天，“推理能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449782&amp;idx=3&amp;sn=e16224c19f82db11e43a007c8d16b3a6&amp;chksm=bfb81dd1615cb78feb22fe5cdeacb7a07fd79367a67ec5ba8dc81ac49732d3c176ce8c65beb3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 11 Aug 2025 02:18:49 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[兔子蹦迪疯传，5亿观看！一段AI视频把全人类拉入虚拟现场]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJ1AECfc83XvD2CgeduUrN97zYic4QbmdhZc0FVAnbefSbd6ib6eHbXd4rhVvk7J7yvQScnMRrxQyrg/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源 | 新智元编辑 | KingHZ最近，一段萌兔深夜「蹦迪」假视频骗了全球上亿人真感情！曾认为自己不会被AI欺骗的一代人，竟然被下面这段兔子蹦床视频给骗了：乍看上去，视频里的兔子非常可爱，TikT</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449780&amp;idx=1&amp;sn=869efffc6a8b1da15c7f8a947923f38d&amp;chksm=bf4b368e2cf42ea1b5af3fe1ea44bfdc85499b3360a04b17b9f7b52abbd9ec1323414977fe98&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 10 Aug 2025 04:03:45 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[投机解码之EAGLE：轻量级草稿模型实现3-4倍推理加速]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/OG6cPvxbL6x24SEpL1rmVDExpMnL0GpvVdWpEc1wX0S9dvUFIABWy5x0YPJD1RicPoqTDI4OPy4UInbgx8CZBKw/300?wxtype=jpeg&amp;wxfrom=0"/><p>👆点击关注｜设为星标｜干货速递👆写在前面上周在大模型推理加速之Speculative Decoding/投机解码(下)，我们提到选择与目标模型同系列的参数量小几个数量级的LLM作为草稿模型，就能比较好</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449780&amp;idx=2&amp;sn=2d7b4dc322ad751969536b69bfc76c96&amp;chksm=bfc3f4072dd6b3a985af088d8f0cdd78c719b54b27c318c99bdd902fb5f9ee229a44a07459a8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 10 Aug 2025 04:03:45 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[推理路径的动态调控：让大模型学会“恰到好处”的思考]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahTUNhnnnBZJ0fVpBOXg3dlUGWPicKsu7eqNI6SFe5tyH1LGUEpNia9aPibDiavIBficz1dK1c9jwX7bJg/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前大型语言模型（LLM）通过思维链（CoT）提升复杂任务推理能力，但研究表明其推理路径存在严重冗余——例如反复验证或无效思维跳跃，导致计算资源浪费和“幻觉”增加。论文：Test-time Promp</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449780&amp;idx=3&amp;sn=5de3aeef26b8a586e1a956168b401ccf&amp;chksm=bf08acf1f9d827e1ecd0d53f8f78473972a3470092b1cae952500b2af4b9b448cd940fc20b61&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 10 Aug 2025 04:03:45 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[GPT5发布，毫无新意，AGI没有盼头了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuwptLasN6IXJpQzTZQdIgia4sbMbmQc2NzqrqpxiaBIy8xSztWf4rbxrJwPIkeVHCCkicYmcqfyjibvSA/640?wxtype=jpeg&amp;wxfrom=0"/><p>这次是熬夜把发布会看完了，看的时候越看越不对劲，满脑子两个字，就这？虽然GPT5把竞技场第一的宝座又拿回来了，但跟gemini pro实在拉不开差距。openai这一把完全是被google逼的，这个5</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449770&amp;idx=1&amp;sn=eafd879cdc65648911e496895e2ea2f0&amp;chksm=bf9df6f8df40136e7b069e4448e27106cf1a50f544f15d736b7732c38c75d03f172816daffc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 01:47:23 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型推理加速之Speculative Decoding/投机解码(下)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/OG6cPvxbL6yHyqhndLNmuDtQKkvZbNpUAf7qf2PrLgvbuXr0sPTWzuibhtr2VCU5ZprpnN6XpzW2icxwQf1picRaA/300?wxtype=jpeg&amp;wxfrom=0"/><p> 写在前面前几天，小喵在Speculative Decoding/投机解码(上)一文中跟大家介绍了投机解码的流程以及涉及的一些细节。今天我们继续了解《Fast Inference from Trans</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449770&amp;idx=2&amp;sn=641f68ef77ab21e26acd5bfe07181fa8&amp;chksm=bfce672c19ec455dab08e08715db2cbb9f33fe1d58823f504c5d39f1d2a6af5e97dd4b16e44f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 01:47:23 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刚刚，小红书开源了首个多模态大模型dots.vlm1，性能直追SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL7OOpicSQ2Vq6u0kBa1hgH5ibju9XAlp4AKjBM2MyiaiceqTOue8p4HicrNCT0rVnyHZUkk5Sv0uvlf2A/640?wxtype=jpeg&amp;wxfrom=0"/><p>  源：新智元，编辑：定慧【导读】擅长「种草」的小红书正加大技术自研力度，两个月内接连开源三款模型！最新开源的首个多模态大模型dots.vlm1，基于自研视觉编码器构建，实测看穿色盲图，破解数独，解高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449768&amp;idx=1&amp;sn=0e942d9f48d0d1716f03f9d8a6061259&amp;chksm=bf22e77bf2c8df61c97ade9c4700c23725f17be935026e6150af26b9d224380ef116721bf3d3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 11:19:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Speculative Decoding/投机解码(上)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/OG6cPvxbL6yExQ0IV1lKDQfcJicTqaMhDPEpHTShYc7LK5WlM6LCXvfq9aNN95vXq83NhrmdDCxghgszcSDiaH8Q/300?wxtype=jpeg&amp;wxfrom=0"/><p> 写在前面上周小喵在MTP in DeepSeek-V3中跟大家分享了DeepSeekV3中的MTP技术DeepSeek-V3 Technical Report[1]，其中有一个遗留知识specula</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449768&amp;idx=2&amp;sn=abd6f3dbe9a41d88751f4e037cb6c475&amp;chksm=bf1e6a4f3a616c501155eaa30a43cfb41d0b903a555a7be45d915fcfb24b552199512de95667&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 11:19:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里健康招聘LLM算法实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSL7OOpicSQ2Vq6u0kBa1hgH5kteTCWVjggvLbRMOb28K1DVCeRic94xpTw4NjI7wl7gg2m48vdTZEPA/300?wxtype=jpeg&amp;wxfrom=0"/><p>我们是阿里健康的算法团队，我们致力于构建健康商品深度理解能力、挖掘商品间的同品关系，并推动其在健康各个业务中应用起来，解决AI导购/搜索/AI客服场景的商品理解不足问题。1. 在这里，你将参与到商品中</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449768&amp;idx=3&amp;sn=0abb420a677b75621c0058d61893fced&amp;chksm=bfdd07624dc710ad87c94e407e5004bbf8d70406e838948cc39ea51d0e57da1e262d04e66c87&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 11:19:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OpenAI 最新开源的 gpt-oss-120b &amp; gpt-oss-20b 模型技术报告英中对照版]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLk1MOib4dRu7yYyGiaCqeXoVBQZ92QjdE2S9vyrKvYgUDicPw5ZpvRnbQ77ZNSBM5IGQ9HtI0yo89kQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>OpenAI 发布的 gpt-oss-120b 与 gpt-oss-20b 是首批面向开源社区、同时强调“强推理+工具调用”的权重开放模型。以下从性能、安全与生态三个维度给出简评。性能：小模型也能打•</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449757&amp;idx=1&amp;sn=d009f24a7bdd5007275c9af773d025e4&amp;chksm=bfaefa35839832bef9aa353984567586752ed8f832c89e890a424f20d18f98d840a8108cffc7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 03:43:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR2025|RLHF本质是模仿学习？新框架DIL在多任务上全面超越DPO，无需调参、性能更强！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKYcvP4PXHMnL9lSCecaBImXpzTh6Gw5cujwqjU13ia5qiaZLkIFRDBQRTJ6lsyAAfSZY5AfN4ZA2qA/300?wxtype=jpeg&amp;wxfrom=0"/><p>0.论文简介本研究从模仿学习的角度出发，探讨大型语言模型与偏好数据的对齐问题。研究者建立了人类反馈强化学习 (RLHF) 与模仿学习 (IL) 之间的紧密理论联系，揭示了RLHF在偏好数据分布上隐式地</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449757&amp;idx=2&amp;sn=bfd38949a9db7d1607ebf482836c422a&amp;chksm=bfc51934dd171f61a790b9f54f549923407d658e002b319b09341c6bb64469a933bca4ac36c8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 03:43:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[通义实验室-算法专家-对话智能&amp;Character Model]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKYcvP4PXHMnL9lSCecaBImByE7l2F3I2fZQ4Ly4OyQNUs2E145UvfZwOn2S8HzBHZsdn7Q4QTLZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>职位描述大模型为世界建模，Character Model进一步为人建模。对话智能团队，以Character Model训练和应用为核心， 建设 “有趣+有用” 的多语言、多模态类人智能体，打造了通义星</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449757&amp;idx=3&amp;sn=965c7100fe7ef6e5e092ea20537eaef3&amp;chksm=bfae20d17217e1d8a9fb935b3ec1c8833f704fcfa39a23affe8dc9873e0d82a4bb00edfc9a53&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 03:43:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[7步解锁大模型！被传疯的AIAgent实操指南]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIAia5kEicuQc7BiaibpFaana4Y6U04lbBttcZy6Z9Bp3icY9AalwsomKPaQajaUhTWcsyAZGiaWQnDDwtg/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍《动手做AI Agent》这本书深入探讨了人工智能时代新兴的技术——AI Agent，即人工智能体。AI Agent能够理解自然语言、生成回复并执行具体行动，它不仅是内容生成工具，也是连接复杂任务</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449736&amp;idx=1&amp;sn=f1e53b8add3519ab772c34bea3a3b192&amp;chksm=bfb76c4a54ac8ea87fa70ac4a8b31412b037a9d93a633fcaf0ece6636f9bae6e6e4f7a45437c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 02:08:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[对噢！为什么LMs就不能直接输出答案+confidence呢？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaTIDr5ysyqwicxLmemAalcxlmey01LTDthVibbUJjKdtGa7EmuIx5KvEulXIrEmciaDyIbicGLvpmRHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前语言模型（LM）通过强化学习（RL）生成推理链（Chain-of-Thought）已在复杂问答任务中取得突破。然而，主流方法依赖二元奖励函数（答案正确得1分，错误得0分），这导致模型为追求高分而盲</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449736&amp;idx=2&amp;sn=1d88693b5e5663d3a03ffb4dd4d1f136&amp;chksm=bf12d99ebf75def38782846cbb1e0e62d8af2afd14498c7c8c6979508c25b3905c888c535980&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 02:08:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[如何利用pytorch memory snapshot进行显存分析]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkMUBRBPHYNpK3c0B1dhRficnaMibmB8VxoPRCdnUhkrck3a7zwakOibVNKoSsRZiaYnhibIhhhuUSaP3Mg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天这篇文章，我们一起来看看如何使用pytorch memory snapshot，分析模型训推中的显存消耗。在阅读本文前，推荐大家先阅读这篇blog：https://huggingface.co/b</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650449736&amp;idx=3&amp;sn=11ca1a8c69a8be3cc1e8093ed376f302&amp;chksm=bfaed88a0768d5bfd962cb8860e29b51b3291bc2e5e2ca5802d13a0cfe95f8664b28a1b92440&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 02:08:13 +0000</pubDate>
    </item>
  </channel>
</rss>