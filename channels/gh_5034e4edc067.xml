<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    


























    <item>
      <title><![CDATA[原来阿里P8的工资这么低啊。。。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/icmWrEONNM8WEZGWlghyyR5gg9dY8agJ5kc1ibVdsZWFzj5608EUC0g2u9fpWCasFtxUG6JuiaXarKvDVVEz5ksXw/640?wxtype=jpeg&amp;wxfrom=0"/><p>原来阿里P8的工资这么低呀。。。曾经的国内互联网公司，无论大小，职级上或多或少，都有点对标阿里的意味，毕竟阿里就是之前十年的Top1，辉煌过，加上创始人自身性格也很高调，使得其影响了很多企业。P8在阿</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=1&amp;sn=a34e45b9d57a2b6bc491ac88935a7e13&amp;chksm=bf451f376dd84a934cc3641475d112fd18993ad8f81d91e84be6b74ed414b3c2511b969e5b84&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[从任务结构到世界模型：LLM 知道什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/37kWYypzzEfXicYH5IHM6xcJZWFa0cLQuKPudeLDSCU9zLDTzk8uibDFnkiaDeJeQV3EUEpRf2iaOHJXOovOGtPv6g/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，来自 MIT 的两位学者证明大语言模型（LLMs）能够理解世界，他们不仅可以习得表面的统计特征，还可以学会时间和空间等维度的结构化知识（该文章在本周的研究速递中获得了推送），表明 LLM 本质上</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=2&amp;sn=07742d5c142c9900f83f16137f873fea&amp;chksm=bf9f3903b2fbfc9cb74c19043ae40147ab8ba4e064838ec7cc3a39ec0fd4e8b23650456e3166&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[百度文心一言招聘大模型算法实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJXh19q8OiaAhadayBQS8rGyJGBIhK7yhkiaTAEvPXDbwnbhepZt8dQQyYkJqzy3teib5atic9xicYNUnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>百度文心一言招聘大模型算法实习生百度文心（ERNIE）团队致力于预训练大模型基础技术的研究和应用，在预训练大模型领域具备深厚的技术积累。文心 ERNIE 自 2019 年诞生至今，在文本、代码、多模态</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=3&amp;sn=ae33011c89d798e95817162bd7edcfe2&amp;chksm=bf8eb6726588b0d145ee027d1528609f53b9acd74cb3aaf433701423796909ca82d738b5484e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[使用opencompass验证模型效果]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgw4KQuYUIQckJMAco6AibX7rrAly6mYGBbHYY2icpa5bAeZVOg6FVVuWm9zibcGic3pNbs5RCKn9tJIog/300?wxtype=jpeg&amp;wxfrom=0"/><p>准备环境使用fastchat部署的openai api server模型官方仓库：https://github.com/open-compass/opencompass1、git clone http</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=4&amp;sn=f1311458faaa0c4542226ab8b409799f&amp;chksm=bfe2a42c24f4d08cd1e97300a0baa7a53c1490b634bb29d6856ed05785649d1b0dc1b5d85bb3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LLM之RAG实战  |  利用LongContextRetriver克服RAG中的中间丢失现象]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1SicnEpfXACBAIY398EiaP6B3ib5yoIUH14LRiaRtK7p0GicQvqds7JowdSHzQTLqWExQEJ0x2sp43YhiaHWA/300?wxtype=jpeg&amp;wxfrom=0"/><p>       人类和大型语言模型（LLM）都有一个共同的行为模式：他们往往擅长处理位于给定内容开头或结尾的信息，而中间的信息往往会被忽视。       来自斯坦福大学、加州大学伯克利分校和Samaya</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441454&amp;idx=5&amp;sn=64d2cc80c298a017a70c80237c43082c&amp;chksm=bfd3fd30704fd96117a4e1eb4484a80478650ff01f17c356d036ceba30fe8c92e96ced53bd7a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 22 Mar 2024 10:44:35 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[transformer再突破！基于Vision Transformer的视觉语言新SOTA]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLEibeP8JRtlhLUOZzJS3mxibsKw4plQy65F7vlmLAzjewxdTliaqvVhypfvLPWP729ZCUTpY0qTXw8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>Transformer 如今已经成为主流，为各种任务创造了 SOTA 结果，它是一种新型的神经网络架构，用于处理多种感知模态数据（如图像、文本、音频等），比如机器翻译和文本生成。我们邀请到哈工大博士李</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441398&amp;idx=1&amp;sn=4ceafbc5ce8a5d7e271d8d896727c2ea&amp;chksm=bf65e3d5afdd074fb3a9f6be8e1012199c5fa755bf74d269d6c3889f6dd4d66f5e3e90914a84&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Mar 2024 03:00:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[增量预训练baichuan-13b-chat遇到的那些坑]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/h4lbevcvkgxpEa1tBhkuFdyk35sT8KiaxzKjZ1soQ0UfI0ZxsxNlAmcjyrYfHbicCvtBuUNTEUKIfmVlAlhw6vNQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言资源单机两4090，如图在这里插入图片描述单卡24G，baichuan-13b-chat单卡推理需要至少26G，因此仅用一张卡，我们是无法加载百川13B的模型，所以，无论是推理还是训练，我们都必须</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441398&amp;idx=2&amp;sn=2854422b50ac020dbb44f8a941ebe3ba&amp;chksm=bf7c21a1548ce8a190bbe5be9c98b933f0b4e34920bb8cd5f5c9d87118b500d4a255a9a22042&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Mar 2024 03:00:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型检索增强生成(RAG)高质量报告]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/vtIvcrPJjh6LwXNicqj4G2tibibibAYyiaOWcrJibYgBSMSicXVKxeYx38A1oXz0fwxicU5oNkXbgPSo2JJTkNuyNZOD5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享一个来自同济大学Haofen Wang的关于检索增强生成的报告：《Retrieval-Augmented Generation (RAG): Paradigms, Technologies, </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441398&amp;idx=3&amp;sn=ba391dc4e131e7f280178aeb6affc321&amp;chksm=bfd719ea1c1f67983ece345e7416a4d11e6778f6893cce7f8f9f9cd7792fd05591fb97ec2ee1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Mar 2024 03:00:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[大模型的模型融合方法]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuwIlZeeWqxu6BzsNJhXFfLzict73Nx1QnDzNnqtpEQbkrpkLaEHgt6f4o588IkBIUg8ocgLhgyRhDQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天来讲一下大模型中的模型融合，并给出大模型融合的有效方法的原理和实现。模型融合大家以前用的很多，特别是在判别模型里，属于永远都能稳定提升的那一类方法。但是生成语言模型，因为解码的过程存在，并不像判别</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441398&amp;idx=4&amp;sn=6646e0c7ff7b008b7f3179ebf18bb6cc&amp;chksm=bf4053a549a21dadf8128c97f9f31075db8d4367ca3bad903f4e280e9bce8578fe9ec6dd3a18&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Mar 2024 03:00:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[COLING2024 | 面向编程的自然语言处理综述]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/58FUuNaBUjp1tGAcib25ibSH9GUR5NUA2Hx7y12dQvGT0MxTR4J5Z4N6dWt2k3iaeicGLsm7GQ1KlUNAX34xicxd6VQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名称：A Survey on Natural Language Processing for Programming论文作者：朱庆福，罗先镇，刘芳，高翠芸，车万翔原创作者：罗先镇，朱庆福论文链接：</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441398&amp;idx=5&amp;sn=392976ffa369c49ce863857488ed3bfb&amp;chksm=bf8181048755687774729f63a263a9ad0d82df84de4a4e67f1e81f48990ab63b0d5c3a60c2d2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 20 Mar 2024 03:00:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[保姆级 Transformer 中文教程，来了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJGdU9mv2W7e08dYWG5EicNWZicD4KU9KsJlA0jwUzrGlpOYO52SCCicskTd4myCZQsOeVg6w3YSw58A/640?wxtype=jpeg&amp;wxfrom=0"/><p>短短五年，Transformer就几乎颠覆了整个自然语言处理领域的研究范式，也促进了计算机视觉、计算生物学等领域的研究进展。这次我邀请了多位顶会大咖，做了22节最全Transformer系列课程，带你</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441384&amp;idx=1&amp;sn=fd1f9b0f8412a1c6dd6df3c54421c681&amp;chksm=bf1de2df6864da35bf37a5f5b297b41aac9201b5d6536605c60e1ea46884d0ebd0c805ee87a3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[探秘Grok-1 - 马斯克旗下xAI开源的大模型，参数量3140亿]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic3obUlcwce1zeoq9y9krpghzp7vMZ9fhEYusDdibzYNhAbkuFSWNvkmwn4MV5thloTrjr5QvluHSdg/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言Grok-1是由马斯克旗下的人 工智能初创公司 xAl 开发的一款大型语言模型，是一个混合专家 (MoE）模型，拥有3140 亿参数，使其成为目前参数量最大的开源大语言模型。Grok-1 的开发和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441384&amp;idx=2&amp;sn=042e7328f8fc560eb8facf67066d6380&amp;chksm=bf005e33675020ce146259a35413994478511cbb382ab646d603c6aa24ed229eccc4a1b35ed6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[字节跳动商业信任与安全团队招文本大模型算法工程师]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLEibeP8JRtlhLUOZzJS3mxibW3YVJKeWjbukibd2XtW9TKwHrKDjc77JeVfQbna01zAmCibErZ43pfibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节跳动商业信任与安全团队招人啦！团队氛围好，业务空间大，欢迎来勾搭[社会社会]（北京/上海）文本大模型算法工程师-商业信任与安全职位描述商业信任与安全算法团队，聚焦于通过人工智能技术（包括但不限于N</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441384&amp;idx=3&amp;sn=e12e43918942be306a7984e979831c80&amp;chksm=bf718067c21b4080c63dbf240b6921630638e5812663a0d4f367ee4b8bdd6bbbf71c5ff90420&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[指令微调数据的高效筛选方法-CaR（排序&amp;聚类）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mNvynY0vLaBXRw2X7AKLDENlGrl7t5RAdkzicFoEvoUuvqtTRrUhKSbw1iaUmfbDF3yxpfE9DPmygQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面大模型时代，指令微调是必不可少的技能。那么如何使用更少的数据，调出更好地效果，更节省训练资源&amp;成本呢？之前已经给大家分享过几篇数据筛选的方法：DEITA、MoDS和IFD。今天给大家带来一篇通</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441384&amp;idx=4&amp;sn=322e77823e37297479627c60efa96308&amp;chksm=bf85d6c7fc40459108fc248ab8629981bb0a5cd790b6dae2bcc934368b285729f983d105a3f5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP 2023 | LLM工业界快速落地之PromptMix: 一种有效的混合数据增强策略将LLM能力迁移到小模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gTSf9kr5zrPeJ4Tw3AWavyQLk8FOay0mMpexs1NHyTicJ4f5DWeVaPb04C2GOcl9CARpnXiaNHAmkGGUDE0FtfBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天分享一篇接受到EMNLP 2023的文章，Title: PromptMix: A Class Boundary Augmentation Method for Large Language Mod</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441384&amp;idx=5&amp;sn=2e2760c9a5cb688a34101df8ab37bf00&amp;chksm=bff1fe2c7cac0461555d882b8ffdde30301db5c2f151e3b4708d5874608944b4e69385802288&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 19 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一个薪资和前景都不错的方向，建议都冲一下！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIIhPggiazR0jAUXkENfVAM7tS6dMYC9TzErBTHzPLcEXaiayabD1ibW1c4UWo0pGQXl6mgYcsGKl70Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>“大模型狂热”从未停止国内巨头战队华为、百度、阿里在AIGC的厮杀中从通用大模型渗透到各垂类应用市场就连中国创投资本也独宠AIGC企业百度、科大讯飞市值分别增加27亿和45亿美元这导致AI人才缺口大、</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441351&amp;idx=1&amp;sn=eb14aa2cb0f95b0e529d02ca27a3fb95&amp;chksm=bf377b73bf711965c1fa33b37568f84f64e3a83b5f52c08d7082c9b7b9f1a1a24ba978c66ea4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文读懂RAG的来源、发展和前沿]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaaNF6dCVvryDiaWXTxq64gDOU2fvfbCgEUPghd6Vicj7qtFqy5RMLjUbic573G2icz8PfapSlHz0yIpA/300?wxtype=jpeg&amp;wxfrom=0"/><p>检索增强生成(Retrieval Augmented Generation，RAG)结合了检索 (Retrieval) 和生成 (Generation) 两个过程，旨在提高机器生成文本的相关性、准确性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441351&amp;idx=2&amp;sn=fc14ae863480688463708276b67d8b93&amp;chksm=bfbc09fef65b796de3d6393dae76e11cc031e4664745e0256b4c3e22122e57009838c307d805&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[稀疏注意力计算:sliding window attention]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Aj0FZbibW466ooF3KOJ8RhRovvK1TC4QLrlngNDzohlT3Hm5tjufbvuQicFerKkop7TpGqPNEQn6axpcvhdtyiavQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LLM的长文本能力现在已经是各个大模型巨头的必争之地。我们之前在《LLM长上下文的问题》简单介绍了目前把大模型理解和生成能力推广到32k+/128k+的主流方法，在《理解Attention:从起源到M</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441351&amp;idx=3&amp;sn=c0cdb5df048d1dffa579baed4a39c96b&amp;chksm=bf8cae070ff4da7eac10651ff641f95758298a1c46b384346c77dae395004f11adb911b6727d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DEITA：融合复杂度、质量、多样性的高效数据筛选]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hq9ANWCLRic0k2jhPhh6VOicFk7w68aR7ILSYfMNdSZcr0FMOkHay901xvxtXfcmZkXCHa1VVRL0s7osTcHdNDBg/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言在复刻ChatGPT语言模型系列-（三）指令学习微调 一文中，我们介绍了指令微调的起源、重要性、主要目的，同时介绍了如何获取多样性的数据、如何选择高质量数据和如何组合高质量的数据。本文将再介绍一个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441351&amp;idx=4&amp;sn=217e49d56dec4a8baafbbbfe919c4535&amp;chksm=bfb6e8f0922d98a1623e7141775e1a349257c3737eb1f1fbcecb1cedf6a49158fb44a5c54c95&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【LLM之上下文窗口扩展】| 无需微调的自扩展大模型上下文窗口]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/N5aX12H1SicnEDzXmW1QvqEjr21MoOwnneIGNHCwTsibXJezuTeK70kSNWB4su7zCMxIROa0vfzpIMuO3zk8Ksww/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文链接：https://simg.baai.ac.cn/paperfile/a34ae7f4-f0ce-4f8f-b8f2-e8e4d84bbee5.pdf       目前大模型基本都采用tran</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650441351&amp;idx=5&amp;sn=551b82a5bb35a3db1c9f390aa1713dfb&amp;chksm=bfa9862de8d26cc61c67f21abdda7c6408d82d7360f4ac6d7e3ad3f69aaa431bda82e3a7214c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 17 Mar 2024 04:10:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
