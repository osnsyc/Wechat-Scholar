<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    




























    <item>
      <title><![CDATA[1999美元！RTX5090发布]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJb0yKNr3WtLwSohOzheFUSbrK8Cgw0NLAk0lEcnfxYwXtf3OVqf2mY7t5zEM6JJTX82WdJoPonCw/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：EETOP1月7日，英伟达在2025年CES 并发布了RTX 50系列GPU。英伟达首先发布了RTX 5070 GPU，售价仅549美元。据英伟达称，该GPU将通过多种方式利用AI技术，提供RT</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446990&amp;idx=1&amp;sn=ec5cd5331b0192e0e718d5a3bf7cc445&amp;chksm=bf4fa927f9439a553a3f937da793931f8dea0bb17ae4718bb15b46b4ae2bb91ce121daf0a144&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 07 Jan 2025 06:39:26 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[2024年RAG：回顾与展望]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVcGjx2ic29DVDUJxlFBHPA9aajp6j2tFIYfWg5xSuiaQV6X2EDvWwe3wCXHSezBaF0OpogLTq4WqiaLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>2024年，RAG（Retrieval-Augmented Generation）技术经历了从狂热到理性的蜕变，成为大模型应用领域不可忽视的关键力量。年初，AI的“无所不能”让市场充满乐观情绪，RAG</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=1&amp;sn=0040aeeaf34a5cd592e93c8593f3f452&amp;chksm=bfb612ac1a9f56e624ba632ab2fc1e2e46e0b3b3de33b14fff57836eccf8e4e2a76deff4f016&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Baichuan Alignment Technical Report 论文精读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxtDLTHYN5ws5MjBgVsDwsz13OU98oYy4CAQ2ot4yqm8q21P15U2hXQR5icxSCsOnWo6PzhIMicZWicVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言最近在研究如果更好的制备通用 SFT 数据，baichuan 这篇文章对通用 SFT和 RLHF 两大技术进行了全面，个人认为非常具有参考意义。Baichuan 将对齐划分为三个阶段： Promp</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=2&amp;sn=c450004b05635a0feceb8d30c3ec2386&amp;chksm=bf052f44777904ef508a4512faa19f9642a258a5733f0ec4dfb4b33238484e259b897b82ad31&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[工作近五年，谈谈各类公司和部门的区别]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/s7YKINJYHDAykAXrsvPIPrLDsOtkpxv2Lb1Xyr1La7ibiarAwALhguhbaKhqH6eORzNRSsKMPvSMpiagboICR0eNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>从实习到工作这些年，我曾在两家外企、两家国内互联网、一家初创公司和一家券商工作过。其中包括Top外企和Top国内互联网。整体下来感触还是很多的，以后可以多分享给大家。国内互联网 VS 外企 VS 金融</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=3&amp;sn=8b121dc43d2536bec13b530ab79de9da&amp;chksm=bfc1ba6143963c3b1a5ebe49d481ebe5e8e817a9795671b0769136e785f1a1b399784700d08e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[[vLLM vs TensorRT-LLM] ：系统调度schedule比较]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLL41WHgwWVzraBAS0f5nGfQYLbUbF6ZTZk2hbkUHricxWTx9EnWPPIiaiaEgKgibdB8cuH8fzhZcarOA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源：oldpan原文：https://medium.com/squeezebits-team-blog/vllm-vs-tensorrt-llm-4-which-scheduler-wins-2dc</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=4&amp;sn=f424c12ac6984dc8573a03553f3bacfa&amp;chksm=bfd0a720b85c8745f5105b96cf606432d2fb1db48eb5c21c5993f269a0854fa6c26bff42e30f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM之LLM的特工行动：工具召唤功能实战案例？Agent 到底是什么？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>智能体Agent新鲜吗？并不新鲜，因为我们之前处理LLM的输出的时候，代码中也会有一些判断是否可以采用LLM的输出，还是需要调用别的信息。不过Agent把之前hardcode部分的调用变为自动决定调用</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446983&amp;idx=5&amp;sn=1efe337727fabff388538f202ca643c3&amp;chksm=bf75488760c6dd81cf85431826b6c4b1de30495a9c8f5bf88c0e0ad6e62453485fc954e5a4c7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:42:45 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从infra的视角聊聊DeepSeek-V3]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKFPuSXXOqRGlq1EfNkNMBDBYJtXnibOFH13QDg4Yb7Nar0t8m32Jic5EaDhlAv6WQvvSnEdfqMDicnw/640?wxtype=jpeg&amp;wxfrom=0"/><p>看完技术报告，从infra的视角分享一些个人看法，供大家讨论。首先，训练超大号的MoE模型，仅使用两千张H800加两个月的时间，就能达到如此好的效果，这点实在是太强了。只能说实践出先知，从DeepSe</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=1&amp;sn=bd9d7b796f7fc6b60e92d9b0b38c6e2f&amp;chksm=bf34b1f360fa2a9d480c398fee7e01000d06e709885fe631a20869dd7b08104b0e2b2b330bc6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文末赠书 | 技术人的年末书单，这10本最受欢迎！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSKFPuSXXOqRGlq1EfNkNMBDEZAfJicBOdh5fXG4TbSiaWiaw6KClDGtFm2YyNQuYG3axNhLCvtlia3Ohg/300?wxtype=jpeg&amp;wxfrom=0"/><p>一年过去，我们如何勾勒自己的2024？这里借用一位相熟多年书友的回答，“认真阅读，好好践行。”这种对阅读最朴素的认知，不失为抵抗现实焦虑的一剂良药。我们结合销量、口碑，阅读趋势，精选出最受欢迎的10本</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=2&amp;sn=f879024a5dc3adaa09e9304da8311b92&amp;chksm=bfc4a980017d614334f1b2a1fe13197f97b56a4fd4a21845817084f031fc8605fc4b012bc06a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解Megatron TP中的计算通信overlap]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkMbLJgBKf7TGLiazdyylqtZemA2Wdgkq4UL3L5GnDtspUWacNbT6EiaAkWrTARBTc2EyIqu2k5WDkyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章想来探索Megatron中实现计算通信overlap的方法。具体来说，Megatron的dp、tp和pp部分，都有可以做overlap的地方，本文探索的是tp部分（更准确地说是megatron</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=3&amp;sn=65f3f848aa069cacd01e79539d498a16&amp;chksm=bf793bf53bd90f68bca95259fad07a6da881e9d997e19b2ad77b39ea3797f0982798824c1c46&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[曾经火热的Graph Embedding和GNN在推荐系统上还有前途吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/7YJVBU9FXkV9af0b3e7IG34IZkiaINIwkBr1CIHw9AlZfgtclYugpiaWSLUKIwSiatorG0YqxdHSEuvElNUg5wKyQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>曾经火热的Graph Embedding和GNN在推荐系统上还有前途吗？前段时间回答了一个问题 为什么最近几年，没人在推荐系统里去玩 GNN 模型，GNN 是凉透了吗？ 感觉大家还挺感兴趣，这次专门开</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=4&amp;sn=fa134c2331fb054b217310dadaa66d00&amp;chksm=bf2047190bab9716998bc38ecc3451d85135c90be4dbfae48fd7e76837a172783458593178f2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：什么是 Sharding? 之ZeRO 优化（Zero Redundancy Optimizer）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>还记得小时候第一次看到《西游记》中孙悟空遇到一堆妖怪的时候，都是拔出一根毫毛变成成千上万个小猴子，把小妖怪都分给每个小猴子，这样大大缓解了美猴王的压力，但是也可能会增加孙悟空赢得胜利的时间，需要等这些</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446932&amp;idx=5&amp;sn=a6b326f587bf900a7b6e771ef2ea83c5&amp;chksm=bfe889c5c50a1f5e839fc052e93b89380fa9efc0322254fd722ad44d9e58c1f31876aafb6d1c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 12:08:32 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌41岁天才科学家SuperGLUE之父英年早逝！两月前留下绝笔：从事大模型研究让我深陷抑郁！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLI18DCL4TiaFN3GMDuVzv8xQgl0LmAK4KphdzFRLrsWWWasm6ocnrEI85K5wLlVAPKXNqkBIncxibQ/640?wxtype=jpeg&amp;wxfrom=0"/><p> 来源新智元 | 编辑部 HYZ【导读】就在刚刚，噩耗传来：年仅41岁的谷歌DeepMind天才科学家Felix Hill英年早逝。他的一篇博客揭露了AI研究者面临的巨大压力：几大公司的竞争，研究方向</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446913&amp;idx=1&amp;sn=29b832d396ba8da2e74dd832e115a528&amp;chksm=bf364127c03f23942ea98970eed1b951fec5da6237615c2ff807b0ada5971f3cc55288be6b98&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 03 Jan 2025 10:21:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[评价deepseek v3：又一个相信自己比英伟达懂GPU计算并做到了的团队]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLI18DCL4TiaFN3GMDuVzv8xg2FjjsFiauqqURSgk2ibXKEgI3Igyoj58kiblXCM7jBdibptp5lPV8gdFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>我觉得 deepseek v3 主要做成了 2 件事：继 flash attention 之后，又一个相信自己比英伟达懂 GPU 计算，并且做到了的团队；找到了 pretrain 的一个 10x 变化</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446913&amp;idx=2&amp;sn=b37b82107baed5fdba27e083230af265&amp;chksm=bf8a1d6c364c943c4e64801c014459a70fd5f9ccd54fcf51e6bf85dc1a428c0226050de4b9cf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 03 Jan 2025 10:21:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[手写self-attention的四重境界 self-attention]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BrtBjG6XSzJoo7gHm1BSPsDGh8UWtbJrAM7gp2k6kevmYk7LZcqE3FhsQyaI41Okw96wGAdys9n3k58TLM1rNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>背景在 AI 相关的面试中，经常会有面试官让写 self-attention，但是因为 transformer 这篇文章其实包含很多的细节，因此可能面试官对于 self-attention 实现到什么</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446913&amp;idx=3&amp;sn=1497a5a9202dea0523ab034c7ef301bb&amp;chksm=bfefaea00a2078783edba3e8d8be5c6047444c1a55076d21aa4ad9b6e500c5ecba462b7108d5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 03 Jan 2025 10:21:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微软公布OpenAI闭源模型参数！4o-mini 8B！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagJXDvsF3HlcGS7dbMEnUw0JKPzEt6aK2DUIMkwdubspoInY4oe8Xy1acHiaicsia1W5rxSfwibwgncicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家新年好！祝大家新的一年薪资歘欻的涨，论文嗖嗖的发！没错，就在前几天，Microsoft发布的arxiv里竟然写了OpenAI闭源的大模型的具体参数！（消息来自：xhs博主 Scarlett_WH）</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446913&amp;idx=4&amp;sn=d44ad93d6732c2a226a9443f5bf7db20&amp;chksm=bf0e3183bfffc3df28c3a1009b7a530031090cf5780c478d9d26c21bd897bcda8f4d157b124b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 03 Jan 2025 10:21:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM 预训练到头了吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mgNw8j9VaKicnQ1LDoAiajibQxVzZ9IeSUXeaLb5wybPXk8RkGwDiaSEAoRozd7xMbw2ZNibHCfsdPdxg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来的是好友@Binyuan的一篇想法，主要是对Ilya的“pre-training as we know it will end” 观点的看法。正文如下：最近，Ilya 在 NeurIPS</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446913&amp;idx=5&amp;sn=3a2ce18486fd3a83d9cbe9ba9f1b3b8a&amp;chksm=bf2a85da18fafae66fc686c4709b7551bc03ac43b2f4ae2ad59da9c2f9bbe468a3095a0f7db5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 03 Jan 2025 10:21:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek-V3技术报告解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJqjy6Efm9SLJ4EmicVDwK41kNTmUianXLgDviciaSNBcpqIlfTJicjY6EQw5tH1BmHg6YYFyMbtAricxCg/640?wxtype=jpeg&amp;wxfrom=0"/><p> 作者：吕阿华原文：https://zhuanlan.zhihu.com/p/1489055778212月中旬，我浙之光Deepseek宣布完成了v2.5的最后一次升级之后，约过了十来天，v3.0就正</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446881&amp;idx=1&amp;sn=405dc7dd2c4cb614160bebd9f3516dca&amp;chksm=bfb3d5c774b538a2297b824908856cceffbb35791c16842821194445724f108be4639ef56257&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 Jan 2025 14:16:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Deepseek V3 预训练策略解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJqjy6Efm9SLJ4EmicVDwK417CNqibdJkPjJggrqBn2SFc5hzFKwVFhtXWuPYNpBa8hR14Gicx2z6yiaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：大润发杀鱼工原文：https://zhuanlan.zhihu.com/p/15073492309训练策略集群：2048*H800，256 nodes，配备NVLink，NVSwitch，以及I</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446881&amp;idx=2&amp;sn=bd997e8c106edd04f028a9b7dc7f880f&amp;chksm=bfbfa621d9727aa17cf70ca621ee8687f1b8f89a3396875cc2248efdbb426879ba257ce80c2d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 Jan 2025 14:16:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[长文 | 大模型Post-Training总结]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nBpNRwzHn1uuNDxp2602vSNniaKS9yedT4pcp33Y4aJz5mX1IgLkt0kSo01icibYchce2ygrXACL2qw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来一篇知乎好友@hadiii的一篇文章，汇总Llama3.1、DeepSeek-V3、TÜLU 3和Qwen2.5的后训练Post-Training技术。知乎：https://zhuanl</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446881&amp;idx=3&amp;sn=93354ebd48be256663068e3fc8808e64&amp;chksm=bf48dca16fa67414e59e5f440cf5749e988d99a1149c0a4be39b796e2bde3b1f4c8e006175da&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 Jan 2025 14:16:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年大模型总结与展望（技术下篇）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGy058d86CodWtNHyhMPrDablpLpqe0dQGrEoqqgkgNSsDf7LYDSWOTmtfQDkkI1XxAA07famWQVMg/300?wxtype=jpeg&amp;wxfrom=0"/><p>接续上文《2024年大模型总结与展望（技术上篇）》1.3算力        大模型热潮进一步推动计算底座迭代升级。主要表现三大趋势特点：   芯片架构定制化以迎合Transformer计算特性，如英伟</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446881&amp;idx=4&amp;sn=01978891e26f7d74b3b0bb382015286b&amp;chksm=bf1b0c3ec8573e0af86eb17733f8512790d6aa7a7c6ebce4aaed19c24d18d0ca850bec712123&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 Jan 2025 14:16:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一本醍醐灌顶的「大语言模型提示工程」教科书，熬夜读完]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLROkF38B0FVOMyI1kL03FOiaylriaxnf6jeBNIqhpoY1LPcHQI6hb4zAiaX8z2NZrvZV38SNrT4iaM2Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍大型语言模型 （LLM） 正在彻底改变世界，有望自动执行任务并解决复杂问题。新一代软件应用程序正在使用这些模型作为构建块，以释放几乎每个领域的新潜力，但可靠地访问这些功能需要新技能。这本书将教你快</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446863&amp;idx=1&amp;sn=3618eddfaacca62219de0b1517fd6776&amp;chksm=bfeacdaf3415ec46b857dccce5bf5d627d9505b9ed04544e84fbe1391b7581c8392c1eb7e73f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 01 Jan 2025 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OpenAI-o3 与 Monte-Carlo 思想]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLR0wpDWC4mwRhDr9hFWrqS0MpxxfSrnqz6zDgJibSSmPzZnjcZHyibPdTRQoovFcejWwy6lYV4JgiaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>o3 来了，分享一些个人的浅见。关于 Test-time Scaling Law 的进展，比我们想象中的要快得多。但我想说的是，这条路其实有些曲折——它是 OpenAI 在追求 AGI 的道路上，采取</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446863&amp;idx=2&amp;sn=df82c31ede343a211d0e980badcbec6d&amp;chksm=bf56553f48fa519a4715cb72127f23a8acbb3ffd1ad668e33e7a72247dce8f7172f7e014674d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 01 Jan 2025 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[o1-Coder：代码领域的OpenAI o1模型复现]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIBz0g3En3bx5zQg8MQojp6VF82C4EI3ITPstou4HDpRwq6naaJxQvcHaTbOFDQGsuV41oPKbk4yQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 作者：莫笑傅立叶原文：https://zhuanlan.zhihu.com/p/11002542959https://www.hotaipapers.com/ai-papers/2412-00154</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446863&amp;idx=3&amp;sn=2ac9777e830dbe81cc79cf72501f1dca&amp;chksm=bf2bf70083b02bb7ce11a135d7a49b04091fd06190e69fd1e575de3e937c6c76e9ef6011647c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 01 Jan 2025 02:10:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeekV3带火大模型infra，入门看这篇就够了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLROkF38B0FVOMyI1kL03FOU7UPR8PkcicVPy8xUhpTWScyHt6xbibeIzykWXpt4tkkRnaTJsog4UPw/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：真中合欢地址：https://zhuanlan.zhihu.com/p/10091011992整理：包包算法笔记为什么会有这篇文章：虽然工作内容不是infra，但是我比较喜欢研究训练方法，魔改训</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=1&amp;sn=85fd17af9ca8ebb9c4d7fd1a880b255b&amp;chksm=bf9a6b504fa03159ea1a34fcf7b00366176d8ce6a0c5cab021084a8b1988d29eba8db16fd336&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[《大语言模型》：人工智能时代的知识盛宴，大模型中文书籍震撼发售！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLROkF38B0FVOMyI1kL03FORDTOtpGv8DRqKWxvqBzZKaj32eHdUgib4ibCMSO5uWj0y4QibZkyShGWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>为了推动大模型技术的普及与传播，经过数月的大量修订，由中国人民大学师生联手撰写的《大语言模型》中文书籍正式出版。作为该领域全面解析大模型技术的中文著作，该书将提供大模型技术的权威介绍，注重为大模型技术</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=2&amp;sn=99959fe43ac0508fcb2ba71e7d6cadab&amp;chksm=bf391d2031aa800c0d4ffa510097a9cad683223443f17909c81117a2a205539a616a016a0338&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[5个开源RAG框架对比]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVdb8ibypmfibEag2TgJcQNA1vcgSkfGMIRPbVJVZ0nMzJ00fX58a3j9AFqGwQ1MplQVgCr1GxwfjibKQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>还在为RAG应用开发头疼吗？别急，今天给大家推荐五款完全开源免费的RAG框架，覆盖自动优化、多模态处理、本地部署、生产环境支持等多种场景，助你轻松搞定RAG开发！👇1. AutoRAG：自动优化，省心</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=3&amp;sn=eb957a44db82b53d98b06cebf1a9469b&amp;chksm=bf07be84220dbf39a6e58c4c4b5d6390325573257a747bb2b29bd99266466c9866e09e9abae9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【多模态&amp;文档智能】OCR-free感知多模态大模型技术链路及训练数据细节]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/kJguDvfjOGAtwHQ0Csm6ibvCBXW3M9nDbxzWuVPznMceOiaDPZiblC7M5jJ7rPurKOCtG69RsN4RBDSd6Sevnf4Bg/300?wxtype=jpeg&amp;wxfrom=0"/><p>目前的一些多模态大模型的工作倾向于使用MLLM进行推理任务，然而，纯OCR任务偏向于模型的感知能力，对于文档场景，由于文字密度较高，现有方法往往通过增加图像token的数量来提升性能。这种策略在增加新</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=4&amp;sn=80c2b79008a032b943561d8679753321&amp;chksm=bfd159beb89bedc03eeb29b6c52fa295a98e206f51fa72b504defeff1b15c92a1121cc7a64db&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[千问LLM：什么是 Sharding? 之数据并行（Data Parallelism）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iabUOs2OBUhTJchV1800lWEhIq8F6xhCBBmI7mrYULAlSl0oCbTL3shIUt5ic9JRFtYZSMek7jTNicib53iakDz9dSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这次我们详细介绍一下 LLM 中的 Sharding 技术，中文叫分片技术。为什么需要分片？因为想要加速训练或者因为LLM参数过多导致不得不分片。那么参数过多的数量级是多大，我来给大家简单算一算。假如</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446856&amp;idx=5&amp;sn=13b9888bcf2f8afb209c4250f4f9dc44&amp;chksm=bf6c43278dd0377169d15ad131bb1067aa2c3b9e047535649f072e2c9372e277a1ca2bb7342d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 31 Dec 2024 11:03:19 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
