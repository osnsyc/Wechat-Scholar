<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AINLP]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AINLP公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5034e4edc067.jpg</url>
      

      <title>gh_5034e4edc067</title>
      

    </image>
    





























    <item>
      <title><![CDATA[大模型存储效率太低，占用空间太大？推荐一个开源神器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK3PjYicVI3JQYOBSjAtTKntOEYPawUQd3EZTvlGKfH5xibDGfJ0O5mHEANOENkaEsoN9uTCU9E3iauw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型工程技术的迅猛进步，提升大模型训练效率已成为推动其发展的关键要素。训练效率 = 训练吞吐 × 训练有效率 × 收敛效率，其中，训练有效率的保障离不开灵活且强大的模型恢复机制。据悉，Meta的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446801&amp;idx=1&amp;sn=41423b6c42f29553ab4f34fc30b01eb9&amp;chksm=bfb65510c5415600c44be762334e08051de5bd404515280e7a7e45ae73ec76a6ef10194fa9d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 28 Dec 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[大模型的基本功]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIURkEnvhgvAZACdIicTK4TtOUC093l7xjQrpru5GeT0uQ9298wUghH1jmZtPBgXCs5ffl4lyO0DoA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Author: [ybq]Link: [https://zhuanlan.zhihu.com/p/716344766]这篇文章给大家推荐几个大模型的练手程序，也就是所谓的“基本功”。先问个问题，除了 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446801&amp;idx=2&amp;sn=79c44d2a883d48beee7b29857d1becad&amp;chksm=bfdf0110465b4713b7fe29128e978b72b1907fcb4cb98daa3b247ed3ce8c9f95fd112405c847&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 28 Dec 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[深度学习工作：从追求 SoTA 到揭示新现象]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSLR0wpDWC4mwRhDr9hFWrqSJFjgIpKXKrhIAhLMaLGqAseREMibsZT8SduEJLLwLNRL8GN6azbuYfg/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨黄哲威 hzwer@知乎来源丨https://zhuanlan.zhihu.com/p/14170281797编辑丨极市平台导读 本文主要讨论了从追求模型 SoTA 到揭示新现象的转变。通过几个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446801&amp;idx=3&amp;sn=0415d20d347eb29cae9bc7de5621dc16&amp;chksm=bf63476997deb6df0c1a993fcc4c88d397345295d78533a4a24b77ee72acfa5fccf79a679bad&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 28 Dec 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[【LLM模型微调】LLMs-PEFT[微调]-QLoRA总结笔记v6.0]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/svfB1Sp4FdAGjG6CTCktBa8hUfec1MISxXE7Yvktanp4iaCxgnnEBA0OBfxjop6WPvprmxm29mDJy9nbNAAbxzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】：本文是LLM模型微调第六篇，分享论文QLoRA: Efficient Finetuning of Quantized LLMs的解读。主要内容有论文解读(提出背景、技术原理，细节补充...)</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446801&amp;idx=4&amp;sn=20b3b45033ca29d0fc6cf31d330119d9&amp;chksm=bf439bb3bf853c9393bc3d578c0e01d179d74abbe07f8e27c25d0451da67849e956894624325&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 28 Dec 2024 04:10:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[75k，确实可以封神了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK3PjYicVI3JQYOBSjAtTKnt3Nic3CIVCJY9a6e79AlHmWxfqUz7coAfNHXQjJo6Ch8z4iba2330zJow/640?wxtype=jpeg&amp;wxfrom=0"/><p>因ChatGPT爆火许多行业未来发展不明朗，技术人纷纷想转行、跳槽到前景光明又高薪的算法岗位。（算法工程师的薪资在各个技术岗位中显然是最高的，更多技术岗位平均薪资详请见下图）事实上，哪怕算法团队申请和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=1&amp;sn=ca6044b328b761f40f44a4187892fd08&amp;chksm=bf9eadc839693c4ddf1d6c26a8aeaaa6f0e2d4a517950957156af39215dc1dd57360e6142ca6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek-V3发布：编程能力超过 Claude Sonnet 3.5！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVdqqjI6LdvcdNQiadVe47oVS7fqG5Voyor5j72RQdJMnwCvJc25pY48Ue4exUpK0ALI1B8Wun6SibicA/300?wxtype=jpeg&amp;wxfrom=0"/><p>备受期待的Deepseek V3终于开源!这款全新的AI模型在多语言编程能力上取得了重大突破，其在aider多语言编程测评中的表现，甚至超越了Claude3.5 Sonnet V2等竞争对手，引发了业</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=2&amp;sn=69d411ac35b88bccad70201bff04f95d&amp;chksm=bf59696621843a30fd51317a3a8a71d2be0a6f35a1a48544c0295474bb0ddd51873e466335e9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[2024年大模型总结与展望（技术上篇）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/9MSPBmHaWGy058d86CodWtNHyhMPrDabq3Mguv2jvfgCDyqiaaEOM0ibIjzOs1LAwMEEjdHLPTcoiaTFG1aXGBKxA/300?wxtype=jpeg&amp;wxfrom=0"/><p>   本文参考了信通院、智源研究院等众多机构、AI行业大佬的观点，再结合本人自己的观察体会总结而成。    2024年是AI时代迈向一个新阶段的开局之年。身处变革的洪流之中，我们见证了许多激动人心的技</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=3&amp;sn=cac20f9af8626b7c58b990645128761f&amp;chksm=bf48e449f581672916f3de3c43ec6adfd8767f10d21648ac543e788083a36f28b2173cd78b8f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[让Agent"少说废话"！打造高效的LLM多智能体系统]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah1aGlib8oybp7QdEiaHpnVytEDsHv5dA5HrWFprcbXybOhQhdvK625YQ68cXkiaF4mmVO5ZGrLoOX6A/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期，大语言模型（LLM）驱动的智能体（MA）取得了显著进展，集体智能表现出超越单个智能体能力的优势，主要归功于精心设计的智能体间通信拓扑。然而，现有的多智能体系统在性能上的提升是以大量的token开</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=4&amp;sn=ff4c3f405a130c3b56b021c766534d39&amp;chksm=bf23f271f89d9ad3c90080d7d8bad26ce0eecd5346e91ac554464c408d051407a34ec136da73&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Scaling Test-Time Compute：向量模型上的思维链]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/3EjVEqjYF3IjMoyELZt7ZKRTgsuY0geiaCjt1NrPNUzeicM9m4CJVGf1h6F7SwI5BIl5XWia0gevsDOWoyRAia5nnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>自从 OpenAI 发布了 o1 模型后，Scaling Test-Time Compute（扩展推理时计算）就成了 AI 圈子里最火爆的话题之一。简单来说，与其在预训练或后训练阶段疯狂堆算力，不如在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446740&amp;idx=5&amp;sn=d869619ec291338bff4b650a8b64c63e&amp;chksm=bf6ff4d796a2654df6dd501430cf086e93734b8c74f8d1b8d153e77fb9dd634d084be9730ea0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 05:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[全是细节｜大模型SFT的100个关键点]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK3PjYicVI3JQYOBSjAtTKntw85EHFia7QUmgicOMe8C7KF8wAV9Unb2bicJkYvnj094z97icxcVY77NCA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者：ybq链接：https://zhuanlan.zhihu.com/p/809229182点击底部访问原文直达这篇文章介绍一下大模型的 sft 如何去做。相比较于上一篇文章介绍的 pretrain</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446728&amp;idx=1&amp;sn=370bbcd9d2e49aa3e60447af176eaf20&amp;chksm=bf91d38ce13b4e1e1ac5b58833775e13c125aef438f389b98d35557d433af4f8d8de5ea07aa0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:28:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2.5 论文精读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxvOklibm1qAjC9rChOcqwYvMJqAR4phFsQ9PTzcfMiaEqib7VZknyL5Fyic9NwESa8wGBDRO2oUR28WSw/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言不得不说，Qwen真的是太卷了，目前看来其基座能力已经稳居开源大哥大的宝座，并且与大多数闭源比也丝毫不逊色，估计很多公司的基座团队已经在被 judge 训基座的意义了。Qwen的开源架势一如既往的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446728&amp;idx=2&amp;sn=3b75039f3fd0352ea4ce41857c7d8fbb&amp;chksm=bf9775b5936590442b4ad0a5a61c02c861bc12a21a49b7898cab45cf985a3f526709f9d68556&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:28:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[技术人该积累什么，才能避免被AI淘汰？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5l8uuaWFH5xbhu792Ne2uhKvh3IncadZ7JAoicvBicy6P9iboQSD2536fRNxxuOaGZSOjAkyE5KWk1iaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：https://www.zhihu.com/question/7440697804/answer/61212648228即使没有 o3，大部分的技术人也一定会被淘汰，这就是当下程序员圈不可避免的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446728&amp;idx=3&amp;sn=e72c46c8023b088158e45b2fd0520f3d&amp;chksm=bfaaf7c63adeef69e3206671b4f9f881f06f8d7eb16b2b8ce63291ed1782f9e67f493c4b4e0e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:28:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[右脑科技招聘AIGC算法实习生]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK3PjYicVI3JQYOBSjAtTKntnsNiaFBNJP9xIJkhE1YCL5Zsqvgu99Q2iawkpL7qUD250JVF8os7hkog/300?wxtype=jpeg&amp;wxfrom=0"/><p>     【岗位名称】AIGC算法实习生【薪资】350-400/天【工作地址】海淀区中关村SOHO大厦【投递方式】careers@rightbrainai.cn，备注实习时长+到岗时间  Hr电话&amp;微</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446728&amp;idx=4&amp;sn=799617b0250de9b4fdc1000c1662b67c&amp;chksm=bf8ecb0e06e4f83f8d70ea954b8823fab90e97f26ca8de67674372be6efba2917f09f4c71f8f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:28:04 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态RAG杀疯了！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIZdlVnsVqPVqcScxQRkwBnm3WFSWKp7ZGrvUDFtfOxzGFaCEj1Wib2K5sN98ohbh8DVBdHGYOdzHQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>2024上半年是大模型的时代，但随着训练推理的深入，大模型也逐渐暴露出幻觉问题，
一些回复与事实知识不符，研究落地面临极大挑战。于是，多模态检索增强生成（mRAG）技术应运而生。近年顶会更是激增了一批</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446582&amp;idx=1&amp;sn=88d5342db4c5da3ceb1f30f60222a20b&amp;chksm=bfd7dbf1a5b95fbe634cc65071f0dbfb634d15c46d7430a80151112e6f7765ef04c2550837f3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 02:20:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM 又一年！！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lDrFs3QsIxrEGeoC2uqZbJXIrsmOD6TXVFLbkHjsBiaTDoVOIVgefdBZJ1NEDqo8ImicaPDvpMaL3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>LLM 的第二年就要结束了，如果 2023 年的主题叫“从零到一”，那么 2024 年的主题无疑是“颠覆认知”。知乎：https://zhuanlan.zhihu.com/p/13803218651过</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446582&amp;idx=2&amp;sn=aad0525599c3b5b340adc8cb728d2e53&amp;chksm=bf99cd22204f7ddf73c9003cbbad7e82b2c62de9aed8c62fe25cdd05f445d3bfdb48b3cbc626&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 02:20:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLAMA3 论文精读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HAFUHkn3vxutIeo0mRMymBic1ke0rHeJfj1fnCGvRiayscrjx3ktP0a014LyNERLeXc509OARs7xkJp9HzEzZn4Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>前言最近对之前精读的论文进行梳理，发现一些笔记还是非常有价值的，稍微改改发布出来给大家看看。LLama3是几个月前的论文了，但是每次精读还是有所收获，本文将一些重点的内容加一些自己的思考和实践进去，对</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446582&amp;idx=3&amp;sn=430f50e147371cfa181b31d50555352f&amp;chksm=bf8a21994e40080788d1eb028ada26f4d0eef5c60ede4b370111d3e0142e9ff4d38f43bcaad6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 02:20:40 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[o1复现的一点点心得]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSIZdlVnsVqPVqcScxQRkwBnEd4nf6chEKk55VKyU6UTA4waMKaXaOKciccemtHjPmxhsU5oAaZFyEQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：皓天地址：https://zhuanlan.zhihu.com/p/13872128423编辑：「深度学习自然语言处理」，转载请联系原作者恰逢o3、gemini-flash-thinking版本</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446566&amp;idx=1&amp;sn=f606d67b6dc3c90e77eea2affa703448&amp;chksm=bff5b5b45f9e8133f73eb1cb6a45201f5042748a69c0f3bf043e72f0a7d4d4d84c5baafe0b69&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 08:57:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[类O1复现项目数据和模型开源啦]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/G7ia3FZ0o0OrrgI2W9HjkxVBpprwP3fQVRicac6rWVHUeZ2CTnXYjUVvHgDYVZpCCkOQArumhNkqcOg9kOwYv0Zg/300?wxtype=jpeg&amp;wxfrom=0"/><p>© 作者｜闵映乾机构｜中国人民大学研究方向｜大语言模型为了帮助开源社区共同研究类o1慢思考系统的实现方法，我们开源了在技术报告Imitate, Explore, and Self-Improve: A</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446566&amp;idx=2&amp;sn=52ffbc4dd6772fe90059f737941b2e28&amp;chksm=bfc1e04ec4921b78c430dad45c361cd3342c326ae8112b16226715e606bd0a39172066b20aab&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 08:57:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[推理模型专题 | 开源类O1：Marco-o1技术全面解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib4ASE8bbRJtwicObIgABpzDd7oBAQABzEfUnUdxGzHKh47J5hL7qnp7Q2JkEKQZDHRfaic7f3gv2vBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言简介Marco推理数据集通过MCTS扩展解空间前置知识：蒙特卡罗树搜索（MCTS）MCTS扩展解空间推理行动策略行动选择思考后的反思实验设置主要结果翻译任务案例研究总结0. 引言引发了学术界和工业</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446566&amp;idx=3&amp;sn=aec74522eecf81beee7cedd0027e224a&amp;chksm=bf88cca3741b4d54e71cc0fd7f708396e5d0e599054e400f409c56f2ff8a2dd065e121231023&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 08:57:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[EMNLP顶会最佳论文解读！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJvwxS6MT3ic26SA7vcz0fGkFc2Yia0SPC8Kib5Qy1C6oUPCPSskKaDVV5AswAA5VxqZ87mCtL6bxsxw/640?wxtype=jpeg&amp;wxfrom=0"/><p>EMNLP会议在自然语言处理领域拥有不可替代的地位。作为计算语言学领域的顶级会议，汇集了世界领先的研究人员、学者和从业者，分享这些领域的最新研究和进步技术。上月中旬 EMNLP 2024最佳论文奖新鲜</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=1&amp;sn=96b0074ae1b6cbadc661d15dce74837f&amp;chksm=bf48c844f4e6e3336a00830657099a21c059b519d15c2263b38c7a1f642a1ff023fae970afb9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM训练全细节 | 如何从零到一进行 pretrain 工作]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSK2y5DziavvVj7obPrPwSiaLQhut1aOouU4Xkrcf8OmxGQZyCFFu75Jw9r42a9N8wxBLoiad2GOPftWA/300?wxtype=jpeg&amp;wxfrom=0"/><p>整理：NLP工作站知乎：https://zhuanlan.zhihu.com/p/718354385这篇文章介绍下如何从零到一进行 pretrain 工作。类似的文章应该有很多，不同的地方可能在于，我</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=2&amp;sn=1d9cde149df7d62b2410e6e4578aa1e2&amp;chksm=bf25ef2890fadd3b7b15dd224cb2e3666d69cdf3d3807fb546aa67345f72fe2697e49c211b01&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[RevThink: “逆向思维”助力每一个LLM梦想]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/86qxNQYXKpuV3Nhze3fSVlP4YPibCOrxFu3o6Y3OYdfFz9iaUibtsnoOecr3oic9kXlfGekrTtiazaTeLcZ22yLQsxg/300?wxtype=jpeg&amp;wxfrom=0"/><p>提纲1 简介2 问题背景3 RevThink    3.1 数据增强    3.2 联合学习4 实验5 讨论参考文献1 简介    逆向思维在人类大脑中占据了重要地位，我们不仅可以从问题推导到答案，也</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=3&amp;sn=297af29761877911bf7bff1ad11a5538&amp;chksm=bfd97c4685f8a205f35097adfa3647fca0f6dbce4e0aa18c12f4b37108047c98ebb2a71e2232&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一局定乾坤！主流O1模型，究竟谁才是地表最强王者？实测对比揭开三足鼎立局面！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/w3hibrVDUAib4HicVib0Do1M1sPdB8gXbL1f0IAS6My9wwDSXhuwt9ibibvoGqqNTzXoXs9ekkJCJjHxQkvfAOpJpmkg/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期，国内多家大厂与创业公司陆续发布了类 O1 推理模型，主打逻辑推理能力。其中，不少模型更是声称在性能上已大幅超越 OpenAI 的 O1-preview 等竞品。那么，这些 O1 模型的实际表现究</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=4&amp;sn=490959098c5c51f6439f07f5ddb521b1&amp;chksm=bf67e108789b11a67484b5a75a4d3358f97eb78af57ddbb10e33a6d5a116397adac2352e9870&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从近100场大模型比赛看大模型关注热点]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IictSfTIpvuwe2rvshJ33UZIovSKagiaXObw4ibBwRNicMcuckzEkGTibO3r5hR3kQGxWf4TleiaDvUnkpDM4KDzqnQg/300?wxtype=jpeg&amp;wxfrom=0"/><p> 作者：砍手豪（授权原创） 链接：https://zhuanlan.zhihu.com/p/720381778在之前的文章55个大模型比赛汇总里可以看到,从去年十月 Kaggle 第一个大模型比赛ht</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446553&amp;idx=5&amp;sn=215f9d5cc6e4836b9a3ec9dd1586c88a&amp;chksm=bf309299ff9cd346a5c9c3e2effddb05d4494ecd312f0f5b1e6f248ee108e116fad8783b579f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 02:07:37 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen2.5技术报告解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJvwxS6MT3ic26SA7vcz0fGkbjKz6AFRvHca6UUH7TBWtlhIJqkjQI2sdK18VzcOez0IbWajXOVnkQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：包包算法笔记这两天Qwen团队发布"Qwen2.5 Technical Report" 的技术报告，下面对该报告做了简单的概括，希望让大家有个快速了解。链接：https://arxiv.org/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446547&amp;idx=1&amp;sn=b005dc62fbab891b71300d41be28a938&amp;chksm=bf8b014d1b1b6bbcca6c37eed38737278552fdc70099348ea385166f4593bef644eb877a26c7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 07:10:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[对OpenAI o3模型的看法、思考与反思]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/nW2ZPfuYqSJvwxS6MT3ic26SA7vcz0fGkUibdxIeic0Pd9IYSWuicl3Qx6O9gBh9IJnfqwv2NMf7bwicrRdhYakjq3w/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：https://www.zhihu.com/question/7416922570/answer/60763494897o1 刚出来的时候，很多人还质疑这还达不到 AGI（通用人工智能）。o3 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446547&amp;idx=2&amp;sn=d66decf5b3c47382f1c5b1763a640460&amp;chksm=bff48b609e8f67c194e9b5ea3844fa9bce575e7497d6e668fa7ab0247a5825c269929ff99c23&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 07:10:51 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Qwen 2.5 技术报告发布！其中有什么秘密？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/1FD1x61uYVfVicUEiagTZov6FPIwI4NSkNYMZ5GicM35KLZf0h10wOJEWtibYGcNbtdbHRYKs91icXpxLiaIKA7c7Fyg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2.5 如何成为最佳开源 LLM？Qwen2.5代表了大型语言模型 (LLM) 开发的重大飞跃。最新版本在前几版的基础上全面改进了预训练和后训练方法。通过利用 18 万亿个 token 的庞大</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650446547&amp;idx=3&amp;sn=56459147391365787260c7315318eeb7&amp;chksm=bf075850e0491584121604bc11013913e676d0ad5ecc5888dcee153010d7d7d1c91751956070&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 07:10:51 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
