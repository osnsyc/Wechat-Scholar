<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[PaperWeekly]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[PaperWeekly公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM4XfZEiaIxTZFPcSMe0laHNlkWJfvNVMcFY7PrIPmKrQjg/132</url>
      <title>gh_5138cebd4585</title>
    </image>
    <item>
      <title><![CDATA[扩散语言模型也能强化学习？Meta田渊栋团队用“三明治梯度”打通RL闭环]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmXjic3mrulcvJxjRyImIuahXichictF3MzibxDYZo4NDXahzVoQhgVWQmLGupiaokQcG0e0qFjp5SgCOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>把“好答案拉上去、坏答案压下去”：SPG 用上下证据界把扩散语言模型的策略梯度夹得又准又稳，一口气把四个经典推理基准的榜首收进囊中。一谈到 dLLM（离散扩散语言模型），大家首先想到的是并行或半自回归</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247710130&amp;idx=1&amp;sn=a4680aada0dbf3f8075b44f211a70477&amp;chksm=97a04161ebfe870bdbb5b1c686851c1a3930fdf0a30edf66a9a57a9e80b8bd0b329f8ad48ebb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 20 Oct 2025 13:50:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 仅用20B tokens蒸出SOTA，小模型的「低秩时刻」到了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmXjic3mrulcvJxjRyImIuahoxWbP3NFwADsQowqGHFyPFpibLnvxn5N5vfcd7LmkRjwXCicBRAJUFSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近我们高效蒸馏的工作 “Low-Rank Clone（LRC）”非常幸运被 NeurIPS 2025 接收为 Spotlight。TL;DR：我们通过训练一组 Low-Rank Projection</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247710130&amp;idx=2&amp;sn=110b3173c250c91aaced08d5670ff7a7&amp;chksm=97b2c93ecd26992255ca61156d88c67d773f13f41b3bd607fc387e01b2ea2cd1a043f44c6e6e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 20 Oct 2025 13:50:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[不靠RL、不用训练：哈佛「Power Sampling」让基座模型推理媲美GRPO]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgltCU6hLQ7Unn761xdoicDCibPFCZQs1YoTyiaibZ11kBgJP2tYzP4Tt5XPgWkicDk89w2UUF6LMmUMhrw/640?wxtype=jpeg&amp;wxfrom=0"/><p>不靠强化学习、不做额外训练、不用校验器，也不需要复杂提示——哈佛团队提出的「Power Sampling」仅靠重新设计采样分布，就让基座模型的单发推理媲美 GRPO，还保持了多样性不坍缩。强化学习（R</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709989&amp;idx=1&amp;sn=662c82b94676f67caec12c814d915f07&amp;chksm=976ec84536fd9edc17c0218bd8da1c449efb76f0973a44541bce1757d261f3049fd15f12d639&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 19 Oct 2025 12:35:27 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[不用微调！像打方向盘一样“操控”大模型思考：Steering正在改写推理范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgltCU6hLQ7Unn761xdoicDCib7ibuevuPttsZ75NUG0cy8GeegricuTp7JiazeoibcYpZeia7zSRFRsB9WVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>过去几年，Prompt Engineering 通过设计提示词引导大模型生成答案，而 Context Engineering 进一步强调优化输入上下文，使模型在推理过程中获得更多相关信息，从而提升理解</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709989&amp;idx=2&amp;sn=3d7969df56fc2978cfd51ad02842950a&amp;chksm=975305268e42965ef458478f3c90ae3a9707dcc54794b05b871962bb8ad9a7f58f5e4cbd21ab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 19 Oct 2025 12:35:27 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[First Try Matters，不是Aha Moment：邴立东团队揭示推理模型靠首答，不靠反思]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmiaDAKH30ztic2HaDCSLWCeOdNqsBlU5HUlUvgTFFQG4eSic7jTIBpNSAp4TiaAnDltVcI1g1R3TKNEw/640?wxtype=jpeg&amp;wxfrom=0"/><p>长思维链没那么神奇：推理模型中九成“反思”只是重复确认，真正决定结果的是第一个答案。邴立东团队系统量化发现，使用有更多反思的数据训练能让首答更准，但推理时截断反思几乎不掉分，却能显著节省 token。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709914&amp;idx=1&amp;sn=cd92d41d97423892cca87318f049dc68&amp;chksm=9785c62ca0390450c88974188230114b2142e1b05e3090eb5294cebd9870432e86376f7057ec&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 18 Oct 2025 18:39:03 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一致性轨迹强化学习登场：上海AI Lab让扩散语言模型实现全并行少步数推理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglucskhct50hCAg0BZibMhVpT0NkpwevVtFPDe1LS6NDwqQFic2mePqlcz4euO8CXCxLic5hdDnYcnOA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由复旦大学、上海人工智能实验室、上海交通大学联合研究团队发布最新论文，提出了一套针对掩码扩散大语言模型（Masked Diffusion Large Language Model，MDLM）的解码策略</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709914&amp;idx=2&amp;sn=bd7b5b05568e7c21aead7f76dca6e3b5&amp;chksm=974941642eacb362eaee256f38ad3ebcd541d5c33856e2bfcd0a013ac6a4e9b37f963dc90090&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 18 Oct 2025 18:39:03 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[早鸟票倒计时2天！全国大模型智能生成大会：推理、多模态、智能体前沿集结]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglucskhct50hCAg0BZibMhVpKicJLjublWPH7oQo6U0CuiaVkb2gIFzwKJmicehzibuMFkBql8DSZia7a4A/300?wxtype=jpeg&amp;wxfrom=0"/><p>会议简介全国大模型智能生成大会（LMG）是中国中文信息学会（CIPS）大模型与生成专业委员会的旗舰学术会议。LMG是国内外大模型技术精英最期待的年度盛会，是极具行业实践的专业大模型交流平台，共同推进大</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709914&amp;idx=3&amp;sn=a6f13d60691986d5b528c554d56842ff&amp;chksm=97c89f7f3ef93b291e404324b4a28b348a2c86ccffad99c810b77f05c6de8545f68db5cc172c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 18 Oct 2025 18:39:03 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta花了420万美元、烧掉40万GPU·小时，只为验证一条Sigmoid曲线]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmiaDAKH30ztic2HaDCSLWCeOSb7Y4l3XrAHSGZK4eXISpSxMbLeEvfVXWgNbcZpkLyHw7zqG3pibghg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Meta 花了 420 万美元、40 万 GPU·小时，只为验证一个大胆猜想： 强化学习的结果，其实在训练一半时就能被算出来。在大模型时代，烧钱的研究已经见怪不怪；但当 Meta 的论文承认——这项实</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=1&amp;sn=2986fb95731ad97b3c473dad0bec0ad1&amp;chksm=979e9a7e23d6523beb3ddb259ed5ce07b5f8d24e7fe69782346c8f202c9c1707564d6d0b0ba6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 17 Oct 2025 17:13:39 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从会画画到会思考：快手可灵提出T2I-CoReBench，最强模型也难逃推理瓶颈]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmiaDAKH30ztic2HaDCSLWCeO8KfLnA37SLkoxsFibOsGEzM6qF7PbtMRuXdiaVN1Yof0hZwuuFYIEvDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>文本生成图像已从“能画出来”进入“要想明白”的时代。快手可灵团队发布的 T2I-CoReBench，用 12 个维度、1080 个高难 Prompt 与 13,500+ 精细化问题，首次系统揭示 T2</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=2&amp;sn=edc4e24618bcb27adb5a47705b58122e&amp;chksm=97a0bd22f80f86b5edede326d7b46c2090417502185631ee85c26e5f5168c6501ae643ae3f46&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 17 Oct 2025 17:13:39 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 上交大提出MM-UPT：多模态大模型的“无监督后训练”范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmiaDAKH30ztic2HaDCSLWCeOq2O8AySBooORbyT6yib2IIMGhZ7cHKMwsmfQmhdTgUa9w9VhgIzWhtQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>自多模态大语言模型（MLLM）问世以来，它们在图像描述、视觉问答等任务中展现了惊人的能力。为了进一步提升模型性能，尤其是在复杂的多模态推理任务上，学术界和工业界的主流范式是监督微调（SFT）或强化学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709834&amp;idx=3&amp;sn=3eb8d617efd73692807b3dcfcd2e9173&amp;chksm=97322c0e8508cf73cc6b82c768dabdfa763dd70018010bc2e4bb945e86e500db1819e802a8c0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 17 Oct 2025 17:13:39 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[GPT越来越保守？斯坦福Manning团队提出Verbalized Sampling，让模型重新“多想一点”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmss4sI1bMib5niaDemCicIebfYY2mHND5Ys4RFqtZib4XBjczm2GIaFzEQBPjdViaTRFFiafiazyjuf4r5Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>当我们发现 GPT 的回答越来越相似、越来越像在背标准答案时，问题或许不在模型的能力，而在它被人类偏好训练“驯化”成了平均值——它学会了迎合最典型的答案，却忘了自己原本的多样性。过去两年，几乎所有经过</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=1&amp;sn=ee844491802086e5370f59ade2660f4b&amp;chksm=972cfda39598f73270bf53a379c67c0cde279a2f0121db0a3c4c29f35d90d00e927250680b24&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 21:20:33 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL 2025 | 北大提出动态焦点解码：让开放生成既“靠谱”又“好看”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmss4sI1bMib5niaDemCicIebfmEdqnGQWRxPicX5oSGulOcTIgPvZgb5TibI9pVMQpD7JhfzND58QdHYQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大语言模型在开放式生成任务中大放异彩，但一个问题始终存在——生成的内容要么太死板，要么太离谱。固定的随机解码温度让模型陷入两难：温度高，输出多样但容易胡说八道；温度低，句句属实却千篇一律。如何</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=2&amp;sn=01d3eb7ed866386741dc09c025cee31a&amp;chksm=97bf28a196aba62f8e8680827fea5ae7c7c78ead011a416d3e7069810430a2bee927b813a387&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 21:20:33 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[统一高效来了！清华发布RLinf-VLA：把VLA+RL的训练与部署“一网打尽”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmss4sI1bMib5niaDemCicIebf7OTsskytkWSHHTAEKs80iaKrxshGicqEKuA6EriagW8yoIfQyLq90sNJg/300?wxtype=jpeg&amp;wxfrom=0"/><p>前段时间清华大学推出了首个面向具身智能的大规模强化学习框架 RLinf，之前主要是从系统设计的角度出发，介绍 RLinf 极度灵活的系统设计思想。最近，团队加班加点，终于出炉了 RLinf 系统中关于</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709740&amp;idx=3&amp;sn=12d9494b3a7a083f1fc7ecb93f582aa6&amp;chksm=972ae6520f3fceeafdbd31fd1e3207a4c572dbfcdbefeb1b1d7368c9001eec83e7ee082f9f44&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 21:20:33 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[罗福莉担任通讯作者，小米 × 北大联合发布R3：让MoE强化学习从崩盘回归可控]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgktzbRrzSfWazucnPjjiaibOM6fhWLzsoIfIaYsXjZdKWISRdXuZ1ShicavtdRIyGglKicuGXvXUkP7rg/640?wxtype=jpeg&amp;wxfrom=0"/><p>“95 后天才少女”罗福莉以通讯作者身份参与小米联合发布的 R3（Rollout Routing Replay），首次从路由一致性层面对齐 MoE 强化学习的根因不稳，让训练曲线从“崩盘”回到可控区间</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=1&amp;sn=6d3e74f75c7470bb03b88c8181547eec&amp;chksm=979b3e1f3686c78ce185574525223263f3a4d5cabeb9f06bcc5df9fd1fe9f447f6b854135a51&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 13:11:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[下周见！Wiley Advanced主编论坛@IROS 2025：从审稿人视角重塑论文表达]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgktzbRrzSfWazucnPjjiaibOM2buTWiaEdn7alDRjno1XJYFPWPQM7usvHibkuXHvyUrOBzsFvBU8szIA/300?wxtype=jpeg&amp;wxfrom=0"/><p>2025年全球机器人领域的顶级盛会——IEEE/RSJ智能机器人与系统国际会议（IROS 2025）将于 10 月19日-25日在杭州国际博览中心隆重召开。今年大会的主题是“人类-机器人前沿”，将重点</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=2&amp;sn=92ded1a85a67dc0a3ff22e852be6cf78&amp;chksm=971696b69eb731a245068ef10d13322815db0fdd007bbcc996e5782d086b44ff8831fafe5001&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 13:11:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI 2026联合会议征稿开启：大语言模型中的深度逻辑推理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgktzbRrzSfWazucnPjjiaibOMavGEyjQ7icnSU8uav5u1FQfbaCnias7S5VJQjjEDdhshd7FNDzfP4N4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>AAAI 2026AAAI人工智能会议（AAAI Conference on Artificial Intelligence）由人工智能促进会（AAAI）主办，是人工智能领域中历史最悠久、涵盖内容最广</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709576&amp;idx=3&amp;sn=e8efa9061b9d95a57a84d68d313951e3&amp;chksm=972e20c4ddafeec2d49f79ee657e27bdb1b158131d94b100e5184f190351ad4f38f815f32445&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 13:11:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[直到毕业我才懂：原来延期的博士，不止我一个]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnptcgLq3PwJia1E41ARQKAotgpkl6zYa7Aw3pTj8tKEANZ8TYpFkbfRTBicjG5FoOXIUmsDDr0DtCQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近经常收到读者的留言 : 抱怨科研真是太难了，竞争压力大，导师不给指导、不开组会，一年见不到导师几次，对于论文初稿、毕业毫无建议! 其实他不是个例，大家也会有这样的烦恼：前沿顶会、期刊论文、综述文献</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=1&amp;sn=96aa08cfe0b8a33329b77118b54c4e19&amp;chksm=97e2c82c55f73c67f7f4ac15cf27e761947205fa391eb46904cc3a696cd99c055b2800d4369f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 13:48:06 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[让论文自己讲！Paper2Video一键生成论文讲解视频，赶顶会DDL不慌了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnptcgLq3PwJia1E41ARQKAoordmCdWIyjrl6dttTFTNGR1dByiaicWGrbZXicnTaJk9m5afrD8VzA3dA/300?wxtype=jpeg&amp;wxfrom=0"/><p>你以为熬夜剪视频能保命，其实 Paper2Video 才是 DDL 真正的救命药。给它一篇论文、讲者图像和音频样本，几分钟就能生成一支“自己讲”的学术演示视频。想象一下：论文刚定稿，你的讲解视频也同步</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=2&amp;sn=6cf48d217ce13cb68c86b21a4d31a6db&amp;chksm=9760fe3fc159c919b482e120a280eaf488d828d2e900ac3228be777d1044d2059117d2ea2441&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 13:48:06 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[8美元“驯服”DeepSeek-V3.2？Training-Free GRPO把RL成本打到地板]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnptcgLq3PwJia1E41ARQKAoibZgWT5RiaichGEas1ibzJ6LXgvJeSmUOFR6jsooaRibLqVnicQ93KsOwHDQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>强化学习之父、图灵奖得主 Richard Sutton 认为：新一代的智能体将主要通过从经验中学习来获得超人类的能力，而不是仅靠人类数据的监督学习。传统 RL 训练在 32B 模型上动辄上万美元，现在</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709503&amp;idx=3&amp;sn=eede2987d8a2ac7125285ebfb7aa9d1f&amp;chksm=97ea2f858a4b7be142c2ee7a94903869e9ddf7f7ab42430caa3d8d5dbd9c81707dcebca3031e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 13:48:06 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[强化学习再迎范式切换：Sergey Levine团队把目标改写成“到达时间”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglia97KIicNkEPSFfE0NrdRaWsWCOahOwPYgfic29UPC41s7mRNcyicKqx9t62q6g6LxDPTAk2PqAYlDQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>还在把“目标”当一帧观测硬塞进网络？来自 UC Berkeley 强化学习大牛 Sergey Levine 团队的新作，直接把范式翻过来——用“从任意状态到目标的最优到达时间”来定义目标。理论上“既足</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709412&amp;idx=1&amp;sn=0390b456ca4f05ba79aff8983093c33d&amp;chksm=97922d9125a31db63d3ad9be69b2f3a68c984ea39047be7e0d0eee414bea53579f0dc401d84d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 23:23:19 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[如果RL可预测，我们还需要把训练跑满吗？中科大揭示参数更新的线性秘密]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglia97KIicNkEPSFfE0NrdRaWPwYHcWBnYDjTyCuTLCrE7wicichjaHbtJBpHQu9EJNcHXEJggsAuc1ibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>RL 训练真的像我们以为的那样“混沌”吗？中科大团队发现，大模型的强化学习过程几乎沿着一条线性轨迹前进——早期的参数更新就能预测训练终局。 从复杂到可预测，这一发现让 RL 的漫长训练第一次显得“可计</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709412&amp;idx=2&amp;sn=b9fd526b87e266001c746686cb9c2078&amp;chksm=97846e7d9b2d6249d7a3d38764a7178eab98cb18f4bad3a0123710e2ae9000f305d3fb498214&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 23:23:19 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Mamba-3惊现ICLR 2026投稿：三重升级打满“推理优先”范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm4iaLGHibC5k1lnPbRHlKicEaJuicGeawgVIoFlIliaZGvR75TKJeicxGO8skI9DVVo7ZouqSaPVKyW9rg/640?wxtype=jpeg&amp;wxfrom=0"/><p>ICLR 2026 投稿惊现 Mamba-3：一场从数值分析、复值状态到硬件算力的系统重构，线性模型的“效率—能力—质量”三线齐升。在 ICLR 2026 的 OpenReview 上，一篇匿名投稿以</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709332&amp;idx=1&amp;sn=ddf9d96ce773db8bfeb657bbc31e060a&amp;chksm=97e002084ba3d2c4f16d5b620a99b6d81ec5afffa460cb1e09b942e4e3fa18e8b29afdf3edbc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 17:10:52 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[93%成功率！从“改提示”到“写剧情”：STaR-Attack用叙事推理攻破大模型防线]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm4iaLGHibC5k1lnPbRHlKicEaF2rzk1nZxjQ2tIJb9X3vHKavc3w8s4ToZV0DmpwcVWxuBHhEacLjcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言近两年，统一多模态大模型（UMMs）的发展让人惊叹。它们不只会理解图文，还能在对话中生成图像、视频，甚至跨模态推理。一个模型“多面手”，似乎无所不能。但能力越强，风险也随之而来。我们的研究首次发现</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709332&amp;idx=2&amp;sn=5198e465e340d40bd7d1d0f4ec94b3fc&amp;chksm=97d1720f1b10f3dbabae5b14b42e28d87aa13d166ee71580780de379de9d512e626ef74b3ebb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 17:10:52 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Attention is NOT All You Need：让“深度”重新流入时间，而非堆叠在参数之上]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkLoia9bWRdPqiaIqI9fgLNiaNkJ6cEYPFSko7pmy2C5sm556e5qaxrL1pQ2ks5sClCGFfTP4icUnH1Nw/640?wxtype=jpeg&amp;wxfrom=0"/><p>自 Attention 统治深度学习以来，我们获得了惊人的速度与可扩展性，却似乎失去了另一种更本质的能力——在时间中递归地思考、积累与演化。当速度压倒深度，我们真的理解了“智能”的含义吗？自 2018</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709240&amp;idx=1&amp;sn=b68daa95bdd0406571b13544ef598111&amp;chksm=9754037fd37afc47f4952d47c2000536cb8f8eabc4ad18289e2943ab4bfb4169682241010880&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 18:09:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 Oral | 1个Token零成本，REG让Diffusion训练收敛快20倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkLoia9bWRdPqiaIqI9fgLNiaN9yEIjNZ5WdYMice2FIKd4ibjDk7JuUTiaPVa2QicT9r7pebTXticwL9ytyw/300?wxtype=jpeg&amp;wxfrom=0"/><p>只需引入一个 class token，REG 就让 Diffusion Transformer 的训练速度飙升至 63 倍，几乎“零成本”实现了更快收敛与更优生成——这项来自 NeurIPS 2025</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709240&amp;idx=2&amp;sn=9ed18c4649a43f9e81e349cb3115eedc&amp;chksm=97e8cdd079757ccf26a004b199a0f8a23fcad3d4da97b97206fc7843a107b79b310c3f019882&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 18:09:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek苦练1T，清华只用5B？InfLLM-V2把稀疏注意力玩明白了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglEVQhCaFLzicCMcOoibdvBicRzgdD9hvZ0Cialtpd650ELI8R4JYfeV3OW8E195ia9qiahXHvX0sdGwkng/640?wxtype=jpeg&amp;wxfrom=0"/><p>引言长序列高效处理已成为大模型应用的关键。传统稠密注意力在序列变长时计算开销极速增长，直接限制了产品可用性与成本可控性。为解决这一痛点，清华与 OpenBMB 提出 InfLLM-V2：一种零额外参数</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=1&amp;sn=1bb896b549716972279d3ac471bcf359&amp;chksm=9705ab8146b3f09f0514b98329549a043ccd25f21835e5a47817f9b2fbf5cee1f1dd2df3da47&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 13:16:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[EMNLP 2025 | 拨云见日：知识电路分析揭示大语言模型“知识遮蔽”幻觉之源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnmWiaJ0shIAxCHLmh5rQ1iaiavicSWZbicurg3BJmYppzggycCOGpDFHaCJUgKhUtpF70SUgewlkWvGAQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>当我们以为大模型的“幻觉”只是记错事实时，PhantomCircuit 揭示了一个更隐蔽的真相——模型其实记得，但被主流知识遮蔽了。高频知识在神经电路中形成偏压，压制了那些低频却正确的事实，让模型“看</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=2&amp;sn=07bb7ebad5d78b866103c55077c17954&amp;chksm=9720ea25d7253a482355fc252ad94a00b6020fd6210b3d8af4b119069f5b60c6f6b817a636da&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 13:16:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[北京/上海内推 | 阶跃星辰招聘RL for AIGC方向算法研究员/实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnmWiaJ0shIAxCHLmh5rQ1iaiaEkRyYxxPCeQJIFFW1RMSA8P05Tlon0icYWSym9HCoOy71vbvzlw029A/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！阶跃星辰阶跃星辰是行业领先的通用大模型创业公司，坚定探索实现通用人工智能的道路</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709188&amp;idx=3&amp;sn=6327b36bd507a1afa9b860c7d054c060&amp;chksm=97058344e96cb111c6e700eb21435c92ce95648ea0781a00040c35c94413e4d88334d788557c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 13:16:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[马毅团队重磅发布新书：从MCR²到白盒Transformer，重构深度学习的第一性原理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCOVxC5Zh5LftZiccf7BdiaxF6WRn3Bo0mElITp40bhODrrK3BPqhkYjj4zJghfbQLfXgsfA7ic3Kqg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在神经网络无处不在的今天，我们似乎已经习惯了“深度学习就是堆结构、调参数”的经验主义时代。但在这一切的背后，一个根本问题始终没有被系统回答——深度网络究竟在学什么？为什么它们能从数据中生长出强大的表征</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=1&amp;sn=1767c8713d3b394708d56874d46b458c&amp;chksm=973306da948db77086dfce1f2d9548ebcaa79682e47938877727ba68ad2b26b7b9062a57cf96&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 23:48:39 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯推出TRM：让大模型像人类一样批判性思考，从文本依赖到事实正确]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCOVxC5Zh5LftZiccf7BdiaxKsWVTOhDTTE0A9j8bm0GawIU1WKNf7BxufnTBCIxM3iaoqkpwn81ic3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，腾讯 WXG 推出了思维监督奖励模型Thinking-supervised Reward Model (TRM)，旨在提升大语言模型（LLM）在开放域问答任务中的事实正确性。TRM 通过引入忠实</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=2&amp;sn=f27724cd8e3624c59e6f9f5e45049312&amp;chksm=97240904bff7bbd3375606251070cd361b21e7017c676f54587a29a5c0b5ed3102b9fefd6a17&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 23:48:39 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[稳住训练、跑出泛化：STAGE重写「自回归图像生成」的强化学习范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCOVxC5Zh5LftZiccf7Bdiaxia8KFYPBN3ib7d22ibHM0z7a7Jf8TfrvjCIWX6SaicHI34icOgBk6Fiaefnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在扩散模型一家独大的时代，自回归文生图的潜力正被重新挖掘——它拥有更强的离散表征能力，却也更容易在强化学习阶段“失稳”。STAGE 在自回归（Autoregressive, AR）文生图模型上首次实现</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709124&amp;idx=3&amp;sn=8a751a960bcca86dad234fc1f0b601df&amp;chksm=9722e8ceae630e50ac217ff60bf7cbc1e9829dc2d1625dc748138a7f0536bb882eea334d2c0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 23:48:39 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[无RLHF，7M小模型反超DeepSeek-R1：三星团队用递归思考取代规模堆叠]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglNCcMajRxBktBd46thELiciaj3HCiaAyGyB7pIibhogESanibguAquQiapwPurq60MMtiaic6NRKdam7liaeA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在所有人都以为智能等同于规模的时代，三星研究团队用一个仅 7M 参数的微型神经网络，递归式地“先提答案、再反思改进”，在复杂推理基准 ARC-AGI 上击败了包括 DeepSeek-R1、Gemini</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247709015&amp;idx=1&amp;sn=f76680bcd85054ecb02d6d5c5c9c0819&amp;chksm=97b334111ca626844d8a8e6a6b82257f489ed1f0937e6ce539410c95e46a395f496f54f7fd3f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 08 Oct 2025 23:34:27 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别梯度！Evolution Strategies全参微调挑战PPO/GRPO：更稳、更省、更好复现]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmcxy1mz2u0VFP9icMNWEXUUib52iaJKAJMgJ3nMeicfxEQyCM7IA2ia3VVt8HdL1CyBkMnRGsLm2QZ38Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>过去两年里，“后训练=RL”的观念几乎成了行业默认。很多团队把 PPO、GRPO 写进了自己的 Pipeline，并习惯性地在动作空间里做探索与优化。这篇论文则把镜头拉回到参数空间：作者将 Evolu</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708997&amp;idx=1&amp;sn=678f7ce1043eb3fa2b5cd16d1d13ef4c&amp;chksm=97bffd4d98b27ef9c4bf708eb4ede7e6cbcfb0ad8b4eb5db8c7d4c98f7ee2e94bc5da8042386&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 07 Oct 2025 19:03:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 北邮用“图+文”把人物检索拉满：自动合成数据 × 细粒度特征对齐]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmcxy1mz2u0VFP9icMNWEXUUfYdWGmiboAHdItvmPnic1ZJWXxUUicNWibuHbSMTBOqFvAKXofRyX8YaxQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在智能安防、失踪人口查找、公共场所人员溯源等实际场景中，我们往往需要结合「目标人物参考照片」和「文字描述」定位具体个体——比如用失踪者过往生活照，搭配“近期穿灰色连帽卫衣、戴黑色边框眼镜”的实时描述展</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708997&amp;idx=2&amp;sn=e2ffabb360e6926bcdf5fad776066335&amp;chksm=973131742549963c06489b989ad2f50c3efe0a7edd18348c8456ef7c728857696d4197afcc6f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 07 Oct 2025 19:03:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[自进化Agent的第三种可能：隐式记忆，不动模型参数，胜过GRPO]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmWoQgricShzibiaMj2GZnAve5KM1wwuHTcVd2YaUZjBKIFAjaZshaicEzxjGozRlAOuEOR2KlmADibGbw/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前，由大型语言模型（LLM）驱动的智能体（Agent）正引领着人工智能领域的变革。然而，智能体的记忆机制——无论是强制调整模型参数的“参数化记忆（Parametric Memory）”，还是将经验外</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708957&amp;idx=1&amp;sn=4735d66301277b6b2dd1c0e4ac4a2d27&amp;chksm=972380b57c4d7e5aa092fc0fd3de67c014e87c4f3a9a517675baae6ff43f91f3916d1ebe2ea2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 06 Oct 2025 20:04:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[真实数据、全链路、可复核：GenoMAS打造更可信的基因分析智能体]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmWoQgricShzibiaMj2GZnAve5Fyr7iaKcibiaqU8Ya1vSYUuR4x9W8DaDBO95kb2icCU4RJClvQ1KkGUEyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在科学研究越来越依靠标准化精密计算手段的今天，用智能体技术来自动化加速科研的潜力让人心潮澎湃。但在现实使用中，无论是 Cursor 还是 Codex，这类智能体多作为辅助工具存在：每推进几步，仍需人工</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708957&amp;idx=2&amp;sn=ddf2cb465568896a1916926307cfd8bd&amp;chksm=97ea518e804ff25209298445972841b5b4ca00fa2bc1d34fb8664d4373e6dc24e87ac77ccdf0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 06 Oct 2025 20:04:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[LSTM之父再出手！xLSTM挑战Transformer：一场关于Scaling Laws的正面交锋]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgn2GBibNuSibHn4v52LddGYibE1l47pyicGPsJ60jUbah66vAlZRNDkDOY3Xp2H02RwW7Fpm85R0fXL0A/640?wxtype=jpeg&amp;wxfrom=0"/><p>近三十年前，Sepp Hochreiter 与 Jürgen Schmidhuber 提出 LSTM，彻底改变了序列建模的走向。如今，Hochreiter 团队将目光投向大模型时代最关键的问题——Sc</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708918&amp;idx=1&amp;sn=d0637133a0ed6cfccbb233468a1997bc&amp;chksm=9774a5ca1ccee1b58453103989716b4ffc54742c395fb024763d2085b8cffaf05fa9f659f3d2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 05 Oct 2025 20:11:50 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | AI也能做数学建模？本科生携手MM-Agent勇夺美赛全球前2%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgn2GBibNuSibHn4v52LddGYibEmI7uneCHm9rwHzznGSnGLy8YsqyX6dNHMrWBTbiaicUvibMeaO6oLAnWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>数学建模，是科学问题从“复杂现实”走向“可计算抽象”的桥梁。它需要严密的逻辑、深厚的知识与大量的推理——这正是人类智慧的堡垒。而如今，来自香港科技大学（广州）的研究团队用 MM-Agent 敲开了这道</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708918&amp;idx=2&amp;sn=9f36e3ca4dd945bbef947b744ed0a960&amp;chksm=97a9b111319930c51c996e7bf858c95d2184f9f78dfb10641659ee991099f01b3a589998cc84&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 05 Oct 2025 20:11:50 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[“移步换景”一试，大模型全乱了：OST-Bench揭示MLLM时空推理短板]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgn2GBibNuSibHn4v52LddGYibEbysrlpFVEuNwUWiaMtSlbztrsLSqXV3Pbd1y5rAnIibo9eDsN0nfuY6A/300?wxtype=jpeg&amp;wxfrom=0"/><p>多模态大语言模型（MLLMs）已在视觉与语言模态融合的感知与推理任务中展现出强大能力。而上海人工智能实验室提出的的 OST-Bench，则是从智能体探索场景的动态在线视角出发，为大模型的能力提出了新的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708918&amp;idx=3&amp;sn=2a67809b53677f80ed8b83c69b510eb7&amp;chksm=97d2c956fe56609b2e067c2f9a5f47ea2a6c04e075907772d1195137cc75272ce5bf2aa8901f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 05 Oct 2025 20:11:50 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[LoRA到底能否媲美全参？Thinking Machines用实验曲线划出「无悔区」]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglEVQhCaFLzicCMcOoibdvBicRo6UanDIaE373okE1hOJnIu423HG11lvs0T0rk0hmW6mHnx6ibicB6mhg/640?wxtype=jpeg&amp;wxfrom=0"/><p>打平全参，还是效率掉队？这是围绕 LoRA 最大的争议。Thinking Machines 团队通过系统化实验与工程级配方，首次证明：在后训练的典型规模下，LoRA 并不是玄学调参，而是能被科学刻画、</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708821&amp;idx=1&amp;sn=197e68d3bb1474e1a7bd501b9a44ead0&amp;chksm=97bafc26d28cf6231a55ad28b126a5e9b420325a7b92436fdb11591fca869934910db2a716b2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 14:02:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[把“俄罗斯方块”搬进设计室：物竞天择让振动微型机器人进化得越跑越快]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglEVQhCaFLzicCMcOoibdvBicRunlkRgr3mW0FegdjsibJlcODV5woGNhVRAXC7QjAUEnYEg519Y9Z19Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>“玛娜生态，末日废土，跑得最快的噬极兽。”在《灵笼》的世界里，谁更适应环境，谁就活下来——“跑得最快”的物种在废土中率先突围。现在，科学家把这条自然法则搬进现实的设计室：把俄罗斯方块当作可拼接的“器官</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708821&amp;idx=2&amp;sn=01fd726c0fbcd4bfcab4b384d0f53666&amp;chksm=97118582a627400cee81c086fbdc9c9969830740340457fcf8e0d2e670ec381821bc02cf8852&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 14:02:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[榜一换人！OCRBench v2九月新榜：揭示多模态大模型文档智能真实水平]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglEVQhCaFLzicCMcOoibdvBicRL57GhrgYA6LzbZ87FhA6yxcvEO57umYB8GTubx9N1U7Z1I7NGeIWRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>现有多模态大模型（LMMs）在复杂多样的 OCR 任务中表现如何？华中科技大学、华南理工大学、阿德莱德大学和字节跳动联合推出新一代 OCR 评测基准 OCRBench v2，并发布最新私有数据榜单（2</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708821&amp;idx=3&amp;sn=0f432df41857a7ee9c3925bbcceff53f&amp;chksm=971a01f58525bdec73bf69cd278876bec43a360e6b11f838cd4bde244f1fee478f1aa9a3ab52&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 14:02:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[4B逼近DeepSeek-R1！Bengio团队「递归聚合」刷新小模型上限]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglDMV4P7ibpu6yrokwbhia8mz4yia3ibSfF3WfUE11pWEt6RJkhjswnlichff25DA2GwgAQKbOjucicGUHg/640?wxtype=jpeg&amp;wxfrom=0"/><p>当“并行分叉”和“逐步自省”不再互斥，Recursive Self-Aggregation（RSA）像一台“思维基因重组机”，把多条推理链里的正确片段拼成更强的解题方案——甚至让 Qwen3-4B 这</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708756&amp;idx=1&amp;sn=023fa291c2258218b129d02932e23633&amp;chksm=970d0cc5ac646877cbdd717763f2937fbac62341ae2a72f1feb12c242d4161420d0780525cd5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 14:30:49 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[KDD 2025 | 看不见也能控：用“基混杂向量”打穿分布移位，交通预测稳了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglDMV4P7ibpu6yrokwbhia8mz3A9rNPyHJjG0LGmdicZVK4pkUuiceib3aPiaspQqGQUvJIYYVGAqqjuDibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>北京航空航天大学联合香港大学提出了基于因果建模的时空基向量表征模型，首次将后门调整原理扩展到连续与未知混杂因子，通过构建基混杂库、自监督任务增强表示，并结合因果解耦机制，实现了在复杂城市场景下更准确、</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708756&amp;idx=2&amp;sn=5d5594beecbecda82d3f380fa14dac2e&amp;chksm=97089cbf009b6129e2ea4c75b44f70728c3a85de9065c880b140b6c09eab575c84f608985a50&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 14:30:49 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[北京内推 | 快手可灵AI技术部招聘视频生成/数字人方向算法实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglDMV4P7ibpu6yrokwbhia8mzicsunuTobz2NHWBJU07iaEKP78ZI5WZu97icvuJOn12TrkyYyEFx38wFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！快手可灵AI技术部负责生成式AI模型的研发和应用，构建超大规模 AI 基础设施</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708756&amp;idx=3&amp;sn=5f48cc8518cd1af8171efa7b5337b2ce&amp;chksm=9768c9c516a6cf0e5189a6c23e5ec4686a30f255893baeb9c586a0ae329d81975c3c9e70d33d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 14:30:49 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[8GB显卡的逆袭！SSD换显存，3060 Ti硬跑100k长上下文]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkgXNRg9KtYmuHuVwIfWFWO0c9ZEk064fW5QZnDB3t8vibIiciaLMwg3vLaChea355A3qCBnNmicSgL8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>在大模型推理的世界里，有一个残酷的现实：上下文越长，钱包越痛。你想在 10 万 tokens 的文档里挖掘知识？对不起，先准备一张几十 GB 显存的高端 GPU，再外加一台服务器的预算。长上下文能力明</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708717&amp;idx=1&amp;sn=5cfb54e7fce4c6ebf223ebe668402975&amp;chksm=9797699f76cda0b4b640a34e1d3f3dbf5f7d099f16bd34ffac938f450f386a8e923b7b5ba790&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Sep 2025 13:34:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 我奶奶都能复现？条件表征学习：矩阵一乘，表征立马“对齐”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkgXNRg9KtYmuHuVwIfWFWOaluZHGKgVTyprg8sQClp4h3p2VFAOZmgicnPoUVeNb7O7zVibadCt4KQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>还在为表征学习只看见“表面信息”而头疼吗？在电商、搜索、检索等实际场景中，我们往往需要的不仅仅是“这是大象”，而是包括环境、颜色、材质、场合在内的多维信息。但传统方法往往只能给出单一标签。本文提出的条</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708717&amp;idx=2&amp;sn=c2144a00e3bbd5d2d4db59976a3f1236&amp;chksm=97df5fd2aa053394baa94dee4498de9c45eb2a6d3cdf2dfc39ba130556cdb6496bffedf197c5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Sep 2025 13:34:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[北京/杭州内推 | 阿里通义实验室招聘多模态大模型与智能体方向算法实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkgXNRg9KtYmuHuVwIfWFWO8u3yEwX6JfJGB54Gia8icM16ybw5UYUFseS1Q5LKIGKarNQcD240GTag/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！阿里巴巴通义实验室致力于AIGC、大模型基础研究和行业应用探索，在视觉、语音、</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708717&amp;idx=3&amp;sn=7f61d03daa3391ca2e9db934c082637b&amp;chksm=97a02691572796b5e79d660ddde3c36eb14c9cf3ee091f00fe92120113adbe0d4b384d80ff12&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Sep 2025 13:34:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[普林斯顿陈丹琦组新作：RLHF难支撑，RLVR有边界？RLMT开辟第三条路]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglS4qOGd9Db5eeUicUy83LrlQ6xAjtBM3pvkJqSTIyNLsumYgP8Loo6tB3JXDvB5Seyglo9oLI3hzQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在大语言模型的进化史上，RLHF（Reinforcement Learning with Human Feedback）无疑是最具里程碑意义的范式之一：它让模型从“机械对话机”蜕变为“人类偏好的镜子”</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708669&amp;idx=1&amp;sn=c8c264e881e8ce83db14bcb2c17540a6&amp;chksm=97d2b951f78b94383aaaf30b1a7c8224217c4d0ae097a5434d4d29ee8a59a898009fd799de22&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Sep 2025 17:34:56 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[128k死穴被击穿！Amazon爆改长上下文：段内压缩快4×，推理不掉点还更准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglS4qOGd9Db5eeUicUy83LrlwkATkNs3BcDhsmph4QLibficVzG4iaxbbOfnxlVYYCIL66icFX5xrQmOrw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在大模型的发展历史上，「上下文长度」一直是横亘在研究和应用之间的最大鸿沟之一。无论是百万行代码的全局理解，还是上百页文档的精确问答，当输入序列超过数万 token，现有 LLM 都会遭遇同样的困境：计</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247708669&amp;idx=2&amp;sn=0daaeb325ee10bb898d37642297433a7&amp;chksm=97b9e6af695860ae69a6197f4cd2d86e8ac52e625d80330d744180e9dd755d519f43650c3522&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Sep 2025 17:34:56 +0800</pubDate>
    </item>
  </channel>
</rss>