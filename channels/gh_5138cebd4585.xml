<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[PaperWeekly]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[PaperWeekly公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5138cebd4585.jpg</url>
      <title>gh_5138cebd4585</title>
    </image>
    <item>
      <title><![CDATA[大力出奇迹失灵了？ModelSwitch跳出采样黑洞，改写大模型推理范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmfwFQ1nvBRCswSllP0AKC1YOar6ue33eSJiaAj8iaud35jKdPShvWfOp4icI2zUYYVZ1xhF4sickIGDQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在大型语言模型（LLM）飞速发展的今天，如何进一步提升其性能，成为了研究者们关注的焦点。现在许多工作基于“重复采样-投票”框架在测试时进行大量采样以提高回答的准确性，有时一个问题甚至需采样成百上千次，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704594&amp;idx=1&amp;sn=03e882e4198653c338bdca35cd828c8f&amp;chksm=970b791bed4f82393c9f78ba55d5c7a8d693f1aa0037bff840d40181521737185512f9b8e98d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 16 Jun 2025 10:06:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL 2025 | 数据多不如风格齐？SCAR精选<1%样本，指令微调效果飙升]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmfwFQ1nvBRCswSllP0AKC1vTxyYTbtpEmOh34AFIkU6axGmSFNJicOEBsic5fYHjoN7e1uW8ia9eD6A/300?wxtype=jpeg&amp;wxfrom=0"/><p>总览这是 RMIT 大学、新南威尔士大学和莫纳什大学联合发表的论文。这篇论文提出了一种新的数据选择方法 SCAR（Style Consistency-Aware Response Ranking），旨</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704594&amp;idx=2&amp;sn=c1bc5387d6cf817fed874430bb109095&amp;chksm=97e0488a4ca0e07eda5f51b816081bfa3a7979c2d887627b50323e5a5e3e92019cb87c719a5e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 16 Jun 2025 10:06:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从“比像素”到“懂语义”！Video-Bench实现视频质量精准打分，突破73%人类认同率]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmfwFQ1nvBRCswSllP0AKC13NtibchQhloiaeo1iakENetOL8HeUeGq4GGGlGaZkr6vibiaicLsjsia5x1lg/300?wxtype=jpeg&amp;wxfrom=0"/><p>现如今，视频生成技术正以前所未有的速度革新着我们的视觉内容创作方式。从电影制作到广告设计，从虚拟现实到社交媒体，高质量且符合人类期望的视频生成模型正变得越来越重要。如何准确评估这些模型的性能，确保它们</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704594&amp;idx=3&amp;sn=1e7a9db4ef0c1cd7905f8996e219387f&amp;chksm=97fbeb2826a965737f239cc82a4bc5380b3ab5d42137f9988b7e1a5234122f405b0ac39f2cae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 16 Jun 2025 10:06:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北京内推 | 小米汽车自动驾驶与机器人部招聘感知算法实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmfwFQ1nvBRCswSllP0AKC1tdnsuicn2zjvOa3uIVtJmyYicstvzF7sNDO9wO2fVia7dEz6y9ftdIwsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！小米加入我们，驶向未来！小米自动驾驶团队致力于打造世界领先的辅助驾驶体验。我们</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704594&amp;idx=4&amp;sn=f917bc67e2e67242f8dfb85b40cfdd02&amp;chksm=974fa2545e34aa4da3b768ed2f6c287e64ddbc4e31a8285554dda79937c7abc2b33ad2491972&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 16 Jun 2025 10:06:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | Agentic时代唤醒NAS"第二春"！智能体超网动态组队，推理成本暴降55%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgn0FDaelq7HqtBmsHk6Zy8Kftb3iaiawEvibgtFmW4c4iacCxLu0mGU37qAlicy3QCCWPvz0Oytx06Fs7A/640?wxtype=jpeg&amp;wxfrom=0"/><p>在 AI 的浪潮之巅，大语言模型（LLM）驱动的多智能体系统，正以其强大的协同能力，不断刷新我们对智能的想象。但一个痛点始终存在：构建这些复杂的系统，往往依赖于“炼丹师”们大量的手动设计和调试，这就像</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704523&amp;idx=1&amp;sn=124c1f1269b344d2d5b4e1f19c7023de&amp;chksm=97f1ad35afb2726c7268019db93a6289e10458090aacf82a8f6adf1ea602687f6bdc4060c0fa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 12 Jun 2025 04:33:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Image Caption复兴宣言！南大港大CapArena重塑「详细图像描述」评测体系]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgn0FDaelq7HqtBmsHk6Zy8KP3IBSTeqIpQcstk8IwszqLo5PFOVlD5UcrDgkoKvW6rJZuzbsKPFVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>图像描述（Image Captioning）是多模态学习中基础且重要的任务，随着 LLM 时代模型的发展，现代的视觉语言模型可以生成详细而全面的描述。然而，由于评测的主观性和困难，当前的视觉语言评测往</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704523&amp;idx=2&amp;sn=7fd196c4d19f8fb2079c816204ec5c43&amp;chksm=974748726e9598b1ce714915001ac6fe777a16a1213af22a4db8849295eed7cd75d6fc7b6396&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 12 Jun 2025 04:33:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[视频理解“隐秘的角落”：多任务视频文本理解评测新基准VidText发布]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgn0FDaelq7HqtBmsHk6Zy8KRP2sDIyvzVOtSt0LgxuvIY2YxiaW3Zia4m7G9icib5wGtnMaeWmfCOm5Fg/300?wxtype=jpeg&amp;wxfrom=0"/><p>视频理解是通往 AGI 的必要路径。当前视频理解的探索主要集中于视频事件内容，人物动作，关系等。然而，嵌入视频中的可视文字却往往被忽略。从视频字幕到场景文字（街头招牌，道路指示牌），这些视频文本对于推</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704523&amp;idx=3&amp;sn=d8a54d5de185d32457b1bdb782bbd87e&amp;chksm=978a772aff85c9070cf220f3819a7fbfaaedf242c2a94b65f9cdc9ea3963ce26666ca84986e3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 12 Jun 2025 04:33:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[博士申请 | 上海交通大学人工智能学院刘松桦老师招收视觉生成方向博士/硕士/实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgn0FDaelq7HqtBmsHk6Zy8KRGnFBNHc59HSoia3G7eu3jXiatE9d3dfyVicicAH4eHng89oXibecNFaFIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！上海交通大学上海交通大学人工智能学院（https://sai.sjtu.edu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704523&amp;idx=4&amp;sn=44b7296403b38e93acc397eea7ca8a44&amp;chksm=97bf09a1957ca47a3a125948b585b56fc4bb1a245e5ea95ddd98666b5dd05d56ae41ec115066&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 12 Jun 2025 04:33:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[建议所有博士都去学一遍，赢麻了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkuGXN6N2CWGxPoJLO97ibzXUECGEsbta24cOApdf87vejR9tppcK8bc6OC5FiaTyMH6gUTyGkxabVQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>搞科研，最怕的就是每天“眼睛读文献，脑袋想方案”。以为只要文献读的够多，准备就足够充分，就能找到好选题，写出好文章。实际上是在用“勤奋读文献”掩盖“不敢开始干”的焦虑。过来人都知道：科研成果是干出来的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704458&amp;idx=1&amp;sn=d33df4972afd4b439231534019ae69c5&amp;chksm=9716e07a1595a246894fbf78a5d3c606fa1b3c7375a4149f4dbba7b491f0d8f59847640f3ab7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 04:31:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL 2025 | 多维阅卷，智识觉醒：打开多模态大模型看图写作评估的认知之门]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkuGXN6N2CWGxPoJLO97ibzXkxtgZoG46ibmOJeJkah6yE4YnbS1yNbDFlAA5DAxKJkRd9yQiaJ2KjKQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>研究背景：线上文章评分与MLLM的新机遇自动作文评分（AES）是教育评估中的重要技术工具，能实现对大规模写作的高效、稳定评分。然而，传统 AES 实现存在三大缺陷：依赖手工特征，通用性差难以评估细粒度</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704458&amp;idx=2&amp;sn=178c8b9e412e642dd364d994ea3ce283&amp;chksm=975a37fa89a5550501ce0acd044d6ecaa1b77c9623006b32da2bd49653c8769b674ff15ebbaa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 04:31:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[视觉感知驱动的多模态推理：阿里通义提出VRAG-RL，定义下一代检索增强生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkuGXN6N2CWGxPoJLO97ibzXl709FicASSgAJzXUlxAcv1YvuF31A5AWoR7ibnBW9HxgHTB2cjU8W65g/300?wxtype=jpeg&amp;wxfrom=0"/><p>在数字化时代，视觉信息在知识传递和决策支持中的重要性日益凸显。然而，传统的检索增强型生成（RAG）方法在处理视觉丰富信息时面临着诸多挑战。一方面，传统的基于文本的方法无法处理视觉相关数据；另一方面，现</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704458&amp;idx=3&amp;sn=4eddba0a4dd97ad7c0d0de617f9f2048&amp;chksm=9713fce6f1692e6215a39c74a36eccb8bd9eccd55baf2de0d0ac956a4c1c098869338b89478a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 04:31:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北京内推 | 字节跳动Data-电商团队招聘大模型算法实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkuGXN6N2CWGxPoJLO97ibzXkdE6ibBal9TT6TEt6iayEI4icvSdfTK4AbE04yR18uFMaCxicSkFHUicqHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！字节跳动Data-电商团队，负责电商创新项目的算法和大数据工作。依托于字节跳动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704458&amp;idx=4&amp;sn=896d490f1ba26b716d4dc12929f71811&amp;chksm=97a1fc01daa86b4c656583a0599dae9d2562ae076c51d36cc541bdd23576bc39a960de62afcf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 04:31:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[端侧模型卷王诞生！MiniCPM4长文本推理提速5倍，0.5B模型屠榜同级]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkuGXN6N2CWGxPoJLO97ibzXbC0G3XkA63QYud9OketPpbeN13iaibflRJicZ5s1FBZVAfW48Vj6hZl7A/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025 智源大会，新一代「面壁小钢炮」 MiniCPM4.0 端侧模型发布。一款 8B 稀疏闪电版，带来端侧性能创新式大跃升；一款 0.5B 实力演绎以小博大，适配广泛终端场景。MiniCPM4.0</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704418&amp;idx=1&amp;sn=648876b5c5700f26b69647d74a886bb4&amp;chksm=9754ddf681bd415344be6a0928ad80483cccbc1cb5168f8ebcabc7730e5484f65bbacb62e3a7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 05:45:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | 不靠复杂架构，经典GNN再证图级任务强基线地位]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkuGXN6N2CWGxPoJLO97ibzXynRALwsZMG3J5d55De7oNlpR472IrrE8Z125z6nG0Bqr8PaIEowPNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>继作者团队此前对经典图神经网络（GNNs）在节点分类任务中的研究 [1]，本研究进一步探讨了经典 GNNs 在图分类与图回归任务中的潜力。为此，本文通过提出 GNN+ 框架，将六项常用超参数技术（边特</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704418&amp;idx=2&amp;sn=2efe8df843d23e7d476be93353aee8a5&amp;chksm=97668b0842f46380010014a34f53c53f12b0759dc3affc33116ca0a854565770bf5bf33a3ab8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 05:45:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[地铁换乘都搞不定？ReasonMap基准揭示多模态大模型细粒度视觉推理短板]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkuGXN6N2CWGxPoJLO97ibzXQFRJeLnC8MMzDGIN8AaX4sHCledicS2v8TUMOxF4cLC8bmL9z176w8w/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大语言模型（LLMs）以及多模态大模型（MLLMs）在多种场景理解和复杂推理任务中取得突破性进展。然而，一个关键问题仍然值得追问：多模态大模型（MLLMs），真的能“看懂图”了吗？特别是在面对</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704418&amp;idx=3&amp;sn=4a60a26108b67b87efb319448fab53a6&amp;chksm=970e70b9d9e0d053123f7038dae5aaeecf768abb8ea0c4c972261b6482bf08306454a3c68436&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 05:45:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[博士申请 | 纽约大学（上海）计算机系谭桥宇老师招收LLM/MLLM方向全奖博士生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkuGXN6N2CWGxPoJLO97ibzXkiarNYwPIxu5XPfla1tWjWibAWWcgsicbUnAARp0IJOEfvaj42SuyibRNQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！纽约大学（上海）上海纽约大学（New York University Shan</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247704418&amp;idx=4&amp;sn=32680cbfdc10294ce56f0867a00c0466&amp;chksm=978f823e2a03d6efa6d4f68bfea7cb8543116fe3f3a7233ec32fb0fcad00c9eb28c7b1a4ceef&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 05:45:13 +0000</pubDate>
    </item>
  </channel>
</rss>