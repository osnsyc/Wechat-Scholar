<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[PaperWeekly]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[PaperWeekly公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5138cebd4585.jpg</url>
      <title>gh_5138cebd4585</title>
    </image>
    <item>
      <title><![CDATA[模型崩溃自救指南：5行代码实现TTA鲁棒性飞跃，天大×腾讯开源COME方案]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkeB30N9LGck7J9zuv43BhZ1O9SoVibsrBmbZbe1Dib5312O7tS4HcCTLicchD4PQ40k5jXKgFc6lM1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>研究背景机器学习模型在诸多领域已经取得了显著的成功，例如图像识别、自然语言处理和自动驾驶等。然而，许多机器学习算法依赖于一个限制性极强的假设，即训练数据和测试数据的分布是相似的。这一假设在现实场景中往</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703131&amp;idx=1&amp;sn=f17c5f83bbbed2a76e686d7b060c3fb6&amp;chksm=977c87dde860af10ed0942e2bf8256c2860e40f8bf457eba35a3dada6084bcd6ebf0816f371c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 06:03:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[RL训练总崩溃？R1-Reward稳定解锁奖励模型Long-Cot推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkeB30N9LGck7J9zuv43BhZziaqOWa0YBRppObWR6h7MicmdYn5XmowaQKJBUWF33HMnJUI5S6sKq9w/300?wxtype=jpeg&amp;wxfrom=0"/><p>多模态奖励模型（MRMs）在提升多模态大语言模型（MLLMs）的表现中起着至关重要的作用，在训练阶段可以提供稳定的 reward，评估阶段可以选择更好的 sample 结果，甚至单独作为 evalua</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703131&amp;idx=2&amp;sn=8dfd2d349790d818855f4178889f94f9&amp;chksm=97605c6db7cefebfd20eb823d075b2bab45c7021315386e48576f29798a9da3fa72d70860c5e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 06:03:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 单图生成3D人体：港科广团队提出分层高斯建模框架MultiGO]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkeB30N9LGck7J9zuv43BhZBsCJHMCiaicTah0UdVxym1TNkibGFhLGz0pmiaXHMXvhVichLcpc2mCbEuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>从一张照片重建出逼真的带纹理的人体 3D 模型一直是计算机视觉领域的难题。港科广团队提出的 MultiGO 创新方案，通过分层建模思路破解了这一挑战——将人体分解为不同精度层级，从基础体型到衣物褶皱逐</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703131&amp;idx=3&amp;sn=3d7147488542adb7e8a2ff0ba119d665&amp;chksm=97bca98bebf11b7769243aae40931c0c1954fd45201f5aaaaf1a3c3dff146c3c1882c71c69bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 06:03:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[博士申请 | 复旦大学智能人机交互实验室招收2026级硕博生（夏令营/推免）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkeB30N9LGck7J9zuv43BhZAKjfRw9SM5zWskiciaq8QvBLbqXXAAicqDgQbaCzn8AujSpZoKgKK8mlg/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！复旦大学探索以人为中心的智能——加入复旦大学计算机科学技术学院 - 智能人机交</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703131&amp;idx=4&amp;sn=9101c29a455f2f16d6f304dcad6f4884&amp;chksm=974b40942edd6a4d7b1eb6e98001766b6e62ff1b87b48b1eab00ee09f77986f7e8fe277b86c0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 06:03:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[「不思考」反而更强？上海AI Lab重新定义视觉强化学习微调最优路径]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCFCgh7crBzterdFdmGV02ITqE8bBDtMHMXpkoNZrgmmpgiaUxcRUtNWRDMmE1P8fr75hyia5v3xNw/640?wxtype=jpeg&amp;wxfrom=0"/><p>引言近年来，基于规则的强化学习（RFT）在多模态大语言模型（MLLMs）中的应用取得了显著进展，并且在一些模型上取得了优于监督微调（SFT）的成果。RFT 利用可验证的奖励进行训练，鼓励模型在回答之前</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703066&amp;idx=1&amp;sn=2829ffbd3f19ea2759efb90a3a709544&amp;chksm=9709f5d7afe3dd487370353ab8dcdd25b79ad4a36d2b00d7ce2c2c59563f0a10ae0ed753d503&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 04:37:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[WWW 2025 | 数据洪流→数据精炼：北理工等提出高效文本行人检索新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCFCgh7crBzterdFdmGV0204tTzXiaJ2DiaHJ2I8tVbjLcAiapyuTCesdIkP9qjZrAPRWZLW5FuI9yg/300?wxtype=jpeg&amp;wxfrom=0"/><p>任务背景以及 Motivation随着深度视觉-语言预训练的飞速发展，文本驱动的行人检索（Text-based Person Search）已成为公共安全与智能监控领域的热门方向。然而，现有方法为了解</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703066&amp;idx=2&amp;sn=ae7983b6f91a11ac30506b85d9d2c092&amp;chksm=97b8deadd6b764125323132ea1f9dd0a8f3c85c182a2495076369c2b91bb784d1c251eb87011&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 04:37:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[中文网页检索挑战上线！GPT-4o准确率仅6.2%，这份新基准打脸所有大模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCFCgh7crBzterdFdmGV02KYhnIX3Qm0srBicycaYMcNcpteuPLNAn6yWEmhH2WfpZlUhEaZtt8WQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>©作者 | 周培林单位 | 香港科技大学（广州）随着大语言模型（LLMs）日渐“拟人化”，能写报告、能画图、还能“冲浪查资料”，不少人以为它们已能应对各种任务。但这次，一项由港科大（广州）、北大、浙大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703066&amp;idx=3&amp;sn=1e16df34d2925315093ee43b33517112&amp;chksm=97c16a70f8b62cdf3b94973f62687028d36e54ae8a70686d0b848e8ab3469200a7af46c99528&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 04:37:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北京内推 | 字节跳动Data-电商团队招聘多模态大模型算法实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkCFCgh7crBzterdFdmGV02s99tPvdLhjR9Y8jQMcEPyjGiaEqnLJqmLN0UTFjz42aQqOicLh26msZQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！字节跳动Data-电商团队，负责电商创新项目的算法和大数据工作。依托于字节跳动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703066&amp;idx=4&amp;sn=874a1cda93b71305e3fe4e0bfcd92ce3&amp;chksm=9751be214fb7edb56697098f3635e97890a0ba3c63e2abfc5ca12bfba4ffaaecb0d95c0ab527&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 04:37:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[因为盲审没过，被延毕了……]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnricAqUsYjk413kibXJ6AqN6NfYYO29WcicXHL2HXuoPvdeSnib4Fv3ib5848U0kCZpqYtWEsQv3k5ynA/640?wxtype=jpeg&amp;wxfrom=0"/><p>临近毕业季，不管是硕士生还是博士生，毕业前最大的一关就是盲审。通过了，就基本可以宣告毕业在即；没过，则要面对可能“延毕”的深渊。实话, 论文盲审没过，一度陷入了自我怀疑中，觉得自己干啥都不行，能力不行</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703013&amp;idx=1&amp;sn=a1c8e7868e6f62c4c8d2107041ef2f86&amp;chksm=97b4dc4515354d27710c2ebca8129447f26d36db5a04ccd827d5bf3ef685f4aad499c200eb1e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 05:33:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 | 从碎片到完整：面向语义完整且等价的多模态视觉分词新范式SeTok]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnricAqUsYjk413kibXJ6AqN66NXma7MicibzIicAfAydau1sKMF82IsiaR8JDG9jVVXdHawCrxm1ZvRC2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前，多模态大语言模型（MLLMs）在视觉-语言理解任务中取得了令人瞩目的进展，其中视觉分词（vision tokenization）作为视觉与语言语义对齐的关键环节，发挥着至关重要的作用。然而，现有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703013&amp;idx=2&amp;sn=7b51f212fcb0ce187fab0fa496c7244d&amp;chksm=97d17867f2fea842e7076aba66caae803cfef7d8dca7a045e53bf41b0d9372c8f26bfb275d3c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 05:33:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[推测性思维链SCoT：小模型“模仿”大模型，最高提速2.9倍，准确率几乎不降]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnricAqUsYjk413kibXJ6AqN6sQKvNNdsoR9v05e4Zovosxh2zmALWn7njyZoOBornMn4tia8V5p878w/300?wxtype=jpeg&amp;wxfrom=0"/><p>现在的大模型（比如论文提到的 Deepseek-R1）虽然能解决复杂数学题，但有两个致命缺点：体型庞大：动辄几百亿参数，像“超级计算机”一样耗资源；思考过程长：解一道题要生成几千甚至上万字的思维链（C</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703013&amp;idx=3&amp;sn=d1f408876c618fdd2e59abf99cbcf43c&amp;chksm=97750911b222fe2963f47f3755c275fd93e33892d1bf17cbeb8d401509f45bc4771d081f5de2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 05:33:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北京内推 | 阿里夸克智能创新技术部招聘多模态算法研究实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnricAqUsYjk413kibXJ6AqN6559EXcbvUFd0qkwNYkZd31ibrkWZD7YjVJxl1Bp9uGjrpp36ibibnWukQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！阿里巴巴团队负责夸克教育多模态大模型的建设工作，有机会接触到前沿的多模态大模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247703013&amp;idx=4&amp;sn=367caf0239b031ac284857160ab4e9f9&amp;chksm=97c3c385a44d988605970566267bbcb4bed5cf7fd0481ee92a57f5e26bb9c53597e7da32c7a1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 05:33:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[爆肝万字！从JanusPro到UniTok，多模态大模型理解与生成的统一之路]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnIekGrCBACyz98L07AiaOCjUH6enTzp3wzmQdNmMgYxOzS5rttECkeaOqGXP5lHE7wGtSo5xiaFPwA/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着 GPT-4o 生成能力的爆火，很多人都在研究怎么让模型既能看懂图片、视频（理解任务），又能根据文字生成图片、视频（生成任务）。自回归模型（就是那种一个接一个预测下一个“词”的模型）在这两方面都取</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247702970&amp;idx=1&amp;sn=ddd70ead9f3915f00cb710a47559f351&amp;chksm=97ac57ed281de372089ee2efd2b48d5ba8945a9fd5d1401620a9b16dda5c63ce6c30a1da5185&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 04:39:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型“快答”能力堪忧？中科院推出S1-Bench，直击大推理模型快思考短板]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnIekGrCBACyz98L07AiaOCjU8PjGWjhYg9HZKv5Apw57MXYq2oBr78t4JnvIgIDMqJBuyweh194yg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大推理模型（LRM）在非常复杂或困难的任务中表现非凡，这依赖于其强大的系统 2 思维模式（深思熟虑的慢思考）。但在日常的使用中，大量用户提问的问题更多是系统 1 问题（这些问题可以直觉快速回答），他们</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247702970&amp;idx=2&amp;sn=db46cfda1633356b6b8cb59f921d8d18&amp;chksm=97dd44173231b19d063d913f0f4bb7db1cd0d70c18edc90071f64b8e1e37fa39133399711537&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 04:39:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3B逆袭7B巨头！Video-XL-Pro登顶长视频理解SOTA，单卡万帧准确率超98%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnIekGrCBACyz98L07AiaOCjWtbpggl5SNdok2noDfkkdjibhC3m1Rpweib80zQ10bfQ1zL8REKpcAEg/300?wxtype=jpeg&amp;wxfrom=0"/><p>长视频理解是多模态大模型的核心能力之一，也是迈向通用人工智能（AGI）的关键一步。然而，现有的多模态大模型难以大规模训练超长视频，并且在处理长视频时，仍然面临性能差和效率低的双重挑战。对此，上海交通大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247702970&amp;idx=3&amp;sn=48f4e05a520584ad36d663f3ab5cb556&amp;chksm=97dce039ba6cf3c878ec509736302b19039e1959c68f7b57e9edb587fb5dc65df05951966669&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 04:39:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[博士申请 | 西湖大学吴泰霖老师招收AI for Science方向博士/博后/实习生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnIekGrCBACyz98L07AiaOCjvIOCCp5icBA6e9mrz6QcvUvWQhUCTmDEpf3zyomAKB9GTjc1h8pZ8WQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>合适的工作难找？最新的招聘信息也不知道？AI 求职为大家精选人工智能领域最新鲜的招聘信息，助你先人一步投递，快人一步入职！西湖大学西湖大学人工智能与科学仿真发现实验室长期开展AI + Science学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247702970&amp;idx=4&amp;sn=5457a9d975e7dbf74fabceff3922359a&amp;chksm=972408947874eb60760eddf560b0f09055b5b517707d4eff402137b4970dccf976c6181361a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 04:39:13 +0000</pubDate>
    </item>
  </channel>
</rss>