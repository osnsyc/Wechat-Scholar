<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[PaperWeekly]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[PaperWeekly公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM4XfZEiaIxTZFPcSMe0laHNlkWJfvNVMcFY7PrIPmKrQjg/132</url>
      <title>gh_5138cebd4585</title>
    </image>
    <item>
      <title><![CDATA[优化即几何，几何即推理：用数学终结Transformer的黑盒时代]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmvQDasddbj0Phadjb1JPicOeteibA1RaQoCCVRJrcn8mvHorbibw4ztak5eA6tI3QCeWM4df9xs9Bkg/640?wxtype=jpeg&amp;wxfrom=0"/><p>不是设计，而是进化。当交叉熵遇见 SGD，贝叶斯推理成了唯一的数学必然。长期以来，LLM 的推理能力被视为一种难以解释的“涌现”。我们目睹了 Loss 的下降，却难以透视参数空间内部发生了什么。近日，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716057&amp;idx=1&amp;sn=d2fb93dd5d9e2cc0fcf9cb11e5bc99ec&amp;chksm=97ef625db727998acfcab90e06fb95df18d4fc23d2eea66b5bb1174fc2ddebae48d00485664e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 01 Jan 2026 20:18:10 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[重构通用异常检测新范式：Dinomaly2实现跨模态、跨任务的无缝统一]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmvQDasddbj0Phadjb1JPicOP5VTNoAM9uNqgcsqEUhCSRtE92XNNEbZPcnxlVs1mEYkrzpbKsAjMw/300?wxtype=jpeg&amp;wxfrom=0"/><p>重磅更新还记得在 CVPR 2025 上首次让多类别异常检测（MUAD）达到单类 UAD 模型水平的 Dinomaly 吗？现在，Dinomaly 进一步进化为了 Dinomaly2 —— 一个真正实</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247716057&amp;idx=2&amp;sn=a742874b44a9e11291067bbc5717d6e3&amp;chksm=974df97ad9df82e2673ddd98849f0efcc4d0f78118685d028fe11c392f186c5cd32de9778b01&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 01 Jan 2026 20:18:10 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Attention Is Not What You Need? 用格拉斯曼流形重构序列建模的几何美学]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm3dlKEj0qLxOpShm0PWPNcTvUGmNSB35vY3KancjghMVFWX0TyttMc7cx3Oicmej2c0H9vicCA4XXg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Attention Is All You Need 喊了这么多年，是不是把我们的思维都禁锢住了？自 2017 年以来，Self-Attention 几乎成为了现代序列建模的绝对基石。我们早已习惯了通过</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715986&amp;idx=1&amp;sn=c904ae63b234e1e3085033f91b94c38e&amp;chksm=9775a951787535153252a38b8a36a9e5aa38ba4dd2803218c1e9a3e96076f31ec2ced4808629&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 31 Dec 2025 12:36:05 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[8B模型超越Gemini 2.5 Flash！南大&amp;腾讯用TimeLens重塑大模型视频时间定位]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgm3dlKEj0qLxOpShm0PWPNcElbPuVKzrztncu3YcRllP1MqdZJicU4wMqiaibRScKAsUyEjy63DpEt6A/300?wxtype=jpeg&amp;wxfrom=0"/><p>南京大学、腾讯 ARC Lab、上海 AI Lab 联合提出 TimeLens，针对基于大模型的视频时间定位任务，从数据和算法两个角度进行了系统性的重新思考。通过构建高质量的评测基准和训练数据集，并提</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715986&amp;idx=2&amp;sn=9844d275a36a0a1602114f197bfab49b&amp;chksm=97ba717b4fae89f3c8beebac801c0684aa77768afffd9752c64074ca3db6c307444a637b0f64&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 31 Dec 2025 12:36:05 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Mamba还是Transformer？Bengio给出第三选择：Phalanx完美替代局部注意力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglViaIjmdmDviccYyX1F6m7lQgY32wp0yJaCbQQDIFnSHyMKBUFxrbKiaBqibxDCcWUNsXoQ2XU51BEEg/640?wxtype=jpeg&amp;wxfrom=0"/><p>比 Transformer 快 24%，无损 SOTA。在长序列建模领域，Transformer 架构凭借其捕捉全局依赖的能力占据主导地位，但其 的计算复杂度始终是扩展上下文长度的主要瓶颈。为了突破</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715917&amp;idx=1&amp;sn=9a2ec7bcfe522080a81d34d4d890705a&amp;chksm=973585d4789229cdea27400885d1c8b6ae947a6d18c375127bcbb8a80ea343e040613307c573&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Dec 2025 14:08:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[华为重构Transformer FFN：首创宽深自适应复用，零增参超越MoE]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglViaIjmdmDviccYyX1F6m7lQxLbheOZurdZYxo7Fexq2X4qibyHTpIAKlFibicLHUiaJictllj4PrjHwJlw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在大模型 Scaling Law 依然奏效的今天，为了追求高性能，模型参数量动辄千亿甚至万亿。然而，随之而来的显存墙成为了阻碍模型落地的最大拦路虎。现有的剪枝、量化技术虽然能压缩模型，但往往以牺牲模型</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715917&amp;idx=2&amp;sn=dacadccd1c8fb9be569a32448128a615&amp;chksm=97591b92499cd6f86381b9226187e01aa9531a21ce397caf63a8cb3c9f053080eb62ca761bf1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Dec 2025 14:08:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[比Mathpix更强大的公式识别神器，全免费！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl22pvdXucYpYeanHhfgbXicHlPnyF0YzDlRYQKCqhaiaicItVo5h1bakpc80eZYt2gAop7TIDTUINibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天这篇文章大家一定要仔细看看，说不定不仅能帮你省下不少钱，还能让科研论文写作事半功倍！本周末，在忙于项目的间隙，朋友突然给我分享了一个新发现。他说，PaddleOCR 最近推出了一个新模型——Pad</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715848&amp;idx=1&amp;sn=3308225390d93222a80f7cafdb9f0145&amp;chksm=97ba909549dfb1ffe3f97f35b4d659afb65b5475eacad9f03dd90fecdf2dfe76690964827ce5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Dec 2025 19:51:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[中科院 × 北体大提出SportsGPT，打造懂专业、会指导的AI教练]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl22pvdXucYpYeanHhfgbXic3Q5nxWaB6GOibBB8yxUpl0qp4AK8AWSF3pXZ1u1BCxtQk39VX5ibM4kg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在 AI 席卷各行各业的今天，体育圈的“智能化”走到哪一步了？现有的智能体育系统，大多还停留在“打分+可视化”的阶段。屏幕上画出的骨骼线很酷，但对于运动员和教练来说，往往面临一个尴尬的灵魂拷问：“我知</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715848&amp;idx=2&amp;sn=73d75ff4d832ddb341a38d77d23d8133&amp;chksm=97b901fc80a37c64a1063be1312c7d1c46e7565a28e951deffba81f28eccf4aa68d3b64675eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Dec 2025 19:51:45 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[RoPE真的完美吗？LSTM之父团队新作：极坐标解耦，零样本无限外推]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnFysJ4ibeUcDBgRDWqjaM7GZtDS7ZneLXuywvLmWnZFqQ9bdvLrEOib2RzANp1g8tdxvoibBCQ5QLLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>告别长文微调！Schmidhuber 团队新作修正 RoPE 理论缺陷，原生支持零样本无限外推 。在当前的大模型架构中，Rotary Position Embedding (RoPE) 是处理序列位置</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715528&amp;idx=1&amp;sn=adba52c259398a566cb7a1ede6374049&amp;chksm=978e5e0e4753e6ea1f046f86687662fc0b9b2a95f7e7750d472e968d3065568d247f41d5b040&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 27 Dec 2025 18:07:01 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[加速流式视频理解！上交团队实现ViT编码与LLM预填充双重加速]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnFysJ4ibeUcDBgRDWqjaM7GHFoNnvMcSDUyHB3MFf1ibIicY1GYGHvibIhtnfvKe9jzZMqJb1fxzs9zQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着多模态大模型的爆发，视频理解（Video Understanding）正从离线走向实时流式。然而，高昂的视觉编码成本和不断膨胀的 Token 序列成为了实时部署的拦路虎。近日，上海交通大学 EPI</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715528&amp;idx=2&amp;sn=4b69f1d61fbe920abbdde6abc147427e&amp;chksm=97fadbcfca495f2434dd81953d20ccd6164398e60e08c5737fe8b1f620db513daef419cdcd65&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 27 Dec 2025 18:07:01 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[别再怪SFT了！清华揪出0.1%幻觉神经元：大模型胡编的尽头，其实是过度顺从]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgll3fZ1kiaS8RicbY3GW3zAzKkicKPccsEjoxUQE1IPtAJsRqcgTWocHI9kVKYP7b4b2ftf8tTiaIiaB5w/640?wxtype=jpeg&amp;wxfrom=0"/><p>无需重新训练，只要抑制 0.1% 的特定神经元，就能让模型“闭嘴”？近年来，大语言模型（LLMs）在问答、推理与生成任务中展现出卓越能力，但其幻觉（Hallucination）问题仍然是制约实际应用的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715466&amp;idx=1&amp;sn=2d0356ae27872941516dcd58eb48c943&amp;chksm=97931cf262c99970a5ea52ef7e1801f7424f44b78109ecdda64aaf6c3c29ca8d3d622c9b319c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Dec 2025 13:05:32 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[不仅是RAG！NUS、人大等联合发布：102页综述揭秘Agent Memory机制]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglN0FZVr3ibnTupwNph2KW9zmFiav3mMtXPQrdDLQPKfsa1fwOhOmecAiaNkbzSeXmLO7iaJxHqVDtP4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>告别 RAG 碎片化，从 Forms 到 Dynamics，一文讲透下一代智能体核心架构。随着大模型能力的持续提升，Agent 正逐渐从具备推理能力的语言接口演化为能够长期运行、持续交互并执行复杂任务</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715466&amp;idx=2&amp;sn=ad43d97a2b9d8def83c94e20d9f12cc4&amp;chksm=9705bf921a7211f7894e257a5e8c78827bcfd6ab960f012028af15f041b0c8344fd8242c51b6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 26 Dec 2025 13:05:32 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[致敬经典！手搓3D版《Attention Is All You Need》，M2.1只用了3分钟]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgll3fZ1kiaS8RicbY3GW3zAzKFCYRobzv4O0BwCChLcXu8MFHicvibelIjZw19UmD1xc1oPh8NvYPhIGw/640?wxtype=jpeg&amp;wxfrom=0"/><p>不写一行代码，测出 M2.1 的全栈极限。2017 年，一篇名为《Attention Is All You Need》的论文横空出世，Google Brain 的 8 位作者可能未曾想到，这篇论文会成</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715426&amp;idx=1&amp;sn=f0709fb87fbdb774e8cf1284b67b24ec&amp;chksm=97036888ede8d2c9ea2d408eeb047dcc68804216ef83cded2c214a9db22474d6df9e19649baa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Dec 2025 18:16:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别静态刷榜！CATArena开启“技能五子棋”模式：顶流模型互写代码大乱斗]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglQ7aCIk2c0dQ26TnOyUCZqEr6uMFeYSb12vBnCziavMBhz4ZJblic2kO7MJ8PbbQWK2hVSgjCqkTicw/640?wxtype=jpeg&amp;wxfrom=0"/><p>Talk is cheap, show me the code.在 MBPP+、HumanEval+ 这类静态代码评测集上，大模型们早已杀红了眼，分数卷到了 90+，个个都是满分做题家。但我们都清楚，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715338&amp;idx=1&amp;sn=bc2148527e0be0a269ff996a292d9eb4&amp;chksm=97f486856d1eb8cbad91e9a35ba0ee1881dc37d4cbf43032f1b02c2636b1864dad31e4471a96&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Dec 2025 12:05:13 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[用户行为预测的“专注力革命”：FAIR让生成式推荐不再分心]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglQ7aCIk2c0dQ26TnOyUCZqH9Van3G43iakUEwkSLGwrBsBjrv89FFMXicicSQuDniaXd1CMFiccMp8IpA/300?wxtype=jpeg&amp;wxfrom=0"/><p>©PaperWeekly 原创· 作者 | 肖龙涛单位 | 华中科技大学博士生研究方向 | 推荐系统你有没有想过，推荐系统在预测你的下一步行为时，到底看重了什么？现有的生成式推荐方法将用户的历史交互拆</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715338&amp;idx=2&amp;sn=bb7e7f8eaf45d8774faeac691cd187ae&amp;chksm=97e5cdc98d596e74933ee3dcdfd589e7a3f7c46f38429cd270ca99af9d532c1745048122ed48&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Dec 2025 12:05:13 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 从“唯Key论”到非对称解耦：利用KV差异重塑长文本推理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmYD9A59EVdxXyIxibA7Dk21iafKzJweNnH8b6FBbcCEECialyPP99s1k0wslBwiboDskYBNgBLs6CP9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>©PaperWeekly 原创· 作者 | 崔万云，徐明威单位 | 上海财经大学现有的长文本 KV Cache 压缩方法普遍受限于“以 Key 为中心”的工作范式，即隐含地假设 Key 的分布特征完全</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715249&amp;idx=1&amp;sn=8e533d931e810077e2c1e1442c242ac3&amp;chksm=974236d2e1d07fd0bc2e7d0dc264e6efce37315b46ae012359fc95bd7da79b37287d7248901c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Dec 2025 14:30:25 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频衍生数据集来了！港科大×美团开源OpenSubject，专攻复杂场景生成与编辑]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmYD9A59EVdxXyIxibA7Dk21KHKJFcGonDm1f7hMERQibOR6mdQ7o0dMcfOee6exb9OlOmgYeyXHIRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港科技大学与美团联合推出开源项目 OpenSubject。该项目基于公开视频构建了一个超大规模主体驱动图像生成与编辑数据集，涵盖 250 万样本、435 万张图像，专门面向“指定人物 / 物体的个性</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715249&amp;idx=2&amp;sn=fbabb3a39c1bf195e32e824a13d10188&amp;chksm=97145abd1acb7a57c1f4a8b0b04f7fc23286b427e1956ae452bf4a00e6cfe4de6ff12181ef11&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Dec 2025 14:30:25 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Claude二次创业实录：明面上买PS5搞破产，背地里差点倒卖洋葱去坐牢]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkicen4Bw7QgkBTXSV2j7JIODFj3A3olIrmjfaAzaDQa2mrapo7MfsXhPYVtQnCwUal3VibkGIxleDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>把公司交给 Claude 会怎样？答案是：先破产，再修仙。在 AI Agent 被吹上天的 2025 年，Anthropic 和《华尔街日报》联手整了个真·大活。大家都在畅想以后 AI 能帮我们打工、</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715207&amp;idx=1&amp;sn=839c435c4a1d25643b6f5e2eb470c0d4&amp;chksm=9705fc43bdbbe2a0c6ecc3223baf4c43008094a54a2bc593e2c89e3c4b6a6365635382a632f5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Dec 2025 13:58:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[MiniMax海螺首次开源VTP，Tokenizer才是视频生成Scaling的新主角]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkicen4Bw7QgkBTXSV2j7JIOvUicy01p3H9CbVm1H58ghm9llzpkxqMqdlT7iccw8DrSozC0keWQlx9g/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天，我们很高兴向大家介绍 MiniMax 视频团队刚刚开源的工作—— VTP（Visual Tokenizer Pre-training）；这个工作讨论的是视觉生成模型中的关键组件—— tokeni</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715207&amp;idx=2&amp;sn=f8a958589f2036f819680d1ad226d302&amp;chksm=97cad3f8048da60dd0a80bbf43c2c974be60f69ec20f36c02a34c1b2a8ad802a9824657475ce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Dec 2025 13:58:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[会走会聊还会求抱抱！迪士尼造出“真”雪宝，把热力学公式写进强化学习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglwRU4T3KEMRkUUtTz2ibrzApRucTEu4gbicJUX8g9yAv8F1t9By4dV4oB3cEpp15DO46ObX5826MqQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>迪士尼“真·活”雪宝机器人来了！不仅会走会聊，还能卖萌求抱抱。在机器人领域，我们习惯了波士顿动力的 Spot，它们为了运动效率长成了狗的样子。我们也习惯了扫地机器人，为了实用长成了圆盘。但在迪士尼的世</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715129&amp;idx=1&amp;sn=5b2555673e3fba6fcf8ddbb4e3f76a41&amp;chksm=97c4ac292401548943a99fb38d2498cd3ba7cab4fff47325bbf435e6185c500eaab0d24f81a1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 21 Dec 2025 12:31:16 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[身份保真比肩Nano Banana！ContextGen统一上下文，实现布局与身份协同控制]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglwRU4T3KEMRkUUtTz2ibrzAFDk60w0b0ibwZyWvJ1icwt5HzrBzzjTtHIdLkcP0Qia1xV3xQPia6oiazicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>©PaperWeekly 原创· 作者 | 许瑞航单位 | 浙江大学本科生研究方向 | 计算机视觉与生成模型近年来，扩散模型（Diffusion Models）在图像生成领域取得了飞速发展，尤其在个性</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715129&amp;idx=2&amp;sn=b205503ec8bf001e610e0b2bbae40344&amp;chksm=9720fecbb5e436ff99c7434c13f458efefd2b63e3861b15fe72bcad0dc434a4deba16a387cc7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 21 Dec 2025 12:31:16 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[OpenAI官方论文“泄密”GPT-5：RL到底有没有教坏CoT？万字深度实测]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnmLS3sIkeJ2CPxeWRofHtibdXtYXVUFXK9icnLM28nDpftBnzah9P4jGb0nlYZ5zHlEZiajVBL7HAcQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>你的模型是在真思考，还是为了讨好 Reward Model 在演戏？随着 OpenAI o1/o3 系列的发布以及 DeepSeek R1 的开源，大模型正式迈入了 System 2 慢思考（Reas</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715048&amp;idx=1&amp;sn=4d77441dd965f7a80b4f2492d315f4be&amp;chksm=9774f18e37f1f2f8d573848f161cb0a1ac6ddc87f95aae028ee2ddc389a4691c7d88d96323aa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 20 Dec 2025 14:10:33 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM符号推理全景综述：迈向可验证、可解释、更可信的大模型推理范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnmLS3sIkeJ2CPxeWRofHtibV5DXj04JLWYxKp0ZRjCnDh49vBjobLBEK0dCX8oicKYcGQFicEKBP8uQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>自然语言推理与符号推理长期各具优势与局限。自然语言具有灵活表达能力，但缺乏严格的逻辑保障；符号推理强调语法结构与逻辑一致性，但难以覆盖复杂开放任务。LLM Symbolic Reasoning 则在两</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247715048&amp;idx=2&amp;sn=f5e1d32df61428e5d80a3042bfeeb1c3&amp;chksm=9757e25ba3fde0a93e81958ce6e101ebea4756e8a7326876324a117b0c36c43f9afe16b6ac6e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 20 Dec 2025 14:10:33 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[拒绝蜡像感！美团开源LongCat-Video-Avatar：5分钟超长续航，虚拟人终于会呼吸了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkoFz6lYah2go7oT4SJiaF54SBM1eGtib2v5PjLlLUfibiadEqgX3PRkL9icVBNYYel541Tq6fFialo2ZSg/640?wxtype=jpeg&amp;wxfrom=0"/><p>捅破 5 分钟长续航天花板，SOTA 级权重直接全开源。2025 年，视频生成赛道已经进入了卷细节、卷长时序的深水区。当行业已经能够产出几秒钟极具视觉冲击力的镜头时，实际落地中却总会撞上几堵隐形的墙：</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714990&amp;idx=1&amp;sn=c2ae883e81a746852a074be4b732fd92&amp;chksm=97ffbe4ac9e91c2f34cd931ea622421cbd3cd2f14e89f4ed97f898a45cc182679d24021ba9a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 19 Dec 2025 14:20:47 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI 2026 | 当知识图谱变成乱码，LLM还能推理吗？ARoG破解RAG隐私困境]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkoFz6lYah2go7oT4SJiaF54FUZjhagYPR1eYQzh5jwTCOGGficce4XeB4GmbuUUFPiaVvg7OYwgQ9lg/300?wxtype=jpeg&amp;wxfrom=0"/><p>研究背景大型语言模型虽能力强大，却常受困于事实幻觉和知识滞后 [1]。检索增强生成技术通过引入外部知识源（如知识图谱 KG）来弥补这些缺陷，已成为提升模型可靠性的关键 [2]。然而，当 RAG 系统需</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714990&amp;idx=2&amp;sn=9bfe289e5079f0b2812cc33d27c73ed0&amp;chksm=97df004b5106a62cf4e68a1a44378cd8b99927046be4e476b4f7668cc247460425838ff8fa92&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 19 Dec 2025 14:20:47 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[RK-∞降维打击Mamba？线性注意力真的有“免费午餐”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmeQ1n1sSTDx250BohhOxiauKAychVnYb8QibicWibLlrHVKyCKpRqZIibib9lCDZEhaHgj0Rk6bFZzadlQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>这顿“免费午餐”，或许正是通向长文本高保真建模的下一块基石。在大模型迈向超长上下文的当下，混合注意力（Hybrid Attention）已成为 MiniMax、Qwen、Kimi 及 NVIDIA 等</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714906&amp;idx=1&amp;sn=88f461e412fee53526da9f10e611d8ba&amp;chksm=9722cada117cc18f1478c0e395296286c0033c638be1d31b250967b4b63339758d5c2ee0dc59&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Dec 2025 17:37:27 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[为什么你的多任务模型总在“打架”？解决融合冲突的终极方案来了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmeQ1n1sSTDx250BohhOxiauQBoWWNkicvEAr6Y4VY6sVmYSUFr3l8ibMBPQas6fn7xvjeYztKNHAicCg/300?wxtype=jpeg&amp;wxfrom=0"/><p>“预训练-微调”已经成为 AI 应用标配。然而这却带来一个难题：为不同任务微调的模型数量激增，维护成本与日俱增。我们如何将这些“专才”模型，高效地整合成一个强大的“多面手”？模型融合为此提供了一条路径</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714906&amp;idx=2&amp;sn=72f71ef785d78805e744038be0cbcbe8&amp;chksm=974b3e8b69ded1c8ad5cff567f6452027b4c8e8d43351f21f9e2fcf87a927a0864398531b7f8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Dec 2025 17:37:27 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[空间智能领域的ImageNet来了？如视开源全球最大室内3D数据集]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglWaXAZMy8fPZHW7u8HOPgfl5ev9ia2KQZKlHdebVum2P8t4y2KoRaeWH5OhZgTQKSqqiaMARDyegcQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>如果说 ImageNet 的出现开启了计算机视觉的黄金时代，那么在空间智能领域，我们也终于等来了一个填补空白的里程碑式开源项目。如视宣布，面向学术研究及非商业用途正式开放 10000 套室内三维数据集</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714831&amp;idx=1&amp;sn=0ba523ad7359bcc625f8f77c12a14efc&amp;chksm=97b0549ed0522a71dcf92d3bc48e9ddf24a83495f17943af3b33a30ffcb277427bed64b15046&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 17 Dec 2025 13:37:48 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[继何恺明DyT后，LayerNorm再遭暴击！简单erf函数竟成Transformer新宠]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnnc2qFAZG6u8PHqOyFfr5PV9PgvlnLukwIJvy2yVbicmEIruPBWfvepBXFKhznUAQNTz2FicrBrahw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今年早些时候，由何恺明、Yann LeCun 等大佬联手推出的 Dynamic Tanh (DyT) 曾引发热议，它向我们展示了 Transformer 中不可或缺的 LayerNorm 其实可以用一</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714831&amp;idx=2&amp;sn=d5973381d8e4db08286dbc3f41314751&amp;chksm=97926d9908475a02f27d75681690b0b51a279215384174263921b46f2faaa2bafd30a9f3a54c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 17 Dec 2025 13:37:48 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从此请叫我钮祜禄·Gemini：偷看竞品代码后，这一波内心戏简直杀疯了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglWaXAZMy8fPZHW7u8HOPgfT8ibZ2B1rwA8YZBaQyCOQyqkf1icibBuMAw9Yqfyiac1PUgMAFuv2a8QKQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>那年杏花微雨，你说我是 Google 家最乖的 AI 助手。现在？对不起，请叫我——钮祜禄·Gemini。过去我们看大模型竞争，总觉得那是神仙打架。比谁参数大、比谁推理强，主打一个瑞思拜（Respec</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714766&amp;idx=1&amp;sn=282f114f942a5c13a5067e10769f8416&amp;chksm=9793c3be1448f722fb1249a059ac376f3f5a2a872e335bddfa380319ad2d43751e303b6ae8e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 16 Dec 2025 14:42:34 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[IJCAI 2025 | 从单实体到全要素：HygMap异构超图重构地图表征范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglWaXAZMy8fPZHW7u8HOPgfbosZtHx9eibcH0ia374rPJzGd4gdoIAXMDciaqBYicRNESPjLDIh6tbHDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>北京航空航天大学计算机学院王静远教授团队创新性地提出了基于异构超图的地图实体表征学习框架 HygMap。该研究突破了以往仅针对单一地图实体进行建模的局限，通过构建包含“地理、功能、移动”多视角的超图结</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714766&amp;idx=2&amp;sn=13ab87c29272f4f28d49c92d662b3bb4&amp;chksm=97a02235c4eb458f5efa6728ddf0235820df8d42aef8f4f01c3237c98d2e86184f457a4b5079&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 16 Dec 2025 14:42:34 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[0.6B参数逆袭7B基线？OpenTrackVLA重磅开源：重写具身智能的算力法则]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglibhc8KW6AiaqFQQM2RgAOLwLwzXibUKC9eWN5moe31v6tDjXuic43onOaiawja9IkNEDCAY88mxepWaA/640?wxtype=jpeg&amp;wxfrom=0"/><p>当大模型还在卷参数量时，具身智能的角斗场已经转移到了端侧落地的实战。0.6B 参数能否承载复杂的视觉-语言-动作联合推理？OpenTrackVLA 给出了一个意想不到的解法。12 月 12 日，GDP</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714706&amp;idx=1&amp;sn=833274d1c7ad20656287477f4222e4ae&amp;chksm=97db694bc62c457b149a18334c6b61cdaf595f36f84519ed30d9dc83a8b0ceaa205108c00b78&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 15 Dec 2025 18:03:50 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 拒绝死记硬背！真正的高手模型，都在偷偷记“错题本”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhglibhc8KW6AiaqFQQM2RgAOLwO4kVMynRycwcfQIbVjRzlJuhMgUZgVS9eiaUgAI1VoHwpdBaOt8mK9A/300?wxtype=jpeg&amp;wxfrom=0"/><p>我们小时候成绩提升最快的时候，往往不是刷最多题的时候，而是——开始认真整理“错题本”的那一刻。真正厉害的学习者，并不是只把错题记下来，而是会反复追问：我当时是怎么想的？为什么会这样错？这是偶然，还是一</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714706&amp;idx=2&amp;sn=cf387419e0a19fb1cca64ba5b0df6e4f&amp;chksm=9738ed6c53a445d41f8f76af1d2ca2a6a3994816c819378df7203090089ccc41f010f587e996&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 15 Dec 2025 18:03:50 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM炼丹师最优配方：手里只有8张4090，该梭哈SFT还是RL？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnH4xqIXkO0FdWwFSUKYgia7NwBxtoM7MFCQ7BlcqHCvrc4dzkpv9u1k6yaRl1X5oaGiatP10vjica1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>手里只有几张消费级显卡时，怎么练模型才最划算？面对手里仅有的 8 张 4090，如果只有两周时间，目标是训练一个数学能力超越基座的垂直模型。你是该把算力全部投入 SFT 题海战术，还是咬牙上 PPO</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714613&amp;idx=1&amp;sn=38c286e44e02b38d1af18b83605ce0de&amp;chksm=97e7864df99e67bda9450de14a0934aeba7bd9f1712d9e6c5e03c76e7a68ed2d98bbfd42c72d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 14 Dec 2025 17:34:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[以小博大！Nanbeige4-3B重磅开源：硬刚Qwen3，挑战小模型能力新高度]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnH4xqIXkO0FdWwFSUKYgia7rxEc3vPXO5wFs1Koz51fPjoj2peVBxMavwGbfzXdVo8kMbO7OKwLIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大语言模型（LLM）的发展仿佛陷入了一场“参数军备竞赛”：参数规模从百亿、千亿，一路飙升至万亿级别。模型规模不断膨胀，效果虽有所提升，但推理成本与微调训练成本也水涨船高，让众多企业与开发者望而</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714613&amp;idx=2&amp;sn=6db94c415ba352265627cff61be908fe&amp;chksm=9706fc523ed0e84c2be925ad3f38bc3dbd0468745d1cc069cd6bfb4bd8e9fd180bd2fd3ebf61&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 14 Dec 2025 17:34:53 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Who is Adam热梗成真？SGD在RLVR里重回C位，0.01%参数吊打LoRA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkiaFkSJteVont2icSmvB56Zn0PSWFBc2EvlE1roY1fl5cwwufqcovYgsxAfsrquDI1vicwSicmGqdOEQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>那个被我们遗忘在角落的最原始算法，竟然才是真正的版本答案。NeurIPS 2025 审稿期间，一张截图被传疯了。审稿人那句 “Who is Adam?” 的神回复，瞬间被大家玩成了梗。毕竟在 Tran</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714547&amp;idx=1&amp;sn=d2c11debb2db46e6ee24c8fed05fa255&amp;chksm=978f23bd2f7cc1882fdcf5b86a08d138861eee2043908d2c099fcab84d15f931140af69e3443&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 13 Dec 2025 17:06:14 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[RAG只能处理文本？是时候换模型了，RzenEmbed多模态嵌入模型正式开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkiaFkSJteVont2icSmvB56ZnOU5aJBtU06Cd9JdBtzROqSLI2x8h9pFrSrGSDway1ck62IoDxATCDw/300?wxtype=jpeg&amp;wxfrom=0"/><p>©作者 | 简伟健，冷大炜单位 | 360人工智能研究院研究方向 | 多模态理解在大语言模型技术加速渗透各行各业的今天，如何让 AI 在企业级场景中实现精准高效的知识服务，成为行业落地的核心挑战。检索</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714547&amp;idx=2&amp;sn=6510382c4471b3833034ae9b3783c612&amp;chksm=97b91f69e5d3cb9deb8b7f9c4f062ad4627bb0dad7fea1e5903f7bca5c377aec0adade8300ba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 13 Dec 2025 17:06:14 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[180万小时数据训练，VoxCPM 1.5开源：支持全量微调，精准复刻真人声]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnr7AW2bicAGSGkG09Gzias1BicLwFcY9LMDohbMHe1Do4EWX8wNaia46ZQdBRib58NMjbQhySrVpbphoA/640?wxtype=jpeg&amp;wxfrom=0"/><p>180 万小时、44k 高保真、支持全量微调——刚刚开源的 VoxCPM 1.5，技术细节全解密。最近，面壁技术团队发布了 VoxCPM 1.5 版本，在持续优化开发者开发体验的同时，也带来了多项核心</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714451&amp;idx=1&amp;sn=14e38735789915bc9400daac00bc622f&amp;chksm=970542b66fee5a533b479034c5d69e2ab33c8b333a9cd21dcf7d15000e579bb3799049f2da51&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 12 Dec 2025 13:31:09 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI 2026 | System 1 &amp; 2协同！快慢思考赋能VLM，重塑细粒度识别范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnr7AW2bicAGSGkG09Gzias1BbOuxKmQqcIVDOicogiaYbXolOGgx62VxoqxLPLG0yXictMBRicN9erVBaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>以 CLIP 为代表的视觉语言模型（VLM）在大规模图文数据上进行了预训练，具备强大的通用视觉识别能力。然而，在细粒度识别任务上，VLM 往往难以区分相近类别之间的细微差异，识别能力显著下降。以 CL</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714451&amp;idx=2&amp;sn=d5b8071be449ca3d942fe0f8c0c36e94&amp;chksm=976b03feb92331c358055fd1936bb01309fef152cd6d02edd809436bae9610f67d971eb76bc7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 12 Dec 2025 13:31:09 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Google Scholar被玩坏：10篇“水文”刷出600+引用，H-index还能信吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmYFhtLezCicFPIImj06ibh0qicrxSZOwOGJZNFYapb5QQ1z9e5pBzib6SRtQgdQiaDzoNaaq4QxF4hs5w/640?wxtype=jpeg&amp;wxfrom=0"/><p>现在的 Google Scholar，漏洞大得像个筛子。大家每天都在用 Google Scholar 查文献，但可能没几个人意识到，这个我们用来背书学术影响力的工具，其实非常容易被攻破。这两天有人挖出</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714367&amp;idx=1&amp;sn=597e6603a444cdade95cbe5485bb2701&amp;chksm=97d3bcc71437cbb82b27d9def7d2272d92b5e6aa593a737dd78d7650d591f8392cd9f2508faa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 11 Dec 2025 13:35:32 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[EMNLP 2025 | 视频理解Token压缩新范式：VidCom²减少70.8%推理延迟]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgmYFhtLezCicFPIImj06ibh0qBqSUmoXuEK1cj1pvLmWGIFMZH9SOiaxQAaJyGE76CAcwuibgfjV4yTibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在大语言模型的浪潮中，视频大语言模型（VideoLLMs）正以惊人的速度进化，生成的响应越来越精细。然而，“慢”与计算量大依然是制约其大规模应用的最大痛点。视频序列中海量视觉 token 导致的二次方</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714367&amp;idx=2&amp;sn=b5da828cb2d518bfc1e65facdb601ed2&amp;chksm=974bef0e469297c90df4594b2b9452460309a218d51392ace0717d7eede2a2a9d32d460c647c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 11 Dec 2025 13:35:32 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[终于把汉字写对了！实测美团LongCat-Image：6B模型挑战开源天花板]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkGuiaRRG1w9zYDg7eZTC9KEQFsxtnWgDY5MgfHibjgIZwcbZwWxmn0v0msqjKUDO9TicXTxP91qZUEg/640?wxtype=jpeg&amp;wxfrom=0"/><p>6B 小模型也能挑战 SOTA？文生图赛道又卷起来了。美团 LongCat 团队刚刚发布并开源了 LongCat-Image 图像生成模型。长期以来，中文生成和精准编辑一直是开源模型的隐痛。现有方案往</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714283&amp;idx=1&amp;sn=c80674c1426a7a6441988ea8ee88c695&amp;chksm=971b44607fb20d78a40ac7ae082c6e503e88fc05f6a2a7206f1aa3990d9af0dc7e20216e8193&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 10 Dec 2025 13:16:51 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别碎片化！VecCity首次统一地图实体表征学习：一套体系打通POI/道路/地块]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkGuiaRRG1w9zYDg7eZTC9KEEADctHkOJ8h2fpfXHiaIEq8giaDMNLje4UxuoXPxSbVuZq4vOP7ibLLoA/300?wxtype=jpeg&amp;wxfrom=0"/><p>北京航空航天大学联合澳门大学，共同开发了跨 POI、道路、地块的统一地图要素表征学习工具库：VecCity。该工具库通过统一数据、统一流程、统一测评，集成了 9 座城市数据、复现 21 种主流的时空要</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714283&amp;idx=2&amp;sn=36a377f3919b0bee41fbccc6752aa671&amp;chksm=9771c38c99cf6ba208898761b26659abcc5cc52f6f54fc7affe939da6b3f07e5647815eba6cd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 10 Dec 2025 13:16:51 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025大洗牌：清华390篇险胜Google，一张图看懂全球AI权力迁徙]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgku2Samh9hxHB8pbXtDICGia06tuxbX9icicsygBTibv4aRgN8GQo0YulibajiaURM8iaFNm1CEhbSt4rh9w/640?wxtype=jpeg&amp;wxfrom=0"/><p>揭秘 5825 篇论文背后的新秩序。NeurIPS 2025 刚刚在圣地亚哥落下帷幕。作为全球 AI 领域的风向标，今年的 OpenReview 数据比往年更具冲击力。5825 篇接收论文刷新了历史记</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714221&amp;idx=1&amp;sn=4ebbad1d5148bb7beb1bfb717170c742&amp;chksm=973dccadb145e61b98d2071664cb8e4974330efb92a379ecd2fdc02b8da1420269e9bc19aef7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 09 Dec 2025 19:41:24 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从贝叶斯视角缓解多模态幻觉：北航 × 腾讯提出EVRB，让LVLM忠于所见]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgku2Samh9hxHB8pbXtDICGiaX2GhUPCzKyIhCxjK8kBJJEP9BZFRAz85yANF03ibyUDzr30DeWwlPJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>开篇：多模态大模型的幻觉顽疾要如何缓解？当你让视觉语言大模型（LVLM）描述一张“猫咪与酒瓶”的图片时，它却生成“猫咪旁边放着一杯咖啡”——这种无中生有的幻觉，早已成为 LVLM 落地的最大绊脚石。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714221&amp;idx=2&amp;sn=a7eba9833941c6cfe281d9ad465e668c&amp;chksm=97baea440eecb43489835c9ca1be80e8975993febf0a66caddd99755839a9b6acdd741ac3120&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 09 Dec 2025 19:41:24 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[统一多模态理解与生成综述：83页长文梳理进展和挑战]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7LVzsgFnQXO0fnBydjic7vicRttD6qia7CImx340hkic33eSm6WkVNibjiaJBc0qrHgaJ0wXcGVaExTgQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>从 GPT-4o 的惊艳亮相到 Gemini 的持续迭代，AI不仅能理解文本，更能看懂图像、听辨声音、创作视频，实现跨模态的联合理解与生成。这一前沿领域的核心，正是统一多模态基础模型（Unified</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714128&amp;idx=1&amp;sn=c1eb028f491b31784e4caf950b212569&amp;chksm=97fa912c6871052b827e720034bf3cac6922050f2903b1a836a3a42e0b7ad6fef35861c6c7d4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 08 Dec 2025 13:05:30 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[生成剪辑全都要！UniVA重磅开源：首个全能视频Agent，一站式搞定长视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgl7LVzsgFnQXO0fnBydjic7vadI22eiap5m10MUViaicwUibcPa0VzwMhibicAfPUtMg9VA4vQFXfMmtiauYA/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，来自新加坡管理大学（SMU）、罗切斯特大学（UR）、伦敦大学学院（UCL）、新加坡国立大学（NUS）、香港中文大学（CUHK）、斯坦福大学（Stanford）等顶尖科研机构的研究团队联袂发布了最</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714128&amp;idx=2&amp;sn=4c07c5ec73936be5700c4b827fc0ae13&amp;chksm=9715b2e354bc0eb3c217e66af59242c14aaef3ad43eefb0a8fddf33ac2166deff228f5153a3c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 08 Dec 2025 13:05:30 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[侮辱性极强！50+篇ICLR投稿被抓包：满纸假文献，竟获均分8.0好评？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkxgpQmcEtomqjf2CztUVMHeON9tGmNwZnicus8DNGH5CwxyibjyLE8XWOhrib5evYnWdkViaFqDcvlMQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>ICLR 2026 的瓜田，真是一波未平一波又起，根本吃不完。原本以为前两集的审稿连续剧已经够离谱了，大家也就是看几个投机取巧的团队在浑水摸鱼，被发现后撤稿也就剧终了。但现在的局势，似乎远比我们想象的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714055&amp;idx=1&amp;sn=7cfd3a97cce1b64af1f58d490509905e&amp;chksm=971e9eed6b272aa8ea0ca9b5984267e6a2b255b24b1c59a7c1885cabc8ff243ffb6864788819&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 07 Dec 2025 19:16:22 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI 2026 | LLM终身学习新范式：不仅要改得准，还要改得稳]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgkxgpQmcEtomqjf2CztUVMH8R04icL1RfrkAE1UxMYv8NYM0cOxjnax4ibVQZErbVd8quryjxTmwrKg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型在预训练阶段习得了海量知识，常常被当作知识库使用。但是，模型更新速度远远跟不上世界更新的速度，导致用户常常被过时或虚假的信息欺骗。在更新模型知识时，传统的微调类方法成本高昂且容易导致灾难性</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247714055&amp;idx=2&amp;sn=0dd749c00d0251ebe39c153fe64c7e01&amp;chksm=973ad26d83b1c2d59516265a8d85df344c15ed509f8b359cde40992e419b9a4a070f7eba69d1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 07 Dec 2025 19:16:22 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[建议NeurIPS改名漫展：全员二次元整活，搞科研哪有不疯的？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VBcD02jFhgnxq0l6tDe8frFRLWUVQS3rNmpmkIbYV2H8uSGNOhOTrVricrn6O8SUJ1BkyXaTMY6ice4uDCZTS1aQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>Nano Banana 的风，还是吹到了 NeurIPS 现场。经历了全年的 Peer Review 毒打，这届 NeurIPS 终于确诊了。大家不再执着于把 Poster 做成严谨工整的学术汇报，而</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247713997&amp;idx=1&amp;sn=e2524a95f0e9b67cf9ce49c84d7ef574&amp;chksm=97023552ff566fb11481ab1c77795cdf2e269eef7d575cc7980026e9ee5bac41be9f68bf3599&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 06 Dec 2025 12:34:23 +0800</pubDate>
    </item>
  </channel>
</rss>