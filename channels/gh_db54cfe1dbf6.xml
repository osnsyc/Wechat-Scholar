<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIWalker]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIWalker公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      <title>gh_db54cfe1dbf6</title>
    </image>
    <item>
      <title><![CDATA[大模型时代，Kaggle比赛可以这样高效！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDh1QwE6Xu7ItKItIgNavQohBpTgNJ0pQnicjJ59hY5Ue3ZPIdIXG1eYfuoic9QjfDiaV3s35iaLKk5QiaA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天聊聊一个困扰很多同学的问题：为什么读了很多论文，自己却还是写不出来？读论文当然很重要，能学到最新研究和创新思路。之所以自己写不出来，其实是缺少了关键的实践环节，没有把理论知识应用于实际问题。推荐一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700290&amp;idx=1&amp;sn=6b1f181856975fd7ea9dc037455ee910&amp;chksm=f2b9fc4fb3de3575dc32f1fa38464b24a54f8ee396d07f1375e23d794695c4bb2c455bb8ad9a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[U-Net和ViT凑一块，会发生什么？U-REPA：精准对齐Diffusion U-Net与ViT特征空间，训练提速42%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfqrnIHcT1dMOiccJsmRJoqyj4t80bLfia4E8mgszA7V04icFrVmhW05Zua2Ot15YKawLwjYeA92QJNBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | 极市平台  作者 | 科技猛兽本文只做学术分享，如有侵权，联系删文极市导读 一种将 Diffusion U-Net 架构对齐到 ViT（Visio</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700290&amp;idx=2&amp;sn=c59812b3b3bddccd62caaad4ff9e4715&amp;chksm=f2dc78c9291bfc5b8efb3dbea176743c7755c9ed070ba0d001337a665203018db0f260458fb4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动提出Pixel-SAIL!单一Transformer实现三大突破，性能不降反升！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IWuYddDHJQorFBEOfFtU8TPIX7D4uHMazCf9mknOoWp4iafibTrtZkeOdsviajlg9vcfaQqB42fY9CQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | AI妙妙房    作者 | 妙妙房最新论文解读系列论文名：Pixel-SAIL: Single Transformer For Pixel-Gro</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700288&amp;idx=1&amp;sn=9b36ffe134dfd50d167bc4e1c72464be&amp;chksm=f20c836e6a58ec462d1754924cebd655504315278f836cbc366c1b509db8c65d6ff55d8e9a7e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Apr 2025 14:47:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek多模态能力起底！一探究竟Janus 系列模型：解耦统一多模态理解和生成模型的视觉编码]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrbPQdqfW0V0UhQIEKXCmT6RpIaM0rnicib0ibx9gOlxt6ticjoajJcYQqbtrbNdxSuwNmic1ACibLzt9mQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨科技猛兽。编辑丨极市平台极市导读DeepSeek 团队生成理解统一架构代表作 Janus 以及后续扩大版本 Janus-Pro。>>加入极市CV技术交流群，走在计算机视觉的最前沿太长不看版Dee</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700281&amp;idx=1&amp;sn=91295e9d89683d2dd45c3fb6a77ae780&amp;chksm=f2d4cf1ce97a4426d20b8acca5f344801df89911dc99320fc56b02d7a2e8c9bc8a52dcf4b120&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Apr 2025 14:16:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MSDA | 多尺度注意力机制，即插即用，无缝涨点]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjICXkHAsujj2L8GfXGaicauM8lTWRoB6icej4CKAocH2nriaAS0NghI3PJeTbXAlxaSnBibwfW6icoMicw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家分享一个，至少能出二区idea的即插即用创新点：多尺度注意力！ 其不仅涨点效果显著，而且很有启发性，近来热度一直居高不下！比如代表模块EMA，23年5月才发表，如今引用量已经100+了！此外</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699959&amp;idx=1&amp;sn=4b7e1560d7e7e63c2032028d51c76592&amp;chksm=f2a64dbe6e64dc4b0f06e115f891f3d72dd399ea01ef6a63279a526dfdd1746e1514c4964809&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Apr 2025 10:04:28 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[修得快，还修得准！新一代视频修复技术FloED性能超越所有扩散模型! | 港科大&amp;达摩院]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogs0icLALvHu7EU0ibQ6DlKzYWiaMViabx65CaGn9YA1LibnMr21SwJ6A6WcqluzJ0HUGzrUkIOibAOyvNw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | AI生成未来  作者 | Bohai Gu等本文只做学术分享，如有侵权，联系删文文章链接：https://arxiv.org/pdf/2412.0</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699959&amp;idx=2&amp;sn=037c6e5f721983ac8c27e4bbf9e8b9a8&amp;chksm=f2f1f3ec1a291dd2bde338ad08441c1dc8f389b27de12368ebbd9c681b32db573087b009e7c0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Apr 2025 10:04:28 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[西工大&amp;台湾清华&amp;西电&amp;港中文 3位 IEEE Fellow 提出异构窗口 Transformer 的图像去噪方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTtJ8QUXbm6oLTNoNXhcSpZVYPibKKM96owXK7jk26AhNndKbQIiaibbdzQtqFKRk4YZ68mk2jDI3yMAw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | 我爱计算机视觉  作者 | CV君本文分享论文Heterogeneous window Transformer for image denoisi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699957&amp;idx=1&amp;sn=0b5d98630c11635897b47eef7e76ae38&amp;chksm=f285977d1acbbc5cd9fc564266645f98b27ca0622cbdefee18a8d86ac13bdfa1eb3c29b47f50&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 LLM优化收录创新高！Dobi-SVD超高压缩与性能完美平衡!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDia0FCGATPXMH4RzN52aibznYeicetbFNMMcMwwsdDLuWQlQBHZoafeue1XTB066ib2QuL5YZZISCABtA/640?wxtype=jpeg&amp;wxfrom=0"/><p>ICLR 2025将于4月24日在新加坡举行，今年的paper list已经公布。大模型仍然火爆，而"优化、高效、自适应和鲁棒”等关键技术的热度也很高。不难看出，学界的研究重点已经向模型优化、训练效率</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699951&amp;idx=1&amp;sn=ff2d973bdfac1a39ee54ee56b0b692e7&amp;chksm=f2466d404afcdac47d5a4879c7d44a9347c5751cd9dc0e73e4cf7902fe38bff8279014575db1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[突破传统“非此即彼”，真灵魂P图！腾讯最新FlexIP黑科技：身份保持和个性化我都要！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojNAzVMog676Mz77eWCZ5NVnWWDzI4KU68b2DfZ5cWbkYcqX6kRIyOE2WFVjLRRal1bUbOibvr47uA/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | AI 生成未来  作者 | Linyan Huang等本文只做学术分享，如有侵权，联系删文文章链接：https://arxiv.org/pdf/2</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699951&amp;idx=2&amp;sn=cc5bab44e6452616e1e6b04f52e13265&amp;chksm=f210fb64660ed26eb64394cd3e6d19c40e6fd81935c91e674d4085e0e4c115515288ae4680be&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[不用英伟达GPU！华为盘古Ultra来了：昇腾原生、135B稠密通用大模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDia0FCGATPXMH4RzN52aibznYSO8zPmfQwX98jiaUcIAmBLD0r7Xpq5pZ9lcoFBrNsewkhvhbRNfeMTw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | 机器之心，机器之心编辑部本文只做学术分享，如有侵权，联系删文终于，华为盘古大模型系列上新了，而且是昇腾原生的通用千亿级语言大模型。我们知道，如今各</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699950&amp;idx=1&amp;sn=84088b7807b60d19805e1870cefb6729&amp;chksm=f2bb7f4840f4f70b3e109ca6fecfbce60558345878277119705aa2eedf9098f8ab38061e574a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谢赛宁等新作上线，多模态理解生成大一统！思路竟与GPT-4o相似？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDia9LvZDkWiarLAUjqPePaScbawL7KtMDlSxsG6fkPyh0gSOHL0Qbo5Aw2pZSnV7Hs4EibxtTSA3icN1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>  新智元报道  编辑：编辑部 HXZ【新智元导读】来自Meta和NYU的团队，刚刚提出了一种MetaQuery新方法，让多模态模型瞬间解锁多模态生成能力！令人惊讶的是，这种方法竟然如此简单，就实现了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699940&amp;idx=1&amp;sn=0988f8f6387dd34e1bd73ad1bbc09f1f&amp;chksm=f205db18d8a0858b249dbde477c193e5658cca520ef913ccf786afca66b53d676c38a208a7da&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 14:25:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR2025 | DeQA-Score: 让大语言模型学会图像质量分数的分布]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/7VDuicY8zqyeBDGQlAlzmgYRUFpcaXAqia7XRrMXlQ51BTxvHic4yBtN2oHeB57JtLSdVNepCBTkAyLdrlqQhcaZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>主页：https://depictqa.github.io/deqa-score论文：https://arxiv.org/abs/2501.11561代码：https://github.com/zhi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699935&amp;idx=1&amp;sn=eae0d16f6519451c929a7af73f9c645d&amp;chksm=f23d5424cfd54ffabbd4e857b2135fb050646f88dd8501cbfb00b957c8bb610bb553eb1989e0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[惊艳！单模型统一多图个性化生成！字节重磅开源UNO, FLUX版训练、推理、权重全开源！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojEvjjQiaXW5nBNczrh6OVpMmXy6LYOULj18hzZaYC6icjEicVX8j5oKgvLB6vam4F917TcCO2FAvPaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | AI生成未来  作者：Shaojin Wu等文章链接：https://huggingface.co/papers/2504.02160 arXiv</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699935&amp;idx=2&amp;sn=d68d0742fda21055231e916f949da1ab&amp;chksm=f2b1e1bcebcbef72654dae5ccf3335bc5700fd6ee8e6b367bc489302e4ded2a1ab6a1672d4d4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[终于可以毕业了，一人成团，独中CVPR2025]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaCdU3zjvibs76rvbDCRL893A5q6gTmzCI5M1m71f5yZ28E6sibkFSQmvTelWALSu67Uw1bQK3urPxQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>被导师放养，你以为是没有压力，自由自在。实际上很多人没有自制力，被放养后没有方向，根本设计不出实验方案。甚至临近毕业，连论文都不会写。这就是放养最严重的后果：写不出论文，没法正常毕业。后面找工作/升学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699933&amp;idx=1&amp;sn=366eb005a748d1b2774068918e87c4da&amp;chksm=f25346e1b97848e69d815142aa69fdbed2494d87f1ea2b0436cf1f1e844376ab761816d44e8b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 09:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑进入“精修时代”！“指哪改哪”！北交&amp;美图发布DCEdit：改图不伤背景的终极方案]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogs0icLALvHu7EU0ibQ6DlKzYgH8tFPuD2b1cfKdVxHawYgtgszHYSUnaptuy3m8ia6IpVgZ40fPrJ9g/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Yihan Hu等    解读：AI生成未来文章链接：https://arxiv.org/pdf/2503.16795亮点直击精确语义定位策略，用于在源图像中进行准确的语义定位；插拔式双层控制机</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699933&amp;idx=2&amp;sn=96afc575520fabb7ac7b1f5c9c4e5db0&amp;chksm=f2c5f57c5c1761715a5eb9dd061a13abd5672985ae4280b6e9365ba38cca56270e071f3444d0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 09:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR2025 | 【方法创新】融入SAM语义信息的双层优化蒸馏：多模态图像融合新思路]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaCdU3zjvibs76rvbDCRL893iayQssaj7Af1rnx67oPEpItcJrydJX8YrFnORArn6sPRJxzYeGiaIDpQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号项目信息文章链接：https://arxiv.org/abs/2503.01210项目链接：https://github.com/RollingPlain/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699932&amp;idx=1&amp;sn=3dea326d218de71055074b938e10c2e4&amp;chksm=f260aa4fb797b4101cf38f6a7d0edc5423c46c571626962ed82b81307fce1d492ea7af1ea1df&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 14:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>