<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      

      <title>gh_db54cfe1dbf6</title>
      

    </image>
    





















    <item>
      <title><![CDATA[参数减少99.5%，媲美全精度FLUX！字节跳动等发布首个1.58-bit FLUX量化模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoh2Zk3Iwj5tM5QKick9Eg7sMHzHPiazuE08RhyHwiaSIKLUWJPrCskqeBNbCda9jDPROSF1YrFkT9yyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Chenglin Yang 等  解读：AI生成未来 文章链接：https://arxiv.org/pdf/2412.18653 项目链接：https</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699644&amp;idx=1&amp;sn=5b8832264289009aee456d21c638f81b&amp;chksm=f21436a3883e92c30372a6577fa3d12f89dc3baa928b4a1fa6d3715180662877b857ce9255d3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 15 Feb 2025 13:57:23 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Janus-Pro开源发布！多模态理解和生成统一新架构！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAddLUovribHUhl2jjG0t5l9D0ialmsgQJWDnJhvuVdvhktHGsfkKP2eexHIXa1wLNjibiaApc0DLJCfPw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 数源AI  作者 | 小源论文名：Janus-Pro: UnifiedMultimodalUnderstanding and Generation</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699644&amp;idx=2&amp;sn=cde359fa87c4ac0e12a48315cdd146ba&amp;chksm=f2464b39c7e17e60798b203037478ddaeac3a4e7b28cc92360c9a11551a2267aa85fcc4fe797&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 15 Feb 2025 13:57:23 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[NVIDIA提出新框架ImageRAG！RAG+AIGC提升图像生成质量！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JK3j8AP855QOPLGKEpd37E3bPLWmIOj4bSM2oUxbcSEQ3NFVFyqRhEKjhBGvFkPMAwAaMsbszianQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI妙妙房  作者 | 妙妙房论文名：ImageRAG: Dynamic Image Retrieval for Reference-Guided</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699639&amp;idx=1&amp;sn=16c850b2b769ec9b0d2ac9b79f9ae855&amp;chksm=f238bbc87b2cd6e55b7d4b6acb6bfe4a36ca1348df01078e4257342c1f370139a6e0e0048798&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 14 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[从低清到4K的魔法：FlashVideo突破高分辨率视频生成计算瓶颈(港大&amp;港中文&amp;字节)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojRPRMskuH1LsopSB0QxFHSEZnzZxCCHYCrPRFgibIxxWJtvibJ6Eibp1EDgPSqyokiba3Z9syUfh9SPQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Shilong Zhang等    解读：AI生成未来论文链接：https://arxiv.org/pdf/2502.05179 项目链接：https</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699637&amp;idx=1&amp;sn=5cdf39cfc25df1abb55c4fa127dba2ad&amp;chksm=f20f635e0cc8a00a32171ae771b794af6abf698854f0d6a637ec3b3671d7c0d7717324ff8d95&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 13 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[我都看饿了！港大&amp;字节发布领先商用级图像视频生成模型Goku有点东西]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiarfqKsZt5JOia1kJbRhQk3IlXhu3NXhpRy5iacBexDEmicr5KBQWBr53FwZH0CE82FvFL7iaFV3L30VQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Shoufa Chen等    解读：AI生成未来文章链接：https://arxiv.org/pdf/2502.04896 项目链接：https:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699635&amp;idx=1&amp;sn=59e552476d38d77daf43139c179816eb&amp;chksm=f208e81151434ee4c8e458e690251d1f2fe830c98bbf21284b59056341755466d3cfd72492d7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 12 Feb 2025 13:59:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2025 NTIRE赛事 |  XGC质量评价挑战赛AI Generated Video赛道，等你来战！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/hEx03cFgUsVRnq63vF3yMuMXUGC8nZ6TASsNkfbSMaXyQVS3jEs9OIGghdfV9U4zFzIaRptE6gsWgF0pJGibF7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>CVPR NTIRE（New Trends in Image Restoration and Enhancement）Workshop 是计算机视觉顶会CVPR下极具影响力的国际学术研讨会，聚焦图像复</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699635&amp;idx=2&amp;sn=0c3bb524995883ab7705195dcf540290&amp;chksm=f21a0e6eafb42023ce6c81fa8230c075a51a7431fc887e37688f63c15585c4483eedea9ae992&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 12 Feb 2025 13:59:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Vision-LSTM | LSTM原作提出新一代LSTM，刷新SOTA高度]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjltaw0SEGqgtjHaQdzYibO4ZibZn4BdiagoXicuzhZNWSNGVhibZmlSgEbeg046bWo1UoSh9DyfibeDiaLQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今年LSTM火了！LSTM原作者分别提出xLSTM和Vision-LSTM，解决了以往的局限性。同时，LSTM+Transformer登上Nature；LSTM+CNN、LSTM+Attention等</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699633&amp;idx=1&amp;sn=df0c5b1807729838cc9ff482bfa9c598&amp;chksm=f2084bfea3a8d7c26b8d570b41aea7fecd304f0a94ab4994fcf30ffa7b7592f457e8bec244c3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 11 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里通义Lab提出LLMDet！利用LLM构建强大的开放词汇检测模型！超过Grounding DINO！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAda5jeuyro2lWcArxz3odb54PeInPEIddolGYhUg5ZPlGYeNwpgVuvtMEeqk9PDIE7UiahXWwaNYHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源于数源AI，作者小源论文名：LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of La</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699633&amp;idx=2&amp;sn=63a02ca3eb06aa46dd51b64c41f9784d&amp;chksm=f215cb435df5eeb9f7e07c92ce4519ed0dea295c06e2465d55867a57d8592c2eaf3970916535&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 11 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[同济提出简化 Transformer结构：在RTX3090上实现CLIP的轻量级训练  ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglUUfpibMCquHiaV7ywvPJLfKM47GhtNBx2YZ8EOPQ0IG6KHA0kLGrZSaNh4GFHUaGWUtZt4Xon2aug/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于集智书童，作者小书童对比语言图像预训练（CLIP）因其卓越的零样本性能和优秀的迁移能力而受到了广泛关注。然而，训练这样的大型模型通常需要大量的计算和存</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699630&amp;idx=1&amp;sn=ccad03e784d3972bd88d6665dada47ff&amp;chksm=f2aac43bee2669326fed64b128832749fdca2275246918c6a8c1af4e16239cf053483f5b7f9d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 10 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[字节提出FlashVideo！更快也更强了！高保真的高分辨率视频生成新SOTA！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAd0deicvXpiazUpCYfuZapDIyrySv8m0ALV62aKfwmZprnLRyickd6yeUeGH5bbvFeOtEnX9ccjPlhQw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于数源AI，作者小源论文名：FlashVideo：Flowing Fidelity to Detail for Efficient High-Resol</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699630&amp;idx=2&amp;sn=46f9bc15c1f8da4bdab163eaa3ed0fd7&amp;chksm=f267870ba668c034b261b779b58aeaa76a209b9cd0dce0d0b3d813cbac58a2ba10ab0b6e5749&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 10 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NTIRE 2025光场图像超分辨挑战赛正式开赛 | 验证平台已上线！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjp2c4Bm06F0KLRcgDiczYEJOyXRxApuwGP5fNwn3EIb7wdDYTKIJtkrdq0Rtf3icOUQn5OFYXGZCicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>光场图像超分辨挑战赛 （Light Field Image Super-Resolution Challenge）将作为NTIRE研讨会的一部分，与CVPR 2025一起举办。NTIRE全称New T</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699618&amp;idx=1&amp;sn=d392b162f0d1ae2e0f94f9cab7573fd9&amp;chksm=f29ba9940d928e425d0f0c1bfce9970b4af752a7c34d25ea2e4973ab01709e1953224e1819fe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 09 Feb 2025 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2024 ｜抖音“BDVQAGroup”获得 DXOMARK 图像质量评估挑战赛全球第二]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/IMJ5I2wiakzu0FIITRah1yQibfc2pjOJIPsPbic17ibq5doClmhfDOVvbLvwpbgel8IJouFg7qHhWJbLQvFDBXxbLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期，在计算机视觉领域最具影响力的「国际竞赛 CVPR 2024 NTIRE」中，抖音基础体验QA团队与AI 平台团队同学组成的“BDVQAGroup”小组，在 DXOMARK的图像质量评估赛道中，凭</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699618&amp;idx=2&amp;sn=a4f419b6d408b1b28ab17ca15b4d1a14&amp;chksm=f2b2fe0e7124841af2870c69ce1e33e8ac295293ef72384a641dd28b793d9b974831852eaac7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 09 Feb 2025 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2025 NTIRE赛事 | AI 生成图像质量评估挑战赛：双赛道 + 大奖 + EvalMuse 数据库，等你来战！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/IMJ5I2wiakztSnU1QgNBIzY7ia5uvRkice6WxtCGdsXAI9xLSEibicnQtf6nSZpSqHvyKssu6iaYf8DJpocSp54WeH2A/640?wxtype=jpeg&amp;wxfrom=0"/><p>CVPR NTIRE（New Trends in Image Restoration and Enhancement）Workshop 是计算机视觉顶会CVPR下极具影响力的国际学术研讨会，聚焦图像复</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699607&amp;idx=1&amp;sn=21c39624f9d75434ca76bdd8ce32f4e3&amp;chksm=f2cd7b800ac89518e173769f70918d5aeffb350e32deea268e18eb7a28e16db3c435fa161900&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 08 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华联合腾讯提出全模态模型Ola！图像、视频和音频等多模态理解一网打尽！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5ILy9I4g9e9dFh1achfYgv3N1UvxyxaO5FN5kwaEYDvzicXohJyGkQPum02iaiaiaoIyUCYuw4f7VG7cQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者妙妙房今日论文推荐论文名：Ola: Pushing the Frontiers of Omni-Modal Language Mode</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699607&amp;idx=2&amp;sn=a603ff11ddc369b524fc57d6282f05bc&amp;chksm=f26f10d6df2d408fe3d6a5f47c8d0d750ef7c9436526f0458e8c434d8439e31c8064e950133b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 08 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
