<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIWalker]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIWalker公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      <title>gh_db54cfe1dbf6</title>
    </image>
    <item>
      <title><![CDATA[PaperMate 正式上线：您的下一代智能学术写作解决方案]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiarNbLYhSib5EXShLXIywoTA3cvPMMou2tFPiaNAVXT9oDNBCtMlPDcc3PUUCsmP4icMcUpsCZdUcDPw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在学术研究与论文写作中，效率与规范性始终是研究者面临的核心挑战。今天，我们正式推出 PaperMate(论文搭子)—— 一款融合人工智能技术的学术写作辅助平台，致力于为学者、科研人员及学生提供从文献管</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700388&amp;idx=1&amp;sn=1a1038eaf03751726d443530995db5de&amp;chksm=f2192caaaef4483bad9a07fca2a9603f48e9bafefca29581b97e7914c7b1478bd106247345d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Jul 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[PINN又爆创新！算法小改，百倍加速！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaUcEBdIP0ur7nqm9vYgWtk6ZNjvrPSHdlDm1t0QlTV0rLKE15NhmYHyZia3PTeTXIP39X40tjoCYg/640?wxtype=jpeg&amp;wxfrom=0"/><p>学术界大明星PINN又新爆了不少好东西，近期的就有权威期刊JCP2025上的VS-PINN，算法小改一下，就比原生PINN加速近百倍！另外还有个经典作Stiff-pinn，单单今年就被引100次！需知</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700383&amp;idx=1&amp;sn=f0ce9bca21e29c489bfecc03c899b85f&amp;chksm=f205c7fc9c193e7df50ff60443a95005a2b35b40af6c76439d78bcb409d79aab540da50ea750&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[WuNeng架构：融合RWKV-7与注意力机制，以多策略增强表达力兼顾计算效率 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVVDYzBKxGI1EYyvBFZYujxTU15Khggj1geV5zGZRJeXCCPBfGp4gn9hIv7rTX6lBW8sCTsb5fbhrg/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | AI视界引擎  作者 | AI引擎WuNeng架构通过将基于循环神经网络（RNN）的RWKV-7与先进的注意力机制相结合，为提升大语言模型的表达能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700383&amp;idx=2&amp;sn=0a932793673110e1e5cad80509d52f08&amp;chksm=f23b03f317a7774eef5e8c48b535dc37f557b2cac7e57484fb41b131792d136f58bf1dc398c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 Workshop - MIPI 赛事启动｜UGC图像质量评估挑战 ViDA-UGC 正式开赛]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/IMJ5I2wiakzuwbLA0UdaGHOFsN7yicT7vNb6Z7NzSDKDQLDWiaegctsNbicLm0ZtF1gaQPibo2qJNzXCZvDEwRnQmXw/640?wxtype=jpeg&amp;wxfrom=0"/><p>ICCV MIPI（Mobile Intelligent Photography and Imaging）Workshop 是计算机视觉顶会 ICCV 下聚焦移动智能摄影与成像的前沿学术研讨会，重点关</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700381&amp;idx=1&amp;sn=c38bb477c20ef74ac1a3eda7361d4108&amp;chksm=f2f31a96a6319b9c884188009a7de1da5764bf8ed90c543230be4dab750c81b10400986bd033&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 15:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[好莱坞颤抖！中国团队造出首个“懂电影”的AI：44万镜头库喂出导演级运镜]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohLaTala1DlaKL90Oib9YfRs0ibWBkLKXNyianp2vqlTHq5ypLgHIpRfaibsvk2OKicXYJokL5C745n10A/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号作者：Kaiyi Huang等    解读：AI生成未来文章链接：https://arxiv.org/pdf/2506.18899 项目链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700381&amp;idx=2&amp;sn=2c067d3c8cccfe62089500b1152d8a8a&amp;chksm=f2d20311f413d71445488c2ab46195df6389c027e3f3fe5a02c09924a3ecbb945c673ecde46a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 15:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态融合原来这么好发论文？看完我像被“点醒”，太赞啦！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaoRIbjJuPglxAEmnImVgjz6MicsoPbycLM6rRpgVDa8pHhvZ669lAdr7C0p5Exf2ZrjbrWmhicqiaBg/640?wxtype=jpeg&amp;wxfrom=0"/><p>谷歌大佬Jeff Dean曾表示，他对多模态的发展非常看好。事实也确实如此，尤其多模态融合，已经成了工业界数字化转型的核心技术，在CVPR等顶会也呈持续霸榜状态。纵观近几年的文章，目前多模态融合主要有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700375&amp;idx=1&amp;sn=136feda88c23d3f9b47e3335757f2650&amp;chksm=f29f74ed2c0743110cc9139f98230fe0c46e39a5621122da7a2d972a09bd20c37312c23b8a07&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 24 Jun 2025 09:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Mamba-Adaptor：融合Adaptor-T与Adaptor-S模块，革新视觉任务，在多场景及基准测试获卓越成效！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVWicse3H09Tl8Tiaf0VDznCKwDVmSrskqh4xBb6aMibiaXRVqM1kxkDocK3PIQpib0x47llAbHYicWzqYRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | AI视界引擎  作者 |  AI引擎近年来，状态空间模型（SSM），尤其是Mamba，在视觉建模方面展现出卓越的性能，并具备高效的模型特性。然而，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700375&amp;idx=2&amp;sn=d908e585f731a5ba3d17ff681e17cb0e&amp;chksm=f245d2b7aa6430a2694a594ec57f7731f239e5093a813790e874b0b0bc95b57f2b4415148dc7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 24 Jun 2025 09:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型六大新动向：LLM+合成数据、LLM+奖励模型、大模型推理、LLM-as-a Judge、安全对齐、长文本]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgzcHbOkT3Fqltz7ic3MOIKFYLesakSfxzm9KqKNeOledxxWZzVhekQhqAtTN7JUxjAA02EiaovtgzA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大模型有多火，自不必多说，但是想发论文完全没头绪？那你一定不要错过这6个，备受顶会青睐的方向！LLM+合成数据：当下的新兴方向，还不算卷。其缓解了大模型依赖海量数据，而诸多真实数据难获取等问题。各类O</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700369&amp;idx=1&amp;sn=9077a26a8ea014de9edde6ac698a1072&amp;chksm=f26531fee49831f21cc1226e15ae7e18db4a4f760f5d468b6769f0da20cf0542ed17b16d8192&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 18 Jun 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[语义分割新高度 | 英伟达提出SeNaTra空间分组层革新Backbone，性能效率双超Swin Transformer]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglTDY72bzYEsBy24c3IiaheZDfEkz4zQwLU79LoeKEfSicuQl9wKbKJaFvWy7Yh1zel671DqFB0JHdQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | 集智书童    作者 | 小书童 精简阅读版本本文主要解决了什么问题1. 统一的分割架构设计：现有的视觉Backbone网络通常依赖于统一的下采样</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700369&amp;idx=2&amp;sn=7baf9d22824eec05cca65f8b56273fad&amp;chksm=f21a7c87231b3632b406c998c78aa0e69784f714ad7e0c35e954f9676fba63674341732075f7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 18 Jun 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[2025顶会上的100个即插即用模块]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgFcicfxqllbicU4LxIML7xx5wkPnJLuTjHfmjU5JZgzvq5Eqz8fcBN2Gfia0YNQ7UHHIH45Se97yhvA/640?wxtype=jpeg&amp;wxfrom=0"/><p>有创新点，就能顺利发paper吗？当然不是！有了创新点只是开始，模型的编码、调试才是重头戏。很多小伙伴都是改了大量的模型和代码，实验结果却没有多少提升，白白耽误投稿时间。今天就分享一些发paper必备</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700362&amp;idx=1&amp;sn=3b09019d748af022eafe64abddd4461f&amp;chksm=f223a813d2b022b3298fa86f451f7c6cad19c0d57c35780428515dc204c4ca455099e1b2abc6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 10:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[西安交大提出DeepKD | 双层解耦+自适应去噪破解知识蒸馏困境，刷新ImageNet等多项SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgmIiciaevBZsFtK90zcS3Kicg9GG0NxNtZaN83k0XENGBMKu7IoBddxfQ244RqgnSZIXcCe3II51j8Yw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 集智书童    作者 | 小书童 精简阅读版本本文主要解决了什么问题1. 目标类和非目标类知识流之间的固有冲突：现有方法未能有效解决目标类和非目标</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700362&amp;idx=2&amp;sn=caf25d80d73c9d8fdd5d4a27a60e6bc8&amp;chksm=f2087fb28a2a4444ca58da7f05274958ec5f76cf2bc323db4b67eb968b94367c5dfcdc024ade&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 10:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NTIRE 2025 用户生成内容视频增强挑战赛：方法与结果]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgFcicfxqllbicU4LxIML7xx5Dks6h4OLhsRoAa0g1G7PibhNibr3smwOic7wgWb3krniaiaM2bpG8k37rDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 小小cv笔记  作者 | bochen论文题目NTIRE 2025 Challenge on UGC Video Enhancement: Met</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700360&amp;idx=1&amp;sn=dd956a6157ae71826f962abcbbe82e02&amp;chksm=f25e33c0ab259b0c59bf7184f8f3ed88e9e0d2c2612af4fa866bef43777cb2390e78673c7510&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[哈工大、西工大、福大、澳大、港中文联合提出一种树形卷积神经网络的图像超分辨方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6sCbWdFy0B6W8icB3v4TcMHNCU8sY1DT50Nv6zTBjY4MXialu7yqEsMGsZLJj3fsu9xCu7nVrttBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 我爱计算机视觉  作者 | 52CV 本篇分享论文A Tree-Guided CNN for Image Super-Resolution，哈工大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700360&amp;idx=2&amp;sn=e5083a9ab29bb8e0ffa88ba86565066c&amp;chksm=f2513f89e7c14c85483bb0b1ded0f324f8480ddde6aac4689f324ac92301e55e3de7fa990a4f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[修图模型照妖镜上线！ImgEdit-Bench三维「死亡评测」曝光，谁在裸泳一测便知]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogrJsxw5f4NIynCF7ds2Cp4Tia9iaYZ02C9hdiaeTp6EiaRnxsRQqOEWdSoQoiaXeibv8pVn4Pd21wEBTTw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Yang Ye等  解读：AI生成未来文章链接：https://arxiv.org/pdf/2505.20275 Git链接：https://gith</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700348&amp;idx=1&amp;sn=e0332fa3d514bc05e580bd8da0c6372c&amp;chksm=f25bbbeb7a259ed71fd5f9b309805eaaf6dbf2b24839272baec0bcc6dfe8b41c7a79b6b3620c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 May 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型那些事儿。。。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgmsJeibUEZYnstTe9ZhvPpcqybx9KxzXefNVEzkkuxktkdicn8IegS7hFPYVCc95sudBFQIKJwX8JQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>作为AI领域的大势所趋，多模态可谓是火的一塌糊涂，在各大顶会都是霸榜的存在！关于它的研究，近来也发生了诸多变化：跨界缝合成为新风向，比如用多模态模型分析财报文本+管理层表情+市场指标预测企业价值；研究</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700346&amp;idx=1&amp;sn=8ed905f406c164c0deae5cf24b74c1b9&amp;chksm=f22341de77f9a4573ef988ba81a4ba254653fc21a1259a27667ba095c442c88db38b627e53f6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 27 May 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[目标检测和语义分割该如何走下去？清华团队为视觉大一统模型指明了方向。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ0NrohXIPQuia7rMdB4dao6srfu4IVoGPfaq8lvv4pFTn9Fax4cA0WzePXLehF3ibTkPxHx6GSDiadicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | CVHub  作者 | 派派星 导读在计算机视觉领域从"任务特化"向"统一开放"的演进历程中，我们见证了从手工特征工程到深度学习范式，再从闭集假设</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700346&amp;idx=2&amp;sn=e6e69807532afa0c18d2c4047ac53465&amp;chksm=f20d5fc9aa193724214eff84d0c9c4839cd07b98b202ed5c3fc31b98c9c6fb22a2a9c50af16f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 27 May 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[RL颠覆视觉传统 | VisionReasoner 首提统一框架，检测/分割/计数3类任务超越YOLO-World等专用模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglNS6v9PSGBf6FzOKb2Wg1ic13iaibuiaCtvGaxjdFhYK6USm0p0icoGicbvkYjqAspqjY7XZSTaRJlSiaAw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | 集智书童  作者 | 小书童精简阅读版本文主要解决了什么问题1. 现有视觉语言模型（LVLMs）在处理多样化视觉感知任务时依赖任务特定模块和奖励函</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700343&amp;idx=1&amp;sn=822e4e1bca6d4517b1cd55b3b0f3a2b7&amp;chksm=f2e7f7f6cbf4bc5cba2203f13949add0a58a29d289aca3a1b699153fefc8a06ffad006018653&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 26 May 2025 14:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>