<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      

      <title>gh_db54cfe1dbf6</title>
      

    </image>
    

















    <item>
      <title><![CDATA[我都看饿了！港大&amp;字节发布领先商用级图像视频生成模型Goku有点东西]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiarfqKsZt5JOia1kJbRhQk3IlXhu3NXhpRy5iacBexDEmicr5KBQWBr53FwZH0CE82FvFL7iaFV3L30VQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Shoufa Chen等    解读：AI生成未来文章链接：https://arxiv.org/pdf/2502.04896 项目链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699635&amp;idx=1&amp;sn=59e552476d38d77daf43139c179816eb&amp;chksm=f208e81151434ee4c8e458e690251d1f2fe830c98bbf21284b59056341755466d3cfd72492d7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 12 Feb 2025 13:59:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 NTIRE赛事 |  XGC质量评价挑战赛AI Generated Video赛道，等你来战！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/hEx03cFgUsVRnq63vF3yMuMXUGC8nZ6TASsNkfbSMaXyQVS3jEs9OIGghdfV9U4zFzIaRptE6gsWgF0pJGibF7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>CVPR NTIRE（New Trends in Image Restoration and Enhancement）Workshop 是计算机视觉顶会CVPR下极具影响力的国际学术研讨会，聚焦图像复</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699635&amp;idx=2&amp;sn=0c3bb524995883ab7705195dcf540290&amp;chksm=f21a0e6eafb42023ce6c81fa8230c075a51a7431fc887e37688f63c15585c4483eedea9ae992&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 12 Feb 2025 13:59:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[Vision-LSTM | LSTM原作提出新一代LSTM，刷新SOTA高度]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjltaw0SEGqgtjHaQdzYibO4ZibZn4BdiagoXicuzhZNWSNGVhibZmlSgEbeg046bWo1UoSh9DyfibeDiaLQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今年LSTM火了！LSTM原作者分别提出xLSTM和Vision-LSTM，解决了以往的局限性。同时，LSTM+Transformer登上Nature；LSTM+CNN、LSTM+Attention等</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699633&amp;idx=1&amp;sn=df0c5b1807729838cc9ff482bfa9c598&amp;chksm=f2084bfea3a8d7c26b8d570b41aea7fecd304f0a94ab4994fcf30ffa7b7592f457e8bec244c3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 11 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里通义Lab提出LLMDet！利用LLM构建强大的开放词汇检测模型！超过Grounding DINO！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAda5jeuyro2lWcArxz3odb54PeInPEIddolGYhUg5ZPlGYeNwpgVuvtMEeqk9PDIE7UiahXWwaNYHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源于数源AI，作者小源论文名：LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of La</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699633&amp;idx=2&amp;sn=63a02ca3eb06aa46dd51b64c41f9784d&amp;chksm=f215cb435df5eeb9f7e07c92ce4519ed0dea295c06e2465d55867a57d8592c2eaf3970916535&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 11 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[同济提出简化 Transformer结构：在RTX3090上实现CLIP的轻量级训练  ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglUUfpibMCquHiaV7ywvPJLfKM47GhtNBx2YZ8EOPQ0IG6KHA0kLGrZSaNh4GFHUaGWUtZt4Xon2aug/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于集智书童，作者小书童对比语言图像预训练（CLIP）因其卓越的零样本性能和优秀的迁移能力而受到了广泛关注。然而，训练这样的大型模型通常需要大量的计算和存</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699630&amp;idx=1&amp;sn=ccad03e784d3972bd88d6665dada47ff&amp;chksm=f2aac43bee2669326fed64b128832749fdca2275246918c6a8c1af4e16239cf053483f5b7f9d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 10 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[字节提出FlashVideo！更快也更强了！高保真的高分辨率视频生成新SOTA！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAd0deicvXpiazUpCYfuZapDIyrySv8m0ALV62aKfwmZprnLRyickd6yeUeGH5bbvFeOtEnX9ccjPlhQw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于数源AI，作者小源论文名：FlashVideo：Flowing Fidelity to Detail for Efficient High-Resol</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699630&amp;idx=2&amp;sn=46f9bc15c1f8da4bdab163eaa3ed0fd7&amp;chksm=f267870ba668c034b261b779b58aeaa76a209b9cd0dce0d0b3d813cbac58a2ba10ab0b6e5749&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 10 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NTIRE 2025光场图像超分辨挑战赛正式开赛 | 验证平台已上线！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjp2c4Bm06F0KLRcgDiczYEJOyXRxApuwGP5fNwn3EIb7wdDYTKIJtkrdq0Rtf3icOUQn5OFYXGZCicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>光场图像超分辨挑战赛 （Light Field Image Super-Resolution Challenge）将作为NTIRE研讨会的一部分，与CVPR 2025一起举办。NTIRE全称New T</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699618&amp;idx=1&amp;sn=d392b162f0d1ae2e0f94f9cab7573fd9&amp;chksm=f29ba9940d928e425d0f0c1bfce9970b4af752a7c34d25ea2e4973ab01709e1953224e1819fe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 09 Feb 2025 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2024 ｜抖音“BDVQAGroup”获得 DXOMARK 图像质量评估挑战赛全球第二]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/IMJ5I2wiakzu0FIITRah1yQibfc2pjOJIPsPbic17ibq5doClmhfDOVvbLvwpbgel8IJouFg7qHhWJbLQvFDBXxbLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期，在计算机视觉领域最具影响力的「国际竞赛 CVPR 2024 NTIRE」中，抖音基础体验QA团队与AI 平台团队同学组成的“BDVQAGroup”小组，在 DXOMARK的图像质量评估赛道中，凭</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699618&amp;idx=2&amp;sn=a4f419b6d408b1b28ab17ca15b4d1a14&amp;chksm=f2b2fe0e7124841af2870c69ce1e33e8ac295293ef72384a641dd28b793d9b974831852eaac7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 09 Feb 2025 04:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CVPR 2025 NTIRE赛事 | AI 生成图像质量评估挑战赛：双赛道 + 大奖 + EvalMuse 数据库，等你来战！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/IMJ5I2wiakztSnU1QgNBIzY7ia5uvRkice6WxtCGdsXAI9xLSEibicnQtf6nSZpSqHvyKssu6iaYf8DJpocSp54WeH2A/640?wxtype=jpeg&amp;wxfrom=0"/><p>CVPR NTIRE（New Trends in Image Restoration and Enhancement）Workshop 是计算机视觉顶会CVPR下极具影响力的国际学术研讨会，聚焦图像复</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699607&amp;idx=1&amp;sn=21c39624f9d75434ca76bdd8ce32f4e3&amp;chksm=f2cd7b800ac89518e173769f70918d5aeffb350e32deea268e18eb7a28e16db3c435fa161900&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 08 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华联合腾讯提出全模态模型Ola！图像、视频和音频等多模态理解一网打尽！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5ILy9I4g9e9dFh1achfYgv3N1UvxyxaO5FN5kwaEYDvzicXohJyGkQPum02iaiaiaoIyUCYuw4f7VG7cQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者妙妙房今日论文推荐论文名：Ola: Pushing the Frontiers of Omni-Modal Language Mode</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699607&amp;idx=2&amp;sn=a603ff11ddc369b524fc57d6282f05bc&amp;chksm=f26f10d6df2d408fe3d6a5f47c8d0d750ef7c9436526f0458e8c434d8439e31c8064e950133b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 08 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ICLR 2025｜4K分辨率拿下！超强杀器SANA：线性扩散模型+文生图+高分辨率+从头训练的极佳范本！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoB3wnvyicAeBiapGlk1QnaYXZCPH1FA4Apdk4C3vqMN8BfEfMegdgP6t7cVx4fib32z9ht9PSdcFiaNQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 Sana通过32倍压缩率的AutoEncoder、线性注意力机制、Decoder-only的文本编码器以及高效</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699605&amp;idx=1&amp;sn=0e09bcf515e8363999a620918f09e36e&amp;chksm=f25d961c38ae70c3b26b0565d3a5b00c5d9f01ceae3e43393dd51545414659e2632dca9eeb33&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 07 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Janus-Pro开源发布！多模态理解和生成统一新架构！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAddLUovribHUhl2jjG0t5l9D0ialmsgQJWDnJhvuVdvhktHGsfkKP2eexHIXa1wLNjibiaApc0DLJCfPw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 数源AI  作者 | 小源 论文名：Janus-Pro: UnifiedMultimodalUnderstanding and Generatio</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699605&amp;idx=2&amp;sn=35deeaf0f7fbf2e51b3f208a2cd5941b&amp;chksm=f230c6aba60c757bff294673688ee9f65b1b36bfdb16ac9494791654d4cf2af1b5028985f4bf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 07 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[上交&amp;哈佛提出FluxSR：首个基于12B+大模型的单步扩散真实世界超分模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohiaxyvzRbsZQPBI3oJpycPj95YDUfvH221sa1p9eCJAbnPn73xsl4zBOwT9qnicBCtOb6220o5wEicA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI生成未来    作者 | Jianze Li等论文链接：https://arxiv.org/pdf/2502.01993 代码&amp;模型链接：ht</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699599&amp;idx=1&amp;sn=52cecdcffdf4b29bccb83097f35ed6d9&amp;chksm=f2fb7e7cca512d5c185eda6f4ce13b4650096428de12887a2dc5803eb09a65e3e13cd6b1ea9f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 06 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[YOLO系列10年更新11个版本，最新模型在目标检测多项任务中达SOTA]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/QkCvnz083AhlqyZDx3ju56I5pao6yBE15a275kTBdn4icXJ6fURcWZRicPOSr8rUAebicfmjggibbFiaAtuuCruKRoQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：大头编辑：李宝珠转载请联系本公众号获得授权，并标明来源HyperAI超神经官网的「教程」板块已上线 YOLO 系列的多个版本，一键部署即可体验~YOLO (You Only Look Once)</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699599&amp;idx=2&amp;sn=6e687911cacef9825076774d468cb182&amp;chksm=f29a63b280d464eb280ba94955af4b1947232db569a8b7399b8b472f032b8f866428996e587e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 06 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[【附复现代码】基于PINN的论文改进探索]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgoy53lXDGsXBe73WEsbdoAicrlVQOJyusjicknnpPicUBUZmOZNWibSAuy9N9EdC1Mm0ahLHpoJfxYOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近有一个大热门：物理信息神经网络（PINN），不仅是各大顶会常客，还连登《Nature》。PINN是将物理定律嵌入深度学习框架，约束神经网络训练的新型方法。特别适用于解决AI交叉学科中复杂的偏微分方</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699597&amp;idx=1&amp;sn=b0fbd16f23ea21266360a36b8012011f&amp;chksm=f2551693646e4b2586d7fd5d03b97c39e4a719758fc47550d325aa833b490389e553f9f3dc11&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 05 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NVIDIA提出SANA1.5！高效线性扩散Transformer助力图像生成新SOTA！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Inicn3eCDibsG5QCtKpvf7BccHrpCTHBJBffEOROEhL7e1fXn5vv1gQicRz4uMAVzwWRJMLNMyLR0uQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI妙妙房    作者 | 妙妙房计算机视觉最新论文今日论文推荐论文名：SANA1.5: Efficient Scaling of Trainin</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699597&amp;idx=2&amp;sn=a402dff910fd5c180b30ad4ddff3df2c&amp;chksm=f2d5261f2561d3649c2059ef83cac6e44ee70f6412bffa809f112aab120108702cbc5ecca5d4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 05 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CoT助力图像生成！港中文提出文生图的o1推理新方案！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAfiaVtMMbFmV8dEcuHMUPnfLTJp5ycd4LHZmLz83uELuvsWBXRTEBHlFnC1ic8FicoO2cOchjuCRt5fA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 数源AI  作者 | 小源论文名：Can We Generate Images with CoT? Let’s Verify and Reinfo</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699595&amp;idx=1&amp;sn=20938e865b712912bac53afac938de62&amp;chksm=f25310a84a54f539786272dbd7db95c453624ae100d5686ed37f08effdff778e094c11f90094&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 04 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Meta最新开源：让LLMs无需任何训练即可“看到”和“听到”！MILS：图像、音视频全SOTA！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icognghe3s2zmv0icZcyxgqgI3J1Bc3oWvJMrjrA7AARdqaMZhOXCuRBtrmGqdgLYbuVq0puLBg614ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Xinlei Chen等   解读：AI生成未来论文地址：https://arxiv.org/pdf/2501.18096 代码：https://gi</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699595&amp;idx=2&amp;sn=1071d7be7e12779c36b5466364aadc84&amp;chksm=f279c795eadcad83672cc5020396940681c61f665a700eabbfe551b4e7178f37e7a0667c5144&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 04 Feb 2025 14:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
