<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      

      <title>gh_db54cfe1dbf6</title>
      

    </image>
    
















    <item>
      <title><![CDATA[书生·浦语大模型升级，突破思维密度，4T数据训出高性能模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDghQcWic0M6MpPS8KLbaK5wia1Vs4ullLnCYp1bC7W4dOic7aSwDuh3XF8P8YexvViaqXLqh1ticic3PXdg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 上海人工智能实验室“尺度定律”之下，大模型除了要突破算力瓶颈，亦面临高质量数据即将“见底”难题。如何通过“通专融合”技术路径实现通用人工智能，正日</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699574&amp;idx=1&amp;sn=d3c42ba339027881b56d01ea7c0b4c36&amp;chksm=f2136c52fe98a1bb773393aa9f2ba0e61283a9836377bf2428e268d60e8717a6aa3a38520ee8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 16 Jan 2025 14:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[哈工大联合华为诺亚提出FramePainter！交互式图像编辑新方法！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KR9doORF5tGianl6WBOu3Nt5LJAUFORqI2qwsVxmGSnoUk4CK9zic7a4NZ603dhvDwYuP7P9Hsr1vQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源于AI妙妙房，作者妙妙房计算机视觉最新论文今日论文推荐论文名：FramePainter: Endowing Interactive Image Editing with Video Diffusi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699574&amp;idx=2&amp;sn=13a63548cd33f3756ea8dda8bd2949da&amp;chksm=f28e473b95271f8cf47bc9f1452d05e9d5dfe0b83a38ef4861eecb7aedcb7d581344914fe181&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 16 Jan 2025 14:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[即插即用，轻松涨点！把大牛的模块缝合到自己的paper里]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgwsoYQUe5BHqMaliadcH45icjt6CAQHg2b4Aeo0ZzwiaOtv0JpgFpZyN5x47icZsdZYj9M040zRknSYQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>有创新点，就能顺利发paper吗？当然不是！有了创新点只是开始，模型的编码、调试才是重头戏。很多小伙伴都是改了大量的模型和代码，实验结果却没有多少提升，白白耽误投稿时间。今天就分享一些发paper必备</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699569&amp;idx=1&amp;sn=8b3041f44459f1b3612759665294c2d4&amp;chksm=f2f9535408370e6070cc22c85c285ce980938db572b5074d1fd368b7580533a552212425bdcc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 Jan 2025 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[贾佳亚团队新作MagicMirror：生成身份一致且高质量个性化视频，效果惊艳！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohNzJYLzvucR101lSrljODrBXEicXlI4nrHW9M6JibzE8H9RXnZZBE3HCibKFuEdHJQiblYDfWPgjHia8w/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Yuechen Zhang等    解读：AI生成未来文章链接：https://arxiv.org/pdf/2501.03931 项目链接：https://julianjuaner.github</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699569&amp;idx=2&amp;sn=7326d979be2fbdc2c545f8b3ea59df43&amp;chksm=f2af88352454ab922cac3a66f79668404e61cb5ab19336d84551dfe7eea017f3ce4933d73e40&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 Jan 2025 10:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[纯卷积实现用于图像生成扩散模型？DiC：重新思考扩散模型中的 3×3 卷积]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfqQownrnbaEwbMmiaasu4LkjhzXAlsFcIkVFz6G2bymqyn2nGCwLpTC24f5NMuBbDmDbCX2QgVWprQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 重新思考了 3×3 卷积这种最简单但是最快的模块，来实现基于纯卷积的扩散模型。太长不看版纯卷积实现且用于图像生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699567&amp;idx=1&amp;sn=5b925b7f365d6cd2d49d0fda66e98283&amp;chksm=f2f374a576adbf7733a9aa045c0fdeb38d9e4139337070ba019f3d40645292acff9c48a0a6b0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NVIDIA提出单一统一自回归框架EditAR！支持多种条件图像生成任务！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JsXhg60oz9M0m6hicEfYRJYPUCdnsNsakpCNMCicbdPZyJLjzdyJHckl3qAsiaSv9A8Bp4tib0ltr8sQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源于AI妙妙房，作者妙妙房今日论文推荐论文名：EditAR: Unified Conditional Generation with Autoregressive Models论文链接：https:</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699567&amp;idx=2&amp;sn=fab3fe7bb6ff4dff2bb414ba46efe8ef&amp;chksm=f2651d6f2f8df0dace2f92eb3f324c11a99ceda47c40da992899d906b960fc6cd4885330b725&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 14 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多视角 Transformer，在图像分类、目标检测以及实例和语义分割实现Top-1 精度 ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgldLkjV2rWT9HmnxWtlnqmxyxAkDb3jBITWZMKia8JA6OVwl45wYs5iaUwCBiag62cxiazNQeDQOLFmOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 集智书童  作者 | 小书童目前正积极研究如何提升视觉 Transformer (ViTs)的效率。大多数研究都集中在有效Token混合器的研究上</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699554&amp;idx=1&amp;sn=2c13c65de08f2999983764ee608b500b&amp;chksm=f2bd63544d5daa99ef8c2bf18195af966f518c67dcf65ece8ce11148b825851b754a112c6927&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华提出ArtCrafter！可控多样的风格迁移框架！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAfJ2HEmicxJ8icVunIPABOUfEyTXFHSxC0sbZoicOaVeibC70QIZBRWA3HhGXXMDUv2bACxKgwVmjWY2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 数源AI  作者 | 小源论文名：ArtCrafter: Text-Image Aligning Style Transfer via Embed</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699554&amp;idx=2&amp;sn=b50b0541cbbd97ba0a86b79de239d3eb&amp;chksm=f21c7fa2d51a6323f7368d7788533e636e43e9f81e6556cb7b6299d1e16211af4f3a3b7d74a1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CubeFormer | 澳门大学提出一种简单但有效的轻量级图像超分辨基线 !]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgmGDI0TBRbGd0Jc7GLugnFckupVctOxVJEjTSSicuv7uF02qoZfdibZDNXZdF3eJtdia64WkpNcTAz2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 集智书童  作者 | 小书童轻量级图像超分辨率(SR)方法旨在使用轻量级神经网络提高图像分辨率并恢复图像细节。然而，当前的轻量级SR方法仍然存在性</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699552&amp;idx=1&amp;sn=a9c4c13a832396bbc6f7c8b828887075&amp;chksm=f299db4f82b162a9ce475d8d82a8c29796420415de990109f122d47e301383646b1f85cf0a1e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 12 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[1.4s 即可生成1024px图像！SnapGen：轻量化架构和训练策略实现端侧文生图]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo0eVZiczoVxof2UIkXZcrwpJpibAeXGlhv7CbawZ061pialSfSAmkRXmXK1MLIdGUuwhRmCJMtPQKOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 极市平台  作者 | 科技猛兽极市导读 在 ImageNet-1K 上，本文的模型仅使用 372M 参数，在 256 px 生成中实现了 2.06</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699552&amp;idx=2&amp;sn=3d66731edf532df8743c43d67aece760&amp;chksm=f27a277f532f09f56bacdbd0ff0d4ab322770cbd2f0d0a20e67ecd0ddccd7f7273add836144c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 12 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[最强最快ViT诞生 | CAS-ViT 提升图像分类、目标检测、语义分割等任务性能，可部署到手机端！！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgnHM7b4wWTtsxbDGn9SFd0o0xFoZ8RVjIPolbrIujmQw01UQiaAw36GJ6icxjJxIlnqcVoZFh28iazxw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于集智书童，作者小书童视觉 Transformer （ViTs）与它们的标记混合器的强大全局上下文能力标志着神经网络的革命性进步。然而，标记之间的双向亲</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699550&amp;idx=1&amp;sn=08d5fbc0a312f9a5efe254366b740b44&amp;chksm=f2a11b5caa9980b4144e069361851d70bd43d466e34fe89f50d7e870e8ef0a8be1d8ad9d2ffd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ECCV 2024  | Arc2Face：身份条件化的人脸生成基础模型，高一致性高质量的AI人脸艺术风格照生成]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VFicX5Qfj1eCbbEzaEgDJFyxytCE8fW4BdBAH8icBmUAiaJQxvrqGicKqJAbUtKIvGEtJYhM9Vic3qvZavPIfnS7UIg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AICV与前沿，作者雨沐林风文章地址：https://arxiv.org/abs/2403.11641项目地址：https://github.com/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699550&amp;idx=2&amp;sn=7c4737b68ac00d35fb998ca44445e037&amp;chksm=f2fc3827117ac7bf75e005d34a64209d0398fcd86004437db394ff5116d93e6fd3dca61612a7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[同济提出简化 Transformer结构：在RTX3090上实现CLIP的轻量级训练  ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglUUfpibMCquHiaV7ywvPJLfKM47GhtNBx2YZ8EOPQ0IG6KHA0kLGrZSaNh4GFHUaGWUtZt4Xon2aug/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于集智书童，作者小书童对比语言图像预训练（CLIP）因其卓越的零样本性能和优秀的迁移能力而受到了广泛关注。然而，训练这样的大型模型通常需要大量的计算和存</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699548&amp;idx=1&amp;sn=08a0e8703e2523875535a56d0ec46959&amp;chksm=f21331bc095179cebabc0272efd8b2e177b3e9a3b3f4813591ad46303135b79902710b4b5c03&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[前微软亚研院视觉专家胡瀚加入腾讯，负责混元多模态大模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/cNFA8C0uVPv4Z4p1wxldNeia3VKT33VvjA451Zbbib81qEcaxTPrFDTg6ib0X1BwEUqc9jQJrnJYA86MrIzrvKUHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源于AI科技评论，作者高允毅胡瀚是计算机视觉领域通用架构Swin Transformer的核心作者之一。作者丨高允毅编辑丨马晓宁AI科技评论独家获悉，前微软亚洲研究院视觉计算组首席研究员胡瀚，不久前</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699548&amp;idx=2&amp;sn=db047116e46e4c52af81e9786c99f61c&amp;chksm=f2f3d2de00725f7348cf13bafa32d84fcecb22f30d84f0c99141fece31336e8fc99d267c287a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[完整复现Sora，Open-Sora最新技术报告发布，提供完整训练代码、权重及数据处理工具]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoj1hpEaPRQEj9tO76J4hgiaXlGiabJtibmOfXyE63RQ8qdVibIHCFSic7BXhv5SkiaHicTjK3JsmjAJibu0mg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Zangwei Zheng等  解读：AI生成未来文章链接：https://arxiv.org/pdf/2412.20404 项目链接：https:/</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699537&amp;idx=1&amp;sn=0733895e0d99f75c18bbeb11dd8bd835&amp;chksm=f2039b995dc76a546108db68330ccb65758beb796b258e41950a54359559ae1f71e2d1c009a0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 14:23:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NJU联合腾讯提出VITA-1.5！GPT-4o级别的实时视觉语音交互框架！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAexxZJfJk9IrwdVx1skibZcupVlU7tLA8AgQicj2HdyTIWkCk5kwymKTZ5xvAAIHml7zDtiatB0bmgibQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于数源AI，作者小源论文名：VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Int</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699537&amp;idx=2&amp;sn=507ad5ac448d662b21052819068a84f7&amp;chksm=f2a8117e91656c15f98fc55a25721f33489e69f9c121d6d4247928175ae4171057b14438fa9c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 14:23:57 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[注意力计算减少99.5%，端侧文生图扩散模型成功范式！CLEAR：类卷积线性扩散Transformer]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfqEKiclfwibEYzUCdLHWicHkhMOLxzH7IO6ZJavtNY2E0ZZzJUSHAVCkR166XI38upoE19QBM5beoYTw/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨科技猛兽。编辑丨极市平台极市导读 本文介绍了一种名为CLEAR的卷积式线性化方法，用于将预训练的扩散变换器的注意力机制线性化，从而显著提高高分辨率图像生成的效率。通过限制特征交互到局部窗口，CL</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699535&amp;idx=1&amp;sn=398aae94a74ae71cb3a52abb29315991&amp;chksm=f29691d4497cc246a5c455abfc240d8880978c3ef722c804e5f32701b6c7bbf43b3a7f05692c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 14:15:01 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
