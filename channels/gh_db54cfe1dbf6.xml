<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIWalker]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIWalker公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      <title>gh_db54cfe1dbf6</title>
    </image>
    <item>
      <title><![CDATA[MIT何恺明再次突破传统：分形递归架构引爆生成模型新纪元！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogiaibpP0CqIiadiaT3ZaLYuibJvk76CcrZiaDeDtriakT7A352bCPtiabGaIjiaELJkbRbicZFD7HXx492Cqug/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Tianhong Li 、Kaiming He等  解读：AI生成未来论文链接：https://arxiv.org/pdf/2502.17437 代码</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699726&amp;idx=1&amp;sn=43ce5bf7dd37615bb7e9fcd51acd4dea&amp;chksm=f2f29fd6e715e01f690f3be67d1bbe5112cf6ad163b19a54ffe29f73566aa3a98ef48d5bd787&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[揭秘线性与 Softmax 注意力差距，赋予线性两特性，多任务超越且计算量低 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVXMdXCynTByTICXxqsKjNgDSYV1BtwTZz3LNNHyaQ2cIIGzMK0iak1Te90NlicjiczzCR01icEXCev6icg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI视界引擎 在现代视觉Transformer设计中，Softmax注意力能够有效捕获长距离的视觉信息；然而，在处理高分辨率输入时会带来巨大的计算</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699726&amp;idx=2&amp;sn=5091adc04e624f5cc2c5dd3fe40d061a&amp;chksm=f2f6736fe7fe2018e648659d8189a0a4092e0c4572c00a3bbdea6b59a00a84dbc3d0ef4639f1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型时代，让DeepSeek告诉你该如何学习目标检测~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaoCqmClacEWGH9M4l8bRcjU38icuRoIfLSWHx0QZAsUibhaXzyCIHyROibbdWua4CMSFeiaoIIzF6vyg/640?wxtype=jpeg&amp;wxfrom=0"/><p>目标检测是计算机视觉领域最核心的技术之一，应用面非常广泛。这里总结了245个目标检测开源项目给大家练习。具体到人体、交通、医疗、工业、开放世界、3D目标、小目标等16个分类。其中包括多个基于YOLOv</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699724&amp;idx=1&amp;sn=f95e999d99601ce18fa4840b149e3a81&amp;chksm=f24592ba93c8ad1a8191d634da202b2e110310f231d54a9755b4039e0a27f2490177e2cc5e88&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Feb 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别800秒魔咒！硬件级STA革新视频DiT注意力，让HunyuanVideo效率提升3.5倍!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohFzlicObmXNQicfPW2nWGQIBooj23sGXdWXfQp1mwViaU1yojYkJ1frSxibicStEaqRFl4kwfjSKASrWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Peiyuan Zhang等  解读：AI生成未来论文链接：https://arxiv.org/pdf/2502.04507Git链接：https://github.com/hao-ai-lab</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699724&amp;idx=2&amp;sn=10d90ee9da64ce12c5cddd81d47e3991&amp;chksm=f29ec308e111d2fb3c11ab9bab137f9934e36c5df6ba399ecc76f185ee417547f5ae40fe46ca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Feb 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[1.4s 即可生成1024px图像！SnapGen：轻量化架构和训练策略实现端侧文生图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo0eVZiczoVxof2UIkXZcrwpJpibAeXGlhv7CbawZ061pialSfSAmkRXmXK1MLIdGUuwhRmCJMtPQKOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨科技猛兽   编辑丨极市平台极市导读 在 ImageNet-1K 上，本文的模型仅使用 372M 参数，在 256 px 生成中实现了 2.06 的 FID。在 T2I 基准测试中 (GenEv</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699722&amp;idx=1&amp;sn=eac3e0258781d983e276fa42f00ced02&amp;chksm=f2e0d8e7f684cc0db3381ea8904d7fab6909a218edb59b6a92218b3f5271d5fb76c967f0af68&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[中科大提出 D-FINE |  通过 FDR 和 GO-LSD 实现最先进的实时目标检测 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgkEY0DXdcmpSibJ1w9GCpNXv4jfWZ3nJRq4XMmwyGgh8yibiaNpT3GSw7qxvQld2iaU9HuGiaibg701SoicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 集智书童  作者 | 小书童作者提出了 D-FINE，这是一个强大的实时目标检测器，通过重新定义DETR模型中的边界框回归任务，实现了出色的局部化</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699714&amp;idx=1&amp;sn=a8b9d3033deedf3382def775a8f804e7&amp;chksm=f2f444ac27d96785f64f2e0f956d0236ed7bea627413afb8568ac5430e029a173c61fb623a02&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[别只盯着DiT，国产模型也在暗自发力！U-ViT：ViT 架构实现 Diffusion 的开山之作！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfq9qeelUQgEiaPb5HuLYmHCnicqwT1Tv8SUlV89gXDbx7USDoicfGt6gKTPrTicibbunM4GdXDoDIXaLjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路  作者丨科技猛兽    编辑丨极市平台极市导读 本文的提出比 DiT 还要早一点，而且本文是用 ViT 架构实现 Diffusion 模型的开山之作，使用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699714&amp;idx=2&amp;sn=55cf68718c4d1bb65b5b78951ba1c390&amp;chksm=f24bb92da0dedff95b72115f20261c94c52b6d89b8ab7bbcc14fe21b37b6395c8732446cee62&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025｜高达 128 倍下采样的 Autoencoder！DC-AE：高效加速高分辨率扩散模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrtgFCshops5lnqQm6okb13RovMELicJicZibmDysiaA4sHU10ovHTiba1Lia9wEh2chpB3rTR431ib7mO1g/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者 | 科技猛兽    编辑 | 极市平台 极市导读 高达 128 倍下采样的 Autoencoder，以加速高分辨率扩散模型。 >>加入极市CV技术交流</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699712&amp;idx=1&amp;sn=75f5783e04220a55ad766f68cfe4da8d&amp;chksm=f2c9a3683e3fbec41f1e50e976f68b8cba3a80c34e2955115cec91d4d58455d4ab9e5a2b9af5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Feb 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[少至8Token完成视觉重建！Apple提出FlexTok！可变长度图像Tokenizer ！性能超过TiTok！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAeBHjqp2kl3UYyWQc8sb6HBpMXibZsiaUQ2qWV2XUe4cHIAlicDbYhiapYicHkETrqjLcBP9lEGL32g3YQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 数源AI  作者 | 小论文名：FlexTok: Resampling Images into 1D Token Sequences of Fle</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699712&amp;idx=2&amp;sn=830462c49619b00b1577c997d3f4afa4&amp;chksm=f2d93df72ecac837b4c2043309e2065de135f671afb0d631f014c3eac0a225243f399288855d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Feb 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SigLIP2 | 多种优化策略加码，助力SigLIP无缝升级]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhtxDnRYlsEdkN7eIfGochfpZ43NicyOerG3FgBfcgRH36NAuYmc4qrgv9eEFvgZiauwDqwlhc7Ft5A/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路注：本文由机器翻译所得，仅供参考paper: https://arxiv.org/abs/2502.14786code：https://github.com</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699710&amp;idx=1&amp;sn=c564833edde6aad75acea6fb439d00f2&amp;chksm=f2285ddda49210ebf2001f76bb66fde6de6500f9e34aa4b7b7afd39fd0031abc8fab190b51fe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[澳门大学提出DC-ControlNet！解耦控制条件！灵活性和精度超过ControlNet！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IJObOoyvhRkCaPGyos7d8xL9KBFJiaWYgoicVEkmuuB7slvPLj3SIW9jx5pace0iagDibDDTLU1P3Lwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI妙妙房  作者 | 妙妙房论文名：DC-ControlNet: Decoupling Inter- and Intra-Element Con</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699710&amp;idx=2&amp;sn=904923ffb45ce76a4df58b057670c478&amp;chksm=f22c200fce89563928ac4a0fa7fcd7b544973012b14faaf4a66d5361a336b32ec24c5a7c1ee8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[再次颠覆学界想象，何恺明发表新作：扩散模型不一定需要噪声条件]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjvvSudib20l2IsXo51qibfuIgjCEMMQbcgvaXicSrNQ0s6CeBZIVX6nuhmWdkm9icpP7nUqSmD9dcNRA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 机器之心  编辑 | 蛋酱、杜伟一直以来，研究者普遍认为，去噪扩散模型要想成功运行，噪声条件是必不可少的。而大神何恺明的一项最新研究，对这个观点提</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699699&amp;idx=1&amp;sn=3572a341c927d04fe0ec53f52b5cb4cb&amp;chksm=f2105801eb754d13e611ee1c5be518c1b8e9348d3fd6856b98f72c096bfba27600ebce510e50&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Transfusion：只用一个模型搞定图像生成和理解任务！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoTWfjBcg9NK6JMMXPOOL3uX4lJKVY3U3g6BTLmI1WUutHnIicsY7icquj6bNWamOAIuv5ibMbHbKskQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者 | 科技猛兽    编辑 | 极市平台极市导读 本文介绍了一种名为 Transfusion 的多模态模型，它通过结合语言建模（文本）和扩散模型（图像）</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699699&amp;idx=2&amp;sn=cda6f60084cab288ce098c4bab06d494&amp;chksm=f22c8d2a83a4faf218cc3c9594453edea8022de0e9551634e26738660ec44e04c6961a37cc35&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[YOLOv12来袭，更高性能、更快速度~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDg7Qqib7F5pMibwWrVaBvniavDiclXUojZl2nplIMsBqpTiad3awyVib8iaiaY9n2TPp1bZVqrRUWN5Q6JMxQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路论文：https://arxiv.org/abs/2502.12524代码：https://github.com/sunsmarterjie/yolov12</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699694&amp;idx=1&amp;sn=22154f77bb76152a3c6905d53026ed6c&amp;chksm=f2abf31c96dea42569aa03d43083c9a0c76468d66bdb44bc99ef341913d88c389ecea604dca8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[梁文锋亲自挂名，DeepSeek 最新论文丢出注意力新机制，推理速度直线提升 11 倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/cNFA8C0uVPs0grSRuCm0ra9BiaVUQru39staYtibiaZczzuN6NwRA9UguRW4qZFHLIeQZNUMQ7Gia1adkn9mf8iaUicA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek 革命性 NSA 注意力机制问世。作者丨郑佳美编辑丨马晓宁2 月 18 日，马斯克发布 Grok 3 的热度还没过去，梁文锋就作为 co-authors 带着 DeepSeek 研究团</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699694&amp;idx=2&amp;sn=9882479c8ff7348ed906d7165d818a23&amp;chksm=f2c15d3c87332d4ccc6640405f4cefe557b9415c8c25e1d58136816fc227ef6c86c2236bbfa2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文模型搭建瓶颈？巧用 100 个模块，突破论文模型构建瓶颈]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjYj3oVD7Cw623CMdL5RAW6LdoOAZemibAA6TJPdcs1ibYVl6yovZvJNibaIHM01RPx70Oym7MpDNjtg/640?wxtype=jpeg&amp;wxfrom=0"/><p>有创新点，就能顺利发paper吗？当然不是！有了创新点只是开始，模型的编码、调试才是重头戏。很多小伙伴都是改了大量的模型和代码，实验结果却没有多少提升，白白耽误投稿时间。今天就分享一些发paper必备</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699681&amp;idx=1&amp;sn=43af5c2654d116773be3d52a58e5e071&amp;chksm=f25e5a1e08d78ebe1da8511b67409daffe43ca00be06c9072552fd187d65e375372fe8914d40&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Feb 2025 10:13:21 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出端到端扩散模型D-DiT！多模态理解和生成统一新架构！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAeYicX3TCrrwIBpqCibdbKazZWPz3GNZhNIDRias6mGXhKeYta6LiamPLgU9zm2AjPydV2BJAmtK4KLGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 数源AI    作者 | 小源论文名：Dual Diffusion for Unified Image Generation and Unders</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699681&amp;idx=2&amp;sn=fcbd2c4352dfafb82f3cd239e4bf75f5&amp;chksm=f239136874fd6173b00c65cb6d63fc0006a1491e85c274607b4c93cc1e830ee338dd59a79503&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Feb 2025 10:13:21 +0000</pubDate>
    </item>
  </channel>
</rss>