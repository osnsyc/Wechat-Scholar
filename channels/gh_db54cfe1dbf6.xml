<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIWalker]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIWalker公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      <title>gh_db54cfe1dbf6</title>
    </image>
    <item>
      <title><![CDATA[TMI 2025 | 最新医疗图像分割模型：Zig-RiR，精准分割二维、三维医疗图像]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaxvZScuhviaKNKdIIMM1iarqVrsxzfV2lHZYc0Duic8HjZmFvYDJJ7NY8ibgN8lyR7Hfqd1bhvGUcfYA/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | tianxiang Chen   编辑 | 我爱计算机视觉本文只做学术分享，如有侵权，联系删文本篇分享 TMI 2025 论文Zig-RiR: Z</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700315&amp;idx=1&amp;sn=7be8e43d0e5d6dc52cc0e39c51793289&amp;chksm=f22086a81e6ebedaeced23ca24ad764d91766828d995bb1d7f495f1e80fa3e4216d43283182b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DefMamba：新型视觉基础模型，借多尺度Backbone与可变形Mamba模块及DS策略革新视觉任务表现 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVVh6LnCCGzHglOQrWwS4vQxPrYw9yVs2Kmf5wC95DbYVAvTeVOiaW1CwibrJRQpO9D8vN6bKrYHBOkw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | AI视界引擎    作者 | AI引擎本文只做学术分享，如有侵权，联系删文近期，状态空间模型（SsM），特别是Mamba，因其能有效平衡计算效率和</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700315&amp;idx=2&amp;sn=6d36f742358adc76bf7166b952645366&amp;chksm=f29c80694578233fb672d0c7266e292e849ea923052ee41205e9c95cde7501a3e713502e7f78&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[RepNet-VSR:用于高保真视频超分辨率的可重参数化架构(CVPRW2025)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgyKrLDHBLL9feRticWTfkZ8TfK2biarYAL5ic2xQboSibDiaRAu1pWMMHtzhe2ue9AoJrBNbAF80oeFWQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | 小小CV笔记本文只做学术分享，如有侵权，联系删文论文题目RepNet-VSR: Reparameterizable Architecture fo</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700306&amp;idx=1&amp;sn=39bd6561ddf9a5f75ac79b2412d6df5b&amp;chksm=f291ac3e3bbe27a5336aa13cccdbb9e025ee931f975dc4f95df122c9f3dcd3bf2804832e1b92&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 14:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态与生成正迈向终极大一统！阿里最新3万字长文梳理统一的多模态理解和生成模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogRqbkUhTmS9O8IP0fqk2lZyHe1koXwSl6wPZnibWgaia4PPZoLlcw30EaIibX5mPt96icylHgpdibwk1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号作者：Xinjie Zhang，Jintao Guo，Shanshan Zhao等  解读：AI生成未来文章链接：https://arxiv.org/pdf</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700306&amp;idx=2&amp;sn=87ca6717bcf84116fa6dda498a25e250&amp;chksm=f2faf723d6168628b718c6cc4d6ce4133dc9fc8c0a749e0a3470c50e09e56d2efed8f94539bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 14:30:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[2025版 | 论文er最爱的即插即用模块，助力无缝涨点]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaVksz194iaJy6b4k9Cy90A7DdubayAxulJuibvYldsswOkzxbJjB2LYKdSMcbQhxjWK6KBQ7npGDuw/640?wxtype=jpeg&amp;wxfrom=0"/><p>如何提升论文创新性和实验效率？猜你想要“即插即用模块”。现在这类能“无缝集成”、“快速启用”的模块已经成了深度学习论文写作的必备工具。一方面因为其模块化设计和标准化接口，可以简化开发流程，方便我们结合</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700301&amp;idx=1&amp;sn=2f3ee38b68a6fb1718ef672203b579bd&amp;chksm=f25a583476613879351c9423500cb793623e21522fecb47e6449c83dca56a888e2c93122ef8e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Attention GhostUNet 融合通道、空间和深度注意力机制于Ghost Bottleneck，实现深度学习模型 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVUbnxzbKj6otpa6anQUp740HBOwTxphdDHSOrnvnLf07u0DpQpUKp32ZrNeaw1ia4KmicAHhZNfAHuw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源于AI视界引擎，作者AI 引擎本文只做学术分享，如有侵权，联系删文引用字数：428/300（单次引用不得超过300字，避免不合理引用）对腹部脂肪组织（包</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700301&amp;idx=2&amp;sn=c8f087c20a84855b88fd6e62175c082f&amp;chksm=f2a0c9e1948fd543fbaf7b51f7e295ca9ea0b955496d7ce1b45e4b44df873c0813b7c7a82e91&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[只需 0.5B 参数，全面覆盖预训练+SFT + RL！极简自回归视觉生成框架SimpleAR]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrZQVFxr3SJ2F6CQPX4XL8mF231wlrykeZ0sXuic0e6GIWqeEth8z7aiaWZA5ozWADicia90Hcj7PoWXg/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号作者丨科技猛兽    编辑丨极市平台极市导读 全面覆盖预训练，SFT，RL的极简自回归视觉生成框架。 >>加入极市CV技术交流群，走在计算机视觉的最前沿太长</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700299&amp;idx=1&amp;sn=5c725bd552b00616eca96cbe51edf360&amp;chksm=f265b7ea425fbf9ec675704cf9385a409ea06a8ebf0b9f535b4453beb29e1aedc0c73e282f9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 14:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>