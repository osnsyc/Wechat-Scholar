<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIWalker]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIWalker公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM6XjnN5JicvO5kPN9BnpGBhbHC5oQRSvFhPI02tnZIia1Qw/132</url>
      <title>gh_db54cfe1dbf6</title>
    </image>
    <item>
      <title><![CDATA[ICCV2025 | UniConvNet：扩展有效感受野的卷积神经网络视觉新主干，性能SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VFicX5Qfj1eAIicOLoLc1dWCGwOE6SicJoLKib5l2fOJ37viasscicpgibDicI7NomKSbAajqeNeSfU6d0cvf8ELbnAHaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源于AICV与前沿，作者雨沐林风项目链接：https://github.com/ai-paperwithcode/UniConvNet文章地址：https</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700454&amp;idx=1&amp;sn=066c219a1d2ca0fb323fd63b11e87c63&amp;chksm=f2cacb42f8ef2bf8563d2857142ef7130cbac14e8a77001aaee9f49db3dee0107d26db04d269&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 18 Aug 2025 21:59:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 ConverseNet：当卷积可以“反向”时，图像恢复会发生什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhBDsnepGv8Bicxkz7D9NopsUEGFB3U5Vttzj4m2MhNMeniagwbTqN1iavIYkia9cTAStyJGRLCbT6r3Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | 我爱计算机视觉 作者 | CV君在神经网络的世界里，卷积（Convolution）和转置卷积（Transposed Convolution）是构</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700443&amp;idx=1&amp;sn=70aa8959e67188feaff79043b6f7e10f&amp;chksm=f286be35a9dd4b3fddcfcb2cce93411bd97215a85b22c5d01d3a056cf89808e69237c41f19a1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 22:38:05 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta视觉基座DINOv3王者归来：自监督首次全面超越弱监督，商用开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhBDsnepGv8Bicxkz7D9Nopsaml4WUibFO1wVEgsDYmGicgIuiczYH3Znx0HVic172q4CGnEEFnlOPvxOQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | 机器之心计算机视觉领域的大部分下游任务都是从二维图像理解（特征提取）开始的。在特征提取、语义理解、图像分割等 CV 基本任务中的模型三幻神分别是</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700443&amp;idx=2&amp;sn=dd8e147c9d725059165e8fe2353f0d44&amp;chksm=f2a0f3e0e661c5d640db9464b12fd7c4399b99c83c11b6c5529afa2c8fa60060c5c034e84396&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 22:38:05 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[有种导师叫做“别人家的导师”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaJlD5dvCkhYM7iaUfibzJASBYU9fENGmmptCYf3fvSeoIYoIhrDrskmt4LxKiaHwcP6NSCIQ3jaso9g/640?wxtype=jpeg&amp;wxfrom=0"/><p>经常写论文的朋友都知道。写好论文和毕业，就业，深造息息相关。写好论文可以说是我们科研人的第一指标。我特意给粉丝整理了下面的这些写论文需要的必备资源，免费分享。赶紧收藏，你一定用的上。【资源一】这是一套</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700434&amp;idx=1&amp;sn=0c3ca669466958470275236f75b3ad35&amp;chksm=f2675823cc58bafbbdd884ebe897d97bc1deae9fd2159ad0932613279ce75840cc5dc3b12a77&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 14 Aug 2025 18:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[小红书 hi lab 开源多模态大模型 dots.vlm1，效果接近闭源 SoTA 模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vxnkL2N86ItibJxwiaeSsT5Gx4WhZFNpI6cgg2VTCZdyOrtUh5moJ5eAw0nEIgicYVnO3SjxrtI6v9yzmbDjszsFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源于小红书技术REDtech，作者等你加入的dots.vlm1 是小红书 hi lab 研发并开源的首个多模态大模型，借助一个从零训练的 12 亿参数视觉编码器以及基于 Deepseek V3 LL</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700434&amp;idx=2&amp;sn=475b19349eb1b5b1324cc90e992488cc&amp;chksm=f25248b67ee37421dbaba81d3e468e228d0cd285a3f972f8d5a01e31bdc639595c8021f6de0d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 14 Aug 2025 18:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[当VLM学会了“回头看” | Qwen-2.5-VL突破性发现，7B模型自主激活'视觉反思'，感知任务性能提升6.3%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglBOuPjYqmddWbnstCaBPSwPCY1200C4LHp495jUYZ9hh0iaKX2GcXslxNzliaXYIcPcTdjjxGia3nicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号来源 | 集智书童 作者 | 小书童精简阅读版本本文主要解决了什么问题1. 多模态大语言模型（MLLMs）在推理后期过度依赖文本信息，忽视视觉输入整合的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700432&amp;idx=1&amp;sn=d9d4bc907cbb576791d48c2281901646&amp;chksm=f27cf760e02ede3fbfeedf784d851500a0c35d0d379d76dc58ed20d655b343d392fd818b148c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 22:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[盗梦空间级AI试衣！中山等发布OMFA：一键“脱衣”换装，姿势任意摆，告别展平图！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohlOLeU2aibQ7Ifm5fchwBrrV7um330sgicw60V9O5pMGTnY4zSdFbyhbtdSajvySwX5XmTCtlECicng/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIWalker”公众号作者：Jinxi Liu等 解读：AI生成未来文章链接：https://arxiv.org/pdf/2508.04559 项目链接：https://one</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700432&amp;idx=2&amp;sn=a77862d21008a18a9c8de17289058c93&amp;chksm=f2819db1df6af3a1ff30667ae669aec1a850b8da844e2a288e0819faa08f96899761afbed91b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 22:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[分享图片]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p></p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700422&amp;idx=1&amp;sn=7507aca434a63bc612a692492c4151d0&amp;chksm=f2afb7860015930ddeb797c7b98184415480b9e511cd119fcba56d74c5ed8117e81de87c97f9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 00:23:42 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[All in one，统一多模态理解与生成！7B 参数的BAGEL为何能媲美GPT-4o？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrWNExpFmicZicfdOARXPWpWMrWHRayzEBhwaCRjW1xdhLNPWVKiaBusj4Go0S9tPmIIm0Aj7vkgWgeA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨科技猛兽。编辑丨极市平台极市导读 字节跳动开源 7B 统一多模态大模型 BAGEL，基于 MoT 架构和 5T 交错图文/视频数据端到端预训练，在理解、生成、编辑三大任务全面刷新开源 SOTA，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700417&amp;idx=1&amp;sn=d928cfb6f4a34a47e7edf4fd99db79e0&amp;chksm=f2e13904989e066c6d22debbfe5a673b79785b9bd8f81d8fb824bfc8439c0b2585fd7df50fb9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 14:15:34 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一网打尽！28个注意力机制模块、21个卷积模块、16个特征融合模块、11个频域模块、8个下采样模块和5个最新的Mamba模块！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDgM6IsJDUOjFfk9HoD2wdESXzDVgO98I9QVicn3MyzQfERzL4vyqBfRZtgw0gL3wX6QRVhMdbxjIMg/640?wxtype=jpeg&amp;wxfrom=0"/><p>有创新点，就能顺利发paper吗？当然不是！有了创新点只是开始，模型的编码、调试才是重头戏。很多小伙伴都是改了大量的模型和代码，实验结果却没有多少提升，白白耽误投稿时间。今天就分享一些发paper必备</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700415&amp;idx=1&amp;sn=111cb0c9f27ef217a6e56a2b1732af72&amp;chksm=f2a71ef5dfc2814db99252905010f0a35c3d9d4afb3659dbff9e549b242d09a20a7f8402d340&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 14:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[无需思维链的视觉顿悟 | Perception-R1开源，刷新大模型认知边界，横扫四大任务]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglBOuPjYqmddWbnstCaBPSwxUWu5mUaxZLdeo9SviaSs0evRZetqwohrI1uQtHYVZn6Bbb8Ooeh0qQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 点击下方卡片，关注“AIWalker”公众号来源 | 集智书童  作者 | 小书童精简阅读版本本文主要解决了什么问题1. 探索基于规则的强化学习（RL）在多模态大语言模型（MLLM）后训练中用于视觉</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700415&amp;idx=2&amp;sn=69ba9941f15085ddb26428ea26dedfea&amp;chksm=f2047cf068380933b7c68c81e7b977ea4280583229d5a5e098e45c90d1d423b4bccf95d998e8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 14:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Lumina-mGPT 2.0横空出世：自回归模型终结扩散时代？媲美DALL·E 3，更自由、更全能！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohsrAl8W92ggQM6BE0ssHxiah79g7VpaJx52B1BcK2XJ5a8NjKUynBWt5d4icLMyR5LgWvDNl3qXAlQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Yi Xin等  解读：AI生成未来论文链接：https://arxiv.org/pdf/2507.17801代码链接：https://github.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700412&amp;idx=1&amp;sn=31cb2ddfee886b70bfd3711f6509407c&amp;chksm=f2f472f2c9639e2ca72ca9a8e670c70b2e4fa1ad1c51b6b11a3b8a94fc13371f6a5cdcbc0f74&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[华科&amp;京东提出CAIG | 基于CTR驱动的广告图像生成，代码已开源！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VFicX5Qfj1eAGKXmJ8FAZTQEbuX588HslrApDHibznibl7WvYh1fR2kOs5bQKgVjgagyTuYNjZiapicTzqrP95HEiaOA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AICV与前沿  作者 | 雨沐林风文章链接：https://arxiv.org/pdf/2502.06823项目链接：https://githu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700412&amp;idx=2&amp;sn=975bbb24ba53b9e229e518e80c3342e8&amp;chksm=f294718f3fa85c27f4af95ef1ac025d60e72de1950a32173a2841faf4afcc4cf0eb41cb575d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR2025 | DeQA-Score: 让大语言模型学会图像质量分数的分布]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/7VDuicY8zqyeBDGQlAlzmgYRUFpcaXAqia7XRrMXlQ51BTxvHic4yBtN2oHeB57JtLSdVNepCBTkAyLdrlqQhcaZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>主页：https://depictqa.github.io/deqa-score论文：https://arxiv.org/abs/2501.11561代码：https://github.com/zhi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700404&amp;idx=1&amp;sn=27ac6750b521b1f268c695e975e5c82a&amp;chksm=f216f307b58b9d46bdd8463fe37a79e57620630b0225f918383bade436298325196aade626c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 14:01:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[哈工大、西工大、福大、澳大、港中文联合提出一种树形卷积神经网络的图像超分辨方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/BJbRvwibeSTu6sCbWdFy0B6W8icB3v4TcMHNCU8sY1DT50Nv6zTBjY4MXialu7yqEsMGsZLJj3fsu9xCu7nVrttBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 我爱计算机视觉  作者 | 52CV 本篇分享论文A Tree-Guided CNN for Image Super-Resolution，哈工大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700404&amp;idx=2&amp;sn=b7333dcb26c2eec91a5bf3b4e814a076&amp;chksm=f2b0512fc9c2dffbba1c0ef017dc91bd4326f7a76582acb4c41c2e2c3bbe9b27fb98d8f0bd58&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 14:01:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Attention机制2025生存指南，110个代码级方案]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaKIicPm6LV26gQY7gpvIqX5RAjwaou7JotFMQaV9F9L2ia0W9ibadu9vNQUu0oWoIWnmGl1aNT7pAsg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在深度学习paper中，注意力机制被广泛使用。作为transformer架构中最重要的组成部分。Attention的可创新性依旧很高。今天给大家分享10种不同的注意力机制创新方向，总共110篇文章及对</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700400&amp;idx=1&amp;sn=64f5768f5ea5f8440285585e997e5b9e&amp;chksm=f25b65fc97f6297d921839615385cd621ac79cd18c153157bbd6132c3bdd29f00e353d5fe156&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[全能高手&amp;科学明星，上海AI实验室开源发布『书生』科学多模态大模型Intern-S1 | WAIC 2025]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/Oibf4sJrpsntBHblz2XfTqgAIpsicaemzltKxK5h5tIYiaCRp404klzIeqbzmH9dvYBeE9QTvkvG4t6giciagwTRmmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>7月26日，2025世界人工智能大会（WAIC 2025）正式开幕。在当天下午举行的科学前沿全体会议上，上海人工智能实验室（上海AI实验室）发布并开源『书生』科学多模态大模型Intern-S1。在科学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651700400&amp;idx=2&amp;sn=55a5b56560fe97f8db2b8bc5e74c5ee9&amp;chksm=f2ea1f6c6e77b2d77fe13fefef7995b9b75a516df3a2028ef9a894fb1774809eb240d0e94bd7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 10:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>