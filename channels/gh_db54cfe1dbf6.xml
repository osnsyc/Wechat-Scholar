<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIWalker]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIWalker公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      <title>gh_db54cfe1dbf6</title>
    </image>
    <item>
      <title><![CDATA[英伟达提出首个Mamba-Transformer视觉骨干网络！打破精度/吞吐瓶颈 | CVPR 2025]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaAiatnfzwvnEljdY9eAgBu5wgVO2xckfPldHn7gsFAgefEvicuMfO9xeibX2NrAt26GIQwiciaTTGFKmA/640?wxtype=jpeg&amp;wxfrom=0"/><p>编辑：KingHZ   来源 | 新智元【新智元导读】CVPR 2025，混合新架构MambaVision来了！Mamba+Transformer混合架构专门为CV应用设计。MambaVision 在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699793&amp;idx=1&amp;sn=386189ab04f279f8a597f91e998e7ee1&amp;chksm=f20d3d0daa775842106e80f050dafb894a193850519a221ddf506e4fbe5245acc44733ae0db4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 09 Mar 2025 15:03:03 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里通义Lab提出LLMDet！利用LLM构建强大的开放词汇检测模型！超过Grounding DINO！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAda5jeuyro2lWcArxz3odb54PeInPEIddolGYhUg5ZPlGYeNwpgVuvtMEeqk9PDIE7UiahXWwaNYHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于数源AI，作者小源论文名：LLMDet: Learning Strong Open-Vocabulary Object Detectors under</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699793&amp;idx=2&amp;sn=5e721a0ecf8a59230c523d10d84f6ec7&amp;chksm=f2e63201202a4aeeb6fb8e43f3d2ce25059e6ab5310c5410df07fd6ab99968da9dd54d3f1391&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 09 Mar 2025 15:03:03 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR`25 | 让暗光照片秒变电影大片！全球首个可训练的HVI色彩空间，突破低光增强瓶颈！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaAiatnfzwvnEljdY9eAgBu5BUIIvJDSyRL9sNNUZL6g1ic9EFFQMNqWtD1ia0tw7cVSMgjicOeMb6MCA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI生成未来文章链接：https://arxiv.org/abs/2502.20272 代码连接：https://github.com/Fedio</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699792&amp;idx=1&amp;sn=bf144234b03e43cce3cafdc287fe76f5&amp;chksm=f2eb5aac4477c8d010fde9429a1e2bf6864844b9b26dbfe11789ab8fc5ae7a7efacb330a4afe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 08 Mar 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[【NeurIPS 2024】南理工提出IMAGPose！用于Pose引导人物图像生成的统一条件框架！照片级真实感！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JooJ8m08gwWicLZ77AltgwI2LoBqS4icyib8U6icnglekic9ldZ3sa3UHTLbicYVVZWl1kXwbpRYRiaXwGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者妙妙房论文名：IMAGPose: A Unified Conditional Framework for Pose-Guided Pe</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699792&amp;idx=2&amp;sn=5859af7409bdb77fc223a9a4ad23c6ae&amp;chksm=f247e5edd9913090bcd3fd682d1e64c90677bdedd9bba14a59f7350261c57317d9948cd8c8bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 08 Mar 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 低层交互破局！GIFNet实现多模态融合通用模型，单一框架横扫多任务场景]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojn9NRdJRwzXtRGDT2lb48oLBkhguEPAwic3AjWyyCKpAnq8spI6m1LjGFaX7Rxa09mk5ltwHKib84Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Chunyang Cheng等    解读：AI生成未来文章链接：https://arxiv.org/pdf/2502.19854 项目链接：http</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699782&amp;idx=1&amp;sn=6fb6c0894f5b1cdfba037e694b046d0d&amp;chksm=f2ae479045a62dfb9c2702e18859e830fc0fb2317d19d955fa3d382e6e111821cd84c8947344&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Mar 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[能效提升8.64倍！庆应义塾大学提出AHCPTQ！SAM模型的量化革命！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IpHIM7G6ztu3jGsGR2FWyL120Gia14mRtHVWKC51FrASQibib6CZpxfaktoNaTZF9a3ERWurzddYF0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者妙妙房论文名：AHCPTQ:Accurate and Hardware-Compatible Post-Training Quanti</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699782&amp;idx=2&amp;sn=8dbd92a064743603bff66db16168846e&amp;chksm=f2eb4065b9e5d19928b7d40296663d2206489a5ef08b80bc94beb6ab9b5c9052b58fd09bec9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Mar 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大地震！杀疯了！计算机视觉研究迎来史上最大进展，解决视觉领域百年难题！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhFMiaelYibmuJpnnTc3eibf2o6t0bkFU5oNicibdLtRGjOQgVOdwDdXRmxdNwm2ibc3cpz460m1D6TLzoQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着深度学习技术的迅速发展，计算机视觉技术领域迎来了新的机遇。传统的成像系统受限于硬件能力和物理法则，往往难以在高分辨率和高速成像之间找到平衡。然而，深度学习凭借其强大的数据处理能力和模式识别优势，正</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699779&amp;idx=1&amp;sn=d099db25f048bbc8aaf69ac4c7f93d36&amp;chksm=f29fcbb76ca9e752a28dedee4b6142c0bf78c8821cd4764e083f051eb49a0e4f78dfa5410ff1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 01:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[新SCMHSA架构缓解 Transformer 下一帧预测语义稀释，适配损失函数性能更优 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVWBzHX5icichNpYQvA588JjmaA5YCoAPnpF0Qicq0M8Y24LEueFSIhxicWtm8jBQG8e5KM6Qqtnwgbtiaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>来源于AI视界引擎，作者AI 引擎视频中的下一帧预测对于自动驾驶、目标跟踪和运动预测等应用至关重要。下一帧预测的主要挑战在于有效地从先前的视频序列中捕获和处理空间和时间信息。以擅长处理序列数据著称的T</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699779&amp;idx=2&amp;sn=45b3ad1a8d4d7a38c4f1cddec32e910e&amp;chksm=f2f7a531b7be03fd042967f87069d275835abc01d548609fb993b650a9042095d77d391077a6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 01:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[PINN 顶会常客又登《Nature》，70 个研究成果 + 代码，无偿分享速扫码]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDjaBoicLRbkzZvsrNJq8mrts75EA9LxyymIicVqVtkAibJ45jGwx1QgSSQy0acjftu9kiaIefCwbGQia0w/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近有一个大热门：物理信息神经网络（PINN），不仅是各大顶会常客，还连登《Nature》。PINN是将物理定律嵌入深度学习框架，约束神经网络训练的新型方法。特别适用于解决AI交叉学科中复杂的偏微分方</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699774&amp;idx=1&amp;sn=22b290fd58363636309622b87b4ad7e4&amp;chksm=f273f2b898a91c37d7bc56021dbf118d3f24bb701b59f2983a0ce24ad7d0c923bb7a83f9ee1d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 扩散模型炼出新绝技！注意力蒸馏技术：图像生成效果全面碾压传统方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojwIAcFMRl0WCobaSgt5yd0p0PP83BhQl2CfZR8y1JicKyC5v7ljgibzJAYkZdiaI0FA9ZC7A3Zcia6dA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Yang Zhou、Xu Gao等  解读：AI生成未来论文链接：https://arxiv.org/pdf/2502.20235 项目链接：http</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699774&amp;idx=2&amp;sn=42c2c84739a144f502d2510ac8597df3&amp;chksm=f2cf923e8b4dd18115cd72d7ff4e3639aaa03a7b399f06c971c910d0c9c7df0cca85b3bf8faa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[革命性突破！中国传媒大学提出DLF范式！引领极端图像压缩革命！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LNt8XgcdTHsFpnWibjBghFhauLpH40zYvXVaIQiaX4hf1HL9Kl0Dz59GaXYHtMU8htXzL463HK6RNQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源于AI妙妙房，作者妙妙房论文名：DLF: Extreme Image Compression with Dual-generative Latent Fusion论文链接：https://arxi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699772&amp;idx=1&amp;sn=aa7643eaa66f1b390eb2192a9e2d05db&amp;chksm=f21eb81b9fc599012b22db0203d6023bb5dd89bbaadae54c656ecc7eaa5dd481a9098210799d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[面向真实场景图像复原，字节跳动提出扩散复原适配器，表现卓越！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiapg9Nqz56H9SicsW5lqdgvPkVWwKribQzucs0ibT7gF6ib45OtG2oUNC9xjAKyibNTj63cJAr3QvEAFBA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路https://arxiv.org/abs/2502.20679摘要扩散模型在生成高度复杂图像分布方面表现出强大的图像生成能力，可作为图像恢复的有力先验。现</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699766&amp;idx=1&amp;sn=eb31b2a0115a4dbb16cd63c0d1738230&amp;chksm=f2a743f2e8fdadbdbb6101b9fa5b68148555fefecb5d1c3134e7fdb1375bff2a346f7a838007&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[自回归视觉生成破局：Next-X 预测，开辟视觉新路径]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhacLP7kxqicmNrJuQqiaDTm1AqwMw41L3uZVESyJuR6hVyfSmR6icxdp6Guoornw1vP4wpMFaH86m8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路https://arxiv.org/abs/2502.20388https://oliverrensu.github.io/project/xAR摘要本文提</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699749&amp;idx=1&amp;sn=3777d73b4cdd2d3b963ac9f7d41f90d1&amp;chksm=f2b1268d5c2b9b87e9afbeec7543d3d88326ac03555ec415f6a16ad63123f819580465e99818&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[轻量级遥感骨干网络LSKNet和Strip R-CNN]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/AhFo6qKW8qs1S9m3ibV8OFOVkKJ626VjnPzwdjwJR0TZlClJJn33oOpOictPTvLR48ib0QVmNgTh87SAZz69qf0iaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>南开大学媒体计算实验室维护的NK-JittorCV最新开源了NK-Remote仓库，用于支持计图框架[1]在遥感目标检测领域的应用。目前，被广泛关注的最新工作 LSKNet [2] 和Strip R-</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699734&amp;idx=1&amp;sn=c56bf861203d8f14780ae11ed365d23d&amp;chksm=f2de5aa73c5197c35fc81a6b5e5c9a420aa9ef5d791c4d2c92d5f082e3ad521ba3293a232cc5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超高动态成像算法：AIGC叠加HDR，捕捉细节，平衡曝光]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oDpticHyXWJFQZFnAHsTtrPBPIibnHziaPv5aQFJy4PSxN8ReWETrTrmpfzCJ0KBsicdLcd0yBf6lbMgribsiahVn2Ng/300?wxtype=jpeg&amp;wxfrom=0"/><p>AIGC不仅能“无中生有”，更可叠加HDR技术，一键拯救图片曝光，贴近人眼成像效果。近日，上海人工智能实验室（上海AI实验室）与香港中文大学、浙江大学联合团队构建出书生·浦像超高动态成像算法（浦像HD</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699734&amp;idx=2&amp;sn=b965a90d6bfde2f1ffe0a33aee446310&amp;chksm=f282965eabee6c3fef0817a1d5a56d594fce370e12d3b631eec71b8760730a52e00f88fe6012&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 13:59:00 +0000</pubDate>
    </item>
  </channel>
</rss>