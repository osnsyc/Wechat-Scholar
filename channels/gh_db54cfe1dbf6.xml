<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIWalker]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIWalker公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      

      <title>gh_db54cfe1dbf6</title>
      

    </image>
    

















    <item>
      <title><![CDATA[让SD系列和FLUX.1无痛升级！浙大&amp;vivo提出CoMPaSS：文生图空间理解能力暴涨！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaqDqOzbacs94RKmy8Gy3hD02xJziaUE2R6uRNLuWORPFCLGrFavv2P4JibFgvX3AKvD3icRDjO8FkBg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Gaoyang Zhang 等    解读：AI生成未来 论文链接:https://arxiv.org/pdf/2412.13195 git链接:ht</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699479&amp;idx=1&amp;sn=5d42ead45987f21644d2f1fb76e0fab7&amp;chksm=f25b71a3f1488f491ff89a133ba197e02518bf25e89325a20bf559aabddd6db153b68a89c7d3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 27 Dec 2024 14:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[横扫2024各大顶会，用Mamba发Paper真的很轻松！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhmAicEoKGQ53uO4o0NzkJ6cicxDdic1ljHLARRpoEicQAg7zGSCIgvrczZpX5pVVOhVwp0jtibexjuGZg/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文收录2024年520篇Mamba论文合集Mamba作为一种具有线性计算复杂度的状态空间模型，今年非常热门，霸榜CVPR / ECCV / AAAI / NeurIPS等多个顶会。Mamba的优势在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699477&amp;idx=1&amp;sn=c8cb2c51708d125f86057aab3ea2a06e&amp;chksm=f25bb5437db5f435afde383b61921d70faacbf7a5a0d38c6ef040d07d154474e27c2dec2544a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[首次超越扩散模型和非自回归Transformer模型！字节开源RAR：自回归生成最新SOTA！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojaVibrjsrCNThrnyzZorNCibVwIb1MCrDfsY9yp1r4oIicvdQib9wcUiaVfML0aWTMFcGXP74wlibTibbwQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>   关注「AIWalker」并星标从此AI不迷路作者：Qihang Yu等    解读：AI生成未来 文章链接：https://arxiv.org/pdf/2411.00776 项目链接：https</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699477&amp;idx=2&amp;sn=c3726d483f1509cf235e6985f2e3da65&amp;chksm=f2bfd434f0098669df831b9ecc22e7e432efb877dca5de40f73b5aff6090f97f39b629fdd098&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InternVL 2.0：多模态大模型新标杆]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/UBMGKFIQrzlzMOESE9OwGQiaGC6JRUDoA4MMOA03qnVyd0pXM1Qr3vicUFnXLG2qPkkg0wicmufp6zLr0D6CNHB2g/640?wxtype=jpeg&amp;wxfrom=0"/><p>7月4日下午，世界人工智能大会科学前沿论坛, 我们发布了InternVL 2.0，中文名称为"书生·万象”，相比业内公认的最强多模态大模型InternVL-1.5，能力又上新台阶。它在关键评测指标比肩</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699476&amp;idx=1&amp;sn=54e0ba6f856e9a3c2030bbe1d51deb90&amp;chksm=f23a2dbc1c185ae7bd2f11465a14b8a5c135c3d2e3e643e5aa7dde09194c1280db6d5a427bcf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[重塑 CLIP模型，jina-clip-v1 统一多模态模型，实现最先进表现 ！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVVtkW5qHUWHFKicnkXl5Q16kF9qg9lbZe0mlweQBW5Fet4B0Uiab8EF6bbLc1skIEziaxEMWzdEFHDBg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI视界引擎，作者AI 引擎对比语言-图像预训练（CLIP）被广泛用于训练模型，在共同的嵌入空间中对齐图像和文本，通过将它们映射到固定大小的向量。这些</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699476&amp;idx=2&amp;sn=2c0d316e32d606ccc92a0e3c153da623&amp;chksm=f2e815be45e7e18746b40287d6993afcb917713b3b1aecce827bc070af117335348ddfcbfe06&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文生图击败所有扩散SOTA方案！智源研究院等提出NOVA：迈向统一的多任务大模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojzEian44LYZicjeqD6Fjl13K0PGEVx5p8cibyvKY9BLkulKCkCltoCX6cwCR1oeUlsurB4zV18L6LDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Haoge Deng 等    解读：AI生成未来 文章链接：https://arxiv.org/pdf/2412.14169 Github链接：ht</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699467&amp;idx=1&amp;sn=74375e470afa3b17b6b01353730ce894&amp;chksm=f23a2cb9859ac958b9a87d9e0b04d5bed78f0109a432b0a7c4cf0acccc545fc8d5b4d9d8ff2b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 14:01:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[源头活水 | MobileNet v1当年做了哪些设计才完成手机端即可部署的使命呢？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/2VBsQebGdeQ02zm2E3JFz9ibmiazy94JFpHe9YxjhumuTB2qiarUKlemLkBBYo1eC3Xh09QIGk40uXIwFTicDrjWZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI落地之芯，作者AI芯落作者提出了一类高效的模型，称为MobileNets，适用于移动和嵌入式视觉应用。MobileNets基于一个简洁的架构，使用</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699467&amp;idx=2&amp;sn=eadaaa74c9526ee51f9f2c5758b09965&amp;chksm=f2ee7d2349375a066b61f4759f091fcf15c888d22f4fb8faf50b027169f7ef9baa5ded709e82&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 14:01:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[超越CogVideoX-5B、Pika、Kling 和 Gen-3！苹果再发新作，视频生成大模型全面报告]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaU9gb3fBukUg9eaI0qvSaia3kNdR1HUxsOicru0rR8O60GvFibdeqicxKazSdn41hVwGneucAjwu1qicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Zongyu Lin 等    解读：AI生成未来 论文链接: https://arxiv.org/abs/2412.07730HuggingFace</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699465&amp;idx=1&amp;sn=3b4e865b759cd7f3ad13935f5ec0d719&amp;chksm=f27ee3fe0c97ebc359030743fecc41ce69a1070c6b221bdbe6db2d2638e03d90bbb2b8d8ae2b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 14:01:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[VILA-U：统一多模态理解与生成模型！多模态任务新架构！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IqN6LmUo0fdib09eyT1m3vNpnpvmiag90TaETdpiblFBx79hRansXeE1JPgNpOI8MZ0KVoOxGcyn49Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者妙妙房论文名：VILA-U: a Unified Foundation Model Integrating
Visual Unders</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699465&amp;idx=2&amp;sn=9f5c18741379b435463b5c9f48c9338d&amp;chksm=f288e42497bc68ea5477b07c531becab0a01d7b67f64bd4335ea57255d35cc047b3056bb6e3a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 14:01:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[释放你的想象！支持25种复杂编辑类型！浙大等提出AnyEdit：统一高质量图像编辑框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogvQmU85Kosfv2RDCta999EbyF8VGjNflEKL8rzY2kCTLkHufbCjRTU5ianGMict4uibvsA4bKvfblyA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Qifan Yu 等  解读：AI生成未来 文章链接：https://arxiv.org/pdf/2411.15738 项目链接：https://dc</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699463&amp;idx=1&amp;sn=786ce6f9506d277be400ab00f845130c&amp;chksm=f28a665589eb94c27b15913be801b9d95a3428dca8f0f90a68395e3516353a379b367471d391&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 14:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InstructSeg来了！全面的指令性视觉分割新方法！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JXJ2jNsoPbZYaxuh3c3VmG7Y9icaDDxk3DWLyFrtibDPsQDfWYxQgZmkozdvpzPviaEibfKNGrGjODhw/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI妙妙房，作者小源论文名：InstructSeg: Unifying Instructed Visual Segmentation with Mul</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699463&amp;idx=2&amp;sn=317b29d1f83ed9dce9e7b73ce294341d&amp;chksm=f2106c91e3db0f5b05afbb575e5c8f728cc56a8de1abdeffbf51fab942ae615aaa8c3dc7277c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 14:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[BiSeNet之忆往昔 | BiSeNet用AI新语言交出了自己的答卷，BiSeNetFormer依旧大杀四方!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVW1dajAo3kYXqaur3qMyNY3bWFKVAhTRtiaic37syfZqtC7RTicwHRyG3GPicvnMnOnRdjhFxn8M2x30A/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源于AI视界引擎，作者AI引擎近期在图像分割领域的进展主要集中在提高模型的效率，以满足实时应用的需求，特别是在边缘设备上。然而，现有的研究主要集中于单任务</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699461&amp;idx=1&amp;sn=268a5f9a0e92dd1a5f62172e7a3ed821&amp;chksm=f2b27c983edd220577f9b09e48707550582a57edd31f80d2a92ccc5c2f79a55e25d2786421ae&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[训练扩散模型比你想象的更简单！谢赛宁老师：Representation matters！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo6MHfL6rh1U7d9022CaPm7e9HXRDxjnVfb8Waf4W3EtcPo9pzWGTHl96cFzbtNmsDEEBX3q0CQ7w/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨科技猛兽    编辑丨极市平台极市导读 表征的对齐真的很重要！之前我们训练扩散模型的路可能是错误的。 太长不看版训练扩散模型可能比你想象的更简单。纽约</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699461&amp;idx=2&amp;sn=9255d5e013ba933e58617bf2adf46947&amp;chksm=f29e13f4a90f2e3f2b39c3a161fdc372e3d26153885acf8ce7a4f6db79a2e22131b9fa18a5c1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文看尽2024年主流11种注意力机制]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaXicJR3DBH33uCibYFbichXEFQTVa3iaaVBWBRS2viaSEMyhYACN5Jjt58cphX8xxGYibyLuXYUicpl22nQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>注意力机制已经成了模型设计的基础架构，现在模型里没个Attention都不好意思发出来。从注意力机制发布到今天，学术界一直在对Attention进行各种魔改。魔改后的Attention能够提升模型的表</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699459&amp;idx=1&amp;sn=401633a52c358f8097a5fb7bf4d2af63&amp;chksm=f26bf61d5b0b2e03b68e9fdd38e3b8282c87d2d60a0b4f3577ec87fe5b951b0930b99d1432ed&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像修复和编辑大一统 | 腾讯&amp;北大等联合提出BrushEdit：BrushNet进阶版来了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoj5y5tcjbKa8WBL9PiayXJ6EyibgRP0vDtog3Of2MQjEfqSjduF7yiaOYwNmVOSfmTFQJ1OSVP7TTZ0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Yaowei Li 等    解读：AI生成未来 文章链接：https://arxiv.org/pdf/2412.10316项目链接：https://</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699459&amp;idx=2&amp;sn=6148140407fd952838ea2c470041db37&amp;chksm=f2ea57a7a9388179aa517a7656329d0d91ef00d3d8e8046e481824f881011378249b83f5a001&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像标注神器 X-AnyLabeling v2.5.0 重磅发布 | 通用视觉任务全新升级，交互式视觉-文本提示功能全面上线！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ364K0zUNtscY3Md7MrnU43iaM2ibPqCRCJl6XzuEXibaNOyHDT0JQXd92Agwetiag4b5mY8W0dgPw5fw/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | CVHub   链接 | 派派星0. 导读X-AnyLabeling[1] 是一款集众多主流深度学习算法模型和丰富功能特性于一体的强大图像标注软件</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699458&amp;idx=1&amp;sn=bde432067980362b4adf62b35e601881&amp;chksm=f23234d7a97b658afff5692398ebddba59b0300bf4c505996c5dcc032481dbb15fbbedbfd27c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[鹏城实验室提出MoH | ViT、DiT和LLM上MoH只使用50%左右Head即可完成超越]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/2VBsQebGdeRKnKsZticPmqULUclU39fqq3hUgBDgrvHouh23EGiaTCD0r9UWWFN0HH0QagYCv0fUJjHXcNLqNUxg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI落地之芯    链接 | AI芯落在这项工作中，作者将Transformer模型的核心多头自注意力机制升级，以提高效率，同时保持或超过先前的准</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699458&amp;idx=2&amp;sn=48461bc3d3e7a65bb38ea4e68d767bdd&amp;chksm=f2a2021addb32dd34907a71313333d20b2e8af03b903e41dc21ba499388ad12cf378bb734eb8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 18 Dec 2024 14:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
