<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIWalker]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIWalker公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_db54cfe1dbf6.jpg</url>
      <title>gh_db54cfe1dbf6</title>
    </image>
    <item>
      <title><![CDATA[革命性突破！中国传媒大学提出DLF范式！引领极端图像压缩革命！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LNt8XgcdTHsFpnWibjBghFhauLpH40zYvXVaIQiaX4hf1HL9Kl0Dz59GaXYHtMU8htXzL463HK6RNQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源于AI妙妙房，作者妙妙房论文名：DLF: Extreme Image Compression with Dual-generative Latent Fusion论文链接：https://arxi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699772&amp;idx=1&amp;sn=aa7643eaa66f1b390eb2192a9e2d05db&amp;chksm=f21eb81b9fc599012b22db0203d6023bb5dd89bbaadae54c656ecc7eaa5dd481a9098210799d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[面向真实场景图像复原，字节跳动提出扩散复原适配器，表现卓越！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiapg9Nqz56H9SicsW5lqdgvPkVWwKribQzucs0ibT7gF6ib45OtG2oUNC9xjAKyibNTj63cJAr3QvEAFBA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路https://arxiv.org/abs/2502.20679摘要扩散模型在生成高度复杂图像分布方面表现出强大的图像生成能力，可作为图像恢复的有力先验。现</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699766&amp;idx=1&amp;sn=eb31b2a0115a4dbb16cd63c0d1738230&amp;chksm=f2a743f2e8fdadbdbb6101b9fa5b68148555fefecb5d1c3134e7fdb1375bff2a346f7a838007&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[自回归视觉生成破局：Next-X 预测，开辟视觉新路径]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhacLP7kxqicmNrJuQqiaDTm1AqwMw41L3uZVESyJuR6hVyfSmR6icxdp6Guoornw1vP4wpMFaH86m8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路https://arxiv.org/abs/2502.20388https://oliverrensu.github.io/project/xAR摘要本文提</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699749&amp;idx=1&amp;sn=3777d73b4cdd2d3b963ac9f7d41f90d1&amp;chksm=f2b1268d5c2b9b87e9afbeec7543d3d88326ac03555ec415f6a16ad63123f819580465e99818&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[轻量级遥感骨干网络LSKNet和Strip R-CNN]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/AhFo6qKW8qs1S9m3ibV8OFOVkKJ626VjnPzwdjwJR0TZlClJJn33oOpOictPTvLR48ib0QVmNgTh87SAZz69qf0iaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>南开大学媒体计算实验室维护的NK-JittorCV最新开源了NK-Remote仓库，用于支持计图框架[1]在遥感目标检测领域的应用。目前，被广泛关注的最新工作 LSKNet [2] 和Strip R-</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699734&amp;idx=1&amp;sn=c56bf861203d8f14780ae11ed365d23d&amp;chksm=f2de5aa73c5197c35fc81a6b5e5c9a420aa9ef5d791c4d2c92d5f082e3ad521ba3293a232cc5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超高动态成像算法：AIGC叠加HDR，捕捉细节，平衡曝光]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oDpticHyXWJFQZFnAHsTtrPBPIibnHziaPv5aQFJy4PSxN8ReWETrTrmpfzCJ0KBsicdLcd0yBf6lbMgribsiahVn2Ng/300?wxtype=jpeg&amp;wxfrom=0"/><p>AIGC不仅能“无中生有”，更可叠加HDR技术，一键拯救图片曝光，贴近人眼成像效果。近日，上海人工智能实验室（上海AI实验室）与香港中文大学、浙江大学联合团队构建出书生·浦像超高动态成像算法（浦像HD</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699734&amp;idx=2&amp;sn=b965a90d6bfde2f1ffe0a33aee446310&amp;chksm=f282965eabee6c3fef0817a1d5a56d594fce370e12d3b631eec71b8760730a52e00f88fe6012&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[少至8Token完成视觉重建！Apple提出FlexTok！可变长度图像Tokenizer ！性能超过TiTok！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDhEaiae8FCYMb1jtePdphDJ0iaCkudGVEE1dwI3IKwgNvjI6XWvgIcFWBMpQhJXaYAprsF3OAlLPS1Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 数源AI  作者 | 小源论文名：FlexTok: Resampling Images into 1D Token Sequences of Fl</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699732&amp;idx=1&amp;sn=5363fcba3655472a3bb384e00e4a1ad5&amp;chksm=f253db149e2c085a4bba20f82c0fd0481894ebf1dc6fd54643392563e5cba76449e92b759cb8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[手把手教你驯服DeepSeek-R1！部署+测试+性能优化万字全攻略]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp8n64epzESzPFtUmloC3pJzZsibUCISlbiaJgQ96Wzqgkrz5OViakrMq6gwo9jl3cuTNVAqAkDicDlLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者丨Mr.Felix    编辑丨极市平台极市导读 本文详细介绍了如何部署和测试DeepSeek-R1模型，涵盖了从Ollama到vLLM的多种推理框架的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699728&amp;idx=1&amp;sn=e962ef7406853c490c39513bac7c54a1&amp;chksm=f24da786b1e902ffe46fe38a8620940f32c59c02cc0e01cacb452d877ae42fe7a64fc5526617&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 14:07:25 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[太强了！浙大联合上海AI Lab提出视觉统一Diffusion架构DICEPTION！各种视觉任务一网打尽！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcb6XeOfGM7ic3jww1VGas5hyQ5UbdLhbhjcqHwrckdlwdXIvppjK9PlGZVkxMpOMiaT6tDJ32KOqiaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 数源AI  作者 | 小源论文名：DICEPTION: A Generalist Diffusion Model for Visual Perce</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699728&amp;idx=2&amp;sn=9f96366db218654abe86dc046ba8390b&amp;chksm=f224755396328d93031323508d1083417187d61f94e5539826fc871c26776f7ab89e4d666f84&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 14:07:25 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MIT何恺明再次突破传统：分形递归架构引爆生成模型新纪元！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogiaibpP0CqIiadiaT3ZaLYuibJvk76CcrZiaDeDtriakT7A352bCPtiabGaIjiaELJkbRbicZFD7HXx492Cqug/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路作者：Tianhong Li 、Kaiming He等  解读：AI生成未来论文链接：https://arxiv.org/pdf/2502.17437 代码</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699726&amp;idx=1&amp;sn=43ce5bf7dd37615bb7e9fcd51acd4dea&amp;chksm=f2f29fd6e715e01f690f3be67d1bbe5112cf6ad163b19a54ffe29f73566aa3a98ef48d5bd787&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[揭秘线性与 Softmax 注意力差距，赋予线性两特性，多任务超越且计算量低 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVXMdXCynTByTICXxqsKjNgDSYV1BtwTZz3LNNHyaQ2cIIGzMK0iak1Te90NlicjiczzCR01icEXCev6icg/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | AI视界引擎 在现代视觉Transformer设计中，Softmax注意力能够有效捕获长距离的视觉信息；然而，在处理高分辨率输入时会带来巨大的计算</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699726&amp;idx=2&amp;sn=5091adc04e624f5cc2c5dd3fe40d061a&amp;chksm=f2f6736fe7fe2018e648659d8189a0a4092e0c4572c00a3bbdea6b59a00a84dbc3d0ef4639f1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 13:59:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型时代，让DeepSeek告诉你该如何学习目标检测~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/VvkhdVVVIDiaoCqmClacEWGH9M4l8bRcjU38icuRoIfLSWHx0QZAsUibhaXzyCIHyROibbdWua4CMSFeiaoIIzF6vyg/640?wxtype=jpeg&amp;wxfrom=0"/><p>目标检测是计算机视觉领域最核心的技术之一，应用面非常广泛。这里总结了245个目标检测开源项目给大家练习。具体到人体、交通、医疗、工业、开放世界、3D目标、小目标等16个分类。其中包括多个基于YOLOv</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699724&amp;idx=1&amp;sn=f95e999d99601ce18fa4840b149e3a81&amp;chksm=f24592ba93c8ad1a8191d634da202b2e110310f231d54a9755b4039e0a27f2490177e2cc5e88&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Feb 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别800秒魔咒！硬件级STA革新视频DiT注意力，让HunyuanVideo效率提升3.5倍!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohFzlicObmXNQicfPW2nWGQIBooj23sGXdWXfQp1mwViaU1yojYkJ1frSxibicStEaqRFl4kwfjSKASrWw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：Peiyuan Zhang等  解读：AI生成未来论文链接：https://arxiv.org/pdf/2502.04507Git链接：https://github.com/hao-ai-lab</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699724&amp;idx=2&amp;sn=10d90ee9da64ce12c5cddd81d47e3991&amp;chksm=f29ec308e111d2fb3c11ab9bab137f9934e36c5df6ba399ecc76f185ee417547f5ae40fe46ca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Feb 2025 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[1.4s 即可生成1024px图像！SnapGen：轻量化架构和训练策略实现端侧文生图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo0eVZiczoVxof2UIkXZcrwpJpibAeXGlhv7CbawZ061pialSfSAmkRXmXK1MLIdGUuwhRmCJMtPQKOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨科技猛兽   编辑丨极市平台极市导读 在 ImageNet-1K 上，本文的模型仅使用 372M 参数，在 256 px 生成中实现了 2.06 的 FID。在 T2I 基准测试中 (GenEv</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699722&amp;idx=1&amp;sn=eac3e0258781d983e276fa42f00ced02&amp;chksm=f2e0d8e7f684cc0db3381ea8904d7fab6909a218edb59b6a92218b3f5271d5fb76c967f0af68&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[中科大提出 D-FINE |  通过 FDR 和 GO-LSD 实现最先进的实时目标检测 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgkEY0DXdcmpSibJ1w9GCpNXv4jfWZ3nJRq4XMmwyGgh8yibiaNpT3GSw7qxvQld2iaU9HuGiaibg701SoicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路来源 | 集智书童  作者 | 小书童作者提出了 D-FINE，这是一个强大的实时目标检测器，通过重新定义DETR模型中的边界框回归任务，实现了出色的局部化</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699714&amp;idx=1&amp;sn=a8b9d3033deedf3382def775a8f804e7&amp;chksm=f2f444ac27d96785f64f2e0f956d0236ed7bea627413afb8568ac5430e029a173c61fb623a02&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Feb 2025 14:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[别只盯着DiT，国产模型也在暗自发力！U-ViT：ViT 架构实现 Diffusion 的开山之作！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfq9qeelUQgEiaPb5HuLYmHCnicqwT1Tv8SUlV89gXDbx7USDoicfGt6gKTPrTicibbunM4GdXDoDIXaLjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>关注「AIWalker」并星标从此AI不迷路  作者丨科技猛兽    编辑丨极市平台极市导读 本文的提出比 DiT 还要早一点，而且本文是用 ViT 架构实现 Diffusion 模型的开山之作，使用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzIyMjIxNDk3OA==&amp;mid=2651699714&amp;idx=2&amp;sn=55cf68718c4d1bb65b5b78951ba1c390&amp;chksm=f24bb92da0dedff95b72115f20261c94c52b6d89b8ab7bbcc14fe21b37b6395c8732446cee62&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Feb 2025 14:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>