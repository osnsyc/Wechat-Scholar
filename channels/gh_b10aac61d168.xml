<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[arXiv每日学术速递]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[arXiv每日学术速递公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_b10aac61d168.jpg</url>
      <title>gh_b10aac61d168</title>
    </image>
    <item>
      <title><![CDATA[传统vs开放，薪资差300%的差距在哪？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN0ZNxOaxYRoxE2YJac3ZQFZXMGDaCMsaLO2woQdbYRcVmPJs3Gfj5tjYRbkBF1PPlGYJSgJbR0ibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>💡 为什么现在所有CV工程师都在学开放词汇技术？“传统模型连‘充电宝’都检测不出？开放词汇让AI听懂人话！”🔥大厂紧急加薪招聘：自动驾驶公司开价80W年薪抢OVD方向人才🔥技术爆发临界点：CLIP+L</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688934&amp;idx=1&amp;sn=4b1d07c401523c3f5291e146ec90bf2d&amp;chksm=ce477ce0d4cac33a030375b1462561cf80a748ffd0f23f1fdcd041060e6479d7043c7a5f845c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 16 Jun 2025 03:23:08 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.6.16]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN0ZNxOaxYRoxE2YJac3ZQFGgjJmFBbzjC99NyXYLalcNtsJJOHjB5NCp6pliaLiacu66RZLlhviaPJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.6.16  人工智能相关计算机视觉与模式识别(cs.CV</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688934&amp;idx=2&amp;sn=6fe407507bd4b00feffd641a352fba49&amp;chksm=ceaa07e84b876dd46cfa11bcaf713da0ce6cac683dae320bb6e380f0733fe47b07c10cd7b5a6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 16 Jun 2025 03:23:08 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[语义分割新高度 | 英伟达提出SeNaTra空间分组层革新Backbone，性能效率双超Swin Transformer]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglTDY72bzYEsBy24c3IiaheZDfEkz4zQwLU79LoeKEfSicuQl9wKbKJaFvWy7Yh1zel671DqFB0JHdQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 精简阅读版本本文主要解决了什么问题1. 统一的分割架构设计：现有的视觉Backbone网络通常依赖于统一的下采样操作，无法适应图像内容的变化。本文提出了一种基于内容感知的空间分组层，旨在替代传统的均</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688934&amp;idx=3&amp;sn=9e25b906cad7b825011dd307a2d69607&amp;chksm=cecaf64c1cd7d254f7cf19481465865d3da77523cac8de71c05638e3038e5f0f688f1920f1d3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 16 Jun 2025 03:23:08 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[EarthInstruct基准搭配InstructSAM框架：解决遥感目标识别难题，多任务性能与效率双提升 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVW11VMQt27L4C09QAxpSHrINZTvfib05l7Z3zicJs9TG0DYBicCdJDibjkWbnESJWp9pG38wJiczeZbg4w/300?wxtype=jpeg&amp;wxfrom=0"/><p>遥感图像中的语言引导目标识别对于大规模制图和自动化数据标注至关重要。然而，现有的开集和视觉定位方法依赖于明确的类别线索，这限制了它们处理需要High-Level推理的复杂或隐式 Query 的能力。为</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688934&amp;idx=4&amp;sn=10a21bcd158a8c93c6310c0ce94752a6&amp;chksm=ce7e55932fb7573c6116c649f193e277d8ea597971216e79189945f27aadf3d1560d7ef5bfa3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 16 Jun 2025 03:23:08 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[「Next-Token」范式改变！刚刚，强化学习预训练来了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPPBDj0RyXoZqcOLmosclzOuOBG796icYG3zxawbsU0zmgGYP2WSxMquIX8Mq9F8hS7feJQoEcz8Nw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：张倩、陈陈谁说强化学习只能是蛋糕上的樱桃，说不定，它也可以是整个蛋糕呢？在 2016 年的一次演讲中，Yann LeCun 曾将强化学习比喻成蛋糕上的樱桃。他提到，「如果把智能比作一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688528&amp;idx=1&amp;sn=ff38c72e687cfdcba16ab33cae050812&amp;chksm=ceed3bd68f1aee9c45985b8d780ca28bae25d1aa683d1d2fd79403fc4721ecf8eda97c577203&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 15 Jun 2025 06:02:11 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[端到端SOTA！中山大学GaussianFusion：高斯建模让自动驾驶感知-规划一体化效率飙升~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28h1wmXUCwTLKv3kml38fyEHEo7ta4P5azKO7H4WCYtl3eJsKP00iautQuLdpVSsmXH3NvwaFcAuywQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>中山大学团队的工作，开闭环的效果都还不错。利用高斯表征和扩散端到端的方法结合在一起，最终效果比DiffusionDrive要好一些。写在前面 &amp; 笔者的个人理解多传感器融合对于提高端到端自动驾驶系统的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688528&amp;idx=2&amp;sn=d013e7eba7444fbe1dc1e8c582652c3f&amp;chksm=cef6055aa3f6a55c3ab35f4d28af7dd3ea4440c45e976c01e4e39396ea4e58a598a509d9d169&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 15 Jun 2025 06:02:11 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[重建与生成不再对立 | GigaTok借语义正则化统一视觉分词器，3B参数完胜VQ-GAN，刷新ImageNet纪录]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglTDY72bzYEsBy24c3IiaheZ1QvLTiatIB9Sgdbo5L98DUib4B0uoftIjDibHNGkib8XZCenhDX1aAFibpA/300?wxtype=jpeg&amp;wxfrom=0"/><p>精简阅读版本本文主要解决了什么问题1. 重建与生成的矛盾：扩展视觉分词器可以提高图像重建质量，但通常会导致下游生成质量下降。作者研究了这一矛盾，并提出了解决方案。2. 潜在空间复杂性增加：随着分词器规</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688528&amp;idx=3&amp;sn=7ee7dab7a2660d5761edb9b175326504&amp;chksm=ceffe4cf46bee22c02b6fab931f8420da15704c98519d13a763c60792c0a02bccb741e09a916&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 15 Jun 2025 06:02:11 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[yyds！一个大模型的新方向，彻底爆发了！！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPPBDj0RyXoZqcOLmosclzOv5q8FCtukyH1HCLbKTjJtcYMfaudmhSYKAe4cBPcef4Hfy1bMxbdYg/640?wxtype=jpeg&amp;wxfrom=0"/><p>同门师兄用大模型3个月发2篇顶会，你还在为实验baseline调不通熬夜—学术赛道上，认知差就是最大的代差！别担心！我们请来了真正的"救星"：【斯坦福博士】+【CVPR 审稿人】每天直播教学2小时！9</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688527&amp;idx=1&amp;sn=4b73937c76bf30fd437adc63f75f3ad6&amp;chksm=ce0b81335a736e5efb5c064d63bfadfef56d6ec41c6770a6991a5596ac9f7ef8f5970aa7b315&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 13 Jun 2025 03:51:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.6.13]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbOxQYicHCzZMvqibVa34c31OefwlLV8vyZyC7hNphV9CS571kF1snibeHOiaIJEKJy1v7S0YJaYhp691A/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.6.13人工智能相关计算机视觉与模式识别(cs.CV) | </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688527&amp;idx=2&amp;sn=497892e62e126140e0bac5e151e3bf4e&amp;chksm=ce7a6f84cd0c0a1788072a40808197493bb739726eea380776ae14a1b46b9785f4458c0b549a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 13 Jun 2025 03:51:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ETT：打破原生多模态学习视觉瓶颈，重塑视觉tokenizer优化范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbOxQYicHCzZMvqibVa34c31Oe2Ym590Mep7cZOcFoNianWa2LVCgzXKALBHoxwttD5DoDbyBBaYDszgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文由北京智源研究院多模态大模型研究中心（团队负责人王鑫龙，团队代表作 EMU 系列、EVA 系列、Painter &amp; SegGPT）、中科院自动化所和大连理工大学联合完成。 在多模态学习蓬勃发展的当</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688527&amp;idx=3&amp;sn=d6a26ccd5e66f41766821fdf30d9cf53&amp;chksm=ce6bb9f1f20df98593fd0b23eb375aa94544524b34c484951bc53a3caa0c81bc137d3b3ca603&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 13 Jun 2025 03:51:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文一起读 | 基于目标对比奖励的机器人强化学习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/G3miadARVe8icgBZWuZCZ6egTryEvxRJUSvxUPqdV6tONicE36cO4ZBYT7WoObVD8NOic2OFicoLnVyDhiafsS1lV3eQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>‍ 导读本文是VCC许聚展同学对论文 On-Robot Reinforcement Learning with Goal-Contrastive Rewards 的解读，该工作来自机器人与人工智能研究</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688527&amp;idx=4&amp;sn=bdd7a179dff1135539c216b12d2fce22&amp;chksm=cea95463de6247de3e0828d163dd2f89901e318eb2a29bd22ad81113bdff9f83c5c4996dc94e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 13 Jun 2025 03:51:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[PINN网络，真的太强了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMGxhXRLKSx3gVUQMibAZcwekLiac8KQykRemuEKMhfNkupTnX6icPCKHnia1jmtpicp8dsBodxGnrYyZg/640?wxtype=jpeg&amp;wxfrom=0"/><p>最近在Nature和Science正刊上，又看不到不少PINN相关的研究！比如预测能力远超SOTA的HFM模型；基于逼近原理的DeepONet……实际上，PINN一直都是爆火的方向！不仅好出创新点，而</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688113&amp;idx=1&amp;sn=461632d8f9ddee7e0a7f992597338602&amp;chksm=ceffa1cd766006bb92824e163325f80a9d8f801fd25885b80117b0202ef33d1a9c320d82a406&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 04:30:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.6.11]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNkzJtGib6LdBBEDsaFrr3jKSDUbm080eKn27CRDUISpiaibUVVibVmrRu632v6cMYfnZFPicGSZfqme6Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.6.11人工智能相关计算机视觉与模式识别(cs.CV) | </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688113&amp;idx=2&amp;sn=31314ce2287f6ae9e0b931dca94f8057&amp;chksm=ce350e4d1e186f6c2802da6f384cc1fbeb3f7efc4613a32b3ecabe74f661f93fa11c27153314&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 04:30:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[突破多模态图像翻译难题：ABS-Mamba借SAM2、CNN、Mamba及LoRA+微调创佳绩 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVVCCBOiaJeiayd0jLAZOV82epIKgibrkJ04OcpT7ewW9LMLWZGhTbn6cmlS5t3T5dlr73fbdUl6HDajg/300?wxtype=jpeg&amp;wxfrom=0"/><p>精确的多模态医学图像翻译需要协调全局解剖语义和局部结构保真度，这一挑战因跨模态信息丢失和结构扭曲而复杂化。作者提出了ABS-Mamba，一种集成Segment Anything Model 2（SAM</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688113&amp;idx=3&amp;sn=714845cfee67134a97314e896668fdcc&amp;chksm=ce648de2e41173646d20fb366c4a42fe4a184eafd7ac384427b994b27feb741cb24a36de7f7a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 04:30:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[新一代世界模型！GeoDrive：显式注入空间结构信息，问鼎SOTA（北大&amp;理想）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28huyTkZWaXqQc5DaOzeichmOvhZmvRCbKHJQhDOT4l9lGib6Zd1SerTAV0FptianpOcm0lb6gB7RDOKg/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京大学、伯克利人工智能研究院（BAIR）与理想汽车（Li Auto）联合出品，GeoDrive 是一款面向自动驾驶的新一代世界模型系统。针对现有方法普遍依赖二维建模、缺乏三维空间感知，从而导致轨迹</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247688113&amp;idx=4&amp;sn=f424aa8e980d01d5140c756a08e87c94&amp;chksm=ce2bb8a7bc797ff56200f185001215a3958495e9d4bf17da952cafd63143fbea706b405818a7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 04:30:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[20年物理疑云消散！「μ子异常」最新实验未发现显著偏差，标准粒子模型屹立不倒]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMGxhXRLKSx3gVUQMibAZcweaft6Ha4kFJxecYk4KFDZtujicuQGLAVxdia5CLV3DFbhbD3AvBpia7F4w/640?wxtype=jpeg&amp;wxfrom=0"/><p>鱼羊 发自 凹非寺转载 | 量子位 | 公众号 QbitAI一度轰动物理学界的「μ子异常」，凉了。美国费米实验室公布的最新实验结果显示：尽管在2021年，研究人员发现μ子的磁性超出理论预测0.1%，令</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247687713&amp;idx=1&amp;sn=98bd44185baf40fbf40a32ded777508b&amp;chksm=ce30cf71d5ef320b8396b12126226bcc3adcf4ab8d22dee2cc8b284d24e02e9483702d6aa0f7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 07:30:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.6.10]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMGxhXRLKSx3gVUQMibAZcweZOvbNVXkolv4YflAuaIEfdhwHADiaRTbFWzmIb0RBpnDHWcMu3FbGtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.6.10人工智能相关计算机视觉与模式识别(cs.CV) | </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247687713&amp;idx=2&amp;sn=c4387210af814fd54c5e178616aac002&amp;chksm=ce5223647b1d4f01a324e5d59f25d1f4c23cc813b1e82e057f8176c87ec7fa3c50d7218cc5d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 07:30:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MGIoU革命 | 统一损失函数高效优化任意凸形状，计算延迟锐减40倍超越KFIoU]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglTDY72bzYEsBy24c3IiaheZjf6UQXXuRiaTibFhBXcLKsIqCeI18FYpbPquBybL0DeWVibib2ia0Bqic2sQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>  精简阅读版本本文主要解决了什么问题1. 优化参数化形状的挑战：当前基于回归的损失（如L1/L2）与IoU缺乏相关性，基于IoU的损失不稳定且仅适用于简单形状。特定任务的优化方法计算密集且难以跨领域</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247687713&amp;idx=3&amp;sn=77c5e94a079a2dfd5be4988a7db57a77&amp;chksm=cefd13cc6837fb226a2bb2896787cba1ce9df65f11cbcf23c71b46d8d61288fccc6d374486f1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 07:30:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ViG3D-UNet：集成3D图与卷积模块，于公开数据集实现高精度连续分割！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVXr4XS4nMp6a497jCF50nIPEiceah4ia9QknGMoG1l7Gf01icPQF1HQP0hZmT7InWJN2PPPRGZzwicicbw/300?wxtype=jpeg&amp;wxfrom=0"/><p>精确的血管分割对于冠状动脉可视化和冠心病诊断至关重要。该任务涉及从体积空间中提取Sparse的树状血管分支。然而，现有方法由于血管分割不连续和端点缺失而面临重大挑战。为解决这一问题，作者引入了一种名为</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247687713&amp;idx=4&amp;sn=7737525dc1b8c1504309719d84223cc5&amp;chksm=ceeb2444cec56df1230ad7aace3f7ac43789d33edc9a4459c97309cf67205cc9e83c04c2df34&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 07:30:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[强的离谱！CNN杀疯了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbO1vNU7sC76gOCdzlHHVG8zMKhuicswY8SUhvF7SicgVUDzy0XfSDiahESUVjVHeWEGuucFKiblIAUuQQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>❓当传统CNN遭遇算力瓶颈，神经压缩技术如何将模型缩小50倍❓液态网络如何模仿人脑实现毫秒级动态响应❓边界注意力怎样突破医疗影像的亚毫米级分割极限如果你对深度学习感兴趣，尤其是卷积神经网络（CNN）和</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247687325&amp;idx=1&amp;sn=76df9c5e89a644e58c4d388fde5a72f6&amp;chksm=ce0d42c3944d95df2c1e1c90d7ba045c52076f4a98d03ff2cc1246f6fdab09e617ec8c62d96b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 07:13:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.6.9]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNxqHlzKWFfibjmT2Yuph9MtBUlchQGn3XrpibRf0ib1pjC4zfRia3KaRunhqDJx2wTs4QdIXtlEgWN3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.6.9人工智能相关计算机视觉与模式识别(cs.CV) | 自</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247687325&amp;idx=2&amp;sn=2fcf3e6a1ec6c1bd7122f15b2827da1b&amp;chksm=ceb085870d9462a845cf9e08bed479f47936b00682aa4036c2eee5c6a498433b887cbc05756f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 07:13:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[仅1.24ms！FPN终结者 | 金字塔Sparse Transformer粗粒度引导细粒度+参数共享，实现检测与分类双赢]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tglTDY72bzYEsBy24c3IiaheZEalYRabXhnJIrDtvO4BkaR9ngqtb60f0icVzPOYibV31xEqHiauCSGBng/300?wxtype=jpeg&amp;wxfrom=0"/><p>   精简阅读版本本文主要解决了什么问题1. 当前基于注意力机制的特征融合方法计算复杂度高，实现困难，限制了其在资源受限环境中的应用。2. 现有的轻量化注意力机制（如Sparse或低秩近似）虽然降低了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247687325&amp;idx=3&amp;sn=309cd532960ac67da6c00cb4bfbe529d&amp;chksm=ce99f755bfcf6b8c8ad31f484e8f2fbc5d447bc585a4c6fef61dd3e814ca5b0903ccf40d5099&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 07:13:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[π0如何用于自动驾驶：CVPR'25端到端亚军方案解读，清华&amp;博世DiffVLA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28hgtXZr1UrRAevUwOdxhO5p4wwGlY7YBaVBY9MqPA8LdbbHzZFKzvu4Defd94r6npP32DOVzUf5kg/300?wxtype=jpeg&amp;wxfrom=0"/><p>🏆 亮眼成果： 博世中国研究院与清华大学AIR团队的最新研究 DiffVLA，首次将通用机器人控制框架π0的"视觉-语言-动作"范式，成功改造为适应自动驾驶严苛要求的专用系统。该成果在Autonomo</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247687325&amp;idx=4&amp;sn=791c601704fc51838740d231a8a7d033&amp;chksm=cef3e6b2d3b6152ec863c8069fa05441a71655325c7994a441ce16a04a099feb59aaf11bfbea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 07:13:58 +0000</pubDate>
    </item>
  </channel>
</rss>