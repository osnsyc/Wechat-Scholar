<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[arXiv每日学术速递]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[arXiv每日学术速递公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_b10aac61d168.jpg</url>
      <title>gh_b10aac61d168</title>
    </image>
    <item>
      <title><![CDATA[为什么Qwen能自我改进推理，Llama却不行？斯坦福找到了原理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMxU0Qr94bpTE7GF1pXdOfWZRppuvFopPt4Cjgv9iayRgfian3J7HBPMSFJqCCugjn8Yr0qTqAttNXA/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心报道编辑：张倩、泽南虽然 Qwen「天生」就会检查自己的答案并修正错误。但找到原理之后，我们也能让 Llama 学会自我改进。给到额外的计算资源和「思考」时间，为什么有的模型能好好利用，把性能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247660176&amp;idx=1&amp;sn=63b5efe2b48b571215d7c4b775525b7d&amp;chksm=ceb39525053f014b8aadb8b621ce132fa3bb73b4ad09b6c0b2287e2f0e7bdad4175012655a55&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 08:25:18 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.6]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMxU0Qr94bpTE7GF1pXdOfWQEpO0rh1U0ZEvKPu0icXHBIDoZ2jVkQj3klUKYiabHmFkT3iav7ZVPnTg/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.3.6  人工智能相关计算机视觉与模式识别(cs.CV)</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247660176&amp;idx=2&amp;sn=90c34b05554d18e7927e205e9f59a325&amp;chksm=ce7cad661c1441233557cbea89aacf83fce9fb61ec57899f129ea4cb093f190820e1db1bda58&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 08:25:18 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文一起读 | 二维扩散先验引导的视觉合理网格变形]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/G3miadARVe89PXabBCLQZCDlvkCuX5BBIKLWnYBATmT46RQ5icjyZhjxhWI1bJf31jGWoS8wicqI6MLdiaxo4YKUibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>‍导读本文是VCC王仕锦同学对论文 As-Plausible-As-Possible: Plausibility-Aware Mesh Deformation Using 2D Diffusion P</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247660176&amp;idx=3&amp;sn=847ce45cd1e8d61e5e428f56433c7ce2&amp;chksm=ce2643697744baad417794195860dbabdb0c7aa60593b7503442bc3286f821f76f865d63c728&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 08:25:18 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港中文&amp;中山大学联合提出NavigateDiff | 首创视觉预测+时空融合，零样本+未知环境无需建图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfXox4VibMYXlvdfAMcADVqcp9ztibtEoib647XVkcroHibh8BhyNicMibjb86evsrceftsuSsZzcvgl6Kew/300?wxtype=jpeg&amp;wxfrom=0"/><p>  导读在未知环境中导航对家用机器人来说是一项重大挑战，需要机器人具备识别和推理新装饰和布局的能力。现有的强化学习方法不能直接应用于新环境，因为它们通常依赖于广泛的地图构建和探索，导致耗时且效率低下。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247660176&amp;idx=4&amp;sn=0358ecf23f73b8004901512c525426fd&amp;chksm=ce55d8071403b307af7910c1740de9cded485baf440e31f80fa44a9805077aa0398864ff9151&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 08:25:18 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[为何说“在国内做科研最忌讳踏实？”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMecib9AjeJy0oGNUEX8hubvMIAEfTa8dpGjLOCFzMedkJ1V02DZtLG4BynibmAGrJC4evBY1wQmLxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>新手搞科研，最忌讳的就是自己埋头苦干。搞科研，只靠自己是不可能发出高区位论文的！一定要多学习那些顶会大牛“成熟的方法论”和“先进的科研思想”。站在别人的经验之上，才更容易挖掘出极具创新性的那种idea</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659770&amp;idx=1&amp;sn=e5da1bd5364e6df8f719d8bbe3e3e982&amp;chksm=cee5728d72708ae901b09fa037b39e90730c325e5e89c1ae9f274f0f6e7e7561287ceb87a864&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 04:38:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.5]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPmcAq5Q89yibj9iapTobphDDBPqcE8JZ29TNmnq1pcV4aL65ydVBE0OvoD6DT7Fj4fKp4MpQLxkfpw/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！ arXiv每日学术速递2025.3.5 人工智能相关计算机视觉与模式识别(cs.CV) |</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659770&amp;idx=2&amp;sn=e2a7b6e6f47768926497436d3ce3fab5&amp;chksm=ceefcc39d99bbffd75979e820d690bf113f10ac370c12e3df5ba8800823a51e13ca89dda71de&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 04:38:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[新SCMHSA架构缓解 Transformer 下一帧预测语义稀释，适配损失函数性能更优 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVWBzHX5icichNpYQvA588JjmaA5YCoAPnpF0Qicq0M8Y24LEueFSIhxicWtm8jBQG8e5KM6Qqtnwgbtiaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>视频中的下一帧预测对于自动驾驶、目标跟踪和运动预测等应用至关重要。下一帧预测的主要挑战在于有效地从先前的视频序列中捕获和处理空间和时间信息。以擅长处理序列数据著称的Transformer架构，在这一领</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659770&amp;idx=3&amp;sn=bd8793ded020a8b075e74161e55aa9b9&amp;chksm=ce9618034248de2bc5b5a668cca4ca2399cabbc5b99f156e62d00086724e6168aca1436a7797&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 04:38:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大/北大等联合提出MapNav | 革新VLN记忆，语义地图替代历史帧，存储开销锐减90%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfXox4VibMYXlvdfAMcADVqcp45Wt9TUzfW75aMzZvsPzj48VdlVicHJICqiaMibLUCzE9VwAich8ftCiaSQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读视觉与语言导航（VLN）是具身AI领域的关键任务，要求智能体在遵循自然语言指令的同时，在多样且未见过环境中进行导航。传统方法在决策过程中高度依赖历史观察作为时空上下文，导致显著的存储和计算开销。在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659770&amp;idx=4&amp;sn=b32952d4259fdb78b69b2a92cd93ce6b&amp;chksm=ce10cb48cd856c1a8ae86c0a999c940465f3d1529a4a500e250c8f83c81297bdb7052a895ab3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 04:38:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[即插即用，轻松涨点！把大牛的模块缝合到自己的paper里]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN2uyevaDrAVk5yicHOHFw60NgQ9vPT4Ft56eiaJ9ROUnvD3KDK0nZzRia0ibIUXVJkvefOw7LogvSxiaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>有创新点，就能顺利发paper吗？当然不是！有了创新点只是开始，模型的编码、调试才是重头戏。很多小伙伴都是改了大量的模型和代码，实验结果却没有多少提升，白白耽误投稿时间。今天就分享一些发paper必备</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659358&amp;idx=1&amp;sn=cc8a8668e09eb9ade50a1c0be047fc2f&amp;chksm=ce426c39869020267ae6bbdf687407ba46293339b815a19ce9903b114cea7f6469f6777697c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 07:10:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.4]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMecib9AjeJy0oGNUEX8hubve1gclmdBdIQtIhzIhgeamcETNudwnXFgW0bJgmcicVx2ZFytg95micibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.3.4  人工智能相关计算机视觉与模式识别(cs.CV)</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659358&amp;idx=2&amp;sn=668de847f8c53f2e992a02f4d38eb516&amp;chksm=ce95ae78c4c337305730e458dffc4746d1f02d59ddfb0ec61d12d4d83a55d01e1c3b6f2aef50&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 07:10:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[西湖/浙大/西交大联合提出VLAS | 端到端语音-动作对齐攻克声纹丢失难题，交互误差直降70%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfXox4VibMYXlvdfAMcADVqcp8ppmtBReBp6XfAb2XtP3EmoicW1uIkHOibWxHrksRd53UkJABb7cVOKg/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读视觉-语言-动作模型（VLAs）因其端到端设计和卓越的性能在机器人操作中越来越受欢迎。然而，现有的VLAs严重依赖仅支持基于文本指令的视觉-语言模型（VLMs），忽视了更自然的语音交互方式。传统的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659358&amp;idx=3&amp;sn=c4f37e260b2b7485e8e45a4cc8ddeacc&amp;chksm=ced6178d08f6ceb012c57eae9a511af5fa838f89059a5dd5e342004c1cea7dca4607fd7a17c5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 07:10:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[端到端SOTA！上交提出DriveTransformer：以Decoder为核心的大一统架构（ICLR'25）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28hEvdjyROpedzVDcV3ZI2dsib9xPCyKBp7MSmSSRSmfCGeD84Dt4GrIM1CuO6GJPvoIktNA1Ox66Gg/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面 &amp; 笔者的个人理解当前端到端自动驾驶架构的串行设计导致训练稳定性问题，而且高度依赖于BEV，严重限制了其Scale Up潜力。在我们ICLR2025工作DriveTransformer中，不</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659358&amp;idx=4&amp;sn=bb9230de12ba9a2a1ca2c3f446930183&amp;chksm=ce4e7ca59600cf55a46f600dada521dc35d3b07633a99931d2cb0d6027e2286b46471845e050&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 07:10:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR2025结果出炉！这些方向杀疯了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMsyb2JPrI7PKgXJtXibBaAibc3ttXYYLFuOwia1smicZMC86iaZMBNqNPC2wsyJb4vuIl79Ddv7ZHhStg/640?wxtype=jpeg&amp;wxfrom=0"/><p>根据2024年谷歌学术指标（Google Scholar Metrics）的最新数据，CVPR已成为全球第二大学术出版物，仅次于《Nature》，超越了《Science》，就拿投稿量来说：2019年有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658973&amp;idx=1&amp;sn=3ba16818c5f7ab75aac7833405d1089e&amp;chksm=ce8a9bd01bf6f811c0c2ca3853aa3ff3901e3b89f877d3985c1074b04e45e9b2c149b107cbe3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 04:51:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.3]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN2uyevaDrAVk5yicHOHFw60J4yGYh7IaRwMmKqDtMCyib51WhYm6SvSmcr2vsdOmr1ic60R28wp6ZpA/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！ arXiv每日学术速递2025.3.3 人工智能相关计算机视觉与模式识别(cs.CV) |</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658973&amp;idx=2&amp;sn=10085e8ceb88ecd7df32b6a6f6fb2a4e&amp;chksm=ce079080dded525d4daf8bad65cda1cbb5ced6624601757075910a9f1dae343adbafc9c4ea0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 04:51:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[不确定性驱动的 UD-Mamba 革新医学图像分割，三数据集验证超强分割性能 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVVZeYxic5l35aPBtr98oWI35CKzHmhYDVwag5VcNcCwtXGUFKQJXVCVW5bfp3hcxg5yDold5VJkBGw/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期的研究突出了Mamba框架，这是一种以线性计算复杂度高效捕捉长程依赖关系的状态空间模型。尽管Mamba在医学图像分割中表现出竞争性的性能，但由于传统基于位置的扫描方法的间歇性特性以及医学图像中常见</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658973&amp;idx=3&amp;sn=4444a0d1e3b82a92a0b55b5cb1ddf19c&amp;chksm=cee427ae09098074278a5c8eee13d1724c79549f12b3d94f38b78223cd546ddd4ae1732a6599&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 04:51:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[扩散模型动态约束新潮流！DDAT流形投影攻克机器人轨迹生成难题，单次规划精度实测飙升]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfXDNFKekaClY1qC6jibS7EyW5XDFpiaEfXIRibtG4YtQJOpmOnTAKl6icatQJ7benQLpMMSF7ktYmqTtw/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读扩散模型因其多模态生成能力在创建图像和视频方面表现出色。正是这些能力使得扩散模型在机器人研究领域越来越受欢迎，它们被广泛用于生成机器人运动。然而，扩散模型的随机性质与描述机器人可行运动的精确动力学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658973&amp;idx=4&amp;sn=089cf7e2986bbf69bf231d2b7c9caca9&amp;chksm=ce86809c814059102b227fb07f675ec00a0c8e5a03ebf90f590112698aca20c29062f22d5ef0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 04:51:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[真抽象了！把论文“摘要”写成 “Pumping elephant”，一中国论文被撤稿]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMsyb2JPrI7PKgXJtXibBaAibyuRO1gPuy75ibfoicyjujLIZ7FZ9nDsMrbeM2obeL6RlfWknnUicMonxw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文募格学术撰写。参考资料：iNature、留学考试、小红书等。请勿二次转载！这下是真的太抽象了....SCI里正确的英文用词有多重要？前段时间，哈尔滨医科大学Zhang Fan团队在Environm</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658573&amp;idx=1&amp;sn=5f476e0ee6850abded1ee39665227f28&amp;chksm=ceb5b2bc8f0e54630ef8707a6b8b59144d0c9d6c4ee764ffacdd7627f5c10491f023413e175e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 07:52:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[语义驱动革命！SIREN三阶注册+非刚性变换，多机器人GSplat地图精度暴增，性能横扫SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfU1lIA0Iicjf0RMsVoOzGqWpIcWbbBSTbjNMxGdnm6oOQ4f0gcfflCvaGibsJmicQF1Ynic6neJPJ1HOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读作者提出了一种名为SIREN的方法，用于注册多机器人高斯喷射（GSplat）地图，该方法在初始化或融合局部子图时无需访问相机姿态、图像和地图间变换。为了实现这些功能，SIREN以三种关键方式利用语</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658573&amp;idx=2&amp;sn=1b3f67ef8e219c12253e3c4adea5fd65&amp;chksm=ce38d1e73b1f5e416c9b5a4a9c3ac86fbc9c169c48f48ab7a58a4cd7e105824a2b85f699882a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 07:52:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[学术圈杀疯了 1个月搞定SCI 这些期刊真的零拒稿！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMYcMy29yUuSCmvJlibGsIEHFSd3g6bIppzbr2QO26RFntnBoO6Kdo2c9vGguCvgbW6KMBGBgRcBTA/640?wxtype=jpeg&amp;wxfrom=0"/><p>如果不是亲眼所见，我是真的不敢相信，从选刊动笔到录用只用了1个月，毕竟过去光等审核能等3个月的，好不容易等到回复了也是各种问题，修改完，每一次的期待又落空也太折磨人了。还不如直接拒稿了，这种修改了几次</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658562&amp;idx=1&amp;sn=d92940dd01f40b0e10ef51dd96f1eeea&amp;chksm=ce559d764682eef12f1a4b13e9b09c12aa48f8d0492746521f71f40c870507ad2780d8854558&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 05:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.2.28]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMYcMy29yUuSCmvJlibGsIEHr9fUBBQ4TxeaeT2aQdia0o0DXbjMSywhDrVjicuZYfqicml6Cr8PxkWIA/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！ arXiv每日学术速递2025.2.28 人工智能相关计算机视觉与模式识别(cs.CV) </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658562&amp;idx=2&amp;sn=cd4812590e62a5fbfc2aae4bf4e134e7&amp;chksm=cea6e1aa237fbede121161f578bfc4cae4d2b41f5e5fc87d08cc7fcff8fe606e2c483e6b9f60&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 05:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[手把手教你驯服DeepSeek-R1！部署+测试+性能优化万字全攻略]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp8n64epzESzPFtUmloC3pJzZsibUCISlbiaJgQ96Wzqgkrz5OViakrMq6gwo9jl3cuTNVAqAkDicDlLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨Mr.Felix编辑丨极市平台极市导读 本文详细介绍了如何部署和测试DeepSeek-R1模型，涵盖了从Ollama到vLLM的多种推理框架的安装与配置，并提供了性能测试结果和优化建议，帮助用户</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658562&amp;idx=3&amp;sn=98486a6ceef924ab9c847e5603d638ae&amp;chksm=ce4c43ebf968d6b7a35d938a29211ea5c8bfb05537db8f2e721d1836dfc13b89f3c1d2bcf084&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 05:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FE-UNet模型融合CNN与Transformer优势，在多生物分割任务中展现先进性能 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVWOMic6vuMQ8P1kskdfGxh71kg49JSdcRiagV7IpCqE47KZdNw8yAASyhTt3LpgTlJygPEx6pYZs7TQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>图像分割是视觉理解中的一个关键任务。卷积神经网络（CNNs）倾向于捕捉图像中的高频特征，而 Transformer （Transformers）则侧重于低频特征。在本文中，作者通过实验量化了CNNs的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658562&amp;idx=4&amp;sn=7366e9a83fe4eb3062d3073e6bdcdb95&amp;chksm=ceef6afdbd9651c9d59b7c9fcd275813eece57e55e4fcf6ff58f45e0b03b562f0e638d69090e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 05:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>