<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[arXiv每日学术速递]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[arXiv每日学术速递公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_b10aac61d168.jpg</url>
      <title>gh_b10aac61d168</title>
    </image>
    <item>
      <title><![CDATA[视觉SSL终于追上了CLIP！Yann LeCun、谢赛宁等新作，逆转VQA任务固有认知]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbOpWDODtvqqTCTVMT3mhQ8813CKT5ATzPAy07WwgRd59aicO7l0P8GXOQTPNH2Q2NyUcS7Ou2T7k6A/640?wxtype=jpeg&amp;wxfrom=0"/><p>转载：机器之心 编辑：蛋酱、杜伟扩展无语言的视觉表征学习。在视觉问题解答（VQA）等多模态环境中，当前视觉自监督学习（SSL）的表现还比不上语言图像预训练（CLIP）。这种差距通常归因于语言监督引入的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247668288&amp;idx=1&amp;sn=48e4df736d0055e65e6c54f50a9009e3&amp;chksm=ce049a1237676a50b3dab788f16a9b6eb71799f24e41d43fc4229657d4d954afc7b7718302be&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 05:16:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.4.3]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbOpWDODtvqqTCTVMT3mhQ88vm4ITFzmicdEkdE7d733Cu33RtvZZR0NSm0W50X8r1ckFqLmq8I5kmw/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.4.3  人工智能相关计算机视觉与模式识别(cs.CV)</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247668288&amp;idx=2&amp;sn=008877ac6db7810f07d141495aa400cb&amp;chksm=ceece29e52c453fd00520bc6a9712ec7c791546967d4e1430e1dcb27679cef2a4f6dd0b1b8a8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 05:16:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文一起读 | MeshPad: 基于草图约束的三维网格生成与编辑]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/G3miadARVe88gb2QST1kxGwtdylOgs4I3AQ8gSlahJvOBnHrdWxRUIKmPia7yxd5icvBeLwB33NQM1b6LXHV2ibpsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>‍ 导读本文是VCC马雪奇同学对近期发布在 Arxiv上的论文 MeshPad: Interactive Sketch-Conditioned Artist-Designed Mesh Generat</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247668288&amp;idx=3&amp;sn=708c6cc369af645d28dca53ea6a5ce97&amp;chksm=cef3a52ec983e48d5f5a2f8ec4819e4a5014b35897036f760a960a9aa03577ca45c2b9eb5646&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 05:16:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[暴拉MagicDrive 20%！西交DualDiff：自动驾驶首个MPI引导的环视视频生成奖励模型~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28jNdKDiakvoTUKvfx720gB1OG5gibcck90NrVxq931B7rvzzM0OybGQhzwfzt1NBIvzcGOeX8UlQvpg/300?wxtype=jpeg&amp;wxfrom=0"/><p>题目：DualDiff+: Dual-Branch Diffusion for High-Fidelity Video Generation with Reward Guidancepaper：htt</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247668288&amp;idx=4&amp;sn=180ff35eb6b21bfc4582597f5bf47437&amp;chksm=ced811c1f1c42a9857a4c000e6b4f69c525e0525be0763235c39641b853d64f31dd40790070e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Apr 2025 05:16:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[贝叶斯+PINN！双重热点buff叠加，轻松斩获Nature子刊！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN1cLp2S2ZF0gicRBFKeq9fxwL9S5OuRdWEs5t93uGb3Tc8zvJwpAlkYuwicZ8GYmjriaAjuYyOdSpgQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>PINN一直以来都是顶会顶刊上的大热方向，相关研究量多且质量高。最近，有关“贝叶斯+PINN”的研究取得了不少突破，多项成果被Neurips、Nature子刊等录用。事实上，这个结合方向的研究热度正逐</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667881&amp;idx=1&amp;sn=09629dfadfe0cbf70852f47d9d3b4013&amp;chksm=ce620d09561f08bb09f142248f915d14bae0e2688a2ca4b834e16a4dcb4600fd6dce4cd88d3f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Apr 2025 03:40:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.4.2]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbOlIYiaIMPcTtCZ16zYkDDBbHFF8Hu07rwSedPEwKQtcjnVfZzGd7ReXdS7raEPIDhoDqib6yvLfpKg/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.4.2  人工智能相关计算机视觉与模式识别(cs.CV)</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667881&amp;idx=2&amp;sn=ae99623188751a8341bb2c7db904b4b2&amp;chksm=cef7099919b70de44c1e2d2e9298e8cfa5444442ba407fcdc04fe30d83cd92fed20ec4d6b2bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Apr 2025 03:40:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[慕尼黑工大最新！OpenDriveVLA：基于大型VLA模型的端到端自动驾驶~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28iagVhxdlEw3HFWEwS80baJFssLxSWjiaKdy6xKzehYsnoGpgltU63pXEsHBBd3KrtYTRGVDqDuE3Vg/300?wxtype=jpeg&amp;wxfrom=0"/><p>专为端到端自动驾驶设计的VLA模型OpenDriveVLA是一种专为端到端自动驾驶设计的视觉语言动作（VLA）模型。OpenDriveVLA基于开源预训练的大型视觉语言模型（VLMs），以3D环境感知</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667881&amp;idx=3&amp;sn=897991a56d782412d5dd6dd26181718b&amp;chksm=ce5e730d143099e712334beb635d9ae60b284c9e22b1f9271778682a3a3d31fe0eb8d07aaac6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Apr 2025 03:40:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[模拟医生会诊，四川大学华西医院团队开发多智能体对话框架助力疾病诊断]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/QkCvnz083AjjgcGzCV5wNnicnF7fd8mgTCzia7QqhSTU5wD7lHNAgySX9Um4BibcBwwdFORel7gOly7ib3bMz5uOmw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：陈曦、游茗柯编辑：李宝珠转载请联系本公众号获得授权，并标明来源近日，四川大学华西医院、华西生物医学大数据中心、浙江大学医学院、北京邮电大学等团队分别基于 GPT-3.5 和 GPT-4，开发了多</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667881&amp;idx=4&amp;sn=74246d4ece9ec23c42307990b6fe4fe0&amp;chksm=ce8358dd403f30cc74387bc6713ef5a5b510901efb3baee3ef41c2b51647cb94ff697aa06391&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Apr 2025 03:40:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[导师放养真的会毁掉一个人]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPzXJlYcZ0Zboaicicx1lMM9BB20VUmVAogfTyMiaibomy9fickaHkFGuM8icclFIA7bCCVajibWlPNj45HA/640?wxtype=jpeg&amp;wxfrom=0"/><p>导师放养的科研人，很容易在科研进度上像只无头苍蝇： 下了一堆论文，打开就犯困，看完全忘光做了三个月实验，数据像乱码，找不到规律发消息石沉大海，组会发言被怼'没深度'看着同门发论文，自己天天怀疑'不是搞</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667474&amp;idx=1&amp;sn=0a9d15dc571679d12a7be46c0dcb988a&amp;chksm=cee2527e27ce906e30bcab92ba57a9c2eee8dd31f241c010eac953f4ae5ccc7a6f5dd48e5364&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Apr 2025 04:56:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.4.1]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN1cLp2S2ZF0gicRBFKeq9fxWWmSbkrW0ogSc0ptveqIlqmvIjLX7oVtHIVSaI8hUyDSn97UrQnjVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.4.1  人工智能相关计算机视觉与模式识别(cs.CV)</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667474&amp;idx=2&amp;sn=f4a6e8548a8502c37b12f5f1e513987c&amp;chksm=cea7dec29a17ff780a6a6f3ff1e6288efa6b503a4bba2e5885f2cd92f0e497ee5b92255ae7eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Apr 2025 04:56:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[在线教程丨YOLO系列重要创新！清华团队发布YOLOE，直击开放场景物体实时检测与分割]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/QkCvnz083Aiat8X69zWgBaeXNqR6SW88Ue6ibpyXGAgicbHMLbVQPztg5h47AGATSjlQGoppZDoGFAATgJWybDsFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：李宝珠转载请联系本公众号获得授权，并标明来源清华大学团队在 YOLO 的基础上，提出了开放物体探测与分割模型 YOLOE，既能听懂语言指令，又能看懂图像，甚至还能自主发现新事物，实现了真正的「实</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667474&amp;idx=3&amp;sn=75bb4fba3d9285b15d34168bb1546025&amp;chksm=ce78df39f004c708172caf4400f67119f634dc8d18bafe37c9b836183a486a188c70b72f9399&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Apr 2025 04:56:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文了解Text Embedding模型：从text2vec、openai-text embedding到m3e、bge]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/WC0sXokAH7BJs2pjcoGdHac3DVuK19AVh1WAFRZHna3BrkFL9xkPGQ0bqcIiaGPMVibibEbylP4vDrzfzC1WLf4QA/300?wxtype=jpeg&amp;wxfrom=0"/><p>01第一部分 衡量文本向量表示效果的榜单：MTEB、C-MTEB1.1 《MTEB: Massive Text Embedding Benchmark(海量文本嵌入基准)》判断哪些文本嵌入模型效果较好</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667474&amp;idx=4&amp;sn=2f6a48554d55f9f3bf816385f4df9b7f&amp;chksm=ce5159195c345a3303d1d194d5ecb3e86b24692576f078d4c8cfd2089631c10749a7f0076923&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Apr 2025 04:56:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[【EI/Scoups/CPCI检索】2025年第三届亚洲计算机视觉、图像处理和模式识别国际会议(CVIPPR 2025)]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPzXJlYcZ0Zboaicicx1lMM9BaAcaftmfJYaqHtQm6j6Cac93SG4OJnDyN0RXsDsIv8EQhkhPtch3vA/640?wxtype=jpeg&amp;wxfrom=0"/><p>1会议简介2025年第三届亚洲计算机视觉、图像处理和模式识别国际会议(CVIPPR 2025)将于2025年5月23-25日在中国厦门举行。该会议由华侨大学主办，华侨大学计算机科学与技术学院承办；厦门</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667074&amp;idx=1&amp;sn=a7d1b16588f1310f0df05cdd5f67cd0c&amp;chksm=ce7f25247240a30498e7645cd8f4d1aa4dd39b7e634a15fdfb20814d6cdb73c1d2a8796244c8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 31 Mar 2025 03:33:43 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.31]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPzXJlYcZ0Zboaicicx1lMM9BVkgkKibrgrK5yINibibNC4bUEZgXz59ibgh6KRXNaWQLGyNw1l8AVwkF2g/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.3.31  人工智能相关计算机视觉与模式识别(cs.CV</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667074&amp;idx=2&amp;sn=9a476038bc0934d29ef67052d42be357&amp;chksm=ce53f4f5c971fe8b356eaa89abaf168b6355cdf145b9c2240fa6a92bf96347dc7d8529dbd8d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 31 Mar 2025 03:33:43 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[上交最新ChatBEV！VLM从BEV问答到场景生成，重新理解自动驾驶上帝视角~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28jg3yeMEotibYu6p4WS6Ennd8uJ6UYAEMVXRl9t5GD3m9iaCib7KIU8zW4hrm9kdDtnhonEx0EW85LZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面&amp;笔者的个人理解交通场景理解是一项基本任务，旨在感知和解释交通场景中的周围环境。它在智能交通系统和自动驾驶任务中起着至关重要的作用，通过实现智能的决策并确保车辆在现实条件下安全高效地运行，为下</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247667074&amp;idx=3&amp;sn=59f23b5f2e2985d21cfa910e7d66150b&amp;chksm=ce70b2e5233af1e0d16566a8cda84bc0104089081fab49e90d2bd641f64e35999a48a7e1ad8e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 31 Mar 2025 03:33:43 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[网上晒图要当心！AI六成可能知道你在哪儿]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPs0dNF66gnMiamDeaib9MSSo1A75doGAib5katqtatYEr1u19V87iaH4dsWyyxAoYPUaxjGCicfI1UJwA/640?wxtype=jpeg&amp;wxfrom=0"/><p>编辑：KingHZ【新智元导读】给AI一张全新的照片，它能以相当高的准确率还猜出照片在哪个城市拍摄的。在新研究中，表现最好的AI模型，猜出图片所在城市的正确率比人类高62.6%！以后网上晒图可要当心了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247666669&amp;idx=1&amp;sn=0c76dd6b067fbef163a246e526056cad&amp;chksm=cec58f9d0be381f56276d5b14776e2a70df5700711a9d843ba36a19d5bb4230042ffbe4b289a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 30 Mar 2025 06:10:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[不用向量量化也能高质量生成？NOVA：重新定义自回归视觉建模]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrdOs0l5fcViclREISniaVwlBMBZTmVYgibj42LI6mK5zuD8SJltDFTKUPLyBFNxCq5o72pRmLyR8zyw/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读一种高效的自回归视频生成方法，通过非量化建模和双向注意力机制，显著降低了训练成本并提升了生成质量，同时在文本到图像和视频任务中展现了强大的zero-shot泛化能力。本文目录1 NOVA：无需矢量</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247666669&amp;idx=2&amp;sn=09889765edd4d1ebabff29c5fd804ff4&amp;chksm=ceac03145ad413b994ceeac0427c0ab36691d04cd0729a125df89f87c6f8a1a993ef005bc3f7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 30 Mar 2025 06:10:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[最全总结！1000篇最新顶会论文！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNkF2u2sPzhnbY5w0AWZ5iahNl9jNHQeYOJib9RUJ9IR2vIj4fAvfDAJ7YhibCNcErtiaRdk8x4EQfjeQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025各大顶会陆续出了DDL，有小伙伴压点提交ACL2025的时候已经将近8500号了，照这个趋势下去加上12月的，应该能冲击12000。肝论文的各位同学们还好嘛？发过顶会的同学都知道，做科研最主要</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247666663&amp;idx=1&amp;sn=e5830e3445b9e8c587f54b546d6de8b9&amp;chksm=ceb5f6bace328c19b1b54d00d9a50f05757fb93bb764720cc0bf50fb16826263a31958d31c9c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Mar 2025 04:39:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.28]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMN0HG24JUrNhW9ibs6cMQUZ4VYMXibVsXmVOOTKTDwa3qgS4UVWyvFlNDjLHSkCvm02nNmNtiafUt9Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.3.28  人工智能相关计算机视觉与模式识别(cs.CV</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247666663&amp;idx=2&amp;sn=0e9b74918c4bf663f08e4fe67bd14985&amp;chksm=cea569adfdc8bf0bcfd909ae255a6a161eeecac31e3ef1dd8cc1b76cb8ef2457092739d8e1d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Mar 2025 04:39:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[澳门大学最新！CoT-Drive：开启自动驾驶思维链时代，突破复杂场景理解瓶颈~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28gVP3BYBFM8j7J5icN9bUKS6s8Uc5vCoQ21BUYSn2yb5BGahLXl9RibdhpDia7qXWTdsR8ATU6icRfw6A/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面 &amp;&amp; 笔者理解感知、预测、规划三位一体的自动驾驶架构虽然在端到端的趋势下，逐渐退出历史舞台，但是对于每个环节的理解和提升，也可以推动更好的模型设计和发展。今天要介绍的这篇工作，就是要用新技术</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247666663&amp;idx=3&amp;sn=2a5e6031c26ce35b5650734a05ef6800&amp;chksm=ce8544ffae05959af367f844665abfae0edb085168cd7f75153421d7c6bc2311417a06f5c702&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Mar 2025 04:39:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文一起读 | 通过模仿GIF中的角色使文本动画化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/G3miadARVe8ibcRmjJd3DBj41jcPJxEayoFoYj5oSHMr82mYp5MxvdS75NlPadia8Vo5oZv4GN6oO9KOKyk44xAkw/300?wxtype=jpeg&amp;wxfrom=0"/><p>‍ 导读本文是VCC方宣彬同学对论文 Wakey-Wakey: Animate Text by Mimicking Characters in a GIF 的解读，该工作来自香港科技大学、复旦大学和微</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247666663&amp;idx=4&amp;sn=b1fb608b05788ab055dc52823b63945a&amp;chksm=ceae831daa3e12d255f4235245d821f1ce1c9a64135edd831ca5fb48d061c7f3c0e9290fa065&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Mar 2025 04:39:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[蚂蚁国产GPU训练大模型细节曝光！Ling模型研发负责人回应：关于我们抠FLOPS的一些点滴]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNkF2u2sPzhnbY5w0AWZ5iah48iammnEPejKmUmxa73nSyd9wWic8arQQyWHtpTOq855fL1X0s9L1y0A/640?wxtype=jpeg&amp;wxfrom=0"/><p>转自 知乎作者 张志强 蚂蚁Ling模型研发负责人蚂蚁开源大模型的低成本训练细节，疑似曝光！这段时间，蚂蚁一篇技术论文引发关注。论文中显示，他们推出的两款MoE大模型，能够在国产GPU上完成与英伟达同</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247666255&amp;idx=1&amp;sn=006c67678463afb63aa436e51ebf872f&amp;chksm=cee7d54b92259368ccda6e055d3d03f0a7ac1997a4670025a327bd1ed4fd3b75e351f1aa1d14&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 05:26:26 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.27]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNkF2u2sPzhnbY5w0AWZ5iahbF6A1pOrPwFQEAtIowWeNnicWlQ5wEqEEzWYicfq7ucQBBPewZqAKgibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.3.27  人工智能相关计算机视觉与模式识别(cs.CV</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247666255&amp;idx=2&amp;sn=f0e40a989d585a3acf7d53e14099fdfc&amp;chksm=ce36aa1ec8f26104275ada2a820214461b548be736b3909e4527d258c6003d913939cb100a71&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 05:26:26 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[世界模型再进化！MiLA：突破智驾视频生成壁垒（南大&amp;小米）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28iacMgrq9HBf5LPZEh5Q7ibkvdx12zqWAfv0wesEWQe9viaR8KhN9ibYVZXJZSbcAckqyzQV00JHbA6eA/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面 &amp; 笔者的个人理解近年来，数据驱动技术显著推动了自动驾驶系统的发展，但对稀有且多样化训练数据的需求仍是一大挑战，需要大量设备和人力投入。世界模型（World Models）通过预测并生成未来</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247666255&amp;idx=3&amp;sn=c004fde98943bcde4ff675e4a093f34d&amp;chksm=ce24b6a57e617ae13b3a8b4ba515b2e68d222bcf11b96570bd4626d927ff528172d60e5035e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 05:26:26 +0000</pubDate>
    </item>
  </channel>
</rss>