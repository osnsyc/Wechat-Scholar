<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[arXiv每日学术速递]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[arXiv每日学术速递公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_b10aac61d168.jpg</url>
      <title>gh_b10aac61d168</title>
    </image>
    <item>
      <title><![CDATA[2025年，大模型LLM还有哪些可研究的方向？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbP3kv1urugZMgwmTDKfVCOIY3J2clDFpCVKHKdiaUrzyfib7ib2ViatbhfkSYcFtldiasU26q56ckbJHFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>近两年LLM在学术界与工业界的发展大家都有目共睹。到了今年，以预训练LLM为代表的大模型PK上半场已然结束，接下来就要进入下半场大模型2.0时代了。那么在这新赛道，关于大模型我们还有什么可做的创新？要</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247680101&amp;idx=1&amp;sn=ee7ec69baec7f0f457b46e7576eb5a01&amp;chksm=cefd30d58bc61bb138fcec13e93c2db7763a318fd9c8a5dbc64d7b8e11d5c4c2afa8c882256d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 May 2025 03:36:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.5.14]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbP3kv1urugZMgwmTDKfVCOIeJUsxU1cAJb7GPLyKkudUlNEftawTluXwrt9pA0JSNxib3rucceBDYA/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.5.14人工智能相关计算机视觉与模式识别(cs.CV) | </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247680101&amp;idx=2&amp;sn=8babf233dc483a95e43490907e33b395&amp;chksm=cef1c9fba8f6b78e94dd0a0dd5b20fe7fb5c2e8adc37d15b34f7fa18dbd37a644a5e59330223&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 May 2025 03:36:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[迈向以人为中心的自动驾驶：LLM与RL结合的快慢架构（同济大学）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28iauCqZNy20c9Or0VKMKleOGgnnLzUicrLwXpI0pCiaXfCCxQ1BhIOQvg9iaaM39JzJrfaysicOasn5a1Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面 &amp; 笔者的个人理解自动驾驶通过数据驱动技术取得了显著进展，在标准化任务中实现了稳健的性能。然而，现有方法经常忽视用户特定的偏好，与用户互动和适应的空间有限。为解决这些挑战，我们提出了一种“快</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247680101&amp;idx=3&amp;sn=cd93f2e117a4de1a3e6aa8a05577beea&amp;chksm=cec29e9b18e96f4d2597a4b4cba4363c99834f9c099c936604cbbd1050c04fa6c9d9e9601ed1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 May 2025 03:36:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[HGO-YOLO 突破硬件限制 | 仅 4.6MB 参数实现 87.4% 精度+56 FPS 实时检测]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/5ooHoYt0tgmyjKibsOhDPmb2AjnmtSLib5buo7YwQFjMZK93BaQ2NwLdpVahXcqqWK5P7caibmf0bfb4dcE6cHSGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读准确且实时的目标检测对于异常行为检测至关重要，尤其是在硬件受限的场景中，平衡准确性和速度对于提升检测性能至关重要。本研究提出了一种名为HGO-YOLO的模型，该模型将HGNetv2架构集成到YOL</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247680101&amp;idx=4&amp;sn=4beab87e0f931120ff78d1c7f25a52b0&amp;chksm=cee3b9bfcaa145f1e37bfea9d5f099734b83ac3860b2078223e881028d76af063b5e9805e6c6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 May 2025 03:36:16 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[全球闲置算力训个模型，性能媲美R1，老黄天塌了！Karpathy曾投资它]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNm65xtibK11IYoMticZyoynEAMyo6qCEEibcAGPRCEWpP37ic6rL1V5NpBLkDclpKyheO4ykN6VP5vrw/640?wxtype=jpeg&amp;wxfrom=0"/><p>白交 克雷西 发自 凹非寺转载 | 量子位 | 公众号 QbitAI一夜之间，老黄天塌了（doge）。全球首个分布式RL训练模型INTELLECT-2发布，它仅通过整合全球闲置或分散的计算资源，就完成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247679698&amp;idx=1&amp;sn=7e0bd32329de411f6e4ce7bcbbbdebea&amp;chksm=ce42ffb21cfc3b61580aaae71d9530841eaceed132d7cf1c91f0ce714384a18023d9ddb9c4e6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 05:14:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.5.13]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNm65xtibK11IYoMticZyoynE8Llmt943iagXH7mw9ntDU3yiadAFbibQucE9j6aPcPAtL1LM02M6yXk4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.5.13人工智能相关计算机视觉与模式识别(cs.CV) | </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247679698&amp;idx=2&amp;sn=9beea450b35129659ff06526376a3d0d&amp;chksm=ce15c360c52d38d1bbb174c3ea7401711e219575777de91b19f46ed2490b9eea80b83071f4cc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 05:14:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SARLANG-1M：突破VLMs应用局限的大规模基准数据集，助力多模态SAR图像理解达人类专家水平 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVXsiaFfyliaUdWwt4HAjXglX2YWlpzA0egUT18w1icPDa3JpSjBOdQiaNtuKCGOibDc5B0VI9hdOHSGwGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>视觉问答（VQA）合成孔径雷达（SAR）是一种关键的遥感技术，能够实现全天候、昼夜不间断的观测，具有强大的地表穿透能力，适用于精确和连续的环境监测与分析。然而，由于SAR成像的复杂物理机制以及其视觉效</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247679698&amp;idx=3&amp;sn=34644e24d3c20b3db14e170ea1a5d412&amp;chksm=ce0e241465df6316e615e345d376095ffa919c3240bf5e28abcb835ca991b7664fbf1fb61dd4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 05:14:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[好崩溃！导师不回消息，论文进度1%该怎么办？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPFibM9H9dqQlSEEj7cC5RS8t34U9v65QAV2lAuib3amCbIWdyQTffychtu11KqIEVdaVyxFtJhicRUg/640?wxtype=jpeg&amp;wxfrom=0"/><p>不得不在一个月时间内写完一篇论文，你是否也体验过这种痛苦？每次看到自己的论文被拒都心如刀割，面对审稿人的意见也无从下手...写作时，总担心自己会犯那些低级错误，让辛苦的研究成果付诸东流...如果你也有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247679299&amp;idx=1&amp;sn=97e070b194539bc1537aba209416c006&amp;chksm=ce9095d05846d7683fd0b129f165950eaaecac846daa89e901bd34d7c5a7828af13b69fb6941&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 03:23:56 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.5.12]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPFibM9H9dqQlSEEj7cC5RS8iadibQhnTpBNkvwdH0FDt3QX10ibz820vyCQyEzWxCnSbHPO5chLib6D8w/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.5.12人工智能相关计算机视觉与模式识别(cs.CV) | </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247679299&amp;idx=2&amp;sn=03f2fa35af6293adf89cce31aa9ccf47&amp;chksm=ce72b8d30a53e6b1645762a728ad3de63d8ff69176457963aeb1fdb00cede1fed2f87acaf0c4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 03:23:56 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[在多模态的浪潮之巅，如何“精雕细琢”图文对齐？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ0KQ4kkGPfHyhHPKPqpz3lj3abiaRVgdvNq6iaqwkBGUzu72iaFPpQiaHicylS5jiaGgQ2xHFpITgggTCicA/300?wxtype=jpeg&amp;wxfrom=0"/><p> 导读近年来，多模态预训练模型如雨后春笋般涌现，其中 OpenAI 的 CLIP 凭借其简洁的对比学习框架和强大的零样本迁移能力，无疑是里程碑式的存在。它成功地将图像和文本映射到共享的语义空间，为诸多</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247679299&amp;idx=3&amp;sn=17443a159b9425f825f7794aba780ec8&amp;chksm=ce4787cc695634e50327bb441aa5660678b4c0bb95813fe4caa92d3320e5509425649aec800b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 03:23:56 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MSA-UNet3+：结合MSD-Bottleneck与CAFM用于DSA图像分割，辅以SPCL克服挑战实现精准诊断 !]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVXFVNo7H1rU7fkdcUS0HCibUYI0QXltdLniaTXJAuiaSylIOSAVickDacgxstPN2THpiaBRXf60iaNqY9iaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>对比学习冠状动脉数字减影血管造影（DSA）图像的精确分割对于诊断和治疗冠状动脉疾病至关重要。尽管基于深度学习的分割技术取得了进展，但低对比度、噪声、重叠结构、类内方差高和类别不平衡等挑战限制了精确的血</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247679299&amp;idx=4&amp;sn=9801bded2ef554a77bd0162189bcc1d4&amp;chksm=cedbd5af6abfcea479638fb78a86035f91ddd3ee186779b3b370170dfe1d273c48c84270b702&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 03:23:56 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[机器人开始抢“主持人”饭碗！上海张江，傅利叶宣布下个十年规划，要做“以人为本的具身智能”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbOfx9Jj4zqtsHW7qbPQQNsl9D4OXtVRfHpCaQEUaB5yfYKX91dmx5svgSZKiaY5YmRUOWaqN4ItknQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>西风 发自 凹非寺量子位 | 公众号 QbitAI打工人打工魂，这年头机器人都开始当主持“人”了。扭头一看，台下还有个小的机器人在举气球：坐标上海张江，人形机器人玩家傅利叶迎来十周年，在十周年庆典暨首</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678893&amp;idx=1&amp;sn=bc62960a45621c12eeefe9851165d480&amp;chksm=ce96a4867e6ace8c150101f19c2c05e57a3bf08515808d2666a3eb40b3378aa4a47a2e9d9353&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 04:51:42 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[如何让 SAM 看懂 “看不见” 的区域，SAMEO 给出了答案。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ0nKnlR1tQ3IQSibb6zDduLibia9oL5tu4m8YDIQIfCyzibj6JfxX8KIEWjLU8dWlwaeduggsARIiabyGw/300?wxtype=jpeg&amp;wxfrom=0"/><p> 导读近年来，Meta 推出的 Segment Anything Model（SAM）凭借“分割一切”的强大能力，在 CV 领域引起巨大关注。它能通过简单提示，快速完成图像中的物体分割任务，已然成为现</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678893&amp;idx=2&amp;sn=918c4edb685f04cecf39667e3d9c5de4&amp;chksm=ce836d2019d450f6213a0a21589c190f0ec012902931f7596b7a051292004f5072640659901e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 04:51:42 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[生成理解统一模型解读：JanusFlow：使用 Rectified Flow 做生成的 Janus]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfqI7KAB8vVZlByI7dFKicN9ZElSicCjibkGQWUKoBE0pfNuDzyOWJL8SoGIvZUgeBariawENooInT9hgA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨科技猛兽编辑丨极市平台导读 DeepSeek 团队生成理解统一架构 Janus 的后续版本，借助 Rectified Flow 做生成。 太长不看版本文介绍 DeepSeek 团队的 Janus</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678893&amp;idx=3&amp;sn=82a4a07b070d7ff97989d13471533751&amp;chksm=ce26d5d05b92254975377dca345e1d720cd5b56ca36d97faf713b9c6ddf289968a929c943b5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 04:51:42 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[世界首个AI多人游戏全面开源！1500刀实时生成，一台PC跑出平行宇宙]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN5wgSGfianp6YQfzk5PYKGAGKsDQD5DiamAVfOZ392LwcuN503iauaGh2wyWELWg1Clrd8S6gfYPEAQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>编辑：定慧 好困【导读】刚刚，全球首个AI多人世界模型开源了！只需一台PC外加1500美元，就能让两个AI智能体在同一个世界中感知、互动、协作。这不仅是AI造梦的一小步，更是AGI创造世界模型的一大步</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678887&amp;idx=1&amp;sn=11ef166172d47999a7c8a32adff44f86&amp;chksm=ce0e1d76e65c7937f01b97138db95291415259ca2c43b0ec4c04071e3353fccc8017556c730c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 10:09:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.5.9]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN5wgSGfianp6YQfzk5PYKGALSFicWc1CQPzJ69xG5DarLGR1aib7iap7VBIndVSVA9HOmFjb7azn76Rw/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.5.9人工智能相关计算机视觉与模式识别(cs.CV) | 自</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678887&amp;idx=2&amp;sn=82befefd91ec4ce857957d8f02566cd1&amp;chksm=ceed19b2b7287f177e3b45650c1297f7e03b6efda34fed8cbf3102713298546203d16cdd7526&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 10:09:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文一起读 | PGC: 单姿态生成物理逼真的高斯衣物]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/G3miadARVe88M3Rj3vuK5BC3j44yqfCxZRoRe2HXicXmLcx4OUWmx48HS9R1XO5giafLib96Nic8VbunW8dINQJerQw/300?wxtype=jpeg&amp;wxfrom=0"/><p>‍ 导读本文是VCC龚云飞同学对论文 PGC: Physics-Based Gaussian Cloth from a Single Pose 的解读，该工作来自斯坦福大学和Meta现实实验室，并已被</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678887&amp;idx=3&amp;sn=af248395426840806efbffdc06927814&amp;chksm=ce406c98b12aa091dcba17e07b4f92d6c72ccf1734f5fca568f7d0640791d46f2b06f2509862&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 10:09:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[机器人界「Sora」来了！清华、星动纪元开源首个AIGC机器人大模型，入选ICML2025 Spotlight]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPAmfeGicQZNdH3Ub07bIkrfQpyMNiauWZlrzfTq8UP0F7ToJGiaRfFrialuJk1aVIWPwTgZ2IibHHicDgg/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器之心发布机器之心编辑部从 2023 年的 Sora 到如今的可灵、Vidu、通义万相，AIGC 生成式技术的魔法席卷全球，打开了 AI 应用落地的大门。无独有偶，AIGC 生成式技术同样在具身智能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678482&amp;idx=1&amp;sn=e08a0e2459b614171810b2c98e8c6369&amp;chksm=ce2e2f4e30e011036646941697baf542a865b347d4a0afac9c0f0311fb9c40078c836779e0cb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 03:54:30 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.5.8]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPAmfeGicQZNdH3Ub07bIkrf0zc2WlF0pj2VK9yN3AvZMvODVoXKtQYK3O6Y2xVRv8uicqsDEK2rZcw/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.5.8人工智能相关计算机视觉与模式识别(cs.CV) | 自</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678482&amp;idx=2&amp;sn=8dc1c056cc6337ede4c7975f08b8e24d&amp;chksm=ce83e4e86245365db657626e26199395db7bc9da2129b537ebd519c489b3ede836b286f55ce3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 03:54:30 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DefMamba：新型视觉基础模型，借多尺度Backbone与可变形Mamba模块及DS策略革新视觉任务表现 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVVh6LnCCGzHglOQrWwS4vQxPrYw9yVs2Kmf5wC95DbYVAvTeVOiaW1CwibrJRQpO9D8vN6bKrYHBOkw/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期，状态空间模型（SsM），特别是Mamba，因其能有效平衡计算效率和性能，吸引了学者的广泛关注。然而，大多数现有的视觉Mamba方法使用预定义的扫描顺序将图像展平为1D序列，导致模型在特征提取过程</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678482&amp;idx=3&amp;sn=25b28d7c071566ef0820c7a4dabb3890&amp;chksm=ce824c17f3b2f5ad210847be0c486b38ce0991006f2b3d7273ecf8783a1cbd16bee9cec61243&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 03:54:30 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SYNTHLLM框架：突破人工智能“数据墙”瓶颈，为AI训练注入新动力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/HkPvwCuFwNN0b75D0SBd74Bhq3ZZFO0CsSlibd5AyPHrsHibyTZD6qQrMPTLFJbe7gdzibL82eb4HicUkIiceC0gN9w/300?wxtype=jpeg&amp;wxfrom=0"/><p>（本文阅读时间：7分钟）编者按：数据是人工智能发展的“动力燃油”，但如今其正面临“枯竭”的风险，这道“数据墙”成为制约大模型性能突破的关键瓶颈。在此背景下，合成数据技术应运而生。近期，微软亚洲研究院推</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678482&amp;idx=4&amp;sn=60fdf064db2e0039b6a71a9302a23928&amp;chksm=cedf4a0cce99df49a37b03e2e3c9665ce9a99ec339e678d91454088008859e933aeb8fbbcbf8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 03:54:30 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超全！2025NLP顶会收录偏好汇总]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNqib5851RViavR602KI8mEfDc8xPmJhxVoDDytD5xVJlRNUTOJSSIwsevZSImN6ROsZYDKOkVL3OZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着计算机学科的不断发展，顶级会议在学术界中的地位越来越重要。2025已经过去了半年，下半年的顶会还有EMNLP/AAAl/WWW/NAACL会议的投稿截稿时间、审稿周期以及近年来的趋势变化。为了帮助</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678077&amp;idx=1&amp;sn=7e592d2d860d35e39929811755a8b07a&amp;chksm=ce834c8996e529666799e13a826d6bdc63f085d3e0fc3b07d0a775dd70552cde6fb4cf997cc6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 03:55:21 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.5.7]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNqib5851RViavR602KI8mEfDjedJ8WkZ2UyMic0Sv93S4KD46G6yH1ejoichiba08JXGLdygF25xyC2tA/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！arXiv每日学术速递2025.5.7人工智能相关计算机视觉与模式识别(cs.CV) | 自</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678077&amp;idx=2&amp;sn=1bd4a4fbb7ab176a727dbed264603fe7&amp;chksm=cebd0f9f2c2e69cccb89a2c354508949d04177d840c7d1996c160d8e2b564b9970dc07f87537&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 03:55:21 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LightEMMA：自动驾驶真的准备好迎接VLM时刻了吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28hbqYqfekY7IRwU7FCez544ic8zQ6aZ1Psc5EAhk7r1JB11mKUaZ4CcL61uDiatHFXJKpYuML8HZzFQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面 &amp; 笔者的个人理解视觉-语言模型（Vision-Language Models, VLMs）在端到端自动驾驶方面展现了显著的潜力。然而，如何充分利用它们的能力以实现安全可靠的车辆控制仍然是一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678077&amp;idx=3&amp;sn=711965e7761276d694e071cafc8f3249&amp;chksm=ce0b76512443f878e4a0148ce01c5be34bdade09b004bc17124f1f9fe2092f112128cd23131f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 03:55:21 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从看见到理解：自动驾驶迈入“思维链”时代]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Ef2ZCfs8ZL7NkbibkUibAxA7d0YqyfKGXn2NMYMibYialaiclojX8xlMKpcbq33Qu04ZjKW3OGdwWxCfGVjiarBw6GQA/300?wxtype=jpeg&amp;wxfrom=0"/><p>1、导言在自动驾驶的技术发展中，一个核心挑战是让自动驾驶系统不仅可以“看见”（感知）环境，更能“理解”环境。尽管现有的自驾技术在感知、决策和控制等领域取得了显著进展，如何在复杂多变的环境中精准地感知、</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247678077&amp;idx=4&amp;sn=d93a659acb2d883f86694166a35ca564&amp;chksm=ce9a357f1a8de247966efb08d11acd7dada8348c5fa5b9cbf5d43c58cecb6db3ac24e7ca98a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 03:55:21 +0000</pubDate>
    </item>
  </channel>
</rss>