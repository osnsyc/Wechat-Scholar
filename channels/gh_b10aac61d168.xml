<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[arXiv每日学术速递]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[arXiv每日学术速递公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_b10aac61d168.jpg</url>
      <title>gh_b10aac61d168</title>
    </image>
    <item>
      <title><![CDATA[为何说“在国内做科研最忌讳踏实？”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMecib9AjeJy0oGNUEX8hubvMIAEfTa8dpGjLOCFzMedkJ1V02DZtLG4BynibmAGrJC4evBY1wQmLxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>新手搞科研，最忌讳的就是自己埋头苦干。搞科研，只靠自己是不可能发出高区位论文的！一定要多学习那些顶会大牛“成熟的方法论”和“先进的科研思想”。站在别人的经验之上，才更容易挖掘出极具创新性的那种idea</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659770&amp;idx=1&amp;sn=e5da1bd5364e6df8f719d8bbe3e3e982&amp;chksm=cee5728d72708ae901b09fa037b39e90730c325e5e89c1ae9f274f0f6e7e7561287ceb87a864&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 04:38:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.5]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPmcAq5Q89yibj9iapTobphDDBPqcE8JZ29TNmnq1pcV4aL65ydVBE0OvoD6DT7Fj4fKp4MpQLxkfpw/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！ arXiv每日学术速递2025.3.5 人工智能相关计算机视觉与模式识别(cs.CV) |</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659770&amp;idx=2&amp;sn=e2a7b6e6f47768926497436d3ce3fab5&amp;chksm=ceefcc39d99bbffd75979e820d690bf113f10ac370c12e3df5ba8800823a51e13ca89dda71de&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 04:38:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[新SCMHSA架构缓解 Transformer 下一帧预测语义稀释，适配损失函数性能更优 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVWBzHX5icichNpYQvA588JjmaA5YCoAPnpF0Qicq0M8Y24LEueFSIhxicWtm8jBQG8e5KM6Qqtnwgbtiaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>视频中的下一帧预测对于自动驾驶、目标跟踪和运动预测等应用至关重要。下一帧预测的主要挑战在于有效地从先前的视频序列中捕获和处理空间和时间信息。以擅长处理序列数据著称的Transformer架构，在这一领</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659770&amp;idx=3&amp;sn=bd8793ded020a8b075e74161e55aa9b9&amp;chksm=ce9618034248de2bc5b5a668cca4ca2399cabbc5b99f156e62d00086724e6168aca1436a7797&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 04:38:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大/北大等联合提出MapNav | 革新VLN记忆，语义地图替代历史帧，存储开销锐减90%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfXox4VibMYXlvdfAMcADVqcp45Wt9TUzfW75aMzZvsPzj48VdlVicHJICqiaMibLUCzE9VwAich8ftCiaSQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读视觉与语言导航（VLN）是具身AI领域的关键任务，要求智能体在遵循自然语言指令的同时，在多样且未见过环境中进行导航。传统方法在决策过程中高度依赖历史观察作为时空上下文，导致显著的存储和计算开销。在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659770&amp;idx=4&amp;sn=b32952d4259fdb78b69b2a92cd93ce6b&amp;chksm=ce10cb48cd856c1a8ae86c0a999c940465f3d1529a4a500e250c8f83c81297bdb7052a895ab3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 04:38:38 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[即插即用，轻松涨点！把大牛的模块缝合到自己的paper里]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN2uyevaDrAVk5yicHOHFw60NgQ9vPT4Ft56eiaJ9ROUnvD3KDK0nZzRia0ibIUXVJkvefOw7LogvSxiaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>有创新点，就能顺利发paper吗？当然不是！有了创新点只是开始，模型的编码、调试才是重头戏。很多小伙伴都是改了大量的模型和代码，实验结果却没有多少提升，白白耽误投稿时间。今天就分享一些发paper必备</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659358&amp;idx=1&amp;sn=cc8a8668e09eb9ade50a1c0be047fc2f&amp;chksm=ce426c39869020267ae6bbdf687407ba46293339b815a19ce9903b114cea7f6469f6777697c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 07:10:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.4]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMecib9AjeJy0oGNUEX8hubve1gclmdBdIQtIhzIhgeamcETNudwnXFgW0bJgmcicVx2ZFytg95micibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！  arXiv每日学术速递2025.3.4  人工智能相关计算机视觉与模式识别(cs.CV)</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659358&amp;idx=2&amp;sn=668de847f8c53f2e992a02f4d38eb516&amp;chksm=ce95ae78c4c337305730e458dffc4746d1f02d59ddfb0ec61d12d4d83a55d01e1c3b6f2aef50&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 07:10:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[西湖/浙大/西交大联合提出VLAS | 端到端语音-动作对齐攻克声纹丢失难题，交互误差直降70%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfXox4VibMYXlvdfAMcADVqcp8ppmtBReBp6XfAb2XtP3EmoicW1uIkHOibWxHrksRd53UkJABb7cVOKg/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读视觉-语言-动作模型（VLAs）因其端到端设计和卓越的性能在机器人操作中越来越受欢迎。然而，现有的VLAs严重依赖仅支持基于文本指令的视觉-语言模型（VLMs），忽视了更自然的语音交互方式。传统的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659358&amp;idx=3&amp;sn=c4f37e260b2b7485e8e45a4cc8ddeacc&amp;chksm=ced6178d08f6ceb012c57eae9a511af5fa838f89059a5dd5e342004c1cea7dca4607fd7a17c5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 07:10:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[端到端SOTA！上交提出DriveTransformer：以Decoder为核心的大一统架构（ICLR'25）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VnDXQzNf28hEvdjyROpedzVDcV3ZI2dsib9xPCyKBp7MSmSSRSmfCGeD84Dt4GrIM1CuO6GJPvoIktNA1Ox66Gg/300?wxtype=jpeg&amp;wxfrom=0"/><p>写在前面 &amp; 笔者的个人理解当前端到端自动驾驶架构的串行设计导致训练稳定性问题，而且高度依赖于BEV，严重限制了其Scale Up潜力。在我们ICLR2025工作DriveTransformer中，不</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247659358&amp;idx=4&amp;sn=bb9230de12ba9a2a1ca2c3f446930183&amp;chksm=ce4e7ca59600cf55a46f600dada521dc35d3b07633a99931d2cb0d6027e2286b46471845e050&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 07:10:55 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR2025结果出炉！这些方向杀疯了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMsyb2JPrI7PKgXJtXibBaAibc3ttXYYLFuOwia1smicZMC86iaZMBNqNPC2wsyJb4vuIl79Ddv7ZHhStg/640?wxtype=jpeg&amp;wxfrom=0"/><p>根据2024年谷歌学术指标（Google Scholar Metrics）的最新数据，CVPR已成为全球第二大学术出版物，仅次于《Nature》，超越了《Science》，就拿投稿量来说：2019年有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658973&amp;idx=1&amp;sn=3ba16818c5f7ab75aac7833405d1089e&amp;chksm=ce8a9bd01bf6f811c0c2ca3853aa3ff3901e3b89f877d3985c1074b04e45e9b2c149b107cbe3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 04:51:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.3.3]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbN2uyevaDrAVk5yicHOHFw60J4yGYh7IaRwMmKqDtMCyib51WhYm6SvSmcr2vsdOmr1ic60R28wp6ZpA/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！ arXiv每日学术速递2025.3.3 人工智能相关计算机视觉与模式识别(cs.CV) |</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658973&amp;idx=2&amp;sn=10085e8ceb88ecd7df32b6a6f6fb2a4e&amp;chksm=ce079080dded525d4daf8bad65cda1cbb5ced6624601757075910a9f1dae343adbafc9c4ea0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 04:51:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[不确定性驱动的 UD-Mamba 革新医学图像分割，三数据集验证超强分割性能 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVVZeYxic5l35aPBtr98oWI35CKzHmhYDVwag5VcNcCwtXGUFKQJXVCVW5bfp3hcxg5yDold5VJkBGw/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期的研究突出了Mamba框架，这是一种以线性计算复杂度高效捕捉长程依赖关系的状态空间模型。尽管Mamba在医学图像分割中表现出竞争性的性能，但由于传统基于位置的扫描方法的间歇性特性以及医学图像中常见</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658973&amp;idx=3&amp;sn=4444a0d1e3b82a92a0b55b5cb1ddf19c&amp;chksm=cee427ae09098074278a5c8eee13d1724c79549f12b3d94f38b78223cd546ddd4ae1732a6599&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 04:51:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[扩散模型动态约束新潮流！DDAT流形投影攻克机器人轨迹生成难题，单次规划精度实测飙升]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfXDNFKekaClY1qC6jibS7EyW5XDFpiaEfXIRibtG4YtQJOpmOnTAKl6icatQJ7benQLpMMSF7ktYmqTtw/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读扩散模型因其多模态生成能力在创建图像和视频方面表现出色。正是这些能力使得扩散模型在机器人研究领域越来越受欢迎，它们被广泛用于生成机器人运动。然而，扩散模型的随机性质与描述机器人可行运动的精确动力学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658973&amp;idx=4&amp;sn=089cf7e2986bbf69bf231d2b7c9caca9&amp;chksm=ce86809c814059102b227fb07f675ec00a0c8e5a03ebf90f590112698aca20c29062f22d5ef0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 04:51:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[真抽象了！把论文“摘要”写成 “Pumping elephant”，一中国论文被撤稿]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMsyb2JPrI7PKgXJtXibBaAibyuRO1gPuy75ibfoicyjujLIZ7FZ9nDsMrbeM2obeL6RlfWknnUicMonxw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本文募格学术撰写。参考资料：iNature、留学考试、小红书等。请勿二次转载！这下是真的太抽象了....SCI里正确的英文用词有多重要？前段时间，哈尔滨医科大学Zhang Fan团队在Environm</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658573&amp;idx=1&amp;sn=5f476e0ee6850abded1ee39665227f28&amp;chksm=ceb5b2bc8f0e54630ef8707a6b8b59144d0c9d6c4ee764ffacdd7627f5c10491f023413e175e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 07:52:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[语义驱动革命！SIREN三阶注册+非刚性变换，多机器人GSplat地图精度暴增，性能横扫SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfU1lIA0Iicjf0RMsVoOzGqWpIcWbbBSTbjNMxGdnm6oOQ4f0gcfflCvaGibsJmicQF1Ynic6neJPJ1HOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>导读作者提出了一种名为SIREN的方法，用于注册多机器人高斯喷射（GSplat）地图，该方法在初始化或融合局部子图时无需访问相机姿态、图像和地图间变换。为了实现这些功能，SIREN以三种关键方式利用语</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658573&amp;idx=2&amp;sn=1b3f67ef8e219c12253e3c4adea5fd65&amp;chksm=ce38d1e73b1f5e416c9b5a4a9c3ac86fbc9c169c48f48ab7a58a4cd7e105824a2b85f699882a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 07:52:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[学术圈杀疯了 1个月搞定SCI 这些期刊真的零拒稿！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMYcMy29yUuSCmvJlibGsIEHFSd3g6bIppzbr2QO26RFntnBoO6Kdo2c9vGguCvgbW6KMBGBgRcBTA/640?wxtype=jpeg&amp;wxfrom=0"/><p>如果不是亲眼所见，我是真的不敢相信，从选刊动笔到录用只用了1个月，毕竟过去光等审核能等3个月的，好不容易等到回复了也是各种问题，修改完，每一次的期待又落空也太折磨人了。还不如直接拒稿了，这种修改了几次</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658562&amp;idx=1&amp;sn=d92940dd01f40b0e10ef51dd96f1eeea&amp;chksm=ce559d764682eef12f1a4b13e9b09c12aa48f8d0492746521f71f40c870507ad2780d8854558&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 05:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.2.28]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbMYcMy29yUuSCmvJlibGsIEHr9fUBBQ4TxeaeT2aQdia0o0DXbjMSywhDrVjicuZYfqicml6Cr8PxkWIA/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！ arXiv每日学术速递2025.2.28 人工智能相关计算机视觉与模式识别(cs.CV) </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658562&amp;idx=2&amp;sn=cd4812590e62a5fbfc2aae4bf4e134e7&amp;chksm=cea6e1aa237fbede121161f578bfc4cae4d2b41f5e5fc87d08cc7fcff8fe606e2c483e6b9f60&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 05:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[手把手教你驯服DeepSeek-R1！部署+测试+性能优化万字全攻略]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp8n64epzESzPFtUmloC3pJzZsibUCISlbiaJgQ96Wzqgkrz5OViakrMq6gwo9jl3cuTNVAqAkDicDlLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨Mr.Felix编辑丨极市平台极市导读 本文详细介绍了如何部署和测试DeepSeek-R1模型，涵盖了从Ollama到vLLM的多种推理框架的安装与配置，并提供了性能测试结果和优化建议，帮助用户</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658562&amp;idx=3&amp;sn=98486a6ceef924ab9c847e5603d638ae&amp;chksm=ce4c43ebf968d6b7a35d938a29211ea5c8bfb05537db8f2e721d1836dfc13b89f3c1d2bcf084&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 05:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FE-UNet模型融合CNN与Transformer优势，在多生物分割任务中展现先进性能 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVWOMic6vuMQ8P1kskdfGxh71kg49JSdcRiagV7IpCqE47KZdNw8yAASyhTt3LpgTlJygPEx6pYZs7TQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>图像分割是视觉理解中的一个关键任务。卷积神经网络（CNNs）倾向于捕捉图像中的高频特征，而 Transformer （Transformers）则侧重于低频特征。在本文中，作者通过实验量化了CNNs的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658562&amp;idx=4&amp;sn=7366e9a83fe4eb3062d3073e6bdcdb95&amp;chksm=ceef6afdbd9651c9d59b7c9fcd275813eece57e55e4fcf6ff58f45e0b03b562f0e638d69090e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 05:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 录用率仅22.1%，中稿量创历史新高！不负责任的审稿人19篇论文被拒。。。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPKBQ4zJUmDQgMrPB8Q9uS9icW0ZJX0YZz0iahCbhq6wvibSgMkO0uqV6qzyhUSibZeQ2rcOp9tq82oeg/640?wxtype=jpeg&amp;wxfrom=0"/><p>【导读】一年一度CVPR录用结果公布了！2878篇论文被接收，录用率22.1%。更惊爆的是，CVPR组委会对不负责任的审稿人进行惩罚，19篇论文直接desk reject。多名华人担任委员会主席。刚刚</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658149&amp;idx=1&amp;sn=abeedd8adb02932cd18976e45706f58d&amp;chksm=cec72d01548384bf5e7f39ed66c0d90ca2bca52773e36d41a5ca657543f8dae7c9fbb58d9fb0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 06:23:26 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.2.27]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbPKBQ4zJUmDQgMrPB8Q9uS94hTpsH6TsLr8KJiaRpA80cNYfKgvKbCx9aXrllqBZNx4UF0nOEG0OHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！ arXiv每日学术速递2025.2.27 人工智能相关计算机视觉与模式识别(cs.CV) </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658149&amp;idx=2&amp;sn=79bfaffdda18f0564e892c3970f4ab96&amp;chksm=ce8a7137afe9c930f1f772fc48535eb4e14cba9403bbbe6075f78dd277aca9ea72d1ebf355ea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 06:23:26 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[论文一起读 | 从多相机图像中学习用于三维目标检测的高分辨率向量表示]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/G3miadARVe8icib4NjOQicAp4vqnVgU1pUsJooiby8toVEet951lvbxMYjib601gahkxNsLc4mHDNYGuVyaRicEbyiaxKQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>‍导读本文是VCC李滨同学对论文 Learning High-resolution Vector Representation from Multi-Camera Images for 3D Obje</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658149&amp;idx=3&amp;sn=a4f8633d1038465e6f45dc828ea87aa0&amp;chksm=cef8b82724a5c65044f722441b48f6bda3586d540720a1b2f4ca07277b10728badf23a5939ce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 06:23:26 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI图像合成新流程，借助LLMs等实现实例级精确操作，无需微调与辅助信息 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVUHCtWchib2uy9siceTZKQ0icgBBj76XtSVd9D0Bdp33eD2psiag4VM94J4UVDp36Z8SPbmO5Cgw2U8Mw/300?wxtype=jpeg&amp;wxfrom=0"/><p>文本到图像合成的进步引入了能够从文本 Prompt 中创建逼真图像的强大生成模型。然而，对图像属性的精确控制仍然具有挑战性，尤其是在实例 Level 。虽然现有方法通过微调或辅助信息提供了一些控制，但</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247658149&amp;idx=4&amp;sn=cf0b4581df05d40fb1fd99e5591a1e77&amp;chksm=cee9812bb19724c69fde51b5b34d74c3719d52ad7e1f366c39381dd8cce2de074809df85924e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 06:23:26 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Transformer是真热啊！叠上小波变换热上加热，绝对还能发更多顶会论文！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbNqPT0FZKBSvw1wLIClT3lyfxkH3LFTicOqzn9Vbdc22xlgcm3eE3fJVFicvWUKt43Qd3rSibgicdEiajQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>围绕Transformer的研究一直以来都是各大顶会的热门投稿方向，比如它自身的魔改、与其他技术结合等等。最近在ECCV 2024上发现的一篇高质量paper就讲的是Transformer结合小波变换</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247657746&amp;idx=1&amp;sn=34c88ae6ac130cefe664797f52ea11d5&amp;chksm=ced1922ba2559832ad601afd431adfd48162bf8328c0b9929774e04a15ad094c28ba4008b4ad&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 05:02:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[arXiv每日学术速递2025.2.26]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/HicsOQIbsWbM6rPa1iaicJqZ4IZZG2X6ibLUf2TSeibPWolqsTSRECeXhPVBDkWibtFXlsJPxLNrSxuOqdhm9DqFXw1Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>涵盖CS|物理|数学|经济|统计|金融|生物|电气等领域，点击阅读原文访问网站arxivdaily.com！ arXiv每日学术速递2025.2.26 人工智能相关计算机视觉与模式识别(cs.CV) </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247657746&amp;idx=2&amp;sn=43edbe4a8bfb8d1fd942167ff261ce0a&amp;chksm=ceace645a050fe983a808485c6383c93b6d0922ded52bfa28d60e32279dbea7bf6bd72ec2f8b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 05:02:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[零样本导航新范式 | 模块化四步法+LLM/VLM双引擎驱动，nDTW暴增碾压VLMaps/SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oCQzz6x3ibfU1lIA0Iicjf0RMsVoOzGqWprsLOl0LnKdC18nYVyJjtiaj0sMq3uRicl8sBnssma3ibcf2dfibzHzc5sw/300?wxtype=jpeg&amp;wxfrom=0"/><p> 导读在本工作中，作者提出了一种模块化方法来解决视觉-语言导航（VLN）任务，通过将问题分解为四个子模块，这些子模块在零样本设置下使用最先进的语言大模型（LLMs）和视觉-语言模型（VLMs）。给定自</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247657746&amp;idx=3&amp;sn=49a2f358d7a9855c6504d0510b6f7c74&amp;chksm=ce19b38b29f876a4ead1875ee6c8758e7e3c1653dfb0ff3db5770874356abd6c36a1fa1a8f42&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 05:02:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[揭秘线性与 Softmax 注意力差距，赋予线性两特性，多任务超越且计算量低 ！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/3zd5t92QHVXMdXCynTByTICXxqsKjNgDSYV1BtwTZz3LNNHyaQ2cIIGzMK0iak1Te90NlicjiczzCR01icEXCev6icg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在现代视觉Transformer设计中，Softmax注意力能够有效捕获长距离的视觉信息；然而，在处理高分辨率输入时会带来巨大的计算成本。相比之下，线性注意力自然享有线性复杂度，并且具有扩展到更高分辨</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&amp;mid=2247657746&amp;idx=4&amp;sn=73abb02b67888ed610ee24d996e82d80&amp;chksm=ce8784f69febccd73d5fb37eec021cf8d929d546c5224623edb9160ecdb23fc81655088328a9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 05:02:05 +0000</pubDate>
    </item>
  </channel>
</rss>