<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[迈过它才是真正的AGI之路：NUS/NTU联合发布通用基准，700种任务、325k道题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah8PXO6icyhjxZak4lKtdBPHR3Uicrs1ZEZ1By47qY69ke54HLPwicJ3iadX8oOicMMte2Vm8Q2Wib3Sibiaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>就像手机摄影从单摄发展到多摄联动，多模态大模型正在经历从"单科专家"到"全能通才"的进化。Title: On Path to Multimodal Generalist: General-Level </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538655&amp;idx=1&amp;sn=77c0143e6b2f3a75838b117ce98154e0&amp;chksm=eadf5a1a0dd6654fd8b9c92b4bf04ea9232c2384069bdae6887f621b8433101181fbdfcf771c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 07:08:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[弹性Reasoning！通过控制预算和RL达到更短、更快、更强]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah8PXO6icyhjxZak4lKtdBPHicYT82jPn0K9pPSRKibZcicCBzmSzib5mu8YXreoGypeH4icibsusmZmBA9w/300?wxtype=jpeg&amp;wxfrom=0"/><p>如今的LLM在解决数学题、编程任务时，常常像“话痨”一样输出冗长的推理步骤。虽然这些步骤能提升准确性，但实际应用中却面临两大问题：资源浪费：生成几千甚至几万个token，消耗大量算力；不可控风险：如果</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538655&amp;idx=2&amp;sn=acf061aa143b12f7ab2bcbf1f202a970&amp;chksm=ea477e104cf3a08fff378814c887c2b5f66e2e891cf5cd12fedd17aad83487f11e0a1da85dd5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 07:08:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[新国立(NUS)计算机系AI方向招生-全奖/带薪-博后博士访问学生intern RA等 – Dr. Yatao Bian]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah8PXO6icyhjxZak4lKtdBPHqrwsQrX0DIqeGuxPkB1g9ibbRfiaAjBO81qpRnBwDtAYXic2abs9Tk3cg/300?wxtype=jpeg&amp;wxfrom=0"/><p>卞亚涛博士 （Yatao Bian,  https://yataobian.com）将于2025年秋季全职加入新加坡国立大学计算机系（NUS, School of Computing），担任博导、独立</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538655&amp;idx=3&amp;sn=051ae5450b534acb9e354c94b8fe49cd&amp;chksm=ea59614fb9ffed1d52b299164507ac9ba4934978d2aee34ed041d6707d773d624b7b947bfe34&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 07:08:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[哈工深发布多模态Reasoning大模型综述：感知、推理、思考和规划]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahBGbJI0D9Vr4OaKiaS88sGqOMDjftDQQrib053aWiaIMSicl2PLHL2JLaUicC9oqE0zoFO93GzqyVysLw/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models链接：https://arxi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538612&amp;idx=1&amp;sn=cabf5d9365cdcf79660a25a16e093067&amp;chksm=ea9b594dde03b8c73b2f93287a40cc2b356bddb84027693bf4a5bbe82854a0aea7da760b0f96&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 06:00:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SIGIR 2025｜打造虚拟情感陪聊机器人新思路：利用个性化实时检索，大幅提升agent主动对话能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahBGbJI0D9Vr4OaKiaS88sGqO85iajGEJyPptRZuWpL7mM5Kc9ibs3bE0TY9WI3yM8k0f1yMfBOaEt4Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文标题：PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval论文链接：http://arxi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538612&amp;idx=2&amp;sn=5cc9017a5d09d838667ab858a8b6729e&amp;chksm=eae8bb40e8bf0b13a1847ad0167daefb2ce6c32032a368fad4d7cb37402eb54875379fd1aadb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 06:00:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[清华提出ConCISE：简单有效，Reasoning过程砍掉一半，准确率不降！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahBGbJI0D9Vr4OaKiaS88sGqEuekiaUgo8IqM2jr3voN3Ozic5aMqv6CvLpGMPOfQUCwfLbxribhdxv4Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>如今的大模型（如DeepSeek-R1）在解数学题或逻辑推理时，明明答案对了，还要反复推演十几步，生成超长的思考链。这不仅浪费算力，用户看着也头疼。论文：ConCISE: Confidence-gui</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538612&amp;idx=3&amp;sn=4cac15140340d73ebd96eba71cef20f5&amp;chksm=ea328f8cf7b5d728eaf8c655bf836be24508bfd127b103cfba61d43037bf04a6c830f8dd9729&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 06:00:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[清华提出Absolute Zero：零数据训练Reasoning LLM！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahJgqmKEsyzDsuEIqnoD4WYzJibjXoKYV5GpAicvtIR4fENRuu68ics3TJ2a3Eanx9xPKtB6RbU6caUQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前训练就像“填鸭式教育”——需要海量人类标注的题目和答案。比如教解数学题，得先准备几万道题+标准答案，费时费力。更可怕的是，如果未来它超越人类，谁来给它出题？论文：Absolute Zero: Re</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538569&amp;idx=1&amp;sn=866dc41ce5e988a4de062500bfb62efe&amp;chksm=eaaf9af2a28dec255af490a21cc1b528d1143459584d171d2f080639efe5b1a6aa5f4101dbc8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 11:07:43 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML2025 | 通过推测搜索加速LLM Reasoning能力，做到又快又好]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahJgqmKEsyzDsuEIqnoD4WYiaLYIl3iafJ8Uhuu8al7Tsgty7qfO5UxMCYicxWwGR5C3PRZbLlQ1MuDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>LLM 的「慢思考」模式像人类解题——通过多步骤推理（树搜索）寻找最优解。但问题在于：生成每个推理步骤（thought）都需要大模型反复计算，导致延迟飙升。就像用超跑在迷宫里找路，虽然性能强，但频繁刹</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538569&amp;idx=2&amp;sn=df782805dbe0cece029a3299befa1922&amp;chksm=ea8b582ef8660661bf16c3a31021c26fb25cbe1d1cae28d2bacee0c6be78f0a559d8736884e5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 11:07:43 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[新SoTA方法RM-R1：让reward model对评分说出原因！超越GPT4o]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahyYVdJSibHuBznRsliay4EC5wFwpxeqb4MKy7ClYeQPMibnwiaeeIVPAaDgkRv7Fu8bibV3eZaX1gTsUA/640?wxtype=jpeg&amp;wxfrom=0"/><p>模型评分为什么需要“会思考”？过去，模型的“评分”就像老师只给分数不写评语——比如你问“哪个回答更好”，它只会输出一个数字或简单结论，但说不出理由。这种“黑箱打分”有两个问题：不透明：用户不知道评分依</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538520&amp;idx=1&amp;sn=677216885f218ed079c199f1051a8dcd&amp;chksm=ea3d381a68a1a908f19d834db5911a12be1ee26aaaaf546c7d00ae37ffb0c5f2366be0a4a657&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 07:18:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | 注意力机制中的极大值：破解大语言模型上下文理解的关键]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahyYVdJSibHuBznRsliay4EC5iaCV0hH2jNRwfGlNQV4LS7sic40k6E11yx04jvzKqfw1SxC47cItxUuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLMs）在上下文知识理解方面取得了令人瞩目的成功。近日，一项来自 ICML 2025 的新研究《Massive Values in Self-Attention Modules are</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538520&amp;idx=2&amp;sn=d32405cf632b452c419652b246645a07&amp;chksm=ea5dbaaf4c99169fdf684c5908bd71dde6e496cf710ed86e33c83c7d15ddb89e0b9fd401f80a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 07:18:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[社交Agent: 通过RL学习自适应Thinking，根据场景在“秒回”和“深思”间灵活切换]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahyYVdJSibHuBznRsliay4EC5icvRjtI9wx57G9VHltefWWjNNMHCUfdIYicSHZMzKCaiaYG3UNq6gaExw/300?wxtype=jpeg&amp;wxfrom=0"/><p>当模型开始“察言观色”...现在的聊天机器人，虽然能写诗、写代码，但在需要“人情世故”的场景里，表现就像钢铁直男——要么无脑秒回，要么长篇大论说废话。比如商业谈判中，对手抛出一个试探性问题，Agent</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538520&amp;idx=3&amp;sn=fe6c8acf3bf04c07757f4543b18fd1f2&amp;chksm=ea7a3bf6f892d55c45e28a268eda82a13e0de66c88ec41ec81758bebac8a22146e18022643e4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 07:18:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[低延迟、高吞吐，LLM优化与高效推理引擎综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahyYVdJSibHuBznRsliay4EC5sWv9KF0le2sf6AArkvsPYV8HJPS2b2uS1wx9zv0RQyWR3cAVIia8nNQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LLM每次回答都要进行复杂的计算，尤其是需要多次调用模型的场景（比如连续推理、多轮对话），成本高得离谱。关键矛盾：用户希望响应快（低延迟），企业想省钱（高吞吐）。典型场景：思维链推理（Chain-of</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538520&amp;idx=4&amp;sn=c4de3f82aac6b7d887c158c8e5d16a8d&amp;chksm=ea32a2953821a1513cd0f9f563705058569b4973289a46278085fc892c199b7a2f72c523a54b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 07:18:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA发布最强开源模型，效果和速度全面超越DeepSeek R1]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajkj19seueR3lNztavDfYeCg9mX8RaEOGOswF1N34HzDf62GG51GywTeic7k1NHcEvkW2ibytQfneAg/640?wxtype=jpeg&amp;wxfrom=0"/><p>NVIDIA最新推出的Llama-Nemotron系列，堪称开源界的“最强大脑”。这个模型家族不仅能解答博士级数理难题，还能像老司机一样根据需求切换“省电模式”和“烧脑模式”。论文：Llama-Nem</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538478&amp;idx=1&amp;sn=164095b1c55a3c3d9dd64d023c0c14e5&amp;chksm=ea41b8513f1688971794a6eb22eb16df466448536c69adf58db6449eac985a951acd88340319&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 05:09:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[以星为舵：LLM的Post-Train与Rest-Time奖励学习综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajkj19seueR3lNztavDfYeCsCVYzjhy4jW4OZib37le68QDm4uHMO7zOiaibWtMRPwgMJibQ2O6BEUfDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>想象你正在教一个小孩做数学题，每次他答对了，你就给一颗星星贴纸；答错了，就温柔地指出问题。久而久之，小孩会越来越擅长解题，因为他知道哪些行为能获得奖励。AI的学习也是如此！论文：Sailing AI </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538478&amp;idx=2&amp;sn=2156ff9644b6b85bc66a3da640d4864c&amp;chksm=ea4a2e17c094a0709a5724d2caba4fcf4b264147b8f812d5b6aeeb2b2b57b2549c52c0078680&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 05:09:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TreeHop：无需LLM的高效多跳问答新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajkj19seueR3lNztavDfYeCq5KGqH8f0hCnvKSntibNrTPxaZ1oG9hzRskT1Ztc9QwGlUxgLpyq1jA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering链接</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538478&amp;idx=3&amp;sn=43ebc23c3387517e6dc07274696384b0&amp;chksm=ea46b572f1274fdf616c7d7cc7a4060eea59f3bc6d8a21704dff8f47a8e690a0eed55405fbab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 05:09:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek-R1发布后的100天复现之旅方法总结]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhB24sPyaVd1yFKFxEz4ZuXSjXpD8VUE047EAfwHhicRFQwOJ459148vosYibD3cK9lebGf4LnIBLg/640?wxtype=jpeg&amp;wxfrom=0"/><p>100天前，DeepSeek团队发布了「推理大模型」DeepSeek-R1。这个模型不仅能回答问题，还能像人类一样一步步「写草稿」「验算」「纠错」，比如解数学题时先列公式再计算，写代码时边写边检查。这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538432&amp;idx=1&amp;sn=552ba0d70e976ef8aa5cffcb27436d15&amp;chksm=eabfc499c29b8842fb0e75c7ed5108b720d9a579e859a95f311f79b4cb36f1c2c673f83bc047&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 02 May 2025 10:22:28 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Reasoning的最终答案可能不是模型想要的答案！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhB24sPyaVd1yFKFxEz4Zu2v2CnwQcchRK2JibicMQzopwiccQ9uYpK66FYB04Aniautibib4pzgcUmYag/300?wxtype=jpeg&amp;wxfrom=0"/><p>打破常规：为什么LLM的最终答案可能不靠谱？大型语言模型（如ChatGPT）解决复杂问题时，通常会生成一段“推理过程”，最后给出答案。传统评估方法只看最终答案的对错，但论文提出一个反直觉的观点：最终答</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538432&amp;idx=2&amp;sn=1c638d9975e82cff98fc3997dd1b8d42&amp;chksm=eaa857d33672232c982a73c1ba8d9fc6217deeca4481e2717235328da84e77a4ba297f439904&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 02 May 2025 10:22:28 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[本周六直播预约 | Test-Time Reasoning综述分享！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhB24sPyaVd1yFKFxEz4ZuDZGoibTFBhcIhjxgwxe3icWVnPAkqXkb4vj8r80PoTNT4fkORsa8cRqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题Test time scaling 综述! 从what, how, where 和how well帮你系统解构！时间2025.5.3 10:30 北京时间内容介绍论文：What, How, Whe</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538432&amp;idx=3&amp;sn=e86ba5067bb2de103c266992160b004e&amp;chksm=ea30cb59ca18cd67412f7f6c8af059266d9ae88d21f5c96b0888e3b97e919fe10443c52fa223&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 02 May 2025 10:22:28 +0000</pubDate>
    </item>
  </channel>
</rss>