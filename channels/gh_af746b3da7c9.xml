<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[邱锡鹏老师团队发现SFT与DPO破壁统一：内隐奖励作为桥梁]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajzGOUduaptGichiaJTyjoFeQytSrMnbxj4gWM7SOrDFSAmnibHGKDcExoHgYd0H5XWX8yHX59OxCr8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）的后训练是将其应用于实际任务的关键阶段，主要包括监督微调（SFT） 和基于人类反馈的偏好学习（如DPO）。传统观点认为SFT仅是DPO的"热身步骤"，两者缺乏理论关联。本文突破性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540695&amp;idx=1&amp;sn=4f459ca72c63347df4b3b2d9d28977ad&amp;chksm=ea93e4d8d0f0ec6e486e016fd4af7975059bc61646f696604156c1d416c1c789a232592f5113&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 15:57:56 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[2025.7.4上午 | 视觉智能驱动的多模态对齐与推理的近期系列工作分享 - 复旦博士生王思尹]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajzGOUduaptGichiaJTyjoFeQz0mo2VIMGB01DJlNYJRRk0QwQaN7aTmNesNALKn4DHjAId73qLnY8w/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题视觉智能驱动的多模态对齐与推理时间2025.07.04 周五 10:30 北京时间b站直播间：https://live.bilibili.com/27784098（点击文末「阅读原文」即可跳转） </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540678&amp;idx=1&amp;sn=35ba0b9a0a82ce5dbf6b2bfcfe84cae0&amp;chksm=ea1e17591c363cf4d34feecdb5940cf8d4f30f768919a99a5eb9a813d76a915625991d901708&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 13:28:01 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[别只卷文本了！港科大、微软这份爆火的“视觉思维”路线图，才是多模态的未来！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiauBEjsyYhsSN2luZkkd5eXInf0oCanPGbWyxmtJNyWdfZwyiadCicCt7h75Yw9kibXJFeS2b00NFhLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下，你在解决一道复杂的几何题时，会自然地在草稿纸上画辅助线来验证思路——这不仅是“看”图，而是“用”图思考。然而，当前的多模态AI（如GPT-4V）大多停留在“静态看图”阶段：先将图像编码为固定</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540672&amp;idx=1&amp;sn=0e2af2aaf97dafa15dce0c7d7ee41d66&amp;chksm=ea61025ba49fc5559b0ab20884a306fd1e72a00d6a8d74331af324750abc09ad70bf886b845c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 10:21:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | 视觉智能驱动的多模态对齐与推理系列工作分享]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiauBEjsyYhsSN2luZkkd5eX70Av3XOKD1Y22REurtrBH9STJRDHVnbC8xCibib4BicKEPmwmQ1zgQvTg/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题视觉智能驱动的多模态对齐与推理时间2025.07.04 周五 10:30 北京时间b站直播间：https://live.bilibili.com/27784098（点击文末「阅读原文」即可跳转） </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540672&amp;idx=2&amp;sn=9c8df8e39ef6d4ab9c249631136aef32&amp;chksm=eaafa234ffcfb5269c8866e6b765371696a8c7fbcd88b607180052e64ee9a7495759f281da93&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 10:21:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[看了这本全是图解的书，算是真的掌握LLM基础和前沿了...]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiauBEjsyYhsSN2luZkkd5eXyicY7wtwauvJGpR66rUa4g8ZWgkYOCXbzICWYU5L4Gt4vlJllGouHJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>01The Illustrated 系列如果你关注大模型技术动态，你可能知道这两个名字：Jay &amp; Maarten，如果你不知道，那你大概率知道这篇文章——“The Illustrated Trans</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540672&amp;idx=3&amp;sn=b4f213d4cfdd18c2dac360a7549ef4eb&amp;chksm=eaa1b0c2bf1b7c1ed9e97a131961785ef19f30d4e892765bd45631869f7d276cbf152a88770c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 10:21:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[思维锚点：破解LLM Reasoning黑箱的关键句]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagaLU6mHvozeiaKX8Sz6gWsWicFXewWGzCiaMn9fzB7fyw8rM9LYCfCzUmpcpwCjJ65NeicLZkeibFsJPQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）的思维链（Chain-of-Thought, CoT）推理虽提升了复杂任务性能，但其自回归特性导致计算过程难以分解。传统可解释性方法关注单次前向传播的神经元激活，对多步推理的"黑</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540618&amp;idx=1&amp;sn=a30969d09a00e14c924c8ae0d0b68aff&amp;chksm=eac3d97521d2ddf6948dfe45303e6f9291d0f83a8ce54fd01ec5455fae5d93d1c60f2cd012e8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 29 Jun 2025 09:57:25 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[绝美无痕，比你还会P图的Agent！仅通过自然语言指令，灵活使用数百工具，超越GPT-4o达60%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajO6icAqEPuc1XrFu0BpZuLeBgxib0jUJ3T0zpjKVicot13mbFuexCpHkiaNW7xLiaoUMg8Xu7KN8icMsKg/640?wxtype=jpeg&amp;wxfrom=0"/><p>照片精修是专业摄影的核心环节，但传统工具如Lightroom操作复杂，而AI方案（如GPT-4o）常因过度重生成像素导致细节失真，且缺乏局部精细控制能力。论文：JarvisArt: Liberatin</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540588&amp;idx=1&amp;sn=5433034c689c2191a3ab4852c94752c0&amp;chksm=ea2cad8c6552f4836d946105fad8f0ca6b0f7a470d36bf6c09dea02d1d637cc88ed5635e26fb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 26 Jun 2025 12:30:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[普林斯顿团队首次提出不确定性量化新范式，让Reasoning模型会说“我不知道”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajO6icAqEPuc1XrFu0BpZuLe8K22DHPrcSF3Unzv3bDf0hJKm79CNhbBIcxoju6Psn2Ef9SBS9d0og/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）在复杂推理任务中取得突破性进展，但其"幻觉"（自信但错误的回答）仍是安全落地的核心障碍。普林斯顿团队首次系统评估推理模型的不确定性量化能力，揭示三个关键问题：模型是否知道自己的无</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540588&amp;idx=2&amp;sn=bf31ec3e992c7f0a4940b226fc7de152&amp;chksm=ea17e6cf7d83609ad2e23e0477dd1176c28ec73594141d97a31673dae1311371341d3a1f4feb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 26 Jun 2025 12:30:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约：NICE×UIUC｜伊利诺伊大学香槟分校(UIUC)专场分享会重磅开启！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajO6icAqEPuc1XrFu0BpZuLeQuAcwd2yQTzwYIzXFx1Wia1urybwammuJWKk0wIINH9wVd1oVGdbPrA/300?wxtype=jpeg&amp;wxfrom=0"/><p>NICE学术将于北京时间 06月29日上午10:00（纽约时间06月28日晚22:00）举办 UIUC专场论文分享会，由陈修司博士（UIUC博后）担任主持人，特邀钱成（UIUC博士生）、王鸿儒（UIU</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540588&amp;idx=3&amp;sn=4d00c5d88fe4009dd9519b552062156d&amp;chksm=ea8b152f7732c6cfdef71a0ceec743ba1e6433eeb923b7ace14256b866b40427e6e2523a9af3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 26 Jun 2025 12:30:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约：NICE×UIUC｜伊利诺伊大学香槟分校(UIUC)专场分享会重磅开启！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajO6icAqEPuc1XrFu0BpZuLeFAuXE6VFFgI0Us3TeHNHI4ORsmmjwqt7D88wEGzIcVZMILxhLABZ4Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>NICE学术将于北京时间 06月29日上午10:00（纽约时间06月28日晚22:00）举办 UIUC专场论文分享会，由陈修司博士（UIUC博后）担任主持人，特邀钱成（UIUC博士生）、王鸿儒（UIU</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540550&amp;idx=1&amp;sn=097fe2f47b69cd9ccf6d44d51d82c373&amp;chksm=ea9c01b6287ab4d2beada108e1aaf30e1cd65f6c3bd778b14c4296e657876ebab422d84c86d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 26 Jun 2025 04:20:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[RL救不了泛化性！揭示LLM数学Reasoning的深层瓶颈]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahglJy55mWgLRAibIjcaI7qMBvWAvOEk4vJVFrcUZffIWoDleMX0BMQoicFia4ZsT2WicaYicBxYCxPUgg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）在数学竞赛级任务（如IMO）上表现亮眼，但依赖机械化的推理模式。当问题需要跳出常规思维（如创新策略或技能组合）时，模型表现急剧下降。现有数学评测集（如GSM8K）存在两大缺陷：混</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540544&amp;idx=1&amp;sn=cf1d343543344eb651c0662b6ddeb53d&amp;chksm=eab080088a031fe0f040188970b7903a6a02f41bbc642269adb2727b01370abfa2149d2b9286&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 25 Jun 2025 09:47:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[更多thinking≠更好结果，精准thinking可砍掉一半长度]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahglJy55mWgLRAibIjcaI7qM63nhXaE7O2G2S3gAVgbIZWTeZ5VC4G7K5rkib7wzbbtV3Ogk8oHlVTw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型推理为什么又长又啰嗦？想象一下让学霸解题：明明第一步就得出答案，却非要反复验算十遍，还写满整张草稿纸——这就是当前大模型（如GPT-4、DeepSeek）的痛点！论文：Optimizing Le</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540544&amp;idx=2&amp;sn=593d35a23378aa1e25756f9ec27dc396&amp;chksm=eab396ddbde4dcb282795c17fc496bdb0c77ce08a2186826ede3b218da2737d01204be369d8e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 25 Jun 2025 09:47:39 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | 强化学习训练能否不依赖外部知识优化模型的弱点？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahESzk3kE3w0hF9DbOfyicicUJlCqC7r0AMk0kAf06vEN6UI8fuNHh1DgVEhGnibMFvDhmdb5NYR6nYw/640?wxtype=jpeg&amp;wxfrom=0"/><p>标题强化学习训练能否不依赖外部知识优化模型的弱点？时间2025.6.27 周五 10:30-11:30 北京时间内容简介这篇论文提出了一种针对强化学习（RL）场景下的启发式的数据合成流程（SwS），通</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540495&amp;idx=1&amp;sn=77c4cb36fe3854ce7b59c7acfbfbf213&amp;chksm=ea95b13b354ddda6034660cc39f5951049b88b874a99a3853e3975cc7b06fc516c77835aee27&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 24 Jun 2025 08:46:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别微调时代：拖拽式LLMs实现12000倍加速适配，输入描述，秒级定制LLM，效果、速度全面超越]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahESzk3kE3w0hF9DbOfyicicULAICxuQzDXV4utFqUrbsEB01YxtnXwgW8AHjtmA7Vytz4hSePUMMSg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（如GPT-4、Llama、Qwen）虽具备强大的零样本能力，但实际落地常需针对特定任务定制模型行为。传统高效微调技术（如LoRA）虽减少参数量，仍需对每个新任务进行数小时至数天的训练，成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540489&amp;idx=1&amp;sn=56ce85be1168baf58642d12c246e35c0&amp;chksm=eaa6a1e61ad05ac8c3d26dc683e06ea0ac4d0b8c2c1abd3e1f2ddc63216476f632a8c4535e96&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 24 Jun 2025 03:09:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL 2025 | 指令遵循不能仅靠常识？GuideBench 揭示大模型如何“踩雷”领域指南规则]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahESzk3kE3w0hF9DbOfyicicUdn8ldYoqaxxw6jzz5ibZicbRuibwlmorc4ibtOKtcPgbibsTlCE6aofjibuA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在 AI 领域，大模型智能体的发展日新月异。我们今天要介绍的这篇 ACL 2025 主会论文——《 GuideBench: Benchmarking Domain-Oriented Guideline</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540489&amp;idx=2&amp;sn=c1ab7ce0503d7d9298a6268d0c4b55ae&amp;chksm=eac0d1d6ba25b2b659b326184a9ccd7eae1d59fc26e3be471a5633191978c058e3c666125a88&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 24 Jun 2025 03:09:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[砍掉70%内存！陈丹琦团队破解LLM长文本瓶颈]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag5ev8FoEiamASsgCItF74t7NvNwicf1aF4xlMHqyOOD6ibS5PrjNNHpWibulicH1b9VvHbzTJjjC8PApg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（如GPT-4、Llama 3）能总结整本书、分析数万行代码，但这种能力需要“记忆”大量上下文信息。想象你在读一本小说：若要理解结局，可能需要反复翻看前面的关键情节。模型同样如此——它通过</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540433&amp;idx=1&amp;sn=f4c4a958bf8c6114ecce75e13abed4c7&amp;chksm=ea6af8f18ae35fec991ea1918202407630f6c55e4dd22104a83181b8a5602c4eac41273351db&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 23 Jun 2025 04:02:18 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[终结Agent乱象：模块化OAgents开源框架统一评估标准]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag5ev8FoEiamASsgCItF74t7WY7w7GjeHFoYX4yVvWzI4ib2buz1Uhibhcag7Q08icLDrZPMdg9PjbVXA/300?wxtype=jpeg&amp;wxfrom=0"/><p>终结Agent乱象：模块化OAgents开源框架统一评估标准近年来，AI Agent 因能解决复杂任务备受关注。但OPPO团队发现：当前研究存在两大痛点：组件设计碎片化：不同框架的规划/记忆/工具模块</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540433&amp;idx=2&amp;sn=d9332fd5c21534f926cd2073deb782c8&amp;chksm=ea6bdc6aeb0714576cae9b8fa234ad63011bf005b4857d1c462620eb1c59c07bfaf4a7763dde&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 23 Jun 2025 04:02:18 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | SwS: 强化学习训练能否不依赖外部知识优化模型的弱点？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag5ev8FoEiamASsgCItF74t7n4E2QllB3jCUJCI5o78YBo0IcVBx7iaOSxrL3SfFAaCfCb3XDcyibA8w/300?wxtype=jpeg&amp;wxfrom=0"/><p>标题SwS-弱点驱动的自我进化，重塑RL边界时间2025.6.27 周五 10:30-11:30 北京时间内容简介这篇论文提出了一种针对强化学习（RL）场景下的启发式的数据合成流程（SwS），通过合成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540433&amp;idx=3&amp;sn=65c669e7b208db54e74343c04a6f8464&amp;chksm=eaefa17dd6d21885a25975c7f3a0ee49e1577ccbab58da7b125dcc7d500007e739475c64a6e1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 23 Jun 2025 04:02:18 +0000</pubDate>
    </item>
  </channel>
</rss>