<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[深度学习自然语言处理]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      

      <title>gh_af746b3da7c9</title>
      

    </image>
    




















    <item>
      <title><![CDATA[Deepseek R1 Zero成功复现, 三阶段RL，Response长度涨幅超50%，涌现语言混杂，double-check]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuZvEI97znd0G0l6VouDSVxIo0C0MqyGAOqdvcOiblKBAKFibvNVd1VpepK04tZthkWNqBNoRcPqfA/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：涮月亮的谪仙人（已授权）链接：https://zhuanlan.zhihu.com/p/21290410831编辑：「深度学习自然语言处理」公众号项目代码可见：Unakar/Logic-RL(h</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247535692&amp;idx=1&amp;sn=b91e950bd4132e79756c6edf3f3b6963&amp;chksm=ea995e425920598681b5d3ae3287c356a7d9eb2333015ebd204ed97a2b8b8c4261e25ef15431&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 05 Feb 2025 08:22:14 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[LightTransfer：将你的LLM轻松转为Hybrid model，增强o1-like长文本生成能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuZvEI97znd0G0l6VouDSVbtz438qbnbIxP1ZcicicSG3Ygb4iaoRrVK6UOWW4Iia8kN7jjndICKoaOA/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近hybrid model的有效性已被广泛验证（比如minimax-01和gemma2等）。该篇论文研究了一个非常有趣的主题：如何将预训练好的dense transformer（如qwq）转化为hy</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247535692&amp;idx=2&amp;sn=eda5ead962e3e136ead35a2abe6593a7&amp;chksm=ea15139569faea05e0704cebf75eb8183fa8cc42297f7b7873f40bbb77ff05ca834359b02f8d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 05 Feb 2025 08:22:14 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[腾讯AI Lab联合苏大上交提出：少切思路多挖矿，让o1类LLM做题不再「三心二意」]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhH7bBxWoicqmXpSvpJ1pgvgibt1ayicoldevaKYCO4GjhTI2snOzsewRz1Zwic2lmVI4IPby9ibwZXyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下，你班上有个超级聪明的学霸，但他做题时总像得了「思维多动症」——一会儿用代数算，突然又切到几何法，再蹦出个微积分，最后…答案错了！这篇论文抓到的正是大语言模型（比如OpenAI的o1）的这个小</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247535645&amp;idx=1&amp;sn=d8575ba255fe80a320f670b114a4ce40&amp;chksm=eafd563db4c33bb9fe3900364549708ea6309c9b567ee49602d514a456d7b4f06fcf87133462&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 04 Feb 2025 08:33:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[新突破！xJailbreak：用强化学习「越狱」大模型，可解释性黑盒攻击来了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhH7bBxWoicqmXpSvpJ1pgvpSQOuBrOKZbaJnUSiaYEicWnBLUibjkMSWnwtQQdsS4XFGuceic6DfSfjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>来自原作者团队投稿编辑：深度学习自然语言处理大型语言模型（如 GPT-4）虽经过安全对齐，但仍易被“越狱”。现有黑盒攻击依赖启发式算法（如遗传算法）优化提示词模板，缺乏可解释性且效率无法保证；白盒攻击</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247535645&amp;idx=2&amp;sn=75fd9427555455ca1956d87efe5a166b&amp;chksm=eaba8fc533be052178e9f1b5874290bf8eadb7895291a387d651624f06f3cc20f614adaca735&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 04 Feb 2025 08:33:34 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
