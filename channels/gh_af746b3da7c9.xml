<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[NVIDIA发布最强开源模型，效果和速度全面超越DeepSeek R1]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajkj19seueR3lNztavDfYeCg9mX8RaEOGOswF1N34HzDf62GG51GywTeic7k1NHcEvkW2ibytQfneAg/640?wxtype=jpeg&amp;wxfrom=0"/><p>NVIDIA最新推出的Llama-Nemotron系列，堪称开源界的“最强大脑”。这个模型家族不仅能解答博士级数理难题，还能像老司机一样根据需求切换“省电模式”和“烧脑模式”。论文：Llama-Nem</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538478&amp;idx=1&amp;sn=164095b1c55a3c3d9dd64d023c0c14e5&amp;chksm=ea41b8513f1688971794a6eb22eb16df466448536c69adf58db6449eac985a951acd88340319&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 05:09:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[以星为舵：LLM的Post-Train与Rest-Time奖励学习综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajkj19seueR3lNztavDfYeCsCVYzjhy4jW4OZib37le68QDm4uHMO7zOiaibWtMRPwgMJibQ2O6BEUfDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>想象你正在教一个小孩做数学题，每次他答对了，你就给一颗星星贴纸；答错了，就温柔地指出问题。久而久之，小孩会越来越擅长解题，因为他知道哪些行为能获得奖励。AI的学习也是如此！论文：Sailing AI </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538478&amp;idx=2&amp;sn=2156ff9644b6b85bc66a3da640d4864c&amp;chksm=ea4a2e17c094a0709a5724d2caba4fcf4b264147b8f812d5b6aeeb2b2b57b2549c52c0078680&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 05:09:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TreeHop：无需LLM的高效多跳问答新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajkj19seueR3lNztavDfYeCq5KGqH8f0hCnvKSntibNrTPxaZ1oG9hzRskT1Ztc9QwGlUxgLpyq1jA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering链接</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538478&amp;idx=3&amp;sn=43ebc23c3387517e6dc07274696384b0&amp;chksm=ea46b572f1274fdf616c7d7cc7a4060eea59f3bc6d8a21704dff8f47a8e690a0eed55405fbab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 05:09:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek-R1发布后的100天复现之旅方法总结]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhB24sPyaVd1yFKFxEz4ZuXSjXpD8VUE047EAfwHhicRFQwOJ459148vosYibD3cK9lebGf4LnIBLg/640?wxtype=jpeg&amp;wxfrom=0"/><p>100天前，DeepSeek团队发布了「推理大模型」DeepSeek-R1。这个模型不仅能回答问题，还能像人类一样一步步「写草稿」「验算」「纠错」，比如解数学题时先列公式再计算，写代码时边写边检查。这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538432&amp;idx=1&amp;sn=552ba0d70e976ef8aa5cffcb27436d15&amp;chksm=eabfc499c29b8842fb0e75c7ed5108b720d9a579e859a95f311f79b4cb36f1c2c673f83bc047&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 02 May 2025 10:22:28 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Reasoning的最终答案可能不是模型想要的答案！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhB24sPyaVd1yFKFxEz4Zu2v2CnwQcchRK2JibicMQzopwiccQ9uYpK66FYB04Aniautibib4pzgcUmYag/300?wxtype=jpeg&amp;wxfrom=0"/><p>打破常规：为什么LLM的最终答案可能不靠谱？大型语言模型（如ChatGPT）解决复杂问题时，通常会生成一段“推理过程”，最后给出答案。传统评估方法只看最终答案的对错，但论文提出一个反直觉的观点：最终答</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538432&amp;idx=2&amp;sn=1c638d9975e82cff98fc3997dd1b8d42&amp;chksm=eaa857d33672232c982a73c1ba8d9fc6217deeca4481e2717235328da84e77a4ba297f439904&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 02 May 2025 10:22:28 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[本周六直播预约 | Test-Time Reasoning综述分享！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhB24sPyaVd1yFKFxEz4ZuDZGoibTFBhcIhjxgwxe3icWVnPAkqXkb4vj8r80PoTNT4fkORsa8cRqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题Test time scaling 综述! 从what, how, where 和how well帮你系统解构！时间2025.5.3 10:30 北京时间内容介绍论文：What, How, Whe</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538432&amp;idx=3&amp;sn=e86ba5067bb2de103c266992160b004e&amp;chksm=ea30cb59ca18cd67412f7f6c8af059266d9ae88d21f5c96b0888e3b97e919fe10443c52fa223&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 02 May 2025 10:22:28 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[体积大、算得慢，如何推的快？LLM高效推理服务最新最全综述！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajGdRbqibZxzSkycIkJ0Yz8ReNIuLr6moMnKbywN3UB9XycGdzzDA6xSNp9BXtBquic5pGj5uANcgnQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家都知道的一件事就是LLM真好用，就是太大了。咋部署才能更加高效呢？真的是个让脑阔疼的问题。比如最近的几十万下载量Mistral-Small-24B-Instruct-2501和 Llama-3.3</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538405&amp;idx=1&amp;sn=b4488ef8f5c55aa8b1f69fcc93da3465&amp;chksm=eab77b1d25963701c3f483dafc4ac32ffc2adbd50f9d74b3649b024ecea54dc922f6e27b6d25&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 01 May 2025 10:52:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | Test time scaling 综述! 从what, how, where 和how well帮你系统解构！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajGdRbqibZxzSkycIkJ0Yz8Rib0TD2Rbg3HWJJ4tySAkMbVW8l2yPwpicuyKILOUItRibexxf4fLC1shQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题Test time scaling 综述! 从what, how, where 和how well帮你系统解构！时间2025.5.3 10:30 北京时间内容介绍论文：What, How, Whe</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538405&amp;idx=2&amp;sn=f4c2a32943d60e6af56a079d3f9e09b6&amp;chksm=ead76eda627fa229e2cd9b6c99324d23e29801effe60fe694884f127ae11d6e8acd221bd5593&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 01 May 2025 10:52:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[PD分离也有问题？semi-PD降低两倍延时，增加一半吞吐！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajGdRbqibZxzSkycIkJ0Yz8RibkFsQ7PagYVz6qU9Mia9iaPjNng5uDZzRibIMs7ibhYOso7EM53ic5aYC1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型服务的效率困局大型语言模型（如ChatGPT、Llama）的服务过程分为两个阶段：预填充（prefill）和 解码（decode）。前者负责理解用户输入并生成第一个词，后者像“打字机”一样逐个输</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538405&amp;idx=3&amp;sn=d7ace18f3ae0cc65ba4d173df0d9baa6&amp;chksm=ead67f71936efe3e4e54865ef5530b66cc5f2cafb3658244456c2d4d75073d5d30e41cea2763&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 01 May 2025 10:52:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[小心！你的手机正在偷偷『学做人』——LLM如何让它自主订咖啡、抢优惠？| 手机端GUI Agent综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiapATcrAicCCmYlE5dia9BykQjld4KZGj5IwLNDQ4EaF0ScogNfticSqcdV3WoIfSOBFRsicBGOeU4r2Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>手机自动化的革命：从「机械操作」到「智能大脑」想象一下，你对着手机说「帮我订一杯拿铁」，手机自动打开外卖APP、选好咖啡、填写地址并支付——整个过程无需任何手动操作。这就是LLM（大语言模型）驱动的手</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538367&amp;idx=1&amp;sn=f74c1c4563d8d3f5d590dcd976ff7201&amp;chksm=eae36a443eb14d1cff22534d53400352ab108ee2c3cf56a670fcdd8e0e791b862df693f46635&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Apr 2025 14:41:41 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[可信大模型 Reliable LLM（四）：利用不确定性估计强化大模型的事实性表达]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiapATcrAicCCmYlE5dia9BykQITHHHN2jibCu5Gq0p05LoicU0loOpv7XJT77uZgPibibibiaaHfK5NABBLWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Beyond Hsueh链接：https://zhuanlan.zhihu.com/p/16213981801本系列 blog 是有关大模型幻觉、知识、不确定性等方向的学习笔记分享，我会持续更新</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538367&amp;idx=2&amp;sn=e0230fd6e192503ebc94b26d5265f00e&amp;chksm=ea78f75e66baee21e6075c6b7d291f8b9ab8bfc01792ea5558245d5ceee1cabb7468aada1a81&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Apr 2025 14:41:41 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Reasoning涨点新方法：LLM「左右互搏」训练模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiapATcrAicCCmYlE5dia9BykQGb7ZrSl4HG1fbXbLpJsxI6icGSPSlDZ9tlKFxTJIbpZqlliaJlgM2WRQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>自我进化的新范式：用「左右互搏」训练模型！这一对抗训练的核心框架想象两个AI在玩「猫鼠游戏」：一个AI专门制造隐蔽的数学推理错误（比如偷偷把方程里的加号改成减号），另一个AI则化身「福尔摩斯」，火眼金</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538367&amp;idx=3&amp;sn=a8b4b73123153b6b2ef5cd97be37d60e&amp;chksm=ea05b3444bdd9b07859822d592a9c4e18eb592191f7a3b5d94f734f4c8149fdd78b1dfd8df42&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Apr 2025 14:41:41 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[推测性思维链SCoT：小模型“模仿”大模型，最高提速2.9倍，准确率几乎不降]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagh0MCSmj5RRdX2CVnFoeB1mJaJZQx8KUXY94LLBWxeru43RkrECTgiaJrT1xxpO6nCHFM8mb5m8QA/640?wxtype=jpeg&amp;wxfrom=0"/><p>现在的大模型（比如论文提到的Deepseek-R1）虽然能解决复杂数学题，但有两个致命缺点：体型庞大：动辄几百亿参数，像“超级计算机”一样耗资源；思考过程长：解一道题要生成几千甚至上万字的思维链（Ch</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538301&amp;idx=1&amp;sn=a10d91ccf6703a9d03d1893cfb4ba654&amp;chksm=ea20d817046bf5767356cde19a3d3cd88971fe1dfd0505e867d4df008e23011aa5468d62e96f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Apr 2025 12:08:23 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[When2Call：哈佛认为LLM也需要“边界感”，要意识到是否何时需要工具调用]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagh0MCSmj5RRdX2CVnFoeB1bha3zyVWMgSwLlnVNUxKCibiaM1mGIyI7iboMg1VTIAibrcs9xXvjaC2iaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI也需要“边界感”？工具调用背后的新问题如今的大语言模型（如ChatGPT）越来越擅长调用外部工具，比如查天气、查数据库。但问题来了：如果AI没有对应的工具，或者用户问题信息不全，它会怎么办？想象一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538301&amp;idx=2&amp;sn=d1dd1163ac6fb8989b1b9239365519ca&amp;chksm=ea18e0fa036ca15c1dc4dc1e178216fb6e77ffe8cb1469ae64914876aa850f0345a19d58188a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Apr 2025 12:08:23 +0000</pubDate>
    </item>
  </channel>
</rss>