<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[直播预约 | LLM Agent的“Windows”来了！AIOS如何构建LLM Agent的生态底座？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagMvu0icOXA3A9805pt7FKHD4uKodmibibtAiarJ7f4KQP6MLRCupwnj5LN2Du5ZPe1RXDkGFz99ic7q6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题LLM Agent的 “Windows” 来了！AIOS如何构建LLM Agent的生态底座？时间北京时间：2025.07.26 (周六) 10:00纽约时间：2025.07.25 (周五) 22</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541602&amp;idx=1&amp;sn=af3c9b30b2e9ee501dfd14f9b1799561&amp;chksm=ea2fbb206015482439ff5df4e392cd906d4cf1779f7e5c982545fbde8b3b7c3781a40f3b0556&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Jul 2025 03:08:06 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一个标点就能迷惑LLM-as-a-Judge！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadDdzCvQ8ZxYfnpA8sRSAOFR1ahsuPibSviaXVgfjicPoicqFbfhSU4XmJR5ckKmGOeOmiaWDFnYvysZQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）作为自动裁判（LLM-as-a-Judge），因其能灵活评估开放域答案质量，正迅速取代传统规则型奖励模型，成为强化学习可验证奖励（RLVR）的核心组件。然而，本文揭露了一个惊人漏</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541393&amp;idx=1&amp;sn=55cce3c6a144487e5c5d337849fc2dbc&amp;chksm=eabbb52b534fa011b56113bed88c316688ac3b2f125f2a758ad64fa11a6feab08b0dc118cc85&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Jul 2025 12:00:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Qwen数学"超能力"的真相：是推理还是记忆？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadDdzCvQ8ZxYfnpA8sRSAOkrJpSy8sQZnOREabOBZ8Pf7u3IZY08hr8ia47vtBxYniccBAxCHqs5qQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，强化学习（RL）被广泛用于提升大语言模型（LLM）的数学推理能力，尤其在Qwen2.5模型上出现了令人费解的现象：随机甚至错误的奖励信号也能显著提高其数学评测分数，而同样方法对其他模型（如Ll</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541393&amp;idx=2&amp;sn=31c39ead61c2ff016202e6f7a859cb90&amp;chksm=ea4998f012cf4f5140f94633110c09c3c0541192466c796147d546d548fed52ce8b361d793ae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Jul 2025 12:00:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | 高效LLM：从训练加速、推理优化，到Agent自主任务]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiadDdzCvQ8ZxYfnpA8sRSAOYsBmBoEx64J93duoF0ErHY5SqotlPia5ibAicpCiaXYc7ORXexyzU1f90Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题高效LLM：从训练加速、推理优化，到Agent自主任务时间北京时间：2025.07.20 (周日) 10:00直播平台微信视频号：b站直播间：https://live.bilibili.com/2</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541363&amp;idx=1&amp;sn=69a829809f14d300857736a42401fa55&amp;chksm=eab70fe686218870f62ae079ed46f6de322b9b83333af44f84ceb0c452b3099084caa4f24c6a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Jul 2025 04:10:23 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[快慢Reasoning综述！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaCxQ2V65sTjTbvH3soGVdlQHVPVT8T6vRicI6g4lavBjmqjJicrS5uURbaugHCHfzL9w6ibB23zkbhg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLMs）虽在复杂推理任务中表现出色，却存在"无差别计算"缺陷：对简单问题过度消耗资源（如用微积分解1+1），对难题却因计算不足而失败。这种低效性严重阻碍其在自动驾驶、实时医疗等场景的应</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541213&amp;idx=1&amp;sn=9dbe6f412f8aab17197a8d2f67cc0071&amp;chksm=ea1c601ef2396f5928dfdbeffe2ecfdba26a0310898e27f7f32ce4247e7486171397ff60bb92&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Jul 2025 13:10:47 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML2025 | 揭示MLLM的图文联动推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaCxQ2V65sTjTbvH3soGVdl7074dNznUoGmtaaSmKPml6Ix7Mhe1H6c9gWibuH45yVCzSKXWq2nwnQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>人类在解决实际问题时，天然融合图像与文本信息：气象学家结合天气图与数据预测风暴，设计师通过文字描述构建空间布局。这种有机多模态推理（Organic Multimodal Reasoning） 是智能的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541213&amp;idx=2&amp;sn=d509f75608344a7d3dbc672560eab317&amp;chksm=ea255985eb60ae1aa0e7f9308e9de6d4e56d81f8f84779a3e3936ae523dd54a3b93f8fee9dbf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Jul 2025 13:10:47 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[揭示隐藏联系：RLHF/DPO即对比学习！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagLNn9vdYASMglCmY8fVaq1fkjeRYPNOKBfsRKA3sFibS0x7eIP9uPMn6iam1CFweKtIdZpQj1mZPuA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）如ChatGPT、Claude等的强大能力令人惊叹，但让它们的输出真正符合人类价值观（如安全、有用、诚实）却是个巨大挑战。当前的主流技术是基于人类反馈的强化学习。简单来说，就是让</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541173&amp;idx=1&amp;sn=3ee8a80171fd817681e4122125c67777&amp;chksm=ea6cacd1dd3c8244780e0e1c2481d03ac6ad3938b9daa87c379d560f99599dace502723f53c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Jul 2025 08:59:01 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Evaluation is All You Need：评估设计的微小差异如何扭曲结果]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagLNn9vdYASMglCmY8fVaq18diatMAzTO7McrjM7e9ysaiaRys33G3xJicEn06zuC7faeh5rrRa033Qw/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇标题致敬Transformer经典论文的《Attention is All You Need》，直指大模型评估领域的“灰犀牛”问题：看似客观的基准测试结果，实则对评估细节极度敏感。研究团队以开源社</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541173&amp;idx=2&amp;sn=bf9d9cd359ea949d56b2d4f4144e9732&amp;chksm=eafda80f792978444420fbabe2ea6816e262c263cc9d90a9bb3116dc1a7117921eb04c21b515&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Jul 2025 08:59:01 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[抛弃预定义Tool，首次提出通过动态工具生成的Agentic多模态Reasoning，破31%涨幅]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahKo2F5CAPgSliajRrjm4ERZjiawiboBlfNufzlsqd7ARB66UOL2Ax2mjlMgBcBkz9DDwz5dESHogicQQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>视觉推理任务中，传统多模态大模型（MLLM）常依赖预定义工具（如目标检测模型），导致灵活性不足与领域适应性差。例如面对艾宾浩斯错觉（Ebbinghaus illusion），GPT-4.1 因套用固有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541132&amp;idx=1&amp;sn=9c6b505219c1908735d6760f602b2450&amp;chksm=ea5627bde12b2b867da79f157a7a89b066a288038cd1279bac9835128ec7b3aaa878fce892ea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Jul 2025 08:08:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepMind揭示Reasoning内在机制]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahKo2F5CAPgSliajRrjm4ERZtHSrz64IUGGKicMibqA3b2AccTYRW7MafgOkkK3nEYrO6N28p3yV86pA/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大型推理模型（如DeepSeek-R1、Gemini等）在数学、编程等复杂任务上表现惊艳，但其内部推理机制却像“黑箱”般难以捉摸。传统模型生成答案像“直行单车道”——步骤线性无回溯；而新型模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541132&amp;idx=2&amp;sn=c982cd4094ed37d4156a1c80241f9326&amp;chksm=ea5d4daeae38acf3b77972b6d19239ffff17e64be5db2d200c6de07309cb6255167475d2cbba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Jul 2025 08:08:27 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[除了prompting外，不动参数，如何改变模型行为？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagK6zOBC2gr2fgJJmjWxeGgOz3Rbvy0aWQev8PZeQhK6sNkJicYOovGveOeSXgVcpxJ8eXgBZUuMXg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（如GPT-4、Llama等）的生成行为控制是确保安全性和可靠性的关键。传统方法依赖提示工程（例如设计系统指令），但其存在三大缺陷：人工依赖强：需专家反复调试提示词；脆弱性高：轻微输入变动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541096&amp;idx=1&amp;sn=352758a8f6ed7b2d01c89676009acc00&amp;chksm=ea76850fa5a080fb38cf2a5eb70af3f72d08a361ce29bc87b41c0da61026a3fed0e919288422&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Jul 2025 15:41:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出小型LLM才是未来，并将重塑Agentic AI]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagK6zOBC2gr2fgJJmjWxeGgYls6tSibxe4641yicYJ07UKVcMsqSUqMAf0kYvFyO4bYiaBGf8U8I8oPA/640?wxtype=jpeg&amp;wxfrom=0"/><p>人工智能代理（Agentic AI）正以惊人速度渗透企业场景：超50%大型IT企业已部署AI代理，行业估值在2024年达52亿美元，预计2034年将突破2000亿美元。然而，当前代理系统严重依赖大型语</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541056&amp;idx=1&amp;sn=222b0f6c007f57f70060cf2cde363358&amp;chksm=ea70ac19c2bd92808767eb570c11fdcb5f3a46e906e68770b7e92fcbbf8ea3ba051e71ceffe1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Jul 2025 07:22:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[中国中文信息学会大模型与生成专委会2025大模型战略研讨会成功举办]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagK6zOBC2gr2fgJJmjWxeGgiajCMdEd0sqW18ELpBFjcnURtU3tIUolibugNNJaqkvqcH2vZsoOLEeQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>2025年6月27日，中国中文信息学会大模型与生成专委会2025大模型战略研讨会在哈尔滨成功举办！本次大会由中国中文信息学会大模型与生成专委会主办，哈尔滨工业大学承办。大会旨在讨论OpenAI-O1、</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541056&amp;idx=2&amp;sn=da508178a902f079f0d1514e257c3f01&amp;chksm=eadbbeaad2a8fa2989f94fa27486fe66e3497ab7bc28e8b2df6bec33cab441e4aad0c4d0634a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Jul 2025 07:22:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[综述 | 从“说出来”到“脑中算”：Latent Reasoning的范式跃迁与无限可能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag6ia6icSUtGgTiab93Gs1Xv7rNVRIhnd624NY5SBXvicEIFXM9nbAoncPAukb8FSdmXFGpXZ7J9ibwR7w/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）在推理任务上表现惊艳，尤其当它们使用显式思维链（Chain-of-Thought, CoT）时——即像人一样一步步写下中间思考过程。这种“说出来再回答”的方式显著提升了模型的性能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541037&amp;idx=1&amp;sn=2a9490e6bd3d8519914a4a615942e68d&amp;chksm=eab3aedd0971fd0c85edec028cedb09246a86b1da74ea3a4e7c611a5a237876d1c8ddedb373a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 12:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI"学霸"也解不出高中题？耶鲁、复旦发布MMSciBench，揭示AI理科推理能力短板]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag6ia6icSUtGgTiab93Gs1Xv7rToo2XtLkIyLMdWhIZpeSYsXFJkedHDzbRZyJ9B8YGMdicKTCMkJg9lA/640?wxtype=jpeg&amp;wxfrom=0"/><p>一份由耶鲁、复旦等高校和机构学者联合推出的全新中文多模态科学基准MMSciBench，通过系统的评测，揭示了当前主流模型在复杂科学推理能力上的具体表现。论文链接：arXiv: https://arxi</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540949&amp;idx=1&amp;sn=1ea01594f82c1251690b922f264ca33e&amp;chksm=ea47522c9a9bcffef13b078fd5ccc6581a1b4d106363da721f354c0c7ab1d1effb3e73ca9059&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 08:19:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[UIUC提出隐式监督新范式：无需标注/RM即可全面提升多模态Reasoning的感知能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag6ia6icSUtGgTiab93Gs1Xv7rNYqVnafouyfompIib5K1P005DgzgFD7JwFbIyKasl6SNdSeVF8OwbdA/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型多模态模型（LMMs）在视觉问答、图像描述等任务中表现优异，但在复杂多模态推理（如几何证明、图表分析）中仍面临挑战。论文揭示：67%的错误源于视觉感知缺陷（如误读空间关系、标签关联），而非逻辑推理</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540949&amp;idx=2&amp;sn=ad45e5aa7ee5a639b0d12fd100c8ecac&amp;chksm=ea9107790aad4c6bcb4dfbc9dce3b992b97cfd182285b5a1ab7e70d457269f65d8948d223e99&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 08:19:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM长文本内卷，谁是真英雄？告别跑分玄学，我们需要一把“公道秤”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhlCZrXsaqfPAaGytWdWU93ibiacTgrEtHUPqicdrfwbTbPa1icics4V0zjKgAUFya8HTN2NKaG4FBDjA/640?wxtype=jpeg&amp;wxfrom=0"/><p>TL;DR: 我们做了一个统一的长上下文评估框架，兼容目前市面上主流的benchmark、model、长上下文加速方法，帮助社区高效地、“真实”地测出长上下文模型的能力。欢迎大家使用，提供宝贵意见（欢</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540918&amp;idx=1&amp;sn=3660b77338c99a39469321d4822cd366&amp;chksm=ea87b5d86b6a1a3d76f7c65941aa46e5cfe494ef23b54052c38c97c3b60402ce7f78d4c677bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 05:20:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | 从大模型的安全对齐到欺骗性对齐系列工作分享]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajhlCZrXsaqfPAaGytWdWU9LFYyHHrHz9S9N8HicBrLIdYQp1lQWAnfW0DuNKWLbBmLaX5ToghPFBw/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题从大模型的安全对齐到欺骗性对齐时间北京时间：2025.07.11 (周五) 10:00直播平台微信视频号：b站直播间：https://live.bilibili.com/27784098（点击文末</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540918&amp;idx=2&amp;sn=7829b1cfc8911746fb1535be5780d7ec&amp;chksm=ea6f7101006cfb0f199d074f0ba6cf7c263afff36c7d48806c98fc41b6a8a792bde9150019af&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 05:20:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[奖励模型迎来预训练新时代！上海AI Lab和复旦联合重塑RL奖励机制]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaJSJaia9VUiaQQLoBnQLw5NsbqV0UTGXu5jibEW1xIaLdgqMcBQhdUrBxFyJkh7kWbnuhn5Cw4eXibaQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）的精调常依赖强化学习人类反馈（RLHF），其效果核心在于奖励模型（RM）能否提供精准的反馈信号。传统RM面临两大瓶颈：数据依赖：需海量人工标注的偏好对（如"A回复优于B"），成本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540895&amp;idx=1&amp;sn=702c3ab7347f598da37d663cc6b3d0f1&amp;chksm=eaebf5e3e96cea8e2cea2b05189a2194fca3631a9e423062e4975ad1959c1a56f7e746e77010&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 07:57:01 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[重塑AI记忆边界：MemOS开源！时序推理较OpenAI提升159%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaJSJaia9VUiaQQLoBnQLw5NsbD7Tr78aYvnotrn0JF2MQyAGALGic5L4yJ5GXHZvSd9HOlKicIJVfggg/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型记忆管理和优化框架是当前各大厂商争相优化的热点方向，MemOS 相比现有 OpenAI 的全局记忆在大模型记忆评测集上呈现出显著的提升，平均准确性提升超过 38.97%，Tokens 的开销进一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247540895&amp;idx=2&amp;sn=cc14a44916fad313ef977ea4ff2b47c1&amp;chksm=ea19e540c604c4bb66e547fdcd1a5591179acc8f7be2512c5e7fa1c706e7eb84e8a481db3ce2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 07:57:01 +0000</pubDate>
    </item>
  </channel>
</rss>