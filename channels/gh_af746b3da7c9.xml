<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[【非官方】NLPCC2025线下交流群]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajicJlRr5ibwdeaLdtqxBNPibYj0oFldW8EqtXyQKx6s8wbYLssJvfodp091SFJ6b4UN02sFRtOBhtkg/640?wxtype=jpeg&amp;wxfrom=0"/><p>从今天开始的NLPCC2025在乌鲁木齐举办，持续3天，有小伙伴在线下的可以进群交流下，大家互相认识，互相学习，互通有无。（非诚勿扰）备注：昵称-学校/公司-方向/会议(eg.ACL)，进入技术/投稿</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542129&amp;idx=1&amp;sn=1f7ea745e4a69ef9e407407e838c3686&amp;chksm=ea78709d9f09be8cfe60739202dc4ded6099e3f0c970a1106da898149b80f79a34dc2892f1ca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 03:24:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[解析天花板？TextIn xParse如何为RAG打造「零损耗」知识管道]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahTUNhnnnBZJ0fVpBOXg3dlRheGMf9P1ic2Cmyy48wBrERzGIbcaFANP800E1mwEQqFKjMvgb7ggCg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在AI应用极速发展的当下，LLM（大语言模型）与RAG（检索增强生成）系统已成为构建智能问答、知识管理等高阶应用的核心引擎。然而，许多团队在项目落地时遭遇了现实的挑战：模型的实际表现——无论是回答的准</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542121&amp;idx=1&amp;sn=a348cbc0f3fb5871de7ca20f42c486ce&amp;chksm=ead717a9a6019a62b1782de33e8f9f5d6c6c2c52a69be15fc67288e40e9c7d04cde1dc77974a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[推理路径的动态调控：让大模型学会“恰到好处”的思考]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahTUNhnnnBZJ0fVpBOXg3dlUGWPicKsu7eqNI6SFe5tyH1LGUEpNia9aPibDiavIBficz1dK1c9jwX7bJg/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前大型语言模型（LLM）通过思维链（CoT）提升复杂任务推理能力，但研究表明其推理路径存在严重冗余——例如反复验证或无效思维跳跃，导致计算资源浪费和“幻觉”增加。论文：Test-time Promp</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542121&amp;idx=2&amp;sn=25095d5eb791cfd37792948594d8b3c4&amp;chksm=eab95bed5f1bd82ada4386498c7bef5f81e70068793f0271390dcaf776101948a8b32138c06e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | 普林斯顿研究员王心怡：大模型如何学习？揭秘LLM"记忆"与"泛化"的平衡艺术]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaodCokNbZaMII5yGicmAA5XEYyiaulBwNc6PLBqtynZCrjiaVyzwyPAgfaDMrv8Y3RGdyDGDKl6FicnA/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题大模型如何学习？揭秘语言模型"记忆"与"泛化"的平衡艺术时间2025.08.09 周六 10:30 北京时间2025.08.08 周五 22:30 纽约时间b站直播间：https://live.b</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542034&amp;idx=1&amp;sn=c28070fa79ba8b0e78a6b7c53c06b03d&amp;chksm=eac968f098c6f41c7e9c0e5e780787e5dfaccc0a5aa324a075d11b2931a1625142d9ac34cda4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 12:36:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[27M参数战胜GPT-4！脑启发的分层Reasoning引擎如何重塑LLM]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaodCokNbZaMII5yGicmAA5XwX1LDEk0pGVGxQVEG8y9yibRR7JHdCRNcwEibJWs69PIsxTl9IryEicNQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前大语言模型（LLM）虽在语言任务中表现卓越，但其核心架构存在根本性缺陷：推理深度不足：Transformer本质是浅层计算（类电路），无法执行需多项式时间的复杂算法（如深度搜索、回溯）。依赖思维链</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542028&amp;idx=1&amp;sn=9cbc2a76eda6a7ddc30aa2facdc3ed7c&amp;chksm=eab95e095b1c8f53abf754b9fcadafea6e947ebe3a6be987b6fdf2c234240e8a3bbe967f0033&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 06:47:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[人格向量：大模型性格的数学解码与精准操控]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaodCokNbZaMII5yGicmAA5Xgp6Crqe2Uh4fw8dEIGxbgtdDRnzpIoEROpwp7BexwedGMzwLjhSmhQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型（如ChatGPT）通过"助手"角色与用户交互，其设计初衷是保持有用、无害、诚实。但在实际应用中，模型可能出现危险行为偏移：微软Bing聊天机器人曾威胁用户，xAI的Grok甚至称赞希特勒。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542028&amp;idx=2&amp;sn=e96fcc66108e94a70f083f5870383585&amp;chksm=eafea9c8612175f78921ecb6eebae00015205ac49c749036e2f8e8e4f07d4b7bb5383cf96d5b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 06:47:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超越人类标注，Meta提出CoT-Self-Instruct：如何用"推理式自进化"重塑LLM训练]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaUvgGdbicAflyj4anQ0CqSBjIkfmRCOWS53uZjYTbF7sib8xPJadg464YI8wnIX9tKKoIDMqAOVnCg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型（LLM）的爆发式发展暴露了核心矛盾：模型越强大，越需要海量高质量训练数据。传统人工标注数据面临三重困境：成本陷阱：专业领域标注（如数学证明）需专家参与，成本指数级增长质量瓶颈：人类标注存在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541995&amp;idx=1&amp;sn=b8762ed640aecb715834d0dee6a1ec19&amp;chksm=ea495c72602358b93af5b89a5b6fd77df36435882ee57f7c3a99d40db3de84806d88f666dcc8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 12:05:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM-based Agent的代码生成综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaUvgGdbicAflyj4anQ0CqSBiaoUzFKr1g94vHvI6nbVjnbFuo2F6JcWatuyVwcRCBOibR5HnlMRJTGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下，未来编写软件不再需要逐行敲代码，而是像对一位超级智能的“数字员工”描述需求，它就能自动分析、设计、编码、测试，最终交付可运行的软件。这并非科幻，而是“基于大语言模型（LLM）的代码生成代理”</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541995&amp;idx=2&amp;sn=d07d00c84784a98074deee63b43ce420&amp;chksm=ea0faaf5f25f0fcf64f8d7751626b2109601ecc58f6fad953efe4230595d132d8a3fafabcaf2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 12:05:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[语言反思>强化学习：伯克利新架构碾压传统RL]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagIDIKeko9hPFSojP2opr8h3jnF3ElShdcINRhaDWM57WgOawSgCibpZyoRhWxfXOoKZCB95BwtFag/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）的下游任务优化长期依赖强化学习（如GRPO算法），但存在万级计算成本高企的痛点。论文：GEPA: Reflective Prompt Evolution Can Outperfo</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541951&amp;idx=1&amp;sn=b7c889a9a52dfbe10034590b9b5af695&amp;chksm=ea5ea22282d612293039a930445cec9659175b008c16f3339c599ff56befcda8a69f59726ac8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 11:45:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌提出破局Self-Consistency计算瓶颈！LLM推理效率革命，推理加速不牺牲精度]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagIDIKeko9hPFSojP2opr8h4QVAyzzdbRyP5LPWrrHmY8DI3uVejQ9Meiar3xX1QjsO4ygeEmhA6EQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型（LLM）在数学推理等复杂任务中常采用自洽性解码（Self-Consistency）：通过生成多条推理路径并投票选出高频答案提升性能。但该方法需采样数十条冗长路径，计算成本极高。与此同时，L</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541951&amp;idx=2&amp;sn=f9c96bd98c5f6d5d0e52d6f661047920&amp;chksm=ea9fc1aa5038f723c10cbf351a8132b87c3c8e7bafbdf401505ce783bf3bfa6b88e261231d7f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 11:45:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 分享会报名收集啦！欢迎分享与NLP有交集的工作哈~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagIDIKeko9hPFSojP2opr8htXgz0jFXFPaR669bvng7t7uTQGktLzTjGpHvialdx9JbUhE88LIcp6Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着多模态研究的深入推进，计算机视觉（CV）与自然语言处理（NLP）领域的交叉融合日益成为前沿探索的核心方向。鉴于此，NICE将在八月初举办ICCV 2025论文分享会。我们诚挚地邀请大家踊跃参与，共</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541951&amp;idx=3&amp;sn=204cbe5f0f921ee6e6c2582f47179257&amp;chksm=ea4ea574966640f176c052af07e0f2cdc06ca8021052a95904ea5bde1b5d0f93a1520fd2e987&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 11:45:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[半量工具，双倍效能：ARPO革新大模型强化学习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah8oqibuibrlghqm4P6Uy4u8RnSzCkdicTkCnbpEAJ7sOmbib3FJMtCavdUUBibyhZ6Zx2YSib8FJYUXU5w/640?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型（LLM）在单轮推理任务中表现出色，但在多轮工具调用（如搜索引擎、Python解释器）场景下面临挑战：传统强化学习（RL）算法过度依赖轨迹级采样，忽视了工具调用后模型行为的不确定性剧增。这导</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541910&amp;idx=1&amp;sn=4061918d122507be2d3f4240080804a1&amp;chksm=eade0a82e21507b52bd514a14377d5a6338f7632c116db1d92ca7fd51e69a4a948cc5bbcd140&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 12:06:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ScreenCoder：视觉-代码对齐新范式，为多模态程序合成开辟道路]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah8oqibuibrlghqm4P6Uy4u8R0ALfib72cq6A3rwLtDN3Vs3KibANU8mSqgBejSdL5tbJu0RoJUoZyMxw/300?wxtype=jpeg&amp;wxfrom=0"/><p>为什么需要更好的UI转代码工具？前端开发中，将设计图转化为代码是耗时且易错的过程。现有基于文本的AI工具（如GPT-4）需冗长描述才能指定布局细节，而视觉语言模型（VLMs）虽可直接解析设计图，却常出</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541910&amp;idx=2&amp;sn=eea08998a08755a047aa959ff9a1339c&amp;chksm=ea3f4ae065e477d6b07367b82bb6d1cf4467837edf60c093f7d013c8260fd6f618f13f092318&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 12:06:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[招聘 | 若干百万年薪的急需岗位：Agent、LLM开发、研究员和Infra等]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah8oqibuibrlghqm4P6Uy4u8RdXrpJAXSsVyNBmvFicM1UERzxmg7qjwqBbcLx2jQ1FV4S1LZZur4Vxw/300?wxtype=jpeg&amp;wxfrom=0"/><p>若干急需的高薪资岗位！都是头部企业（科技/量化）公司。Agent高级开发工程师LLM应用开发工程师机器学习研究员AI Infra 工程师邮箱aijob@fintechgl.com （备注：姓名-岗位）</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541910&amp;idx=3&amp;sn=a5f7c3fb16a01f31c2fa3f23b5b21376&amp;chksm=ea2538fd83172f273efe7da5646d61588974e1ede3011b42ea3e275a9a67cc5e0d683881eeb7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 12:06:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[同样的示例，放在prompt的不同位置，竟会导致模型答案天差地别！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagvycRmVTb3dfCLWD2yUmYuk6MtgXDL8dteCuHgiaMHrMNPNGonW7UexB7t6Hc0wg1r55krgWTZFGA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）如ChatGPT、Llama、Qwen等，拥有一种神奇的能力——上下文学习（In-Context Learning, ICL）。只需在输入提示（Prompt）中放入几个任务示例（</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541871&amp;idx=1&amp;sn=cb15910e6bb956fa4f425a0ed2374576&amp;chksm=ea32d1247879c0eae4d5414cd2dd7349f0b7e6dca1c44ee90c238ddf8486adfaf83d5eb1f797&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 08:56:17 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[让MLLM学会主动观察！视觉感知Token引爆多模态进化]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagvycRmVTb3dfCLWD2yUmYurDibXbAEErg5MPddTJo1BLeZbqWZsC94blibicdRwUtcTPM8rlvrGthDw/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前多模态大模型（MLLM）虽能处理图文信息，但其视觉感知完全依赖预编码特征，缺乏自主控制能力。例如：无法主动聚焦图像关键区域、难以抑制文本幻觉、空间推理易出错。论文：Introducing Visu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541871&amp;idx=2&amp;sn=a4a143f51fc1dc485da5344524cb73f1&amp;chksm=ea64b9437c364bc4ca830765beee830365195b3ea5297ea384cdcc6ef672ef739cf8c258d3fb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 08:56:17 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 分享会报名收集啦！欢迎分享与NLP有交集的工作哈~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagvycRmVTb3dfCLWD2yUmYun6SFzGt5yR2ibnKicrET7QdSl7OcqCkldlttGSDUZZhibDRiaibz5cuEQGA/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着多模态研究的深入推进，计算机视觉（CV）与自然语言处理（NLP）领域的交叉融合日益成为前沿探索的核心方向。鉴于此，NICE将在八月初举办ICCV 2025论文分享会。我们诚挚地邀请大家踊跃参与，共</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541833&amp;idx=1&amp;sn=3650a209510ecec3e2f7e47e4e038aee&amp;chksm=ea8685b55d9cdefa78e3c23f26f6a6e5d4cecdbd20d8d61df4cca15bcbabf60e344efa3426c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 03:32:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI医生能看片：华为瑞金RuiPath病理大模型评测体验]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia7DyZ59UYAzw2y7lFoo73ovfNiaTLwr2TRia1qt9XWzF9m6gnDPq3lWuiaSaSSx2hEHGZC8W6qybaLQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>引言哈佛医学院Faisal Mahmood在24年的Nature Medicine上面连续发表了两篇病理基座模型UNI和CONCH, 吸引了一大波研究者来从事病理基座模型的研究范式。在期刊，大家通过关</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541827&amp;idx=1&amp;sn=0e4f2464e33b832ea67d3b0cc196491a&amp;chksm=ea5c2ad6af5b039092b04bece2b1c4c8c5e92f199228615ee2a2bfbb2120dd2a9c6575f6def1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 11:32:14 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[新一代RAG框架DeepSieve：让LLM成为知识导航员，破解RAG异构检索难题]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia7DyZ59UYAzw2y7lFoo73oDhSXNR0c3op4dRqCOGNrH0cMLrG5ial2uT0lWy4wEjxyMBFWwL98zeQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）在数学推理、常识问答等任务中表现出色，却难以回答需动态知识支持的复杂问题（如实时新闻、专业领域查询）。传统检索增强生成（RAG）通过引入外部知识缓解此问题，但面临两大瓶颈：查询侧</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541827&amp;idx=2&amp;sn=cda324fc08334616fbeb93ed34205cc1&amp;chksm=eaf631c962137b8a0c9af3bf57655254751756694f01079d994ab493b0fcb43e7d989505446f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 11:32:14 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[96.3%准确率！Routine框架：让企业级Agent告别“不靠谱”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia7DyZ59UYAzw2y7lFoo73oBoXbibqZQplWXUSJyrEHC0Lys4ia5gBhNCQ0EKTcoa0fib3JkRW5V6o5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下，你给一个超级聪明的AI助手布置一项公司里的复杂任务，比如“查一下新员工小王的部门预算还剩多少，并和去年对比生成报告”。通用AI模型（如GPT-4）可能想法天马行空，但实际操作起来却容易“掉链</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541827&amp;idx=3&amp;sn=55636e3649f7ec61f30096844d2ab88a&amp;chksm=ea3f01889cc33fd67db030e3e1df2dffa1f25ed198bd5ad8988a51d3059a703433ef5b363c99&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 11:32:14 +0000</pubDate>
    </item>
  </channel>
</rss>