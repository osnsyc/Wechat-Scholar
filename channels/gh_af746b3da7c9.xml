<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[从零到有：打造迷你DeepSeek-R1最全教程]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia6SJB7GrjjtB26BGUA8aqEA6hBN8Q8VAdJGZoKkqGsFWeBwZ7jN4rH8C5vuuCibEYv7FIhLK7NV7Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>打开GpuGeek算力市场，地址如下：https://gpugeek.com/login?type=register&amp;source=wechat_DLNLP_01其中最香的是RTX-A5000-24G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539238&amp;idx=1&amp;sn=52785c5ce8bf8169b3087d109a852f67&amp;chksm=eae23feb8fe70062995a23c046b0808bdee302fece8bacfff936abe4603a91e9ca69d8d56018&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 08:50:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL 2025 | 清华&amp;港中文提出 MorphMark：全新理论视角破解大模型水印效力与文本质量的两难困境]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia6SJB7GrjjtB26BGUA8aqE7icnWaDVISQkNbEMReYb6qeHHTTPOLibUsibeicwWLAPuqOoVAGEFiceuJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：MorphMark: Flexible Adaptive Watermarking for Large Language Models链接：https://arxiv.org/abs/2505.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539238&amp;idx=2&amp;sn=f42937219114bd79d418a432c2393b0a&amp;chksm=eac5e9ef12b01ce4b0e95cfb1752ebfa16f92429abf057a4334de3a7b1d74ddae32918e94748&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 08:50:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[在Think中边搜索边调整的搜索增强Reasoning方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia6SJB7GrjjtB26BGUA8aqE07InJpGGCdXXwsiczBrVnperhBmzxEXFSfElS80UFPSBsC5fs538wvQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>为什么需要“外接大脑”？LLM虽然“知识渊博”，但本质是“死记硬背”——训练数据外的信息它无法掌握。比如问它“2024年奥运会新增项目”，它可能瞎猜。于是科学家们给AI装上“外接大脑”：检索增强生成（</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539238&amp;idx=3&amp;sn=0dd675aef346c43f7670b3b4acc80e7a&amp;chksm=ea5058287f3db2b3cedb821f392e652c7f5870da170a2c92ccce8ad10c1a05fe46b740b38879&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 08:50:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | 无需训练，即时对齐大模型偏好]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiag98LoUGfvTHicRVK9jRYv4uk96EfBbJiaia1MvxSBZibv20npNEA7JJHo3b5v3ldtqtqMIlgW66gZ3g/640?wxtype=jpeg&amp;wxfrom=0"/><p>TPO：推理时即时偏好对齐的新方案 为了让大模型（LLM）的行为更符合人类预期，一系列训练时对齐方法（例如RLHF和DPO）通过微调模型参数来实现偏好优化。然而，这种“训练时对齐”模式不仅耗时耗力，而</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539202&amp;idx=1&amp;sn=0eed57d030fb967564ac635ecd6293cb&amp;chksm=ea23a5c1758b3fa2d9e33a2b45484abcf3be298e66bbd554288e05851075326d2568751fd525&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 14:18:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 Oral | LLM也有从众心理！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiag98LoUGfvTHicRVK9jRYv4SI1Qb1NTqNrOHYsN7xTjZhF3HvQdYrkicicZB3uOqmuYiaNib3QWiarCakQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>当你和朋友玩“谁是卧底”时，明明知道正确答案，但看到所有人都选同一个错误选项，你会不会怀疑自己？最新研究发现，大型语言模型（LLM）组成的AI团队，居然也会犯这种“从众”错误！论文：Do as We </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539202&amp;idx=2&amp;sn=41b0bea4575111a5626729fdc97fbe2d&amp;chksm=ea035f0438df5cea3499a833ff531c129b93d408bf1087cc63765263f900003085232214bea2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 14:18:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL2025 | 抓出0.1%的捣乱分子压缩方法OTT：近乎无损 超越KIVI，内存减6.4倍 吞吐量提2.3倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahjSlXD4qibHCzpgnVNuhNmgaoPdbpk4tb2sicfEibLz978rdGIkqibZsLxY8X0ThVS0XV35alvIjgV6w/640?wxtype=jpeg&amp;wxfrom=0"/><p>LLM 生成文本时，需要记住所有已生成内容的关键信息（类似“临时笔记”），这就是KV Cache。它的存在让计算复杂度从平方级降到线性级，但代价是内存占用飙升。举个栗子🌰：LLaMA-3-8B模型处理</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539160&amp;idx=1&amp;sn=cf1acd98d304b129d66b51f3b05020b9&amp;chksm=ea5ea8445246a2824098bee257d34f5f8bab93e6c61ffbae26030a875a895edf9fac7d0f1fe2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 08:09:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Reasoning新突破：SoftCoT++如何让LLM‘多想几条路’？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahjSlXD4qibHCzpgnVNuhNmgmBZelEQlzNjVhhAiciaEs40yBkdtjNBzibDmZ7k2GBcOvsc0lodo1bUeA/300?wxtype=jpeg&amp;wxfrom=0"/><p>LRM 的推理能力依赖“思维链”（Chain-of-Thought, CoT），即生成中间推理步骤。但传统方法在离散的token空间生成这些步骤，存在两大问题：信息丢失：每一步只能选一个词，复杂逻辑可</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539160&amp;idx=2&amp;sn=d27ce5cd589b1bf020fcabdb94a585b2&amp;chksm=ea0b129e2d969c0d2b1ab435fff220a19ad4c04c83c9a597836b11bbe660d69fe534f8180112&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 08:09:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FudanNLP邱锡鹏老师组-25普博/26直博/26普博/26保研 招生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahlhzvX5DAHVe5pUvFEZaj3I8A2AsRLhfrfuXxTtdZKtuwy8sXwIrQpXaJc6lUficCEXevgHHhZQag/640?wxtype=jpeg&amp;wxfrom=0"/><p>复旦大学自然语言处理实验室（FudanNLP）邱锡鹏老师组开放第二批2025年普通博士招生，复旦官方报名系统已开放（即日起至 5 月 25 号）。该批次招生拟入学时间为 2025年9月。 同时，实验室</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539135&amp;idx=1&amp;sn=22e6faf4fbba354ecc80c6923d4b9160&amp;chksm=eaf04a910ae8a51a4036ed1d68fdc706e21012afef99abee8101c2e801101cb2360c2abfda22&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 10:48:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态大模型集体翻车，GPT-4o仅50%安全通过率——SIUO 揭示跨模态安全盲区]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahlhzvX5DAHVe5pUvFEZaj33dL6ZtOnkSUOqia5YaZrcenI25vd8qlNKqElE2K5LvXY5wpXt0b5c3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着通用人工智能（AGI）日益融入人类生活的各个方面，确保多模态大模型的安全对齐已成为亟需解决的重要问题。现有研究大多聚焦于单模态风险（如有害文本或图像），却往往忽视跨模态组合所潜藏的安全隐患——即便</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539135&amp;idx=2&amp;sn=cfa3b789b365096529ec5a72b4bdad1d&amp;chksm=ea64b439a7e41197492f76298d1006a4f6e264f31aa58ca6e649c64edbf774332690fdc7000c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 10:48:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[苏州大学OpenNLG小组近期录用15篇ACL、2篇ICML等论文！招生贴]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah306xYta2M8cHhJfFqzp97FCicRJoOh3PoIVl5S8DMe8Xoh93azKQ6LVR22lPesqtBDQ3Pc7UMyHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近期国际顶会或期刊陆续公布录取结果，我们刚成立4年多的年轻Team苏州大学OpenNLG小组，共收获19篇论文录用，分别为15篇ACL（8main+7findings）、2篇ICML、1篇TACL（A</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539101&amp;idx=1&amp;sn=04f41a3e3b9fc2c2f667ef41fb3c82de&amp;chksm=ea4ebed7bd70a7b85af9b78a93100dc9cf9cefcba46652225677a7e5402d45b1fafd9072e2e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 14:59:26 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Qwen突破：用「并行计算」代替「堆参数」，新方法内存降22倍、延迟降6倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah306xYta2M8cHhJfFqzp97pk9mC9lPMqQ0OTHMFT8nzkjE3truCEvDLy8RTnwpWDPA7v8kcLcFXQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Parallel Scaling Law for Language Models链接：https://arxiv.org/pdf/2505.10475LLM 的进化一直依赖「堆参数」，但模型越大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539101&amp;idx=2&amp;sn=a6f6d4ecfcbf475195a3c7251303e5d2&amp;chksm=ea7cf4aa8be820a55eff7729fd3d10aac27af7ed0c6e2ca94cc962c2aa00afb3a3a3aac7d2a7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 14:59:26 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[完全从0开始，仅用8元+9h！即可训练出Tiny LLM全流程教程，包含Reasoning、MoE等]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajEib6TPfeUGlfZ3mPB17GmibibMdGolxcDrctjFlQIzc6tichYCPH09Dtu8IcBUNcxlM2nucPiariblGeg/640?wxtype=jpeg&amp;wxfrom=0"/><p>打开GpuGeek算力市场，地址如下：https://gpugeek.com/login?type=register&amp;source=wechat_DLNLP_01其中最香的是RTX-A5000-24G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538995&amp;idx=1&amp;sn=1d849e875791df98f860302e90b4cc46&amp;chksm=eaaf7db648eec7f2db329a8988ab1a736eec3dc119619bf7b019b0f3cf5eb516598301aad5ba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 04:37:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别Reasoning模型的“灵光一现”，推理能力可控了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajEib6TPfeUGlfZ3mPB17Gmibia7icywNxnvicVKqk6gNePobduS3Q4MplReCHLb0BVQXHR7eoia8fk4SYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>为什么说模型的“灵光一现”不可靠？当前像GPT-4o、DeepSeek-R1等大模型虽然能生成复杂推理链，但它们的“高级操作”（比如自我纠正、反向验证）往往是随机触发的，就像突然的“灵光一现”。这种不</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538995&amp;idx=2&amp;sn=a3e25d61998452eafe08d0d5eff3cc13&amp;chksm=eab925aba321d6f85fe5592c25364b624bc9c5afba88ec8bc25ee2754a5b610ff2e1d9f14e40&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 04:37:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL2025 | 代码助手火了，但安全吗？所有模型评估结果都很扎心]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajEib6TPfeUGlfZ3mPB17GmibyyxvWS5T6icqA53nRdavIOHUaJEDEykDPtNROBicSIqroxicH2ibbVOtZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近，GitHub Copilot、ChatGPT等AI代码生成工具火遍全网，程序员只需输入需求，它就能秒出代码，效率提升肉眼可见。但问题来了：这些生成的代码真的安全吗？论文：Can You Real</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538995&amp;idx=3&amp;sn=70d1ccfa41f6b2adac05de8281e48b76&amp;chksm=ea2572efcfb6b4e3c6cc1d3eb26a4c0c56d7329259b090e57f1eebb58462e3e047214ee78b90&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 04:37:02 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[清华刘知远团队：高质量LLM训练数据获取新方法！成本降90%，性能大提升]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaQhsTaRQf4dIBrrqefqpGtYkKiaK0IMl2pnxPUq6oZdDPbmSxWklZVVFpgBdZVbNmDBiaMV7R2sJOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>如果把训练LLM比作“养孩子”，那么数据就是“营养配方”。过去大家拼命堆数据量，但现在发现，“垃圾食品”喂多了，LLM也会变“笨”。论文：Ultra-FineWeb: Efficient Data F</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538857&amp;idx=1&amp;sn=ec04bf019c8147eb4db589d5fc9b23f9&amp;chksm=eaf492d31bbd0699449a771a92ca506f1e3f4f1218fcbcca553bcbd3791b1691d8e64e23c85d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 04:52:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[14小时近500 Star！快速进阶LLM/AI的必读系列]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaQhsTaRQf4dIBrrqefqpGt38pDFMIzTyoKlj2anOicBibFQ8tZiaAT5obIibX48Mgrcsd3xZhpP2JODQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>TokenizationByte-pair Encodinghttps://arxiv.org/pdf/1508.07909Byte Latent Transformer: Patches Scale</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538857&amp;idx=2&amp;sn=57bbfb82c1def2a8b2c80a772bba5b6a&amp;chksm=ea6a91d6c2df26d3bd23788d53590b6164130859afa5fc3f8aeeee766a5af01362d7fba36bc2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 04:52:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[模型宣称的“百万字处理能力”是真本事，还是营销噱头？LongCodeBench揭露真相]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaQhsTaRQf4dIBrrqefqpGtge8mUxhBTT94ruGEeSXUyFR4FBBkIU9obpw50cZybR6sfp3ur7pJqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大模型的处理能力突飞猛进，从最初只能读几千字，进化到号称能处理百万字上下文。这种能力在现实场景中至关重要——比如我们希望它直接阅读整个GitHub代码库找bug，或者律师需要AI分析上百页合同</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538857&amp;idx=3&amp;sn=91cc892e9b6c74c6ad36743ebfbb2bbf&amp;chksm=ea17d0e1358dc94a555114135a3a86a0f08e2ab7a275ff267cfd69cdd394256b3408a3e26247&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 04:52:32 +0000</pubDate>
    </item>
  </channel>
</rss>