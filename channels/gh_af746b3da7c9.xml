<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[16.8万篇论文揭秘：LLM如何血洗学术界，中美暗战谁赢了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahJckgYUic3hFiabZVcyTSI0niau8dM4zkjJ28z4icTo5L876P0wkaTD391TW2rjYNOUQMibibDZO0zKa2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>过去6年，AI领域最火的词非“大语言模型”（LLM）莫属。从ChatGPT到文心一言，这些模型不仅能写诗、编程，甚至能帮科学家搞研究。但LLM的影响力到底有多大？这篇论文给出了答案——研究者们分析了7</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537511&amp;idx=1&amp;sn=187aed686715eb8a1407e62f51379cac&amp;chksm=eaa12db119a685cd0c39d4fe9058628f2ea297ebec17bb5256c4e660bf2b608086c95ed599ee&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 07:30:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[啊？强大的Reasoning模型仍需好的prompt，性能暴增23%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahJckgYUic3hFiabZVcyTSI0nuyRcR0qrR1t6UmJKGKLcTaAxeLgibH0SW5TOHFo13WCIl3eupa4iapIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>过去人们认为，像ChatGPT这类“大脑发达”的LLM模型，只需简单指令就能完美执行任务。论文：Revisiting Prompt Optimization with Large Reasoning </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537511&amp;idx=2&amp;sn=555bd400431da3f43c734cbb8e23fe6b&amp;chksm=eaddd2173860bdea98b18de1ddb4149386bc807029e65e22f6d88c7df847f241402e0471d86b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 07:30:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Vision-R1：激发多模态大模型的推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahJckgYUic3hFiabZVcyTSI0njiarX4eOt1QTm3151gicjQn8sRCKEicm1lHuXnGQqGOGd2O4Pbwa9sibyg/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：大家好我是爱因链接：https://zhuanlan.zhihu.com/p/29618155786编辑：「深度学习自然语言处理」公众号论文：Vision-R1: Incentivizing R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537511&amp;idx=3&amp;sn=c16bc3d531fe0408d70c637a4afd3123&amp;chksm=eaa67069369f95f6329b31923c94cc6dc0d870e03811f16d53358ba6a12ff58a26c964a16535&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 07:30:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM Reasoning能力最近大跃进？不，都是「水分」！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahOrNeqrs0Via5wLLIXiazmR18W6V0oQ5JTsgJ7VRsqemU5YGvvrUNP8bMyt4CJGY7OYcebBhahs9Bg/640?wxtype=jpeg&amp;wxfrom=0"/><p>为什么语言模型推理能力的评估「水分」这么大？近几年，ChatGPT、Claude等大模型的「数学解题」「逻辑推理」能力突飞猛进，各大实验室争相发布「突破性成果」。但论文一针见血地指出：很多所谓的进步，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537468&amp;idx=1&amp;sn=8c7063c36b04dd8b6b6769f69945834e&amp;chksm=eab8a9de51127c45fb96fffbcd16593a6c7a2f3ce34553b5c066fcdcf4dec4af7b9c1f06620d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 11:08:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[车万翔老师的《自然语言处理：基于大语言模型的方法》得看！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahOrNeqrs0Via5wLLIXiazmR1cTSSmx9yw0iayNzI6H0HpL7MaPpK30AKIxUpwhB8nAgHp3uibe5RXKEQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型的飞速发展离不开自然语言技术！而如今的自然语言技术，也随着大模型的发展不断精进~~曾经的自然语言处理可能是基于深度学习、预训练进行，而如今如何基于大语言模型进行自然语言处理呢？想了解这一方法，就</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537468&amp;idx=2&amp;sn=0c7fb1b1e18b4e33283e0a7c1a205d01&amp;chksm=ea12875912f0fc366446f22464062764c8ca5bd8f02a9198f4419f7487c9c1541af1eb29aa93&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 11:08:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NYU发现Reasoning模型有第六感！可提前预判答案，少干活还拿高分！几乎无损]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajDYSnzruBIl3bTLM9FhibZqsEfsib7ssMjUSMcuw4ibs19nrsibRMW8NT6TANGAWM72Ijn5y5wzxjBrQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>老话常谈，推理模型的“过度思考”是什么？比如解一道数学题，它明明已经算对了，却还在反复验算，甚至尝试其他方法。这就是论文提到的“过度思考（Overthinking）”现象。论文：Reasoning M</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537446&amp;idx=1&amp;sn=2fddb78cac861641065e53bd35879550&amp;chksm=eaa85248c3e0697cc4b6780c9e4767d9fe6ef385a792221e936445df2f0e0c77432cfd216e56&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 07:07:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[想得久≠答得对！LLM应该自主决定Reasoning长度！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajDYSnzruBIl3bTLM9FhibZqK31DCD5KqPEIINODBicoWJ0TO80Q85t1HEd03InYYOoqBCia8ymKhbJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>想得久≠答得对！你可能以为，让LLM像人类一样「仔细思考」就能提高答案质量，但最新研究却打脸了——大模型想得越久，可能错得越多！论文：Towards Thinking-Optimal Scaling </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537446&amp;idx=2&amp;sn=b9cf754049700fd2570c6722ffb3790d&amp;chksm=ea0dd4573aace72d7f8c21c866a8aae1f31d3e0838fa72db2ce256bb087ca2a7679492c3df5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 07:07:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA["反转诅咒"彻底解决，反向推理准确率96%！新架构突破LLM多年认知瓶颈]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajDYSnzruBIl3bTLM9FhibZqBZMCJB2mnmIo4xG8H8Ag00YIbwIZoU6iafVmCpsQOnnlSDY2KBOeABg/300?wxtype=jpeg&amp;wxfrom=0"/><p>"反转诅咒"：一个令人头疼的Bug：想象你教LLM记住"张三的妻子是李四"，但当问"李四的丈夫是谁"时，却一脸懵——这就是反转诅咒。论文：Is the Reversal Curse a Binding</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537446&amp;idx=3&amp;sn=fd216e134d77470a949f32d87f4e7e25&amp;chksm=ea36cc81fd1beefda51c6f02847206f99a4e555f41c165a7c9b0cfe3bb2dd45a3f1d82636c08&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 07:07:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[60.4分！字节Seed团队VAPO刷新Reasoning纪录：训练快10倍，错误率砍半]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfXPD1h1MraJmW7X4KIs0wvPjSLxpwQgEOHGtfDWmxSrQV652u3XZdxvbPZZNMiak9OpARsQicz0qA/640?wxtype=jpeg&amp;wxfrom=0"/><p>一个刚学数学的小学生，面对一道复杂应用题，需要一步步列式计算，中间错一步就全盘皆输。现在的大模型在做类似「多步推理」任务时，也会遇到同样的问题。而字节Seed团队最新提出的VAPO框架，就像给LLM配</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537403&amp;idx=1&amp;sn=44fd74084e00727dbb0b34dfa2db3646&amp;chksm=ea525d889aac3c20fd691f5360a482d4844322f721f465fe3a92f7939c80f760e58cb826bb52&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:24:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NICE54期 | 首个面向天文学的大规模多模态基础模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfXPD1h1MraJmW7X4KIs0wQUdUldwEsJWyr85vhtTicHrb1HW9CA9rmKVzlVUFHbALZvpiaUXksthw/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题AION-1：首个面向天文学的大规模多模态基础模型时间2025.4.13 10:30 北京时间大纲虽然基础模型在多个领域展现出了巨大潜力，但天文学由于其数据模态高度多样，目前仍缺乏一个统一的联合建</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537403&amp;idx=2&amp;sn=0f956105a7508673464c4014e0155373&amp;chksm=ea6a6c0f15230f4d4836a678ce535ff6bac1d6ce9f3177b3bbe3409bd3e51258fabfdfa33ecc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:24:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[如今的Reasoning模型都不具备批判性思维！简单问题, Overthinking！离谱]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfXPD1h1MraJmW7X4KIs0wDNacHZAr9AdUF7jlfJ3ykia5VmU7dWt2rmlvglfCIg6UsZgqhSl1Nww/300?wxtype=jpeg&amp;wxfrom=0"/><p>“宇宙终极问题的答案是42！”——科幻经典《银河系漫游指南》中，超级计算机用750万年算出了一个荒诞答案。没想到，现实中的大模型竟也上演了类似剧情：当被问到“a的值是多少”这种无解问题时，某顶尖推理模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537403&amp;idx=3&amp;sn=dfd078d4cb3509c32401374fc73877ad&amp;chksm=ea156bc6830e6da985c2775afde02fca59ec32f0053502b8eba8ae284be90a75b8f26edfd2d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:24:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[聊聊 LLM 推理引擎中，那些已经成为事实标准的优化方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfXPD1h1MraJmW7X4KIs0w2tIZbYibxCwbXr82XjhxjmHuyXXibKhMDsOuS6OdI8icXZEhXqo2gviauw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：进击的Killua原文：https://zhuanlan.zhihu.com/p/685706549编辑：青稞AI  本文主要是记录目前在各个LLM推理引擎中经常使用的一些方法。一、模型架构优化</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537403&amp;idx=4&amp;sn=8bc27d6e15e02fc02da6656b6d492758&amp;chksm=ea5eecd368e02de0f5d80f1df5809088fb478a57686ffc2bafb64d8b3b82b68d74748a6da0b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:24:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯AI Lab联合苏大提出一种新颖的RL评分方法，7B小模型暴打72B巨头！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaia3jFMqJljPtHqicib1WflKglhlBZSiazb1uTzKB0qMbsjRyJsdhmBEIJUgSxfHvias7RiaQiaFEZopIMQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>算是咱们领域最近的一个新闻：强化学习的“评分标准”升级了！过去，LLM学数学、写代码时，系统只能根据“答案对不对”给个简单对错分。论文：Crossing the Reward Bridge: Expa</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537371&amp;idx=1&amp;sn=3141287ba40978843a4dd5455aec44f6&amp;chksm=eaf93407fb56f1319536774587aee4ece2b7a7c9c64254e1e127c88213f09d40a6f9731f3fba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 09:48:44 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[你说量化到底伤不伤害Reasoning啊？一项实证研究]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaia3jFMqJljPtHqicib1WflKguYichxuC28Cft6tPvlGjnMAcbeo7vJeiaOuLNNyrJ2xBeG6iaRZ6jd9hg/300?wxtype=jpeg&amp;wxfrom=0"/><p>如今的大模型啥都能干，但它们的“大脑”实在太占地方——动辄几百亿参数，推理速度慢、内存消耗大。 于是学者们搬出了量化技术，试图把模型的“高精度思维”压缩成“精简版”，比如从32位浮点数降到8位甚至4位</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537371&amp;idx=2&amp;sn=c408395059b29bd3fadca5baabd77cff&amp;chksm=ea6138cfd8063e9ae9100ee4f2e2e890a4dc547f275aa7f517f0fdc1c18103c360b10c49e4e6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 09:48:44 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3倍效率学习的漫画书《StatQuest图解机器学习（全彩）》]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaia3jFMqJljPtHqicib1WflKgPsRvmPcusHYWibK2kqIJh9J8ib4khGze8NNDxYuI5DjT1UeGGvxHo3sg/300?wxtype=jpeg&amp;wxfrom=0"/><p>一旦关注了StatQuest，想必会被Josh Starmer傻傻的曲风吸引，艰涩难懂的机器学习瞬间变得妙趣横生，甚至会不自觉跟着教程BAM起来!!!这位油管关注超135万的大神，任教于常春藤院校北卡</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537371&amp;idx=3&amp;sn=8bea6fca73967813f2eaf6f57fb4cc4f&amp;chksm=eacc7157de9ce42ee7270107fc0ddef03d8fed2a4ae7c6e9057a1e08ab8273b08a28ae353226&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 09:48:44 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NAACL2025 Oral | LLM的知识边界到底在哪里？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZwwS54GXy4bRFKdgkHiaMianQql3gTLmdGgvjUftcNIsFxLyZzaIEGX5nkLSoxqH87frof8d98EIA/640?wxtype=jpeg&amp;wxfrom=0"/><p>当Agent的能力越来越超出我们的想象，当大模型的边界不断地被扩展到具身智能，深度研究等各种垂直领域，我们不禁发问，模型的能力扩展有尽头吗，模型对自身能力有感知吗，模型是否可以像人类一样可以基于自身的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537332&amp;idx=1&amp;sn=9bd6d8fcfacee67fcbc2b299890eee9c&amp;chksm=ea81dc902db67f015bdee721f7ac6f9b50a565cd49242c353043ba9f1347999df682913948d2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 10:04:51 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一个“打脸”结论！模型太大反而会损害推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZwwS54GXy4bRFKdgkHiaMiaiaYNTnyrMYJ5ribNHqHPvszLsqmwtvcMTgF4yRtu0dZD0OmLKJXCFT7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>你可能会想：模型不是参数越多、规模越大越好吗？但这项研究给出了一个“打脸”结论——模型太大反而会损害推理能力！论文：Do Larger Language Models Imply Better Rea</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537332&amp;idx=2&amp;sn=5bf2f4e400fb8211c44aa22557fca8b3&amp;chksm=ea0b03f1798ab2122e5e270013f4bd608c0b07bd2cd9a04bb311f85675d6cbc40ec3f2b56737&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 10:04:51 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[像人类一样看视频！VideoMind提出长视频推理新范式，超越 GPT-4o，AK两次转发！代码、数据、Demo全开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZwwS54GXy4bRFKdgkHiaMiaLrsCyQSmO9QPXbrnqmtETVnynsEpOT3XdMlia7kVATy301R0yR1JtcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>标题：VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning作者：Ye Liu*, Kevin Qinghong Lin*, Chang W</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537332&amp;idx=3&amp;sn=254919aa3f5825b4f12b5315b604e8e8&amp;chksm=ea0ddb1176b84d12a5ab93c7595ff56cee211d72f2696cf8482dc8d86c5606c643f6a718906d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 10:04:51 +0000</pubDate>
    </item>
  </channel>
</rss>