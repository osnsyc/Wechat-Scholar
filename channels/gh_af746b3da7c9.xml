<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM6qfKicTFQYIA3iacpJhzc9JvSOA6fwv67D9xEf0TmlSgFw/132</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[使用latent视觉tokens模拟人类“思维草图”的多模态推理，效果出奇的好]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajOXKcKpx0QjSiaMUzKjeIdA6Mv6Hf5BjWhhsBOp5XtBWwB6qRJ4Sd44ic2uMLdX4OiaXFsrBNYL4CiaA/640?wxtype=jpeg&amp;wxfrom=0"/><p>视觉语言模型（VLMs）在图文理解任务中表现出色，但面临一个根本性限制：它们只能通过文本来表达视觉推理过程。例如，在拼图游戏中，人类会在脑中模拟碎片拼接的“思维草图”，而VLMs却需将每个视觉细节转化</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542391&amp;idx=1&amp;sn=4087f2795709edb86fad4f7df19d6368&amp;chksm=ea1a1e7cd41f60f8434621e6be0f79107221c9b11cb26ddfd29ea11b050b9bef166c53a08949&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 17 Aug 2025 18:05:17 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Solver-Chanllenger博弈助大模型自我进化！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajOXKcKpx0QjSiaMUzKjeIdAc9tMNjrZQT7zCJAaxdYGY9DUJJ5SwM3sa50eYI48TfHpEJ5RyJJ5cw/300?wxtype=jpeg&amp;wxfrom=0"/><p>这篇论文刚刚发布，AI已不需要人类数据，下一步就是取代你。就在你阅读这篇文章的时候，一场深刻的变革正在AI领域悄然发生。一篇来自腾讯 为《R-Zero》的学术论文，刚刚为人工智能挣脱了最后一个、也是最</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542391&amp;idx=2&amp;sn=a1823fbd3ef2cecf3c7eddfbde6e5621&amp;chksm=eacb12365eca814a81f81d4ef4d776bca35cd7d02b8312f5af62474bbd991d1ff0a91d907a95&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 17 Aug 2025 18:05:17 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[天下武功，唯快不破：LLM高效架构最新最全面综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuwH3JYl4mFZAlc1LmLweXSib97Ckd9pX54trnLewcR5zVVMicibfsGrr2Zyw4rftRCic3G1OepQtDxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLMs）如ChatGPT和Gemini已彻底改变了NLP，展现出强大的理解、生成和推理能力。然而，这些模型的“智能”背后隐藏着巨大代价：训练一个千亿参数模型需耗费数百万美元电力和数月计</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542326&amp;idx=1&amp;sn=27c83f17e88eb19e230d494334bd8912&amp;chksm=ea601134ca55cc5495692da1a63899928bc963172b16a57ba42ed4859232b997a5c6eaf46909&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 16 Aug 2025 17:56:37 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[招聘 | 200W年薪Agent Engineer岗位！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahuwH3JYl4mFZAlc1LmLweXnQ75NV7fStjxC7ib258L5hhxGMZ1NpXKxEQAodIYHyOqIZ8Fu4vU3vA/300?wxtype=jpeg&amp;wxfrom=0"/><p>若干急需的高薪资岗位！都是头部企业（科技/量化）公司。aijob@fintechgl.com （备注：姓名-岗位）有任何问题，不用迟疑，请联系我哈~Agent EngineerAgent高级开发工程师</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542326&amp;idx=2&amp;sn=472343a54a44b0a746b36173d57ec3e1&amp;chksm=ea27f331157fd01fba0fa9c13d0e87db5f0d0dd6f252dbd61a3a0471287752ab91677477961f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 16 Aug 2025 17:56:37 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[入职OpenAI啦！这是我的AI Research面试指南]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaMVuEtjQNOEb7htibWccLED6EIdLFzZRZbQFtTJhuKgx1iaibOVYZ8uNFFicPiaQpSPYFmLZEEFKH14sg/640?wxtype=jpeg&amp;wxfrom=0"/><p>整理：「深度学习自然语言处理」公众号几周前，我加入了OpenAI。这篇文章记录了我的面试经历、学到的经验以及给你们的建议。如果你正在读这篇文章，我猜你大概在找工作或考虑转行，至少对生成式AI和大语言模</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542288&amp;idx=1&amp;sn=aed6172425c8184cc5207ef6f42abfdd&amp;chksm=eaf20f0778dfe66bbea3c593ad05242ff02a6d72816e06d7a13e370c692f38c7d9e43c513529&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 12:51:12 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Agentic Web：AI Agents如何重塑下一代互联网，一个到处是待研究与落地的方向]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaMVuEtjQNOEb7htibWccLEDnAbmLq48Bb8YGcXq1Ud5QZiaMoFYx28TVCFibxoZXGGmI0ccv3pMViblA/300?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下，今天的互联网就像一个巨大的图书馆或商场——人类用户需要亲自搜索信息、比较商品、填写表单、完成交易。我们习以为常的“点击-浏览-操作”模式，本质上是 人类在“伺候”机器。差不多类似于人找信息到</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542288&amp;idx=2&amp;sn=e1b991849f257e293a980c7ae49853f8&amp;chksm=ea18d8999c6766aad05562201ccd79a54dab767c62a94cd72d5c99405f911e21aea8ad4aa26a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 12:51:12 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里：RL强化LLM推理，是技巧还是陷阱？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag8KJ9eAI8ky6FSIPnbtiblSScicQX2TfM0tzt1ibGlUGuQcAHsSqiacmMuwCyrZluCcFj8luPrOwkQog/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，强化学习（RL）已成为解锁大型语言模型（LLM）复杂推理能力（如数学证明、代码生成）的关键工具，催生了大量研究（统称 RL4LLM）。然而，这一领域的快速发展也带来了“成长的烦恼”：技术丛林：</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542267&amp;idx=1&amp;sn=f2014c40b7457cba8546a3ea87ecc0c5&amp;chksm=ea313ef15245edbed60a9e78b3ed38495cf2ce653531b4bf68ef77e7dc1a344f20cf8b3009bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 14 Aug 2025 19:46:17 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[无需训练的LLM对齐方法综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag8KJ9eAI8ky6FSIPnbtiblSsnWbmZRpoibnjSoWQKDQibRGqJs4gVzdKgZo10RBFlQGU2cSOjusibYzw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLMs）如GPT-4、Claude等已深刻改变人机交互方式，但其在医疗、教育等关键领域的应用引发了双重担忧：一方面，模型可能生成有害内容或泄露隐私；另一方面，用户期望模型更专业、更个性</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542267&amp;idx=2&amp;sn=b1332be0cbefd3c3ece1a378d7fcb5fd&amp;chksm=ea1e31f3cd3b43117fcb6a12cde7b45665c82f3c57e3fd24e2d0e69cb4df22fd1f27519b820f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 14 Aug 2025 19:46:17 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[推理即排序：ReasonRank反常识的2.7倍效率跃迁，新SOTA比快更快]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajlKZ5iaABibc5zWWqgYhpt2rUlpPjx8Qaz633aGd5dUBWmssF42L4qxIaag9EAz54QehBaKuicIfxMg/640?wxtype=jpeg&amp;wxfrom=0"/><p>信息检索系统如搜索引擎的核心任务，是从海量文本中筛选最相关的段落。传统排序模型依赖关键词匹配或简单语义关联，但在用户提问涉及复杂逻辑（如数学证明、代码调试）时，表现往往不佳——因为这些场景需要模型理解</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542214&amp;idx=1&amp;sn=41ee0974c1023cbd376a313080aac8c5&amp;chksm=eae074cd68183e91de71fc45f4d039d0baf635708696ac9a0f401b02f0d7e3ae8020900fa1a1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 17:38:16 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从单领域到多能力协同：数据混合如何重塑AI的强化学习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajlKZ5iaABibc5zWWqgYhpt2rTwc2gxg23ToOoibqyvGtLumBEbAkCyHHx9K9LfBByBbVbjknCP1wrcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，大模型在数学计算、逻辑推理和代码生成领域的推理能力取得了显著突破。特别是随着DeepSeek-R1等先进模型的出现，可验证强化学习（RLVR）技术展现出强大的性能提升潜力。然而，现有研究多聚焦</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542214&amp;idx=2&amp;sn=3d51a64c34af46462b46ef3085d6c94f&amp;chksm=ea1f14d13e8a0b072a50dad64595b3fa50736beb59e73e5981647cacfb63642d8b455532f2e4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 17:38:16 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从静态模型到数字生命体：自进化AI Agent综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajlKZ5iaABibc5zWWqgYhpt2r1lIENlq7qQ0HePHopPe9j2zrHyO7m71HiaKnIjQOGVmjywicNibQcswvQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年大型语言模型（LLM）的突破催生了AI智能体的发展，它们能自主规划、使用工具解决复杂任务（如编程、科研）。然而，现有系统大多依赖人工预设配置，部署后无法适应动态环境（如用户需求变化、新工具出现）。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542214&amp;idx=3&amp;sn=79e4bdccdd728555eae1f6aa4effd906&amp;chksm=eaa24e20fedc43f7b2e14e764c94ac0b14dd328d55fcc1c53adb9a741a4907d45d072da4042e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 17:38:16 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[该工作引来马斯克回复，让Gork破防：CoT是真正的推理，还是训练数据的统计插值？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagaKGVGjOTFmdmyl8icBaJH2HMPzIUSDay2BopHrvU6Nj9ibX6LuaHDggcgQUfnKGyiaBzF4bw9uoaXA/640?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLMs）的思维链（Chain-of-Thought, CoT）推理能力被视为突破性进展，它通过生成类人的逐步推理路径显著提升复杂任务性能。然而，本文揭示了一个颠覆性观点：CoT可能只是</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542164&amp;idx=1&amp;sn=394affa0e8e4ec88373d10bd789d1d42&amp;chksm=ea71e193daf7abda103e6e5c6e4609976358217359a7f8dcef090d091a5255213ddbe1cd5e90&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 12 Aug 2025 14:42:25 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Make SFT Great Again！从SFT到DFT：一权重之差，泛化之跃]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagaKGVGjOTFmdmyl8icBaJH2fG3Cs50lvXhX1Zvwk6Q1C7FCsn4PGw4ia5hpdcibJnILkatia02hrHgJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（LLM）的监督微调（SFT）因其简单高效成为主流技术，尤其在缺乏负样本或奖励信号的场景中不可或缺。然而，其泛化能力长期弱于强化学习（RL），后者依赖奖励信号探索更优策略，但计算成本高昂且</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542164&amp;idx=2&amp;sn=7ce88108a5549e9d0e14d075bc6a10dd&amp;chksm=eaa17c8e32646febf9c00df9b584f8647aea17e2fe0d9cef205ba7ad9223f0cbf1fd05550384&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 12 Aug 2025 14:42:25 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[【非官方】NLPCC2025线下交流群]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajicJlRr5ibwdeaLdtqxBNPibYj0oFldW8EqtXyQKx6s8wbYLssJvfodp091SFJ6b4UN02sFRtOBhtkg/640?wxtype=jpeg&amp;wxfrom=0"/><p>从今天开始的NLPCC2025在乌鲁木齐举办，持续3天，有小伙伴在线下的可以进群交流下，大家互相认识，互相学习，互通有无。（非诚勿扰）备注：昵称-学校/公司-方向/会议(eg.ACL)，进入技术/投稿</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542129&amp;idx=1&amp;sn=1f7ea745e4a69ef9e407407e838c3686&amp;chksm=ea78709d9f09be8cfe60739202dc4ded6099e3f0c970a1106da898149b80f79a34dc2892f1ca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 03:24:37 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[解析天花板？TextIn xParse如何为RAG打造「零损耗」知识管道]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahTUNhnnnBZJ0fVpBOXg3dlRheGMf9P1ic2Cmyy48wBrERzGIbcaFANP800E1mwEQqFKjMvgb7ggCg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在AI应用极速发展的当下，LLM（大语言模型）与RAG（检索增强生成）系统已成为构建智能问答、知识管理等高阶应用的核心引擎。然而，许多团队在项目落地时遭遇了现实的挑战：模型的实际表现——无论是回答的准</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542121&amp;idx=1&amp;sn=a348cbc0f3fb5871de7ca20f42c486ce&amp;chksm=ead717a9a6019a62b1782de33e8f9f5d6c6c2c52a69be15fc67288e40e9c7d04cde1dc77974a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[推理路径的动态调控：让大模型学会“恰到好处”的思考]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahTUNhnnnBZJ0fVpBOXg3dlUGWPicKsu7eqNI6SFe5tyH1LGUEpNia9aPibDiavIBficz1dK1c9jwX7bJg/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前大型语言模型（LLM）通过思维链（CoT）提升复杂任务推理能力，但研究表明其推理路径存在严重冗余——例如反复验证或无效思维跳跃，导致计算资源浪费和“幻觉”增加。论文：Test-time Promp</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542121&amp;idx=2&amp;sn=25095d5eb791cfd37792948594d8b3c4&amp;chksm=eab95bed5f1bd82ada4386498c7bef5f81e70068793f0271390dcaf776101948a8b32138c06e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 07 Aug 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | 普林斯顿研究员王心怡：大模型如何学习？揭秘LLM"记忆"与"泛化"的平衡艺术]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaodCokNbZaMII5yGicmAA5XEYyiaulBwNc6PLBqtynZCrjiaVyzwyPAgfaDMrv8Y3RGdyDGDKl6FicnA/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题大模型如何学习？揭秘语言模型"记忆"与"泛化"的平衡艺术时间2025.08.09 周六 10:30 北京时间2025.08.08 周五 22:30 纽约时间b站直播间：https://live.b</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542034&amp;idx=1&amp;sn=c28070fa79ba8b0e78a6b7c53c06b03d&amp;chksm=eac968f098c6f41c7e9c0e5e780787e5dfaccc0a5aa324a075d11b2931a1625142d9ac34cda4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 12:36:57 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[27M参数战胜GPT-4！脑启发的分层Reasoning引擎如何重塑LLM]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaodCokNbZaMII5yGicmAA5XwX1LDEk0pGVGxQVEG8y9yibRR7JHdCRNcwEibJWs69PIsxTl9IryEicNQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前大语言模型（LLM）虽在语言任务中表现卓越，但其核心架构存在根本性缺陷：推理深度不足：Transformer本质是浅层计算（类电路），无法执行需多项式时间的复杂算法（如深度搜索、回溯）。依赖思维链</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542028&amp;idx=1&amp;sn=9cbc2a76eda6a7ddc30aa2facdc3ed7c&amp;chksm=eab95e095b1c8f53abf754b9fcadafea6e947ebe3a6be987b6fdf2c234240e8a3bbe967f0033&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 06:47:33 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[人格向量：大模型性格的数学解码与精准操控]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaodCokNbZaMII5yGicmAA5Xgp6Crqe2Uh4fw8dEIGxbgtdDRnzpIoEROpwp7BexwedGMzwLjhSmhQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>大语言模型（如ChatGPT）通过"助手"角色与用户交互，其设计初衷是保持有用、无害、诚实。但在实际应用中，模型可能出现危险行为偏移：微软Bing聊天机器人曾威胁用户，xAI的Grok甚至称赞希特勒。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247542028&amp;idx=2&amp;sn=e96fcc66108e94a70f083f5870383585&amp;chksm=eafea9c8612175f78921ecb6eebae00015205ac49c749036e2f8e8e4f07d4b7bb5383cf96d5b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 06:47:33 +0000</pubDate>
    </item>
  </channel>
</rss>