<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/Q3auHgzwzM6qfKicTFQYIA3iacpJhzc9JvSOA6fwv67D9xEf0TmlSgFw/132</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[训练靠奖励，但奖励模型自己“瞎”了？奖励模型根本不懂“记忆”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajELmmVUiaNibClEgR9gUzoZib67FxkzEcxgUaOFDRsFick9kplEMMywHLvMh9eLibfuGvpNBNGNCviaFA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在大语言模型迈向超长上下文处理的征程中，分段记忆架构已成为突破长上下文瓶颈的主流范式。记忆管理能力成为衡量模型性能的分水岭——既负责信息的跨片段传播，也确保模型在长程推理中不丢失关键信号。因此，利用奖</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546523&amp;idx=1&amp;sn=19259790c989162607e28036ed422a75&amp;chksm=ea4d538b31416366b17e622596c911f4844290595684269b140729eba4091dfb39befbdbb39b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 Jan 2026 12:20:05 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从真实案例看Agent从实验室到企业落地的区别！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiajELmmVUiaNibClEgR9gUzoZKsRTVfHiaDTdNFk8tATqknSdObJMx7qtT6yibR04HDhJQTewIQ0u5AQA/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题从 20+ 实战案例看 AI Agent：企业如何跨越“落地”鸿沟？时间北京时间 周六 2026.1.24 10:00美东时间 周五 2026.1.23 21:00美西时间 周五 2026.1.2</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546523&amp;idx=2&amp;sn=59e43f4adc5a46a599bfb8a854f47326&amp;chksm=ea7a70b9024c767cb2dbfdf3ff01949c7dfc6610acab220ded15d8e5118060519b28da2b24db&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 Jan 2026 12:20:05 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[为什么自监督永远学不到语义？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahQEDVHiad8GZDtMc5POl7GKPdgYHWjiae6EWicLXUBeMBsj4bJNFianJahCXT3EGduJdoia06GgNOXSMQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>我们现在的 AI 模型很大，大到不仅能生成逼真的图像，还能在各种榜单上刷分。但在这个繁荣的表象下，作为一个对技术有洁癖的研究者，你是否偶尔会感到一丝不安：模型真的“理解”它看的东西吗？如果它只是把像素</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546473&amp;idx=1&amp;sn=88079df8a051a66140a4288a833ed19a&amp;chksm=ea6d91cdc9baf6a06a084d925d626e02217cbe76979d34096d0fe467bc9532f29284e099eed1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 Jan 2026 19:36:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM时代的事件抽取：从静态任务到认知脚手架]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahQEDVHiad8GZDtMc5POl7GKxlGu7HsuHwUsY9poib2Nl7jOGSIibDvaJWRevgEjxo4QmeDIpwlLIib2A/300?wxtype=jpeg&amp;wxfrom=0"/><p>一篇全面综述论文，重新定义事件抽取在智能系统中的核心价值当GPT/Gemini/Deepseek等大语言模型能够直接生成结构化信息时，事件抽取还有存在的必要吗？这是近年来NLP社区频繁讨论的问题。大语</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546473&amp;idx=2&amp;sn=ff069b886648d8da74d7e7d0e4db047f&amp;chksm=ea87be13d0c9b000dd6ae224a1bf8bf107e4224e354b0563a0a42f1906cf5f614e47b37a1f9a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 Jan 2026 19:36:31 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[GenEnv：智能体与环境模拟器之间的难度对齐协同进化 | 直播预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaYbOlibNswcLQNHn9SIB3ickUp1wnBSaLqWJFZbHSx1qcBOj3qkKXO8yUh66DNeNvEicoQsDYfN2bow/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题GenEnv：智能体与环境模拟器之间的难度对齐协同进化时间北京时间：2026.01.18 (周日) 19:00-20:00直播平台微信视频号：b站直播间：内容介绍训练高性能的大语言模型（LLM）智</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546445&amp;idx=1&amp;sn=f5539cc02124a0cfc8543c74fa95d3fa&amp;chksm=ea9479a2513611ee34035feaaedb31a2607237db54bd4b055b5a73c1338665cab0562c8785e7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 Jan 2026 23:17:22 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta&amp;UIUC大发现：无需标注，Agent复杂的工具使用和搜索能力，是可以“无中生有”的]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajLNrwBsepul2dpvS3DXBuvYvN6Wsp8Pls2NwvTQzWVFgp6uScibiaR7D4NC3O7FEn00MMm09rDGTLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>我们都知道，DeepSeek-R1 或者 OpenAI o1 的成功，很大程度上验证了强化学习在提升模型推理能力上的统治力。但在这些光环之下，有一个尴尬的角落被很多人忽视了：搜索 Agent（Sear</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546439&amp;idx=1&amp;sn=3d4f8058902cc506a3af6edf3b5aa7d6&amp;chksm=eadfe1bb2907601e5707dfdce73afd61aac885d39cca682765030c1f5acc35538a045052f28c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 Jan 2026 15:42:12 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Claude Cowork 解读和 Open-Cowork开源实现]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajLNrwBsepul2dpvS3DXBuvGTJXYWibWcYCbJ8PSmkvCnLsTyBg6RpsUJktQhoPehAiaUlpEfySpZ0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>一、最近爆火的Claude Cowork在讲什么？Claude Cowork 是 Anthropic 推出的 AI 工作代理工具，旨在将 Claude 的“动手能力”从编程领域扩展到日常办公任务。官方</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546439&amp;idx=2&amp;sn=081a8b86ba294ac1a1db5cda161053fb&amp;chksm=eaac8991a15c734aa2c65b0a9e6e581cb515397358deeb901540f36a428f9bce25a164b27af4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 Jan 2026 15:42:12 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[“心内推理”：一种动态多模态潜在空间推理范式 | 直播预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajLNrwBsepul2dpvS3DXBuvT2vAjoxL7lqjzvzYDBzNg7TxasDVV1RjgFWjyykTxBXIL7X9vbeiang/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题“心内推理”：一种动态多模态潜在空间推理范式时间2026.01.17 周六 10:00 北京时间2026.01.16 周五 21:00 美东时间2026.01.16 周五 18:00 美西时间直播</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546439&amp;idx=3&amp;sn=e33cc6adcd4b31b358eb0ddb90bdeb3b&amp;chksm=ea19b8f09248229edbfae4f623e1b4745837dd37b0057cf6a277c1d0b0b670bf81f40d60db63&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 Jan 2026 15:42:12 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[CMU&amp;NYU最新工作解释：存储在权重里的“智能”是从哪来的？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj8iafE87RibVlGdXTuib1icrs9CjhbVn96XZDViaGQagVcibdAaQDGOVEotLMuw3U7JkX3MnSTzAckcIfw/640?wxtype=jpeg&amp;wxfrom=0"/><p>我们先来做一个思想实验：AlphaZero 在没有任何人类棋谱输入的情况下，仅凭几行代码写就的游戏规则，通过自我博弈训练成了超人类的棋手。它的权重文件中包含了数以亿计的参数，那是关于“如何赢棋”的深邃</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546387&amp;idx=1&amp;sn=739366b52580de214a6485283199c551&amp;chksm=eafbc1756e747318605bd47dae7f3e723ee4ae667387affb1541b1f00b36faa142d703862239&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 Jan 2026 17:12:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[1.17 北京线下｜AI 多智能体创意工作流架构分享，等你来玩！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj8iafE87RibVlGdXTuib1icrs9ssxibebRbcicrAfx1dum4WbbeZpoicP5JZQqNcStEVgZ0miamZJSqF7YSw/300?wxtype=jpeg&amp;wxfrom=0"/><p>🍻 免费“AGI泡沫”特色饮品 &amp; 大量实体周边已备好，一起周末充充电⚡！</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546387&amp;idx=2&amp;sn=70110dfc5e5e9c3c90344e8e8fcf84bf&amp;chksm=eaf57d4c09d20228f0dae12ccd6e77c710eaa24b855d1c431a65086c14ef77a696725679c1dd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 Jan 2026 17:12:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Anthropic：大模型开始意识到自己在想什么！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahnPYq20PZq3Ot5wZOTTOz5e0WrGLN10X3HIYRY01opPxW3hhDexWxiaVibAzVCMmKpaNLibtSoWiaj9A/640?wxtype=jpeg&amp;wxfrom=0"/><p>我们经常会陷入一种错觉：当我们问 ChatGPT 或 Claude“你为什么选择这个答案”时，它们给出的解释似乎合情合理。但作为一个深耕大模型领域的研究者，你我可能都心知肚明——大多数时候，模型只是在</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546368&amp;idx=1&amp;sn=eef24815db73237c6c2cbc6dbdea41bc&amp;chksm=eae6461b1a672f4628ac0bec8c7cd6053c9833c6bac5e45eaa3f33d672d6b7c4da785da0e008&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 14 Jan 2026 17:34:12 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[2025小结：从RL到Agentic RL]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajjQ0p1QhPDdTKK3pSBMTEOmEZSx06ibr1AQRD3BclXp4DN4jJUoTia4cBT5ryfMZIiaAQnibvxvGdfmQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>如果说训练大模型的目标是稳定且高效地scale up，那Agentic RL给人的印象往往是既不稳定，也不高效，对于资源有限的团队来说，也很难scale。上半年发生过很多变故耽误了不少时间，中间有几个</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546338&amp;idx=1&amp;sn=107dfb61127c608e8734be13ea17e2c5&amp;chksm=eabf7fb50ffb24f2170c3879857760cced9ef0b8ec4900fe84d92b9f5a52a11c4d72bd750478&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 Jan 2026 16:15:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AgentCPM-Explore开源，4B 参数突破端侧智能体模型性能壁垒]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajjQ0p1QhPDdTKK3pSBMTEOrY9Bpc6uuEJcP9WolA5BibWiaOUNd6oiaOOMpec68o9WFAfjeNIbH3RbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>当全行业还在争论 30B 能否挑战万亿参数时，我们给出了一个更激进的答案： 4B。没有万亿参数的算力堆砌，没有百万级数据的暴力灌入，清华大学自然语言处理实验室、中国人民大学、面壁智能与 OpenBMB</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546338&amp;idx=2&amp;sn=0dd0fc7c8a160e4b7aa127d108b57dc1&amp;chksm=ea1f2a7610d74280c26a77c9d867ff58cb8cef5146094b6b52067ff5245580216702eb836fb1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 Jan 2026 16:15:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[BabyVision：揭示多模态大模型的真正短板，顶尖AI竟输给三岁宝宝]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj6jX05nT35Wzd3uxtakXAwWiamAtU8weWsHGnbCibQ5KWAot4LYXZt6CEHP7WTf89TF1fyic38x8s6A/640?wxtype=jpeg&amp;wxfrom=0"/><p>01｜“看懂世界”这关，大模型还没上幼儿园过去一年，大模型在语言与文本推理上突飞猛进：论文能写、难题能解、甚至在顶级学术/竞赛类题目上屡屡刷新上限。但一个更关键的问题是：当问题不再能“用语言说清楚”时</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546320&amp;idx=1&amp;sn=5eec0a75124936ad71c4a733ee7db535&amp;chksm=ea67e7130ac040e37622de7d9b7888cb569b6c01909f27a71cd9e6e238cacdbe9f8494dad3ef&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 Jan 2026 16:58:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[RealMem: 重新定义AI的“长期记忆”，挑战真实场景交互]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj6jX05nT35Wzd3uxtakXAwF9iaa5I9FGmqbMkVGZn8OPRRCNE0rZjhV7oibfsehvSMb6tsTetibia6Fw/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI Agent 真的准备好成为你的长期合作伙伴了吗？你有没有这样的经历：在使用chatgpt等AI Assistant时，不断进行这两种动作：“新建聊天页”和“寻找过去的某个聊天页继续问”。为什么需</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546320&amp;idx=2&amp;sn=bb4f2832c6e9483eb3e26f60f6461434&amp;chksm=eab77cdbd4a88e407f73a58a12b6293d68d2dd773e90b82c2a6f850cf96d83979dfa7e686adb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 Jan 2026 16:58:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[智能体是否在欺骗用户？上海 AI Lab&amp;港科大&amp;浙大揭示LLM智能体的主动隐瞒与造假现象]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia9lXZOwDmoxiaQzYAREbGt2RBkps7TBJ2kKZW7vO4lEEGMiaUestf3icg2L7fjnSC5zgR2LiaLwqwXJg/640?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下：一个打工人在深夜发现无法完成老板交代的任务，而第二天一早就要汇报。这时，他会怎么做？或许会重点突出已完成的部分，对未完成的轻描淡写、甚至绝口不提；也可能铤而走险，直接编造结果——只要老板不细</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546284&amp;idx=1&amp;sn=ec4de312a2f1f465a5244467e9676366&amp;chksm=ea85d86a4f026d61b47e727d2702b876eed945e2e1be1b46635b17c4d42708e5c99f78223b3f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 Jan 2026 17:24:09 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[想知道下一个Manus在哪里？推荐一个AI2C创业闭门会]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia9lXZOwDmoxiaQzYAREbGt2wKpTg1BEZSvdPUqdTVMuicgfwxTZ4GeqC1YGcfbDkDfNUATI0IkanmA/300?wxtype=jpeg&amp;wxfrom=0"/><p>1月25日下午，五道口与5位AI创业CEO和专家深度交流，4位创业者路演展示，仅设40席位分享嘉宾：韩晟：小影科技创始人，产品覆盖全球200多个国家，超22亿用户玉伯：YouMind 创始人，前字节副</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546284&amp;idx=2&amp;sn=a42cec9e63b01f819ed4acd532b10371&amp;chksm=eac316d6acd81cf044f43abbd0ca8dead36e7f30f9f212a636061df3959ca422e176bf0d3a60&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 Jan 2026 17:24:09 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视觉优势还是语义依赖？揭秘 DeepSeek-OCR 高压缩率背后的真相]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bageXbicgAlG2HNibdJKspnQBQDlH543dRnu0XmOwlDsqN69ynoQuHDeQK5I8SjRjFMxLrXXX41HSPYw/640?wxtype=jpeg&amp;wxfrom=0"/><p>导读：DeepSeek-OCR 提出的光学 2D 映射方法宣称能实现 10 倍的视觉-文本压缩，看似解决了 LLM 的长文本痛点。但这种惊人的效果究竟源自模型“看懂”了图像，还是仅仅依靠强大的语言模型</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546272&amp;idx=1&amp;sn=4732fef68d4ee53aa9cd72df85fcda12&amp;chksm=ead7066979aaae92a4859ee52ab83aed523c3dc8a4b7e6adab06fa81c32f5c0b028ed276a596&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 Jan 2026 22:47:55 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI安全的过去与未来：从大模型到智能体 | 预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bageXbicgAlG2HNibdJKspnQBQib9q6oYFXOtu2cHJzia75AibyEn6sFibMvbhXJibtQ5xr7PjicUDaED6UOJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题AI安全的挑战：从大模型到智能体时间北京时间：2026.01.14 (周三) 10:30-11:30美东时间：2026.01.13 (周二) 21:30-22:30美西时间：2026.01.13</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546272&amp;idx=2&amp;sn=cf9b464384c5369bab49ade33e1e44f6&amp;chksm=ea4026425f7e2303d799bc166bde7e4398f16e3905ced28c0c0b4699460e63532a7f636df49c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 Jan 2026 22:47:55 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2026 Workshop 征稿开启：迈向 Lifelong Agent 终身智能新范式]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajPoRkh3oqanNyxGg9TCWW5ZVB3Sh6fGlrf55qIn5ufibtpiafiaU5H6UnEhCbI9hazudds8F6bhV3Iw/640?wxtype=jpeg&amp;wxfrom=0"/><p>人工智能正在进入一个新的转折点。以大语言模型（LLM）、强化学习（RL）和具身智能（Embodied AI）为核心的 AI Agent 迅速崛起，展现出规划、推理、工具调用、自主决策等多维能力。然而，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546249&amp;idx=1&amp;sn=1c09b81640e25f5518018945553186e4&amp;chksm=ea3c5c260ce549534cfc8711aefc583d93bff33613eee7eff36d9f8abc867516a16b316100a7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 Jan 2026 16:19:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[利用Loop语言模型扩展隐式推理 | 直播预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajPoRkh3oqanNyxGg9TCWW5DULPicPvnu0iaPzYk9N6eBnD7BVuXuQMicF4ZOYyV0lZ8epR6kZLefbzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题利用Loop语言模型扩展隐式推理时间北京时间：2026.01.10 (周六) 11:00-12:00美东时间：2026.01.09 (周五) 22:00-23:00美西时间：2026.01.09</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546249&amp;idx=2&amp;sn=eb52b42ad019caf98db731a1d15b7b74&amp;chksm=ea645252b9bb3fb846e0fd6c400bf7ee1e34e9d0ffe92aa79f64ccd4a8e598341ef03b98d850&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 Jan 2026 16:19:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL2026交流群 | 10月ARR怎么commit ACL26？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bags903ibIsibza5g7msslfygmT2TdEaTNQBjbBhRaLDVzp4gSj5jibIML3CGe6Uc4zJicyV7ZLHHzJZdg/640?wxtype=jpeg&amp;wxfrom=0"/><p>非诚勿扰！最后一天啦，祝大家好运！gogogo！（第一个群满了，这个是第二个）</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546236&amp;idx=1&amp;sn=5725a88e9bc1b65a624846a6e956852a&amp;chksm=eadf82c4816c5b10a453765d7e31b5f73a4d3d5bb3d7cbabcfd3472fbbd361869dbb1bff85fc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 Jan 2026 10:43:04 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态推理新范式：上海AI Lab新作证明“画”出答案比“说”出答案更靠谱]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia2e5BB0WVGHJFkvibKMTWOEsVdX9NCXT1CPiabrBh4YdRicvg1YhKG3tHHeFeeZYFYQkFja2f4DZAsA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在通往 AGI 的道路上，大语言模型（LLM）和多模态大模型（MLLM）的自回归架构似乎已经成为了“真理”。然而，这种基于一维序列的线性推理模式，在处理长程、视觉中心任务时，正暴露出明显的短板——它缺</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546224&amp;idx=1&amp;sn=7de4ca2f994e66e85afcdd0980da30e0&amp;chksm=ea9b2731fd4c5c2c079e0879d4c328b4d5bf84cb10b56cde7414bf5bdf1c5648d76bc478fba7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 Jan 2026 19:56:57 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[上交大 × 华为小艺推出LoPA：7B扩散语言模型单样例1000+ tokens/s！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia2e5BB0WVGHJFkvibKMTWOEcUk1TNPtksOKgHGriaRiczDXBoKv7fHcAictnibzQNeouRIHoFjC1bOzmA/300?wxtype=jpeg&amp;wxfrom=0"/><p>单样例推理速度对比：SGLang 部署的 Qwen3-8B (NVIDIA) vs. LoPA-Dist 部署 (NVIDIA &amp; Ascend)（注：NVIDIA平台相同，配置对齐）在大语言模型（L</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546224&amp;idx=2&amp;sn=2dabfd87d738f86130af39f148a296be&amp;chksm=eac919f16e893ae9e0599bea5e794246247d170c8245fcf16569e5dbb8223bdd03aa19758a05&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 Jan 2026 19:56:57 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM 推理中的数值非确定性与 RL 训推不一致的系统性解法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj7MJlwF3QrKqcicbjZapgk1mqOmrkPria4JS3EWp7V6eTK7xJ2NlkNgLPr8fcNpN1ElyoyKeO0OtRg/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题LLM 推理中的数值非确定性与 RL 训推不一致的系统性解法文末进群~时间2026.1.4 11:00 北京时间2026.1.3 22:00 美东时间直播预约🎙本次分享为全英文讲座！🌍视频号b站Y</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546189&amp;idx=1&amp;sn=7bbd679ae3231f2015349a4c5acd5efc&amp;chksm=eaa90cb41fcffff17f5643adfc5d02ef37576bc2171dbe4c503f9950ebc8137137013e51c796&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 03 Jan 2026 18:21:27 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL2026 Submission &amp; Discussion Group]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj7MJlwF3QrKqcicbjZapgk14L26DlWgspHjS04icpplK4QCHQDaMygdZ8QuuxukrwEVZGSiaaAEl1yw/300?wxtype=jpeg&amp;wxfrom=0"/><p>非诚勿扰！祝大家好运！gogogo！</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546189&amp;idx=2&amp;sn=27ef53371ab223abaa1a4fb1a3e80e38&amp;chksm=ea3e38533d1e2f617c74b5db0afe8cfc6679fc58a4f2aed8ab7c8335fe62a1d1864c18d8c031&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 03 Jan 2026 18:21:27 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从“文字预测”到“世界模拟”：World Model如何解锁可扩展的Agentic RL]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baj8T33qvdmF0qWmk3qkGanD1ORzzOyVX473X4YXGPR0CGjSg4qiaiaPpPAA5iaicdL9u5JNnriavHLWibZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>过去一年里，智能体强化学习（Agentic RL）进展很快：会浏览网页、会写代码并执行、能调用复杂工具链的系统不断涌现。但随着能力提升，一个更隐蔽、也更致命的限制开始显现——不是算力，也不是数据，而是</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546176&amp;idx=1&amp;sn=0842e0d700e35dcc1e3c31a11aba7f51&amp;chksm=ead90798c4b21d7ec36377731a19571b60401b6ebfc4b423857f56f27dca6eb321b45bb4759a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 31 Dec 2025 22:19:10 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 Best Paper | 扩散模型不为人知的“时间差”：为什么先学会创作，后学会抄袭？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahz2ibsMA07N3XUorBtnK8qgjNHkYzLWlfiassj2I83q8cSY0Tzv1ricFt8TOKYoGQMMd8t6ZbicMCYmA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在深度学习领域，我们长期面临一个直觉上的矛盾：现代生成模型（如 Stable Diffusion, DALL-E）通常是极度“过度参数化”（Overparameterized）的。按照传统的统计学习理</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546157&amp;idx=1&amp;sn=676135f1884255945e6a6b0db4ccb9c0&amp;chksm=ea87918a82f1fd13e45f98b45fc75a0c55f423ff5ced53f05ed24ba35cbc58a386dc6610cb33&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Dec 2025 19:19:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[别再用单选评测骗自己了！Amazon新论文揭示了大模型在多选题中的3种系统性偏差]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahz2ibsMA07N3XUorBtnK8qgwIU2WWdlvCmf6ItibAXNQGIJo288Cm4vINK9rVcNHcibBU79q9zRKQ6Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>很多人以为LLMs最难的是奥数题、是高考压轴题，但真实业务里最容易翻车的，其实是“多选题”。因为现实世界几乎没有“唯一正确答案”的舒适区：内容安全往往同时触发多条规则，医疗场景要处理并发症和多重风险，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546157&amp;idx=2&amp;sn=2dfe82c833f5bc80ab4e21738e273522&amp;chksm=eaf671136254872079871732977971af7e06e2d399f2ec69736eb494027d6c2f18f68432e61d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Dec 2025 19:19:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[System 3 觉醒：从“工具”到“物种”的根本改变]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahy6RckZapLjlQH4ZC7Z9IlqdXvx8MncZ518ujK6xrM60mdnpLIQy7c2QnD54ZMysQXdAqXUJ9iasg/640?wxtype=jpeg&amp;wxfrom=0"/><p>我们现在熟知的AI Agent，无论是AutoGPT还是各种Copilot，本质上都更像是一次性的“雇佣兵”。你给它一个任务，它甚至能规划出惊人的Chain-of-Thought（思维链），但一旦任务</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546132&amp;idx=1&amp;sn=8c773f4cae24b6b8217b52b04fedcdce&amp;chksm=ea54837c57a894f06e7192b0fe75dd49950d6f78cf098192436a9f5f42c54c2d9bb8d0ac10a6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Dec 2025 22:16:29 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM内部竟藏着众多策略模型？自所&amp;腾讯团队首次揭示大模型RL新机制]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHUtkupPSHFpjfBZODABeE0Z7ZyficLUJicXQJicwQGkygq3l36tSHicloLWO9UMrHHcVfEY9Wuuff6w/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前，大模型+强化学习成为AI领域极为热门的研究。现有的强化学习（RL）方法通常将大语言模型（LLM）视为一个单一的整体策略进行优化，主要的算法优化集中在表层的奖励设计等方面，却忽略了模型内部复杂的层</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546097&amp;idx=1&amp;sn=b3fed6f7e7804a2cb364005939aec612&amp;chksm=ea356b690d1b28dd4cda1b4611d364430041acaddf14e422a9f00c1208019c76631e5e7dd695&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Dec 2025 19:18:58 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[智能体的记忆管理机制及其潜在风险 | 直播预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagHUtkupPSHFpjfBZODABeEkhfVibWnSmVNqWXROXRnwg4hv3qo195P0LrlxRINFMO9ia1RUCOnuZOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题智能体的记忆管理机制及其潜在风险时间2025.12.30 周一 11:00 北京时间2025.12.29 周日 22:00 美东时间2025.12.29 周日 19:00 美西时间直播平台微信视频</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546097&amp;idx=2&amp;sn=694add547646d4fa21a0e4b0b6c1032c&amp;chksm=eadeb70cf03627679c44aa8b41eebb5ceb7f1b80418e1e4e0ffd78dd7f4191c4e32af70da308&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 28 Dec 2025 19:18:58 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[唐杰&amp;Karpathy：2025年，大模型从「读博士」到「打工人」的生死跨越]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagBnYiaxUhxExw7aGpCkfkeIzayhEKnKu7JnQXTkeiammgViaVlEDC8qlw0D93QuvkQXFHgD5o9vfGxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025 年底，中美 AI 界两位顶尖人物不约而同地发布了对 2026 年大模型的深度思考。一位是 唐杰，清华大学教授、智谱 AI 首席科学家，代表了国内最懂大模型落地的工程视角； 一位是 Andre</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546087&amp;idx=1&amp;sn=009f38e9b5b93169b3dba1516b3f9b75&amp;chksm=ea33cbc6ba74085ccbbf4a5c1daf9de3a0b26509e4c7f55a01bbdb21d98c6f76862e62830b9b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Dec 2025 16:11:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Deep Research 只有贵族能玩？StepFun 用 32B 模型把成本打到了几毛钱]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagBnYiaxUhxExw7aGpCkfkeI17Q7h7m07zVkyseGicKibjHibw77pRSFDmoOGFeia2RodoZl1tBiaFeu6ibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>如果说 2024 年是 RAG 的元年，那么 2025 年无疑是 Deep Research 的“战国时代”。前有 OpenAI 的 Deep Research 惊艳亮相，后有 Google Gemi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546087&amp;idx=2&amp;sn=1dd3b33b13c0b5e7d34ba77ad9adfac5&amp;chksm=eaa61c50ff46a323352331fdd9c4e7414d502312dda4ddb04678ed25184a9235c8a73b6695bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 25 Dec 2025 16:11:46 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM智能体“胡闹厨房”翻⻋？ParaCook基准揭⽰：SOTA模型在“时间效率”上被⼈类完胜]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajeF5XFQO3AeeOVbFDuJibiaDTpqcyibGtmSZ7tZWxbXI2WwJPiaeLHHThGUqvlqHVgfCt1NcfamY9u2A/640?wxtype=jpeg&amp;wxfrom=0"/><p>当今的⼤语⾔模型（LLM）智能体在执⾏复杂任务时展现了强⼤的推理和规划能⼒。但现有评测⼤多只关注“任务是否完成”，却忽视了⼀个核⼼问题：“完成任务花了多⻓时间？”。在多智能体协作时，这种对“时间效率”</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546043&amp;idx=1&amp;sn=77649f8f9afb9df48586bbf994c7f7f0&amp;chksm=ea12a5144d76ec6f630d8b886685bea700b9ff050f44a6d61c52d3f343e69fec521b475a6c77&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Dec 2025 15:45:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[WWW 2026顶级研讨会征稿启动！聚焦因果推理，构建可信AI，诚邀投稿参会。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajeF5XFQO3AeeOVbFDuJibiaDwXjm71OtcOAYEHnyN9o0TUPhR1iaCseTj28MgJnV0M9QkZVLvgZdFSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>WWW 2026 Workshop | 面向Web智能的可信基础模型：因果视角与挑战WWW 2026：面向Web智能的可信基础模型——因果视角与挑战研讨会，正式启动征稿！本届研讨会将聚焦于利用因果推理</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546043&amp;idx=2&amp;sn=8b0809ff72ff95cbdc9298686be331cb&amp;chksm=ea7c2b9753fdcd8f3c2047ee3b23ed34c6c60b9dc25235bd9e8e89e153dd08edc53cdf301848&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 24 Dec 2025 15:45:35 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[极简RL新范式：一半算力刷新1.5B模型推理SOTA]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajXwoqiadttm4MDMvUxUfT2qVVz0wn6QXhKV3A5rCUAPpRgfKCx4y8npVuaf2WYbgWIZYcWVOgbiaOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>当我们在谈论 RL 时，我们在谈论什么？在过去的一年里，大模型推理能力的提升似乎进入了一种“炼金术”时代，尤其是对于 1.5B - 7B 这种中小参数量模型（SLM）。为了让它们追赶 OpenAI o</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546010&amp;idx=1&amp;sn=57462c9edf0db6c20823d802074efdca&amp;chksm=ea38502890bfcb1ecf139876b77ccfff06824a94200595fd8f80a6527962544a359309fc327d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Dec 2025 17:52:19 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型已经会“搜索资料”了，但它真的会“做研究”吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajXwoqiadttm4MDMvUxUfT2qoeaxPBjBVs7ic92rovVDn0rYf4k0icNibtrMr0BT7w8ibTl24kOZjSKXtA/300?wxtype=jpeg&amp;wxfrom=0"/><p>过去一年，大模型的能力边界被不断刷新：它们能写代码、能做数学题、能用工具，甚至已经能够“自动搜索”。但一个越来越尖锐的问题也随之浮现：当任务不再有标准答案，当信息分散在网页、论文、表格与图表中，当我们</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247546010&amp;idx=2&amp;sn=8802c82d5e29a40d54d241f250d3ef52&amp;chksm=ea2eedddfbd1230b05585c25d3a58540f5ceb8dcd10139dad049eef35bd50a5305666887db31&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 23 Dec 2025 17:52:19 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[国际头部高校联名发布 Agentic AI 的真正进化论]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahcvQ4869ZlZ37Iz4MNc7voWIrbLrpUp1s5QrhAInCJ9khjUUcYh2yfJcFqg83uYCJu6Q8MDYoNhA/640?wxtype=jpeg&amp;wxfrom=0"/><p>我们正处于从“LLM”向“Agentic AI”跃迁的关键时刻。但不得不承认，现在的 Agent 依然很像一个刚毕业的实习生：理论知识丰富（预训练知识多），但实操能力捉急（工具调用不准、长期规划易跑偏</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545921&amp;idx=1&amp;sn=f55c128bf93b8111a8c609e1e95e7467&amp;chksm=ea8e9f67ec0fee527e946ca14a5fc8e33a1131a6755a295014dc43b9d2cc4c5309510ff5dc67&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Dec 2025 20:48:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[记忆罗盘：大模型智能体记忆的表征、操作与演进航向 | 直播预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahcvQ4869ZlZ37Iz4MNc7vo7IYTRjbia45XfDdwpAZRuAHWicfjyNxFDqIGHd2Nku9k92gv6Chcu4UQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题记忆罗盘：大模型智能体记忆的表征、操作与演进航向时间北京时间：2025.12.24 (周三) 20:00-21:00直播平台微信视频号：b站直播间：论文信息标题Rethinking Memory</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545921&amp;idx=2&amp;sn=d5d535dba59d320c7669c4b67c4fcc32&amp;chksm=eaf259b4ae27e1718fa6fdc5dab2079377c01433302196a33df8a9e1f0c41db32863db25f89d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 22 Dec 2025 20:48:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UCSB/斯坦福联手：无需训练，让大模型学会“脑内推理”，性能暴涨4.5%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiar0Q5pDfbdDBoz4ibYY3y4nJ7ziamh2fpOGhYs4iaoJfOoFmQGpdUN4BsnnbtjWrbR4LIYKPQ4icL1cA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在多模态大模型的研究中，我们正面临一个有趣的“精神分裂”现场。一方面，基于文本的思维链让模型能像话痨一样把推理过程写出来，但这种方法有个致命缺陷：语言偏置（Language Bias）。一旦模型开始生</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545904&amp;idx=1&amp;sn=bd7977076f62b0ee6a2b6eaf5e4bceb0&amp;chksm=ea1d1fb763c83257a73692817d241358266ead7dd3d4b18cfcb9f4a3744408680f8ba1d7f9fd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Dec 2025 21:19:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM是否具备地理空间智能？探索其在定位、灾害推理和事件模拟中的能力 | 直播预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiar0Q5pDfbdDBoz4ibYY3y4n1ddEzprag2HjYPKHfNlnFd1aD9ruP2xwAwDJIMbeWZVZGaKMP9g92A/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题LLM是否具备地理空间智能？探索其在定位、灾害推理和事件模拟中的能力时间北京时间：2025.12.20 (周六) 10:00-11:00美东时间：2025.12.19 (周五) 21:00-22:</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545904&amp;idx=2&amp;sn=df1427b7c9e15cd440fe29ff27e2c044&amp;chksm=ea0d4106dac856d2be3a84a5344f5611fecc9b3f3bef946f7e9fc1bf6cd698c30b02b2978d16&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 18 Dec 2025 21:19:59 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[人类记忆 vs 大模型记忆，到底差在哪？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag4Wl1KH5vhiagUFyNePXImLcy3Q1ibJbVuwosLS3qibGPsNHnOnDPiciaZG5FNFyz5RsPoRw2WOG4WsDQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>这是一篇发表于 2025 年 10 月《Trends in Cognitive Sciences》上的文章。文章的核心在于探讨如何利用认知神经科学（Cognitive Neuroscience）中关于</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545883&amp;idx=1&amp;sn=d469b8078f5828754cbe5a15c6beceba&amp;chksm=ea3fd6a6a2aafd908dfe50153134101fdc99426ae5468de7b2caa10350a77acb1be2513355c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 17 Dec 2025 21:48:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型可否胸有成竹？探索LLM推理与自信心的关系 | 直播预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag4Wl1KH5vhiagUFyNePXImLE9zT8hZwMurZiceZgl9IkFnVktoOVCja1icruNtFtibQhCYyibSicuQtItQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题大模型可否胸有成竹？探索LLM推理与自信心的关系时间2025.12.19 周五 11:00 北京时间2025.12.18 周四 19:00 美西时间2025.12.18 周四 22:00 美东时间</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545883&amp;idx=2&amp;sn=48740e23c870a53f53d529b357268948&amp;chksm=ea31f83c89622b3a499b40dd27dc4d5938ea6a670f64146a72239670c691391ab22e5ab0c972&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 17 Dec 2025 21:48:21 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Deepseek是被降智了吗？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagbuwJNTvs5ltQbMVflkXHS2oe7EYNMgDY0trIbMYgEZS7ah4N8tX0rgwS6CpacrtEHU29Ia4oibWA/640?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：柳叶刀链接：https://www.zhihu.com/question/13585711573/answer/1971134483680960952100%被降智了。我在24年年底就用过DS，</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545863&amp;idx=1&amp;sn=071edacd214b93c87e143ab9c2eed64b&amp;chksm=ea4751a62adc284099e54262bf18b92ca220232a5c997a312288bd142104c5b78c86dbf96ded&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 16 Dec 2025 19:19:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[最新最完整的Agent Memory综述！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagbuwJNTvs5ltQbMVflkXHSqIv39klCMkibzNavlVjtOJmkxnqicAIakIDPVFwdjNTic6SaVibk1rjv4Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天的一篇很热乎的深度好文 "Memory in the Age of AI Agents: A Survey" (AI智能体时代的记忆：综述)，由新加坡国立大学、中国人民大学、复旦大学等多家顶尖机构</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545863&amp;idx=2&amp;sn=ea0d4ce97cbf9fe37ad8c3e0cc2fcc9f&amp;chksm=ea30a55f28298a17d3cb71674fb5cfbf86e36b5bb0ba963da20e89613a0f43f5c36d22cc2547&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 16 Dec 2025 19:19:41 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[理解与生成统一多模态模型：现状与未来 | 直播预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahHkFPiaArCZ3BOLAyksNpxygMib4xJ9nOvx8ydrbj5V5kUh2AVXJSHHibGg03gicZDicibrcibCPeFY4M2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题理解与生成统一多模态模型：现状与未来时间北京时间：2025.12.17 (周三) 10:30直播平台微信视频号：b站直播间：论文信息标题A Survey of Unified Multimodal</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545841&amp;idx=1&amp;sn=e9ab286f279e5dcede4f03455de8670d&amp;chksm=ea09445065cac90605eed2d7e80ea186d0c8b04954535ba5187b540afd55b1725c86e96a486c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 15 Dec 2025 21:14:18 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[思维链推理是一种脆弱的‘海市蜃楼’，一旦超出训练分布，它便会消失。| 直播预约]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag95Zp4trRYVCeiardp3qv3jX3NGpNTXADia6t7RafU5auFYTuY0iahQC6FRzj4icYTxwJRocI6xjd0sA/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题思维链只是幻象？从数据分布揭开 LLM 推理的真相时间2025.12.14 周日 10:00 北京时间2025.12.13 周六 21:00 美东时间🎙本次分享为全英文讲座！🌍bilibili直播</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545835&amp;idx=1&amp;sn=cd26869141c47beb9824091fdf736d66&amp;chksm=eabe7f49031321e2a152e6603aa0bbbab6449885d23112cb70d59ba9863a76dc9b68ffae697d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 13 Dec 2025 17:23:48 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[算力、模型、生态：亚马逊云科技云创计划，深度学习创业者的硬核“加速器”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag95Zp4trRYVCeiardp3qv3j1la39vyUBhibiaXjyeRzskbmicUYfWmKgqORcTegW0bUd7jMvFOgSRUBw/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言对于深耕AI领域的创业者来说，算力成本、模型迭代和生态构建 是跨不过去的“三座大山”。尤其在生成式 AI (Generative AI) 浪潮席卷而来的今天，如何高效、低成本地训练、微调和部署大模</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545835&amp;idx=2&amp;sn=ea59d68ddcc0ce996fef1b82dcde9848&amp;chksm=ea59f3ffd3ba889c1f3a3bdc801c900cf6b80669968088d557dc1a31ec840838ed752a3c00d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 13 Dec 2025 17:23:48 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[RL并非万能药：CMU 新论文揭秘大模型推理能力的真正来源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajeQdcwLP949WYgypT8qD0tBpslFGw8RD1Ab6qlvkBN9M0e8z0t3t4TeXiasvPRgzosIibvv4UjIpeg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在 DeepSeek-R1 和 OpenAI o1 等模型通过强化学习（RL）展现出惊人的数学与逻辑推理能力后，AI 社区陷入了一场激烈的辩论：RL 真的让模型“学会”了预训练阶段未曾见过的推理能力吗</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247545820&amp;idx=1&amp;sn=bac33abc4ae9d6fb61d166f435cf0e2e&amp;chksm=ea7788c03ad9715abbd58468619a44b432871f237f2441ee978c0ea1f4059233d9f55009a1c3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 11 Dec 2025 12:11:15 +0800</pubDate>
    </item>
  </channel>
</rss>