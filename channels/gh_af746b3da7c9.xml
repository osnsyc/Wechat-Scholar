<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[NYU发现Reasoning模型有第六感！可提前预判答案，少干活还拿高分！几乎无损]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajDYSnzruBIl3bTLM9FhibZqsEfsib7ssMjUSMcuw4ibs19nrsibRMW8NT6TANGAWM72Ijn5y5wzxjBrQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>老话常谈，推理模型的“过度思考”是什么？比如解一道数学题，它明明已经算对了，却还在反复验算，甚至尝试其他方法。这就是论文提到的“过度思考（Overthinking）”现象。论文：Reasoning M</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537446&amp;idx=1&amp;sn=2fddb78cac861641065e53bd35879550&amp;chksm=eaa85248c3e0697cc4b6780c9e4767d9fe6ef385a792221e936445df2f0e0c77432cfd216e56&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 07:07:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[想得久≠答得对！LLM应该自主决定Reasoning长度！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajDYSnzruBIl3bTLM9FhibZqK31DCD5KqPEIINODBicoWJ0TO80Q85t1HEd03InYYOoqBCia8ymKhbJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>想得久≠答得对！你可能以为，让LLM像人类一样「仔细思考」就能提高答案质量，但最新研究却打脸了——大模型想得越久，可能错得越多！论文：Towards Thinking-Optimal Scaling </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537446&amp;idx=2&amp;sn=b9cf754049700fd2570c6722ffb3790d&amp;chksm=ea0dd4573aace72d7f8c21c866a8aae1f31d3e0838fa72db2ce256bb087ca2a7679492c3df5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 07:07:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA["反转诅咒"彻底解决，反向推理准确率96%！新架构突破LLM多年认知瓶颈]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajDYSnzruBIl3bTLM9FhibZqBZMCJB2mnmIo4xG8H8Ag00YIbwIZoU6iafVmCpsQOnnlSDY2KBOeABg/300?wxtype=jpeg&amp;wxfrom=0"/><p>"反转诅咒"：一个令人头疼的Bug：想象你教LLM记住"张三的妻子是李四"，但当问"李四的丈夫是谁"时，却一脸懵——这就是反转诅咒。论文：Is the Reversal Curse a Binding</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537446&amp;idx=3&amp;sn=fd216e134d77470a949f32d87f4e7e25&amp;chksm=ea36cc81fd1beefda51c6f02847206f99a4e555f41c165a7c9b0cfe3bb2dd45a3f1d82636c08&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 07:07:29 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[60.4分！字节Seed团队VAPO刷新Reasoning纪录：训练快10倍，错误率砍半]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfXPD1h1MraJmW7X4KIs0wvPjSLxpwQgEOHGtfDWmxSrQV652u3XZdxvbPZZNMiak9OpARsQicz0qA/640?wxtype=jpeg&amp;wxfrom=0"/><p>一个刚学数学的小学生，面对一道复杂应用题，需要一步步列式计算，中间错一步就全盘皆输。现在的大模型在做类似「多步推理」任务时，也会遇到同样的问题。而字节Seed团队最新提出的VAPO框架，就像给LLM配</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537403&amp;idx=1&amp;sn=44fd74084e00727dbb0b34dfa2db3646&amp;chksm=ea525d889aac3c20fd691f5360a482d4844322f721f465fe3a92f7939c80f760e58cb826bb52&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:24:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NICE54期 | 首个面向天文学的大规模多模态基础模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfXPD1h1MraJmW7X4KIs0wQUdUldwEsJWyr85vhtTicHrb1HW9CA9rmKVzlVUFHbALZvpiaUXksthw/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题AION-1：首个面向天文学的大规模多模态基础模型时间2025.4.13 10:30 北京时间大纲虽然基础模型在多个领域展现出了巨大潜力，但天文学由于其数据模态高度多样，目前仍缺乏一个统一的联合建</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537403&amp;idx=2&amp;sn=0f956105a7508673464c4014e0155373&amp;chksm=ea6a6c0f15230f4d4836a678ce535ff6bac1d6ce9f3177b3bbe3409bd3e51258fabfdfa33ecc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:24:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[如今的Reasoning模型都不具备批判性思维！简单问题, Overthinking！离谱]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfXPD1h1MraJmW7X4KIs0wDNacHZAr9AdUF7jlfJ3ykia5VmU7dWt2rmlvglfCIg6UsZgqhSl1Nww/300?wxtype=jpeg&amp;wxfrom=0"/><p>“宇宙终极问题的答案是42！”——科幻经典《银河系漫游指南》中，超级计算机用750万年算出了一个荒诞答案。没想到，现实中的大模型竟也上演了类似剧情：当被问到“a的值是多少”这种无解问题时，某顶尖推理模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537403&amp;idx=3&amp;sn=dfd078d4cb3509c32401374fc73877ad&amp;chksm=ea156bc6830e6da985c2775afde02fca59ec32f0053502b8eba8ae284be90a75b8f26edfd2d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:24:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[聊聊 LLM 推理引擎中，那些已经成为事实标准的优化方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahfXPD1h1MraJmW7X4KIs0w2tIZbYibxCwbXr82XjhxjmHuyXXibKhMDsOuS6OdI8icXZEhXqo2gviauw/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：进击的Killua原文：https://zhuanlan.zhihu.com/p/685706549编辑：青稞AI  本文主要是记录目前在各个LLM推理引擎中经常使用的一些方法。一、模型架构优化</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537403&amp;idx=4&amp;sn=8bc27d6e15e02fc02da6656b6d492758&amp;chksm=ea5eecd368e02de0f5d80f1df5809088fb478a57686ffc2bafb64d8b3b82b68d74748a6da0b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Apr 2025 07:24:36 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯AI Lab联合苏大提出一种新颖的RL评分方法，7B小模型暴打72B巨头！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaia3jFMqJljPtHqicib1WflKglhlBZSiazb1uTzKB0qMbsjRyJsdhmBEIJUgSxfHvias7RiaQiaFEZopIMQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>算是咱们领域最近的一个新闻：强化学习的“评分标准”升级了！过去，LLM学数学、写代码时，系统只能根据“答案对不对”给个简单对错分。论文：Crossing the Reward Bridge: Expa</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537371&amp;idx=1&amp;sn=3141287ba40978843a4dd5455aec44f6&amp;chksm=eaf93407fb56f1319536774587aee4ece2b7a7c9c64254e1e127c88213f09d40a6f9731f3fba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 09:48:44 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[你说量化到底伤不伤害Reasoning啊？一项实证研究]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaia3jFMqJljPtHqicib1WflKguYichxuC28Cft6tPvlGjnMAcbeo7vJeiaOuLNNyrJ2xBeG6iaRZ6jd9hg/300?wxtype=jpeg&amp;wxfrom=0"/><p>如今的大模型啥都能干，但它们的“大脑”实在太占地方——动辄几百亿参数，推理速度慢、内存消耗大。 于是学者们搬出了量化技术，试图把模型的“高精度思维”压缩成“精简版”，比如从32位浮点数降到8位甚至4位</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537371&amp;idx=2&amp;sn=c408395059b29bd3fadca5baabd77cff&amp;chksm=ea6138cfd8063e9ae9100ee4f2e2e890a4dc547f275aa7f517f0fdc1c18103c360b10c49e4e6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 09:48:44 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3倍效率学习的漫画书《StatQuest图解机器学习（全彩）》]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaia3jFMqJljPtHqicib1WflKgPsRvmPcusHYWibK2kqIJh9J8ib4khGze8NNDxYuI5DjT1UeGGvxHo3sg/300?wxtype=jpeg&amp;wxfrom=0"/><p>一旦关注了StatQuest，想必会被Josh Starmer傻傻的曲风吸引，艰涩难懂的机器学习瞬间变得妙趣横生，甚至会不自觉跟着教程BAM起来!!!这位油管关注超135万的大神，任教于常春藤院校北卡</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537371&amp;idx=3&amp;sn=8bea6fca73967813f2eaf6f57fb4cc4f&amp;chksm=eacc7157de9ce42ee7270107fc0ddef03d8fed2a4ae7c6e9057a1e08ab8273b08a28ae353226&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Apr 2025 09:48:44 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NAACL2025 Oral | LLM的知识边界到底在哪里？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZwwS54GXy4bRFKdgkHiaMianQql3gTLmdGgvjUftcNIsFxLyZzaIEGX5nkLSoxqH87frof8d98EIA/640?wxtype=jpeg&amp;wxfrom=0"/><p>当Agent的能力越来越超出我们的想象，当大模型的边界不断地被扩展到具身智能，深度研究等各种垂直领域，我们不禁发问，模型的能力扩展有尽头吗，模型对自身能力有感知吗，模型是否可以像人类一样可以基于自身的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537332&amp;idx=1&amp;sn=9bd6d8fcfacee67fcbc2b299890eee9c&amp;chksm=ea81dc902db67f015bdee721f7ac6f9b50a565cd49242c353043ba9f1347999df682913948d2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 10:04:51 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一个“打脸”结论！模型太大反而会损害推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZwwS54GXy4bRFKdgkHiaMiaiaYNTnyrMYJ5ribNHqHPvszLsqmwtvcMTgF4yRtu0dZD0OmLKJXCFT7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>你可能会想：模型不是参数越多、规模越大越好吗？但这项研究给出了一个“打脸”结论——模型太大反而会损害推理能力！论文：Do Larger Language Models Imply Better Rea</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537332&amp;idx=2&amp;sn=5bf2f4e400fb8211c44aa22557fca8b3&amp;chksm=ea0b03f1798ab2122e5e270013f4bd608c0b07bd2cd9a04bb311f85675d6cbc40ec3f2b56737&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 10:04:51 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[像人类一样看视频！VideoMind提出长视频推理新范式，超越 GPT-4o，AK两次转发！代码、数据、Demo全开源]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagZwwS54GXy4bRFKdgkHiaMiaLrsCyQSmO9QPXbrnqmtETVnynsEpOT3XdMlia7kVATy301R0yR1JtcQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>标题：VideoMind: A Chain-of-LoRA Agent for Long Video Reasoning作者：Ye Liu*, Kevin Qinghong Lin*, Chang W</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537332&amp;idx=3&amp;sn=254919aa3f5825b4f12b5315b604e8e8&amp;chksm=ea0ddb1176b84d12a5ab93c7595ff56cee211d72f2696cf8482dc8d86c5606c643f6a718906d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Apr 2025 10:04:51 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态Reasoning新综述！从训练优化和实时推理角度全面总结]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahsFxN8j8Q0hMECIDnLU3qNJqQy7faSMqRkgH0WlfaAw8QbydbLxnkRht8xo6cNtb6HJKJMGz0F5A/640?wxtype=jpeg&amp;wxfrom=0"/><p>人类的聪明之处在于能“分步骤解决问题”。比如算一道数学题，我们会先列公式、再分步计算，最后验证结果。而传统的AI模型更像“直觉派选手”，直接输出答案，但面对复杂任务容易出错。论文：Why Reason</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537279&amp;idx=1&amp;sn=211e1971f5466a34e8aab4d9af26be90&amp;chksm=eac1a2f24248f207c7c58187a8ac62bcfa5d6415d455d5da1e39277dc0afa4bb96369aeb02d1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:25:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[强大新RAG范式！动态将上下文转化为参数知识，有效缓解RAG幻觉！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahsFxN8j8Q0hMECIDnLU3qNeMXWDibiaUZXhrr9KMWVsoUWySk0rbOGTI1Vibic2XxCZnUPtjGtHLj7Sw/300?wxtype=jpeg&amp;wxfrom=0"/><p>检索增强生成（RAG）通过从外部源检索相关文档并将其合并到上下文中来增强大语言模型（LLMs）。虽然它通过提供事实文本提高了可靠性，但随着上下文长度的增长，显著增加了推理成本，并引入了具有挑战性的RA</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537279&amp;idx=2&amp;sn=b8cc8b2f5b33a51f73b04adf3cb5dddf&amp;chksm=ea460e799e9beed5a2da868acb016a238c03d683b06e85231562941cc1915ed05d48c43b77c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Apr 2025 04:25:54 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[各种角度全面聊聊Llama 4~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahOQS8ibaYA7cIVkXGlZAicya7P7iatd2yQbhabibudKIwdriawlricibMf3uZ4ysMZ2TG7cvUHSjBpUTicXQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天铺天盖地的Llama 4，有些头晕眼花，在此我们梳理了下并站在更高的解读简单谈一谈~深夜突袭：Meta的“开源核弹”为何此时引爆？2025年4月5日，Meta突然在周末发布Llama 4系列，被网</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537240&amp;idx=1&amp;sn=f2668cb2a6fafef9f660fb24a11d4b89&amp;chksm=eabb338581bab30b0a85252eb460827eeedfab2eaa86452efd1bfbfbe50ea0ccdd7048ddf6ac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 06:18:53 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[最新成果：基于图的 RAG 统一框架 in-depth 分析]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahOQS8ibaYA7cIVkXGlZAicyaIKZoTpy3tHzZZ4TMkNcVJ98WGGmlPek5iamT0w9dWqV8icdxCtfFaRBw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：In-depth Analysis of Graph-based RAG in a Unified Framework链接：https://arxiv.org/abs/2503.04338代码：</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537240&amp;idx=2&amp;sn=ed5c6ad092f05a747db3d48b9d0f273c&amp;chksm=ea57a2fd8543e052f50bccce93b75fe4cb0bbf1d37323cf40af9ded026c550be11469215e583&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 06:18:53 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[136个样本训练8小时！UI-R1如何让小模型吊打GPT-4？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahOQS8ibaYA7cIVkXGlZAicya8dPvp2ocibAgretrMZj7Y8Mv5UVRia9bxX0o6U2XJKskXM0veERTGAZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement Learning链接：https://arxiv.org/pd</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247537240&amp;idx=3&amp;sn=23dd01ba8fcbc94aa8eef1f72d6ac6ce&amp;chksm=eae89dd7ac0b9850ca376d1e2408b0aac00cd9d33f3981b734cb3d6e642b460d8f1b3ecb619c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Apr 2025 06:18:53 +0000</pubDate>
    </item>
  </channel>
</rss>