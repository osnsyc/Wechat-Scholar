<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[对噢！为什么LMs就不能直接输出答案+confidence呢？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaTIDr5ysyqwicxLmemAalcxlmey01LTDthVibbUJjKdtGa7EmuIx5KvEulXIrEmciaDyIbicGLvpmRHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>当前语言模型（LM）通过强化学习（RL）生成推理链（Chain-of-Thought）已在复杂问答任务中取得突破。然而，主流方法依赖二元奖励函数（答案正确得1分，错误得0分），这导致模型为追求高分而盲</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541712&amp;idx=1&amp;sn=fb5fb4f2d89b8d686c2880c3608158a0&amp;chksm=ea11f7db8355322313f96861d40bc1762c67947cfba9300272f0a5bef8ac917bcb92b1ffade7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 06:58:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek-GRPO重要性权重设计错误？详解Qwen3新强化学习算法GSPO]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaTIDr5ysyqwicxLmemAalcxp76Gy3YwE2D09PvJzDhpAAR7gH5GEYDglJmO5fkxQw6zVcrR1zqVoQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>作者：绊缘https://zhuanlan.zhihu.com/p/1932829167801574272编辑：青稞AI   1. 引言在更大的语言模型上使用 GRPO 时，会出现训练不稳定的情况[1</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541712&amp;idx=2&amp;sn=472deea7e6b14a5bad05dd78227332ae&amp;chksm=ea18d405af9df67adea0bdd3060e6059fa5b24d011bf69c20bf90c24f8686916d3c51e5cd03d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 06:58:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Test-Time中的逆Scaling law！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaTIDr5ysyqwicxLmemAalcxMl5FtibicusD6jjEUpLD1YibaPrhnEUL1ib94Z5egXUAicZ1QuBly7DU3yw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在AI领域，扩大模型规模（参数数量）和测试时计算量（推理步数）被视为提升性能的核心路径。经典研究（如Chain of Thought）表明：让模型“多思考几步”能显著提高复杂任务的表现。然而，这篇由爱</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541712&amp;idx=3&amp;sn=d2b1a7c69749a809b9a0f9d0e6e3a404&amp;chksm=eab89eceeadfb652fd5ec2e66bca86f7e15e0a77b50f3540cf0a24a056e72f308e7ba6c3a47b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 06:58:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI'26、NIPS'25交流群快进~  若干核心问题都在这里面~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaTIDr5ysyqwicxLmemAalcxTkKuWia8GaqcCFAj8FicAY5EBb99Wjw4g8GaeEhGwwNUuvfTKfrlGHag/300?wxtype=jpeg&amp;wxfrom=0"/><p>赶紧进，超过200人就不能扫码进啦~   进不去的看文末~进不去的，扫码，备注AAAI2026即可~</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541712&amp;idx=4&amp;sn=7b40f811030c7e6c954bc7790f83973e&amp;chksm=ea51a49abff96a821f186c85cec69f6c2f3af9a4de31527c039e53680b12f2290a969c2f166e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 06:58:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AAAI'26摘要提交后还能改吗？ -- 昨天的群已满，新群建立！没进的快~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajKFZflJADibwwwvORFXS86Esy3avPzcZDsxGyq8K0WmkeJWWzeJ9icpOwkNUXCjYYiakT1cK1ps0vGQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>赶紧进，超过200人就不能扫码进啦~   进不去的看文末~进不去的，扫码，备注AAAI2026即可~</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541668&amp;idx=1&amp;sn=b32fcb5d19a3c3cbb0f15e8c0827e1de&amp;chksm=ea0fdb1beb3589c1e18abe060bc88c26ec96b31c980c78b5851bf115d1095901a0ca2ce546ad&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Jul 2025 10:02:08 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[快进！AAAI2026交流群！取号已经过了3w了...]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajWPR9dHKibGne2kSfaZDkKm4lu5eJwhW0HDrTPC5DcjPr9WvQzn4q3lb8QRv0E54rffJJOPCOlT5Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>赶紧进，超过200人就不能扫码进啦~   进不去的看文末~进不去的，扫码，备注AAAI2026即可~</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541654&amp;idx=1&amp;sn=151d048eb05343ea322830c1b86671c2&amp;chksm=ea5d42af0f386f02fb3e0b7cde6c0ef146421504067d3cbef060a4f238758e0ec50ffb1e93c8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Jul 2025 09:30:01 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[微调重要表征以增强思维链的推理能力]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagMvu0icOXA3A9805pt7FKHDDiaQD4OLFoKsuvJXSWvr4Ozn4abian9GdvHdcQ5oKzrO3ia1dzZGSl4qw/640?wxtype=jpeg&amp;wxfrom=0"/><p>期刊/会议：ACL2025论文地址：https://arxiv.org/abs/2507.10085机构：阿里云智能-飞天实验室关键词：LLM reasoning，Chain-of-Thought，P</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541648&amp;idx=1&amp;sn=6544a25ca325b631a0c08ebab1e98005&amp;chksm=ead7b7dba2b193d92b149dd7b294bde3acdd566c2905d8ee5e4aa5fcda85976f906be6c8f821&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Jul 2025 13:42:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[扩散模型+自进化：这篇论文让Deep Researcher错误率直降70%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagMvu0icOXA3A9805pt7FKHDibM59c83aURSCR4J2wvUqiaYj7fOZYDHFOdicgXMeDicdCNF1elLyTKL3Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前基于大语言模型（LLM）的深度研究代理（DR Agent）在生成复杂研究报告时面临关键瓶颈：传统链式推理（如思维链CoT）或采样策略（如最佳N采样）虽能处理简单任务，但在多轮搜索-推理-修订的长流</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541648&amp;idx=2&amp;sn=d03c6606ad2ea3c3e88c14de91577d0f&amp;chksm=ea6544e06804a6517b39ab728f58ff0a68d87e612040729c3a6e11f63d798032ee1341d962a6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Jul 2025 13:42:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型如何"不训练"也能学习？——上下文学习的隐式权重更新机制]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagMvu0icOXA3A9805pt7FKHDjIEGAQefH0X4kHvicf3k4mc6c3855jLI5ujCB3ZdX2CYcCDsutVFuXw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大型语言模型（如GPT系列）能在推理时通过提示中的示例即时学习新任务，这种现象称为上下文学习（ICL）。传统机器学习需要通过权重更新来学习，而ICL却无需修改模型参数，其机制一直是未解之谜。论文：Le</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541648&amp;idx=3&amp;sn=59213ada7703e712bbc1c6503863d482&amp;chksm=eab3e440d5945630ad01a6c43eafcc4d596e4bef511830b07148153c11f37d84badc446207b9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Jul 2025 13:42:13 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | LLM Agent的“Windows”来了！AIOS如何构建LLM Agent的生态底座？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagMvu0icOXA3A9805pt7FKHD4uKodmibibtAiarJ7f4KQP6MLRCupwnj5LN2Du5ZPe1RXDkGFz99ic7q6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>主题LLM Agent的 “Windows” 来了！AIOS如何构建LLM Agent的生态底座？时间北京时间：2025.07.26 (周六) 10:00纽约时间：2025.07.25 (周五) 22</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247541602&amp;idx=1&amp;sn=af3c9b30b2e9ee501dfd14f9b1799561&amp;chksm=ea2fbb206015482439ff5df4e392cd906d4cf1779f7e5c982545fbde8b3b7c3781a40f3b0556&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Jul 2025 03:08:06 +0000</pubDate>
    </item>
  </channel>
</rss>