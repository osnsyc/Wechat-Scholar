<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[体积大、算得慢，如何推的快？LLM高效推理服务最新最全综述！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajGdRbqibZxzSkycIkJ0Yz8ReNIuLr6moMnKbywN3UB9XycGdzzDA6xSNp9BXtBquic5pGj5uANcgnQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家都知道的一件事就是LLM真好用，就是太大了。咋部署才能更加高效呢？真的是个让脑阔疼的问题。比如最近的几十万下载量Mistral-Small-24B-Instruct-2501和 Llama-3.3</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538405&amp;idx=1&amp;sn=b4488ef8f5c55aa8b1f69fcc93da3465&amp;chksm=eab77b1d25963701c3f483dafc4ac32ffc2adbd50f9d74b3649b024ecea54dc922f6e27b6d25&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 01 May 2025 10:52:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | Test time scaling 综述! 从what, how, where 和how well帮你系统解构！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajGdRbqibZxzSkycIkJ0Yz8Rib0TD2Rbg3HWJJ4tySAkMbVW8l2yPwpicuyKILOUItRibexxf4fLC1shQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题Test time scaling 综述! 从what, how, where 和how well帮你系统解构！时间2025.5.3 10:30 北京时间内容介绍论文：What, How, Whe</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538405&amp;idx=2&amp;sn=f4c2a32943d60e6af56a079d3f9e09b6&amp;chksm=ead76eda627fa229e2cd9b6c99324d23e29801effe60fe694884f127ae11d6e8acd221bd5593&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 01 May 2025 10:52:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[PD分离也有问题？semi-PD降低两倍延时，增加一半吞吐！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bajGdRbqibZxzSkycIkJ0Yz8RibkFsQ7PagYVz6qU9Mia9iaPjNng5uDZzRibIMs7ibhYOso7EM53ic5aYC1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型服务的效率困局大型语言模型（如ChatGPT、Llama）的服务过程分为两个阶段：预填充（prefill）和 解码（decode）。前者负责理解用户输入并生成第一个词，后者像“打字机”一样逐个输</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538405&amp;idx=3&amp;sn=d7ace18f3ae0cc65ba4d173df0d9baa6&amp;chksm=ead67f71936efe3e4e54865ef5530b66cc5f2cafb3658244456c2d4d75073d5d30e41cea2763&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 01 May 2025 10:52:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[小心！你的手机正在偷偷『学做人』——LLM如何让它自主订咖啡、抢优惠？| 手机端GUI Agent综述]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiapATcrAicCCmYlE5dia9BykQjld4KZGj5IwLNDQ4EaF0ScogNfticSqcdV3WoIfSOBFRsicBGOeU4r2Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>手机自动化的革命：从「机械操作」到「智能大脑」想象一下，你对着手机说「帮我订一杯拿铁」，手机自动打开外卖APP、选好咖啡、填写地址并支付——整个过程无需任何手动操作。这就是LLM（大语言模型）驱动的手</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538367&amp;idx=1&amp;sn=f74c1c4563d8d3f5d590dcd976ff7201&amp;chksm=eae36a443eb14d1cff22534d53400352ab108ee2c3cf56a670fcdd8e0e791b862df693f46635&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Apr 2025 14:41:41 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[可信大模型 Reliable LLM（四）：利用不确定性估计强化大模型的事实性表达]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiapATcrAicCCmYlE5dia9BykQITHHHN2jibCu5Gq0p05LoicU0loOpv7XJT77uZgPibibibiaaHfK5NABBLWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>知乎：Beyond Hsueh链接：https://zhuanlan.zhihu.com/p/16213981801本系列 blog 是有关大模型幻觉、知识、不确定性等方向的学习笔记分享，我会持续更新</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538367&amp;idx=2&amp;sn=e0230fd6e192503ebc94b26d5265f00e&amp;chksm=ea78f75e66baee21e6075c6b7d291f8b9ab8bfc01792ea5558245d5ceee1cabb7468aada1a81&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Apr 2025 14:41:41 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Reasoning涨点新方法：LLM「左右互搏」训练模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiapATcrAicCCmYlE5dia9BykQGb7ZrSl4HG1fbXbLpJsxI6icGSPSlDZ9tlKFxTJIbpZqlliaJlgM2WRQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>自我进化的新范式：用「左右互搏」训练模型！这一对抗训练的核心框架想象两个AI在玩「猫鼠游戏」：一个AI专门制造隐蔽的数学推理错误（比如偷偷把方程里的加号改成减号），另一个AI则化身「福尔摩斯」，火眼金</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538367&amp;idx=3&amp;sn=a8b4b73123153b6b2ef5cd97be37d60e&amp;chksm=ea05b3444bdd9b07859822d592a9c4e18eb592191f7a3b5d94f734f4c8149fdd78b1dfd8df42&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Apr 2025 14:41:41 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[推测性思维链SCoT：小模型“模仿”大模型，最高提速2.9倍，准确率几乎不降]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagh0MCSmj5RRdX2CVnFoeB1mJaJZQx8KUXY94LLBWxeru43RkrECTgiaJrT1xxpO6nCHFM8mb5m8QA/640?wxtype=jpeg&amp;wxfrom=0"/><p>现在的大模型（比如论文提到的Deepseek-R1）虽然能解决复杂数学题，但有两个致命缺点：体型庞大：动辄几百亿参数，像“超级计算机”一样耗资源；思考过程长：解一道题要生成几千甚至上万字的思维链（Ch</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538301&amp;idx=1&amp;sn=a10d91ccf6703a9d03d1893cfb4ba654&amp;chksm=ea20d817046bf5767356cde19a3d3cd88971fe1dfd0505e867d4df008e23011aa5468d62e96f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Apr 2025 12:08:23 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[When2Call：哈佛认为LLM也需要“边界感”，要意识到是否何时需要工具调用]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagh0MCSmj5RRdX2CVnFoeB1bha3zyVWMgSwLlnVNUxKCibiaM1mGIyI7iboMg1VTIAibrcs9xXvjaC2iaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI也需要“边界感”？工具调用背后的新问题如今的大语言模型（如ChatGPT）越来越擅长调用外部工具，比如查天气、查数据库。但问题来了：如果AI没有对应的工具，或者用户问题信息不全，它会怎么办？想象一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538301&amp;idx=2&amp;sn=d1dd1163ac6fb8989b1b9239365519ca&amp;chksm=ea18e0fa036ca15c1dc4dc1e178216fb6e77ffe8cb1469ae64914876aa850f0345a19d58188a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Apr 2025 12:08:23 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大+阿里提出快慢思考新方法：在多模态Reasoning上准确率涨10%，长度砍半]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagMGIXCyzVhiawY4Jjpa9x5KibqmCEvzibFUBe4L7gJHzNAEb5RlTly3rwfkaAptfjpXxlhrJNzlQOxQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>为什么大模型会“想太多”？当你被问到“1+1等于几”时，如果非要先写一篇《论加法本源》再回答“2”，这就是典型的“过度思考”。当前的大型视觉语言模型（LVLM）也面临同样问题：无论问题难易，它们都会生</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538275&amp;idx=1&amp;sn=959fd8c85780a51ceee9a78ab2aa5c45&amp;chksm=ea009cfc5e93d12510e23309a7ab96d613e97673ca87f02ad3fcd55c71a4aad9d77e9145075d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Apr 2025 13:12:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[直播预约 | LUFFY：让推理模型实现“即学即用”的强化学习训练方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagMGIXCyzVhiawY4Jjpa9x5KkdaxHpbicdpCQju49webpyO4jy5IUwQiaLzIibhw5HL7KVzBU19n0lIBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>主题LUFFY：让推理模型实现“即学即用”的强化学习训练方法时间2025.4.29 20:00 北京时间分享内容paper: Learning to Reason under Off-Policy G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538275&amp;idx=2&amp;sn=7ae8c129c62000bbfdf842e7a49c30d7&amp;chksm=eaf921219af75f19ce0d1fa0800a97b9419ddf62c60dd9fccc2f3310c0cb95883e8e82e9cca3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Apr 2025 13:12:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[不用训练！TRACE让LLM生成既安全又有料]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagMGIXCyzVhiawY4Jjpa9x5K4XZWsibXbCh97asiciavlp3AzA3XDZtb9yib3xUudPxCIG1s1eE82hAMCQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>为什么需要控制生成内容？如今的大语言模型（如GPT、Gemma）虽然能写诗聊天，但有个致命问题——它们像“走一步看一步”的短视者。生成内容时，模型只根据当前已生成的文本预测下一个词，无法全局考虑“整段</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538275&amp;idx=3&amp;sn=228503600aee8179bc4d301c2ba04b5a&amp;chksm=ea2f15d241cc223a9123834a39aa57906f3694a51457135c18cf54105dcc22f0469c93ec0320&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Apr 2025 13:12:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[特征工程、模型结构、AIGC——大模型在推荐系统中的3大落地方向]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagMGIXCyzVhiawY4Jjpa9x5KCQRKak6icJ1hblXP5J0M36c0uic4anSWEKbNGEdTxECroy39mia8Qu6NA/300?wxtype=jpeg&amp;wxfrom=0"/><p>特征工程、模型结构、AIGC——大模型在推荐系统中的3大落地方向今天我们谈谈一个搜广推行业这两年怎么都绕不开的一个话题，大模型在推荐系统中的应用。两年前，我们可以说大模型是推荐系统的未来，但如今，大模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538275&amp;idx=4&amp;sn=5c1f55b6f8954c99c0c0e4b55ccbfb22&amp;chksm=eaeba874c9b0661aa68bf63cd1e1ff065b1b6aff2a7a33e7297fdf198303884b17ebdc57067f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Apr 2025 13:12:07 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌发现LLM是Greedy Agent，提出用RL调教出理性决策]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaB1aa7ZM4O8fSkf0YJlnQtRH2iaNWdejqh8TdiaIv99G8EXpRibD6ibqY3z164oiaoxSice2V7UG3BPCSw/640?wxtype=jpeg&amp;wxfrom=0"/><p>大模型的“决策短板”从何而来？大语言模型（如ChatGPT、Gemma2）在文本生成、代码编写等领域大放异彩，但当它们被用作“智能体”做决策时，却常犯低级错误：比如玩井字棋胜率只有15%（不如随机玩家</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538240&amp;idx=1&amp;sn=80ae3560e3cfde3c0d32449b93585131&amp;chksm=eacc6b5a23cf17563ff1a3355fdbc768057d1635bf569869def5b1d3613b1b895aa68a6d8f56&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Apr 2025 13:32:04 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Tiny Reasoning模型：LoRA+RL=9美元训练费，性能碾压同行]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiaB1aa7ZM4O8fSkf0YJlnQtcNTUBj9ZqD43lBibOJgPhkKkeXMd8H5I50Z5Aia2LBDr6xScU9dWyqtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>低成本也能训练“聪明”小模型？Tina的野心当前大语言模型动辄千亿参数，训练成本高达数百万美元，但Tina团队反其道而行——用1.5B参数的“迷你”模型，搭配创新方法，实现低成本高效推理。核心问题：如</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538240&amp;idx=2&amp;sn=62045adadb2756b6e62e93d8f3408aba&amp;chksm=ea52ec561c681b8ff13d7533dfe371d50859375dd9d5a40e8f9955b887a9017c04b20ad08ef3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Apr 2025 13:32:04 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NUS发布Reasoning中的安全问题综述，idea满满~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahqxXwfEf6HqS9H9usmkMaegVc2lztdYENhsbtIzia6U2S5ibEGoma2yjuYoaKu5Vr8wzmhc6CcyD2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>当AI学会“思考”，安全问题如何破局？最近，以DeepSeek-R1、OpenAI的o1系列为代表的大型推理模型（LRMs）横空出世。它们不仅能生成答案，还能像人类一样“写草稿”“分步骤推导”，在数学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538212&amp;idx=1&amp;sn=7d50d37f025fc1b90ed45feae0ce731c&amp;chksm=ea53fbb24e44870561ed70bf702b0d6d8b92ae68516192f8cae03812f360fa9f86c5222cb089&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Apr 2025 10:57:04 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型在线辅导小模型，正确率提50%、推理效率涨90%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahqxXwfEf6HqS9H9usmkMaeRVjvq7SftBl7zSiaWBVRMILic4DIeQIfLdkicGXBb36MPsqjRskOfVCIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>想一下，一个刚学数学的小学生（小模型SLM），虽然做题快，但遇到复杂问题就容易卡壳。而博士生导师（大模型LLM）知识渊博，但计算成本高。论文：Guiding Reasoning in Small La</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538212&amp;idx=2&amp;sn=0d9d56848222474b404512214395f834&amp;chksm=ea5a94a37cc547780a711319c98b4fe2836f2b0aef9a6ccb019d7e74c776f7acc3c326a20503&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Apr 2025 10:57:04 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里发布多模态UniME：硬负样本+知识蒸馏=性能天花板，准确率暴涨27%]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahqxXwfEf6HqS9H9usmkMaeXbblbgm1ASLLeYrbicniaqAcUbZF7LBwfRGUn0lCXh8Z3muEK0VEVQeA/300?wxtype=jpeg&amp;wxfrom=0"/><p>为什么传统模型不够用？多模态模型（比如大家熟悉的CLIP）在图像-文本匹配任务中表现不错，但存在三大硬伤：文本截断：只能处理77个token，长文本直接“被砍头”；孤立编码：图片和文本分开处理，缺乏深</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538212&amp;idx=3&amp;sn=63eb17827ac018078f3f025014f677e7&amp;chksm=ea538e9fd5840d02b3498f8822da1c5a780eb9907493e90ee3f531bf3a424a9d415e6ff044b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Apr 2025 10:57:04 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[揭开o3的神秘面纱，港中文/UIUC/普林斯顿联合推出OTC-PO，让你的Agent既聪明又高效]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagGcxQJIDoPN6vjicI8ao078LpFFeWSkfCm11jfrw8rHwKYEe0OByIX6IaLF78wdWJxSiakLUk0VX5Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>RL is All You Need for Agent while OTC-PO is All You Need for Agentic RLAgent 即一系列自动化帮助人类完成具体任务的智能体或</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538171&amp;idx=1&amp;sn=c6388857de39f6230ff5e1080555b2c8&amp;chksm=ea17c4293ee1ed0c1636fe9f2d04bbde1bf7960b828f995d42419030051e39509436d97b1718&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Apr 2025 05:22:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[首届CogMAEC@MM’25研讨会求稿，探索认知驱动的多模态情感与共情智能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagGcxQJIDoPN6vjicI8ao078G4iaAkxT5drEHQKJVvSMSVbr5hLdVqYEzncOcB05IwQs4yc0u7Qblzg/300?wxtype=jpeg&amp;wxfrom=0"/><p>时间：2025年10月27日至31日地点：爱尔兰·都柏林 | ACM Multimedia 2025官网：https://CogMAEC.github.io/MM2025为什么关注CogMAEC？当人</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538171&amp;idx=2&amp;sn=5bb8081dd45be4fec11bf79f46351073&amp;chksm=eabf7a0c6a8bee65cd22b970d632fae5106278ca636f1dac9e217e468dfc387f093b42538339&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Apr 2025 05:22:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[1.5B小模型+32B外援=28%准确提升+8倍提速？SplitReason实现推理过程“无缝接力”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagGcxQJIDoPN6vjicI8ao078V2sEjR9kXMtyGq78Xn08HafwPpEBfd6udO8ia9WA7wkAhvEaaFtS6kg/300?wxtype=jpeg&amp;wxfrom=0"/><p>为什么需要让LLM学会“呼叫外援”？大语言模型（如ChatGPT）虽然强大，但推理速度慢、算力消耗高。尤其是数学题、编程题等需要多步推理的任务，生成几千个token是家常便饭。这就像让一个博士生做小学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538171&amp;idx=3&amp;sn=52f514ba7ee1b783089e487e63697d53&amp;chksm=eaf5e061a728c47a90fbe3020860fd63932ccb219f058e20287ef2e736108e2c08be3ef5b72b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Apr 2025 05:22:05 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[华人团队提出视觉推理测评标准，揭露SoTA模型残酷现状]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagGcxQJIDoPN6vjicI8ao078RWLr7KwnuJZ9PDuYyE9wGRPJYygKKEYhzY7MSPc0o8PBzST3ytYq2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>为什么需要新的视觉推理测评标准？当前的多模态大模型（如GPT-4o、Gemini）看似能“看图说话”，但论文揭露了一个残酷真相：它们可能只是在玩“文字游戏”！现有测评标准存在重大漏洞——允许模型先把图</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247538171&amp;idx=4&amp;sn=589ff3cabec5148a9780d3ace4a57268&amp;chksm=eafc46bf17542b3709366fd85e2ed7f8d71a58a5488fd2df4a5078c8aa0798bb31421f172db8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Apr 2025 05:22:05 +0000</pubDate>
    </item>
  </channel>
</rss>