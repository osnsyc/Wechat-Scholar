<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[深度学习自然语言处理]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[深度学习自然语言处理公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_af746b3da7c9.jpg</url>
      <title>gh_af746b3da7c9</title>
    </image>
    <item>
      <title><![CDATA[ACL2025分享会报名啦！六月中旬开始！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagND96DPnkhsE9UStMLVfVuLckKy2Qab495Eia5RiawX5Cy4xSCucqqrvGu9tMsCzeD4uMJibibh7QWqA/640?wxtype=jpeg&amp;wxfrom=0"/><p>NICE将要在六月中旬分批举办ACL2025论文分享会，在此邀请大家来分享自己的工作，好的工作应该让更多的人看到！（文末了解NICE详情）报名方式报名后，我们会通过微信尽快联系你哒~扫码(或者) 链接</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539363&amp;idx=1&amp;sn=edb8c37c0f77e9e729a8cb344b459ce7&amp;chksm=ea706ea0381edb191ad9a8e4e967688e3ddf62a025c478f19509e850c76560a8b2433d480dc9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 24 May 2025 11:09:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[用教学反向评估AI！复旦联合创智学院提出Teach2Eval，实现超越基准的能力评估]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagND96DPnkhsE9UStMLVfVuNsrxib3iaAyMrpaM4svViaxFgic0zWtaHlPT35uLK9LIbI0PzRzdKx7TOA/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着大模型展现跨领域泛化能力，AI研究已进入「下半场」——核心命题不再是追求模型规模或训练方法的突破，而是构建能真实映射现实世界复杂性的评估体系。正如Teach2Eval研究所示：真正的智能评估不应停</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539363&amp;idx=2&amp;sn=7377e2ff62198af3e5913d9161b4fb18&amp;chksm=ea00a165e6ac4725cc77e501cb14ae268860d3941dee31a4e370a032cec7eae71846b31a0733&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 24 May 2025 11:09:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML2025分享会报名收集啦！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagND96DPnkhsE9UStMLVfVuB5ziceJ1QFibTWYb0JGGAuqXpq5C2qMNcllxJOoiaDh1RJDHVwAITTMDw/300?wxtype=jpeg&amp;wxfrom=0"/><p>NICE将要在五月末和六月初分批举办论文分享会，在此邀请大家来分享自己的工作，好的工作应该让更多的人看到！（文末了解NICE详情）报名方式报名后，我们会通过微信尽快联系你哒~扫码(或者) 链接http</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539363&amp;idx=3&amp;sn=75442ffce9e819f3db8dabb04102a8f4&amp;chksm=ea9b9f58e57ba2df3c829e93bb9a283bdb8fe1e9f62ced40cbc6da24a658f5c00ba32d49cadf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 24 May 2025 11:09:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[312条数据训练出“电脑高手”！刘鹏飞团队提出PC Agent-E，性能超越Claude]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagND96DPnkhsE9UStMLVfVuUXIfzdgwlRJicicJvs6esLQ89cREicsHialzzj2eEx0tiaDy0DsTduhrWZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>为什么训练“会操作电脑的AI”这么难？ 想象一下，你希望训练一个AI助手帮你处理电脑上的各种任务：整理文件、安装软件、调试代码……但现实是，这样的AI至今仍像个“学步儿童”。为什么呢？两大难题：数据太</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539363&amp;idx=4&amp;sn=547ef07165c7a3fdd969818d19c12022&amp;chksm=ea3086cfe534b7ff70fe5bd50063c97efffc5a783edd1a29686cb36ecfbaf32146c71efa490c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 24 May 2025 11:09:22 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL2025 | LLM的“记忆”与“推理”该分家了吗？一种全新的训练范式，彻底厘清思考流程]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag2RMozBDBCLFVG7XibicOXRejMnHNWQMTN6su2FfoghVDXtNxyI69PfRPRGoibHw4w9WgSbnFicYjX9g/640?wxtype=jpeg&amp;wxfrom=0"/><p>在大型语言模型（LLMs）横扫NLP任务的时代，模型的推理路径却依然是一团迷雾。面对复杂问题，LLMs是凭“记忆”说话，还是靠“推理”得出结论？我们能不能把这两者解耦，从而获得更可控、更可靠的模型行为</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539324&amp;idx=1&amp;sn=fc02987abd9370396436be587c429927&amp;chksm=eadbff91a58e1a12b04717e0df93790f56c89fa4b30d3a379bac64a8207688432842633b86c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 23 May 2025 09:51:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[上海AI Lab等推出硬核评测！SOTA大模型栽在解密推理上，结构化推理竟成致命伤]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag2RMozBDBCLFVG7XibicOXRe4zNyxzMEK5xXSOQjAtMa1BwUiboGzv7FuETeKMMnLicxFouIAXry42Cg/300?wxtype=jpeg&amp;wxfrom=0"/><p>摘要： 大语言模型能写诗、能编程、能解数学题，无所不能？慢着！当遇上加密数据，即使是最新的Qwen3和顶尖推理模型也直冒冷汗！上海AI Lab等联合推出的 CipherBank 评测，用海量真实隐私场</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539324&amp;idx=2&amp;sn=9f0427a39804e66ff0947ad641b6db90&amp;chksm=ead426a80b3bb159e774d64efc170565e6603ee0894fd93c8c6bac61626a2c9de583be74342d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 23 May 2025 09:51:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[招聘 | 智谱-LLM Post-training/Evaluation-全职/实习]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bag2RMozBDBCLFVG7XibicOXRe94KePk7RjPgXQRTBbuPlwB8wKiaNMCF5Qsaps2Pol2VPtGKLJ9g75Tg/300?wxtype=jpeg&amp;wxfrom=0"/><p>一线大模型公司，面向某知名原生大模型场景进行基础模型优化（场景绝对知名，但由于合作公司要求暂时保密，不过可以私聊告知）方向LLM Post-training或Evaluation岗位全职、校招实习、科</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539324&amp;idx=3&amp;sn=80620beccf5f1cd2ba87fc46c14b8c53&amp;chksm=ea4554210a1cd6d4420f295243be61b111afcda5d736994893e381bb577f9dec8e10ccdb7d55&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 23 May 2025 09:51:12 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[强化学习背后的隐藏代价：幻觉税]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagobB6cKeicuo960PRFpDiaBksvqzMwia4YBBRibJjQNhLIZMqmdONTticXyYIYWgZMVvH3ic8b1QQ4lacQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文：The Hallucination Tax of Reinforcement Finetuning链接：https://arxiv.org/pdf/2505.13988大模型的“自信陷阱”：强化</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539278&amp;idx=1&amp;sn=582dc4b0006ca3f98b0844f8a8bc5151&amp;chksm=eac303862dfc6feca4b085c50566855a7a2ca6f8431418462bf011389a7a8e26441cd5179e10&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 May 2025 09:31:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[PhD补录 | 哈工深计算机学院陈科海老师补录2025级9月入学博士生，10天内有效，先到先得]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagobB6cKeicuo960PRFpDiaBkC8LaYh6gC2FnBicWRYF7DiaNJKQgcz965gvSRC9DseAhPvZdVKOGt8nQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>哈尔滨工业大学（深圳）计算机学院陈科海老师补录2025级9月入学博士研究生导师简介陈科海，博士，哈尔滨工业大学（深圳）计算机学院教授，博士生导师，国家级青年人才。2020年获中国中文信息学会“优秀博士</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539278&amp;idx=2&amp;sn=d814fd5eca4a5ab75de21514f993168a&amp;chksm=ea173ba6e92958b18e96b8281080906720c6d0462103bd53fe1f1e2eba9006af4e8493b67a6f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 May 2025 09:31:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[学会“模糊思考”：推理速度提升22%，还少犯错]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagobB6cKeicuo960PRFpDiaBkaWAKs5OtCgrlC4yzUbhDH5NrgM1EojsnO2DYohgELsotdrXoBhtX8Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>过去的 LLM 在推理时，每一步只能选一个确定的词（比如“苹果”或“香蕉”），就像考试时必须在ABCD中硬选一个答案。这种离散符号的思考方式有两个致命问题：容易走错路：一旦某一步选错词，后续推理全盘崩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539278&amp;idx=3&amp;sn=bdf197b63047f3082b2dc383661e8b4a&amp;chksm=ea91ddbcfa73536d5a0768645d4e58ed36fd340994985a444d5eb7392905b721724264fb1d58&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 May 2025 09:31:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML2025分享会报名收集啦！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bagobB6cKeicuo960PRFpDiaBkWcFH9Lmnf736pgz5WYB90vMoAE9jZsLPUlWVh2b4kcYH5IH0y1sibIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>NICE将要在五月末和六月初分批举办论文分享会，在此邀请大家来分享自己的工作，好的工作应该让更多的人看到！（文末了解NICE详情）报名方式报名后，我们会通过微信尽快联系你哒~扫码(或者) 链接http</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539278&amp;idx=4&amp;sn=3e64aeb0ba698753545eb84d7f1b47e5&amp;chksm=ea5e56d042b6dfb6a38d3b58069df136e2c370d51012379d1c1441240d9fcb6ba34a85e3cc65&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 May 2025 09:31:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从零到有：打造迷你DeepSeek-R1最全教程]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia6SJB7GrjjtB26BGUA8aqEA6hBN8Q8VAdJGZoKkqGsFWeBwZ7jN4rH8C5vuuCibEYv7FIhLK7NV7Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>打开GpuGeek算力市场，地址如下：https://gpugeek.com/login?type=register&amp;source=wechat_DLNLP_01其中最香的是RTX-A5000-24G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539238&amp;idx=1&amp;sn=52785c5ce8bf8169b3087d109a852f67&amp;chksm=eae23feb8fe70062995a23c046b0808bdee302fece8bacfff936abe4603a91e9ca69d8d56018&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 08:50:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL 2025 | 清华&amp;港中文提出 MorphMark：全新理论视角破解大模型水印效力与文本质量的两难困境]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia6SJB7GrjjtB26BGUA8aqE7icnWaDVISQkNbEMReYb6qeHHTTPOLibUsibeicwWLAPuqOoVAGEFiceuJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：MorphMark: Flexible Adaptive Watermarking for Large Language Models链接：https://arxiv.org/abs/2505.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539238&amp;idx=2&amp;sn=f42937219114bd79d418a432c2393b0a&amp;chksm=eac5e9ef12b01ce4b0e95cfb1752ebfa16f92429abf057a4334de3a7b1d74ddae32918e94748&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 08:50:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[在Think中边搜索边调整的搜索增强Reasoning方法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baia6SJB7GrjjtB26BGUA8aqE07InJpGGCdXXwsiczBrVnperhBmzxEXFSfElS80UFPSBsC5fs538wvQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>为什么需要“外接大脑”？LLM虽然“知识渊博”，但本质是“死记硬背”——训练数据外的信息它无法掌握。比如问它“2024年奥运会新增项目”，它可能瞎猜。于是科学家们给AI装上“外接大脑”：检索增强生成（</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539238&amp;idx=3&amp;sn=0dd675aef346c43f7670b3b4acc80e7a&amp;chksm=ea5058287f3db2b3cedb821f392e652c7f5870da170a2c92ccce8ad10c1a05fe46b740b38879&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 08:50:58 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | 无需训练，即时对齐大模型偏好]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiag98LoUGfvTHicRVK9jRYv4uk96EfBbJiaia1MvxSBZibv20npNEA7JJHo3b5v3ldtqtqMIlgW66gZ3g/640?wxtype=jpeg&amp;wxfrom=0"/><p>TPO：推理时即时偏好对齐的新方案 为了让大模型（LLM）的行为更符合人类预期，一系列训练时对齐方法（例如RLHF和DPO）通过微调模型参数来实现偏好优化。然而，这种“训练时对齐”模式不仅耗时耗力，而</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539202&amp;idx=1&amp;sn=0eed57d030fb967564ac635ecd6293cb&amp;chksm=ea23a5c1758b3fa2d9e33a2b45484abcf3be298e66bbd554288e05851075326d2568751fd525&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 14:18:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 Oral | LLM也有从众心理！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6baiag98LoUGfvTHicRVK9jRYv4SI1Qb1NTqNrOHYsN7xTjZhF3HvQdYrkicicZB3uOqmuYiaNib3QWiarCakQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>当你和朋友玩“谁是卧底”时，明明知道正确答案，但看到所有人都选同一个错误选项，你会不会怀疑自己？最新研究发现，大型语言模型（LLM）组成的AI团队，居然也会犯这种“从众”错误！论文：Do as We </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539202&amp;idx=2&amp;sn=41b0bea4575111a5626729fdc97fbe2d&amp;chksm=ea035f0438df5cea3499a833ff531c129b93d408bf1087cc63765263f900003085232214bea2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 14:18:31 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL2025 | 抓出0.1%的捣乱分子压缩方法OTT：近乎无损 超越KIVI，内存减6.4倍 吞吐量提2.3倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahjSlXD4qibHCzpgnVNuhNmgaoPdbpk4tb2sicfEibLz978rdGIkqibZsLxY8X0ThVS0XV35alvIjgV6w/640?wxtype=jpeg&amp;wxfrom=0"/><p>LLM 生成文本时，需要记住所有已生成内容的关键信息（类似“临时笔记”），这就是KV Cache。它的存在让计算复杂度从平方级降到线性级，但代价是内存占用飙升。举个栗子🌰：LLaMA-3-8B模型处理</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539160&amp;idx=1&amp;sn=cf1acd98d304b129d66b51f3b05020b9&amp;chksm=ea5ea8445246a2824098bee257d34f5f8bab93e6c61ffbae26030a875a895edf9fac7d0f1fe2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 08:09:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Reasoning新突破：SoftCoT++如何让LLM‘多想几条路’？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahjSlXD4qibHCzpgnVNuhNmgmBZelEQlzNjVhhAiciaEs40yBkdtjNBzibDmZ7k2GBcOvsc0lodo1bUeA/300?wxtype=jpeg&amp;wxfrom=0"/><p>LRM 的推理能力依赖“思维链”（Chain-of-Thought, CoT），即生成中间推理步骤。但传统方法在离散的token空间生成这些步骤，存在两大问题：信息丢失：每一步只能选一个词，复杂逻辑可</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539160&amp;idx=2&amp;sn=d27ce5cd589b1bf020fcabdb94a585b2&amp;chksm=ea0b129e2d969c0d2b1ab435fff220a19ad4c04c83c9a597836b11bbe660d69fe534f8180112&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 08:09:48 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FudanNLP邱锡鹏老师组-25普博/26直博/26普博/26保研 招生]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahlhzvX5DAHVe5pUvFEZaj3I8A2AsRLhfrfuXxTtdZKtuwy8sXwIrQpXaJc6lUficCEXevgHHhZQag/640?wxtype=jpeg&amp;wxfrom=0"/><p>复旦大学自然语言处理实验室（FudanNLP）邱锡鹏老师组开放第二批2025年普通博士招生，复旦官方报名系统已开放（即日起至 5 月 25 号）。该批次招生拟入学时间为 2025年9月。 同时，实验室</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539135&amp;idx=1&amp;sn=22e6faf4fbba354ecc80c6923d4b9160&amp;chksm=eaf04a910ae8a51a4036ed1d68fdc706e21012afef99abee8101c2e801101cb2360c2abfda22&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 10:48:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态大模型集体翻车，GPT-4o仅50%安全通过率——SIUO 揭示跨模态安全盲区]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bahlhzvX5DAHVe5pUvFEZaj33dL6ZtOnkSUOqia5YaZrcenI25vd8qlNKqElE2K5LvXY5wpXt0b5c3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>随着通用人工智能（AGI）日益融入人类生活的各个方面，确保多模态大模型的安全对齐已成为亟需解决的重要问题。现有研究大多聚焦于单模态风险（如有害文本或图像），却往往忽视跨模态组合所潜藏的安全隐患——即便</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539135&amp;idx=2&amp;sn=cfa3b789b365096529ec5a72b4bdad1d&amp;chksm=ea64b439a7e41197492f76298d1006a4f6e264f31aa58ca6e649c64edbf774332690fdc7000c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 10:48:52 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[苏州大学OpenNLG小组近期录用15篇ACL、2篇ICML等论文！招生贴]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah306xYta2M8cHhJfFqzp97FCicRJoOh3PoIVl5S8DMe8Xoh93azKQ6LVR22lPesqtBDQ3Pc7UMyHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近期国际顶会或期刊陆续公布录取结果，我们刚成立4年多的年轻Team苏州大学OpenNLG小组，共收获19篇论文录用，分别为15篇ACL（8main+7findings）、2篇ICML、1篇TACL（A</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539101&amp;idx=1&amp;sn=04f41a3e3b9fc2c2f667ef41fb3c82de&amp;chksm=ea4ebed7bd70a7b85af9b78a93100dc9cf9cefcba46652225677a7e5402d45b1fafd9072e2e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 14:59:26 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Qwen突破：用「并行计算」代替「堆参数」，新方法内存降22倍、延迟降6倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/gKaxjIx6bah306xYta2M8cHhJfFqzp97pk9mC9lPMqQ0OTHMFT8nzkjE3truCEvDLy8RTnwpWDPA7v8kcLcFXQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文：Parallel Scaling Law for Language Models链接：https://arxiv.org/pdf/2505.10475LLM 的进化一直依赖「堆参数」，但模型越大</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&amp;mid=2247539101&amp;idx=2&amp;sn=a6f6d4ecfcbf475195a3c7251303e5d2&amp;chksm=ea7cf4aa8be820a55eff7729fd3d10aac27af7ed0c6e2ca94cc962c2aa00afb3a3a3aac7d2a7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 14:59:26 +0000</pubDate>
    </item>
  </channel>
</rss>