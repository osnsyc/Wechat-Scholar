<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AINLPer]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AINLPer公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_895a8687a10f.jpg</url>
      <title>gh_895a8687a10f</title>
    </image>
    <item>
      <title><![CDATA[当年错过比特币的人，现在都在疯抢它！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZqRSKPUbPwsoqzHOicWGRrYHGicBwIFUbtKmTFfA0N95UhnvhtyFr4Eick5keaVTXc4nR6DMNIQLiaicA/640?wxtype=jpeg&amp;wxfrom=0"/><p></p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247503721&amp;idx=1&amp;sn=75147e6f4a300a5a85e36a0010070c7d&amp;chksm=fb9a0676fdde32a49d3b2f39521271161b91d303fdd3c9655f655ec59c359b0a630066cf94a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 13:57:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[PITT | 提出PhyT2V框架：让文生视频（T2V）更符合物理规律（CVPR2025）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZqRSKPUbPwsoqzHOicWGRrYC88qYWbotVyfQibo7JyC5dLInPdxURIOkM0iaCfhMVGwiaxib64RLCg8AQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方“AINLPer“，添加关注更多干货，第一时间送达更多精彩内容->专注大模型、Agent、RAG等前沿分享！当前文本生成视频（T2V）技术正在从注重视觉质量与模型规模的扩展阶段，迈向更关注物理</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247503721&amp;idx=2&amp;sn=beba381555571ff0b4bb4005dbfa7aa9&amp;chksm=fbf10c90292a57e8b774281e2db3be4f69d4df8afb267aa310618f46dbf02aef7a36a283bb3f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 13:57:15 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LLM每周速递！| 涉及多模态、测试时对齐、大模型Agent、RAG优化、模型分布训练等]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabWR1waf2PzXvfAh4pDlyaiatiagc8J62fkgUG87TL7d9gfqoQpT9tqRTTiamAOo56kxKA7e0Z0XaW4g/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方“AINLPer“，添加关注更多干货，第一时间送达更多精彩内容->专注大模型、Agent、RAG等前沿分享！引言紧跟技术发展趋势，快速了解大模型最新动态。今天继续总结最近一周的研究动态，本片文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247503709&amp;idx=1&amp;sn=916f0bde340261f7ec5c9c6441a9c5c6&amp;chksm=fb3542a801e2b7a08f9abd4c3c5a8677cd33f0b8603af9b2df2e5165beeb63d76d40e98297f0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 14:15:03 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Apple | 开源视觉语言模型：FastVLM，可手机运行，首token速度提升 85 倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiabWR1waf2PzXvfAh4pDlyaiarzsUkeqmzRLLnc7bJWzJO4t04YAWlzUr0mPWrqybicsxV2pqicGyMuWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方“AINLPer“，添加关注更多干货，第一时间送达更多精彩内容->专注大模型、Agent、RAG等前沿分享！当你用苹果手机随手拍图问 AI：「这是什么？」，背后的 FastVLM 模型正在默默</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247503709&amp;idx=2&amp;sn=93645ab2ab91a40590d02f6662a5f577&amp;chksm=fb27043dddde1a69cb2e6f4938ab4d8c40571ec3bb17937f6cdc80203f72e48d0aea78569b53&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 14:15:03 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Transformer | 一文带你了解Embedding（从传统嵌入方法到大模型Embedding）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZ6D3kBib26icDyBrgh6kibjwaPGoGaWXicib0GQX8RRQfFm72IoRia69ZkibCwG59fOibJHJNeicDypBATJ3Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方“AINLPer“，添加关注更多干货，第一时间送达更多精彩内容->专注大模型、Agent、RAG等前沿分享！引言Embedding是 LLM 的语义支柱，它可以将原始文本转换为向量形式来方便模</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247503680&amp;idx=1&amp;sn=e6b06342031a5c2f2b5f66b15afb5249&amp;chksm=fb55c92d2dcc4bbb6cb841148903f453085fa3068066acaaafae2700a9c60ce5cae1841ca0c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 13:58:59 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Google | 发布革命性编码智能体：AlphaEvolve，突破数学极限！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaZ6D3kBib26icDyBrgh6kibjwanxud31ZnTW55k3zyluDiaCpsv5CqeWFuCtd04ykw0omM7ibEx29aQoyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方“AINLPer“，添加关注更多干货，第一时间送达更多精彩内容->专注大模型、Agent、RAG等前沿分享！今天，DeepMind 正式发布了 AlphaEvolve —— 一个由 LLMs </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247503680&amp;idx=2&amp;sn=b82dead6cb1e8383261868034f07912c&amp;chksm=fb08f5537724a852e5527969980f2ff289d16b130b4af3a9a95efd09d8b5c52e9aeb49abe062&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 13:58:59 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[快手&amp;中科院 | 提出多模态奖励模型：R1-Reward，比SOTA模型提升5%-15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BQYN3xneiaaPHUeuaQfyp667kabsV9icZFficVFRjZ5jicyzRrPD5tcqicjSsbRIeic78mYxeKOYNIuwibzoTnFEv8nw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方“AINLPer“，添加关注更多干货，第一时间送达更多精彩内容->专注大模型、Agent、RAG等前沿分享！多模态奖励模型（MRMs）在提升多模态大语言模型（MLLMs）的表现中起着至关重要的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&amp;mid=2247503653&amp;idx=1&amp;sn=af8263ba88b275e22cae7f7fcb3dca2f&amp;chksm=fb1467b273a0a71c45d8718e931aa138415a60f3a9c7f0c8d24fa20295b06aaa399b774f3a17&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 14:23:02 +0000</pubDate>
    </item>
  </channel>
</rss>