<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[GiantPandaCV]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[GiantPandaCV公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_f24964232d76.jpg</url>
      

      <title>gh_f24964232d76</title>
      

    </image>
    


















    <item>
      <title><![CDATA[谈谈对DeepSeek-R1的一些理解]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkNDib4nCAroOEOW3ZKWWReKKvia4Kb81n8FIJzWnffVvuh3SavYJjdrdPFH0rJK6KXDmNzHQp2oicnlw/640?wxtype=jpeg&amp;wxfrom=0"/><p>一、写在前面在OpenAI o1刚放出来时，它有限的技术报告里，有2个内容格外抓人眼球：Inference/test-time scalingRL我一直是把这2者理解为两个独立的个体，在这个基础上，当</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526147&amp;idx=1&amp;sn=0a279482ae4ad49c5ae2922f37d2d7d3&amp;chksm=9eac12372855c30d70c1fd299bf9eb7d428be2f558b144455f840a75620de94a644915c4f41f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 23 Jan 2025 14:44:13 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[使用NCU和Cursor Claude-sonnet-3.5写出高效cuda算子的正确姿势]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3sQ5uEmqQWibCRRdaAJq2Mfaf7GJzNUJkheiaC0oIibbBNic9IOdQAbynCryorSIVleTFFiaoEZGvLxicUg/640?wxtype=jpeg&amp;wxfrom=0"/><p>我的课程笔记，欢迎关注：https://github.com/BBuf/how-to-optim-algorithm-in-cuda/tree/master/cuda-mode 。0x0. 预览版上周</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526144&amp;idx=1&amp;sn=0e2a8596b726805e8376c36a2d69c02b&amp;chksm=9eef6e6e5c09c85ab07d0c2dfff30fc80eaa5a9cef1c56e164daf78168827c86eeb444817319&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 21 Jan 2025 11:10:18 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[再读MLA，还有多少细节是你不知道的]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkMHicT7tD3vIcaMSdQOchTicDiajK9gDrqxz1FQquxMkIhAEVkMqlX064Kpyxib9UveJcsPYLONrg1hPA/640?wxtype=jpeg&amp;wxfrom=0"/><p>关于MLA，我想先简单记录下我了解它的心路历程：我第一次了解MLA，是在它刚出来的档口。在我读过它的原生实践后，我发现它既不省KV cache，还徒增了计算量。这个问题让我困扰了很久，当时网上对MLA</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526125&amp;idx=1&amp;sn=eeaf163026a230a9d316668ec7a5c92d&amp;chksm=9eda81dc3e1903751060612530527253e196ec2bea0d6c112e8262103d1c1954f62bafdcf082&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 20 Jan 2025 12:39:26 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[PyTorch博客 《使用 Triton 加速 2D 动态块量化 Float8 GEMM 简介》]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3tzr6AYxLSze8mibqqbgOFibv7BCXiczbmBKgzMmywEaHsWsjVQ636O8iabKwPTCf6z849rgwlM7LoxMg/640?wxtype=jpeg&amp;wxfrom=0"/><p>博客来源：https://pytorch.org/blog/accelerating-gemms-triton/ 这里做了翻译。这篇博客主要讲了如何用 Triton 来优化 Float8 格式的矩阵乘</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526123&amp;idx=1&amp;sn=c94d16930ac2ce6984e0ce34907c09f3&amp;chksm=9e1bda7b8afee5bfcbb1f9d1f5bef9da2e91517e8f447f33b6af6a7a377913787af30c533083&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 19 Jan 2025 15:14:11 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[书生·浦语大模型升级，突破思维密度，4T数据训出高性能模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/oDpticHyXWJH71PrnrZxUKpcicEh6lOu1QZ6El6eSYNas4PwpeK1u6674iaibL4fU6evrmjdtq83DKia36261p7Oedg/640?wxtype=jpeg&amp;wxfrom=0"/><p>“尺度定律”之下，大模型除了要突破算力瓶颈，亦面临高质量数据即将“见底”难题。如何通过“通专融合”技术路径实现通用人工智能，正日益成为业内共识。1月15日，上海人工智能实验室对书生大模型进行重要版本升</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526107&amp;idx=1&amp;sn=44693ccb021aeda105455b807b1f61e3&amp;chksm=9e7e986bde1a0845c482340fa35a10662224e3beb7705562c83fa534a3e4faa3a53dd0e744d7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 16 Jan 2025 13:16:01 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[PyTorch 博客 CUTLASS Ping-Pong GEMM Kernel 简介]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3vmqmwUtMNU7T5Fr416UicHSTib6qOOkOm7gwrC8DV4s6Xl5L2cGDMy6l2iaw28YlytYX80ibwicicZictiaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>博客来源：https://pytorch.org/blog/cutlass-ping-pong-gemm-kernel/ 这里做了个翻译。这篇PyTorch的blog简要介绍了 CUTLASS 中的 </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526105&amp;idx=1&amp;sn=6e9ee5343b11132436d59aeeff9aae84&amp;chksm=9e12061f295482657375cb574234b4f38a1f0acf628fa79b747b505c087259204b41afa2074d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 15 Jan 2025 02:44:10 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[精选25篇NIPS年度Paper，2024 AI研究总结]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/P0Ka1WNRwjX4dzWwZBINtyqsfBhR6yaO8G4b5Ml941mQkGuyNaeobdxA2l76a5T8KuyE4kabnoyE4Eulrfq1aA/640?wxtype=jpeg&amp;wxfrom=0"/><p>SmartFlowAI点击上方蓝字关注我们顶会 Oral Paper 作为在更高学术标准下筛选出的优质文章，对学界发展有着重大影响。我们今天简单对 NIPS 2024 的 72 篇 Oral Pape</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526092&amp;idx=1&amp;sn=56e6e1656a2335783ee8eb054c2f0acb&amp;chksm=9ef0be63afd5efe11730bf00d4ca82e1e6fc324900681d7ca5d40b54a08cc0ef1e5253586d58&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 13 Jan 2025 13:51:30 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[SGLang的Expert Parallel特性解读]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3tDtPgDZYdgYZViao3CBNYP3FI9anHz8Pibh6L4dibl3tYbpKGpIch3siaKic1PFGJJRd1jbTeSicVQqzKw/640?wxtype=jpeg&amp;wxfrom=0"/><p>0x0. 前言最近在SGlang仓库下做了一段时间的开发和学习，对SGLang的一些比较新的Feature也开始有一些了解。这篇文章就是尝试来梳理一下SGLang中Expert Parallel的实现</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526090&amp;idx=1&amp;sn=83eb057c0034d41fc8d4da0cce80531f&amp;chksm=9e43462becfceb8606d76c5a3a4ee510425f7a1799bfa68e01b1b6d6bc5da6cc46f14d0ddbe2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 11 Jan 2025 14:14:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[简单聊聊Deepseek V3的FP8训练]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/P0Ka1WNRwjVS8Xsu2RRQoqLpI3R4M3FqJOVib3EhOruANBcorhjfToW2ibKDz8yX2I40qUCtqGkufpia2cpLMKqyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>SmartFlowAI点击上方蓝字关注我们作者：企鹅火烈鸟🦩全文约 2400 字，预计阅读时间 6 分钟引子Deepseek V3的报告在网上放出之后，在知乎也看了很多训练分析和推理的文章。前段时间也</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526061&amp;idx=1&amp;sn=6b6bc78f35f37700c3620e3655bcd106&amp;chksm=9e0c15b3dd3403a303d91c4cead8143c841ac7fd05e4f28f899648f5d710103c08ee399c8500&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 08:41:08 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[[分布式训练与TorchTitan] PyTorch中的Async Tensor Parallelism介绍]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3uRrqyH7Z703hyUnew05npP32VzhhNMibXs8x7iaxoxibhrt4qlxVDknxMxVd8MnHUvibDCooibSY9tyqw/640?wxtype=jpeg&amp;wxfrom=0"/><p>来源：https://discuss.pytorch.org/t/distributed-w-torchtitan-introducing-async-tensor-parallelism-in-py</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526050&amp;idx=1&amp;sn=6a02448e248dec1ccbb48ed1e2d4bc05&amp;chksm=9eb08e077a671fbb6887c6dda889d2eb8180aba4271bdebd9e076598118cf90b8c86bd1addec&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 03:59:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用torchtune把LLaMa-3.1 8B蒸馏为1B]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3uRrqyH7Z703hyUnew05npP61IOiadvkTEKyFcJhjABdicCNoLuE9O8FrWPz6GI38XAOF2YZBPppzWw/640?wxtype=jpeg&amp;wxfrom=0"/><p>博客来源：https://pytorch.org/blog/llama-into-torchtune/ by Linda Wang, Evan Smothers, Kartikay Khandelwa</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526033&amp;idx=1&amp;sn=e4e30a614b2af39ec9c2fbbb74acc859&amp;chksm=9e4a90b1f6501ae69437b2e080c111c59aa0d65bf1395b8b96da4555b4e271fcf398dbcbdae9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 10:35:27 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图解Megatron TP中的计算通信overlap]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/GmyBmIxnRkMbLJgBKf7TGLiazdyylqtZemA2Wdgkq4UL3L5GnDtspUWacNbT6EiaAkWrTARBTc2EyIqu2k5WDkyA/640?wxtype=jpeg&amp;wxfrom=0"/><p>这篇文章想来探索Megatron中实现计算通信overlap的方法。具体来说，Megatron的dp、tp和pp部分，都有可以做overlap的地方，本文探索的是tp部分（更准确地说是megatron</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526014&amp;idx=1&amp;sn=1a5259d6795d15f36e8478c383d03706&amp;chksm=9e787f1c6a8d76261828ba1253b57a0e3940b65e3104781b143a14021d70cd7b6bb80952306c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 14:00:06 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[将Diffusion模型的推理速度提升了8倍，顺利拿到6家企业offer]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3vAZzAvWexy7k7NbhnLO24xeWAYAoXPM5ZYnQKq09LwPviacx4GeTjILaEWjx9tK70xWx6eZPqHBOw/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是图书李，硕士毕业于苏州大学，今年6月毕业加入了大厂做模型推理的工作，毕业时拿到了华为南研所、腾讯北京等6家企业offer。研一研二期间，我是做计算机视觉算法的，每天为提升模型在各大数据集上</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526010&amp;idx=1&amp;sn=da89e3d0691afcb6a0ed41bbcae507fd&amp;chksm=9e1d5a071af0d45cbceba428b23931007a283efd2888b606f5c8cb423db9815cb1b20438f385&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 03 Jan 2025 01:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[让预训练 Transformer 生成更长的文本/图像：位置编码长度外推技术]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/PPYfhrH0Fa2o24mv3KkY6rplSaAb9DEarVg50HYGPx7NHbTIiaF2IrQ9GDCVfs9uEDfs8TJUpL3SGVMFqHlOJ1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>随着视觉主干模型不断向 Transformer 靠拢，和 Transformer 配套的一些技术也从 NLP 社区涌入了 CV 社区。比如 Stable Diffusion 3 还在用标准 Trans</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526012&amp;idx=1&amp;sn=6d35716aa0b291561d2f3fd045b89215&amp;chksm=9ef3733916bc7e646d8482318e055323a65a8e6c42d40b30d81ee3c8812ac2ee968f0421f24b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 Jan 2025 09:18:23 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Triton Kernel 编译阶段]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3ureqDDGkdSUOMHUtKJBSTMZByFQ6qafICibAHBuZDn9Ek7DlAGMlRwu7GdYU3nY3eButGxkEBm8Pw/640?wxtype=jpeg&amp;wxfrom=0"/><p>博客来源：https://pytorch.org/blog/triton-kernel-compilation-stages/ 。这里做个翻译，是CUDA-MODE 课程笔记 第29课 Triton内</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247526004&amp;idx=1&amp;sn=ca6686fe23250d5833827e995900a755&amp;chksm=9e01386100ec25d7cd93cac8f9a6af447ec8b24df35a1092775883dd16cf4db9d35fb742f092&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 31 Dec 2024 15:17:55 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CUDA-MODE课程笔记 第17课 GPU集合通信(NCCL)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3v72TynCMiahOoyviawMZRRFnwZ9zajxH06Vg6FTicuoBMpIEEd2PKunpib0AU4ibFeOR6KRLCzuibrL3Ag/640?wxtype=jpeg&amp;wxfrom=0"/><p>我的课程笔记，欢迎关注：https://github.com/BBuf/how-to-optim-algorithm-in-cuda/tree/master/cuda-mode 。这节课介绍了NVID</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247525989&amp;idx=1&amp;sn=1184d6e38b0f139b156ee19599dc10e7&amp;chksm=9e90f133c4e7feb3c2622db907e4dae1493bf93ba431a9bcd692a7f033938338ea3e715d33e3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 30 Dec 2024 14:24:50 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AWQ：模型量化应当关注激活值]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/SdQCib1UzF3vEcROdcga2tociaw3nV3qDAfmckHiaswiaHkXxfGbcIRUYUiatIHjWreHGkjw5p3CMXRsW60z7miaUjHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>作者丨Chayenne Zhao来源丨https://zhuanlan.zhihu.com/p/942485319编辑丨GiantPandaCV这篇文章是 AWQ（activation-aware w</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247525943&amp;idx=1&amp;sn=8ea8a7804c495fec327cbc9e7ef6437f&amp;chksm=9ec7376d881e64391ba6c122ef663b540c34f76b73d9563e09ace617ec889fa0568220d4482b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 11:16:07 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NIPS 2024 最佳论文 VAR 深度解读：下一尺度预测为何能超越扩散模型？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/PPYfhrH0Fa2s3PxEicuvjNMzZ2IoWlgG8BYkeBO2BxnXVbSmsjIAKMapdCVb4wHhMaian1rOyCIcquwgJiadxaGXg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今年四月，北大和字节跳动在 Arxiv 上发表了论文Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale P</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&amp;mid=2247525942&amp;idx=1&amp;sn=29ead2b88ee6c524d2261bcce89d0378&amp;chksm=9e20de2171823ad4c57ce2db529b7ecb51bf293e3a675622a86029ce42f659809b18dde47096&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 09:44:59 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
