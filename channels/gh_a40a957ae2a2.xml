<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[NLP工作站]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[NLP工作站公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_a40a957ae2a2.jpg</url>
      

      <title>gh_a40a957ae2a2</title>
      

    </image>
    






    <item>
      <title><![CDATA[如何让 RLHF 训练更稳定？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mAtKvC3qQQOhcOI6hxibh1icOu8xoicTQmpIgvJvdJqrrC6aE6xZyVaVcyWdt9E1XdLQfLA0vPBc6Ag/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来一篇知乎好友@何枝的文章，主要介绍一个可视化LLM强化学习训练过程的工具-RL Logging Board。知乎：https://zhuanlan.zhihu.com/p/1673494</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247491310&amp;idx=1&amp;sn=9549f30a56455ce35f179d7f27ce90ca&amp;chksm=ce0bbc010fa22b04e69221deb9d5c45950046096c12fc1ba665bddaee5ca085bb8b72eca2770&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 07 Jan 2025 03:29:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[长文 | 大模型Post-Training总结]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5nBpNRwzHn1uuNDxp2602vSNniaKS9yedT4pcp33Y4aJz5mX1IgLkt0kSo01icibYchce2ygrXACL2qw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来一篇知乎好友@hadiii的一篇文章，汇总Llama3.1、DeepSeek-V3、TÜLU 3和Qwen2.5的后训练Post-Training技术。知乎：https://zhuanl</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247491293&amp;idx=1&amp;sn=229260e3bfb82b555327702e93b88dc6&amp;chksm=ce31a42d3740a73d074514c1a080a85827f43b3e53847407c759909970fe0357babc4c694956&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 02 Jan 2025 06:12:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[微软论文爆出GPT-4o参数为200B，而GPT-4o-mini 只有8B参数]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lkhkuagem3bBBguviaHcxzaFKVjha5N9uR5z8dsm23yibyKxqAicacp84wWycshm5O1X3DTr1xOufug/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是刘聪NLP。震惊，今天看到一篇论文，竟然爆出GPT、Claude等一众模型的参数规模。文章来自微软，暂不知信息的真假，先看论文截图。arxiv: https://arxiv.org/pdf</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247491225&amp;idx=1&amp;sn=b38a2bac3cd4c8a6a6ae732ba24afa5b&amp;chksm=ce8ba03ddb2383783ed9349b1e35d53b2c6a03fb3433f9dc065381ed9a1d7ad1de42d8339dbf&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 01 Jan 2025 12:31:53 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[LLM 预训练到头了吗？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5mgNw8j9VaKicnQ1LDoAiajibQxVzZ9IeSUXeaLb5wybPXk8RkGwDiaSEAoRozd7xMbw2ZNibHCfsdPdxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家带来的是好友@Binyuan的一篇想法，主要是对Ilya的“pre-training as we know it will end” 观点的看法。正文如下：最近，Ilya 在 NeurIPS</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247491219&amp;idx=1&amp;sn=9800a9d53cebb0c0061401a57ede6c68&amp;chksm=ce24c0819166f4d8fb77259a63da2d46bde2bfa1d093425f0422f04320d7408c3ae4c9424e6b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 01 Jan 2025 03:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[回顾2024：与LLM又相伴一年的经历与思考]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5lxJofZY46QNM7TtqxicGBWr9hJMd8DZsTHLsaI6yDeARqcN8fOJ3Vfud8GRWHBsVmAx9icubfNWYJg/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是刘聪NLP。又到了一年一度年终总结时刻，不过今年这篇总结，跟往年的不同，今年只聊LLM。2024年是LLM蓬勃发展的第二年，只能说发展确实十分迅速，层出不穷的，但也让很多人看清了LLM现有</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247491215&amp;idx=1&amp;sn=e5c6752701a334ca7414422abb857a43&amp;chksm=ce733e150badc2426a706503a9f6a7d156124e2629c566dcc8b5f461592a7c8a7f0a655c59c0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 31 Dec 2024 01:09:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态大模型在表格解析任务上效果如何？亲身经历全是泪！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/iceGibVicRfib5n0ib2QaKK8tj3C5BlRssc8JBQlvrHpGDjic0QsqAJCicQKaMic25wWvpY8g6m12LrQ1Ticu7JYSa8spkw/640?wxtype=jpeg&amp;wxfrom=0"/><p>大家好，我是刘聪NLP。前段时间一直都在尝试用多模态大模型进行落地应用，除了问答之外，那么最容易想到的就是文档解析了。一来多模态大模型本身就有强大的OCR功能，二来知识加工对于大模型落地来说也是重中之</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=Mzg5MTU1NTE1OQ==&amp;mid=2247491195&amp;idx=1&amp;sn=04f9092b0bb06404ad149fea8f347d47&amp;chksm=ceb980b380b493c8d8d8a88a2af7b637b2319c245e3afcaf1743502540473e74c047635b2728&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 01:20:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
