<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[CAAI认知系统与信息处理专委会]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[CAAI认知系统与信息处理专委会公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_7b616b8cdb4a.jpg</url>
      

      <title>gh_7b616b8cdb4a</title>
      

    </image>
    












    <item>
      <title><![CDATA[力肌图（FMG）传感器用于人机交互协作]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1pHwF6p5ibNgTFXaQHdIFXN9j6MmiaVNP8oH6xMoHl4K0UWvdwVQTdhrgSXY1aKDABX4LdgP8y8Iz5A/640?wxtype=jpeg&amp;wxfrom=0"/><p>想象一下，与一个能理解你的行动方式、精确感知你抬起一个箱子时用了多大的力，或者你拿工具时有多轻柔的机器人并肩工作 —— 这就是我们正在构建的人机协作的未来。机器人正在成为我们的队友，无论它们是用于制造</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501235&amp;idx=1&amp;sn=ab617611b355d4139426a3a6997c4884&amp;chksm=fd5cd74d2f5fa56464632af806f7e23af7635eadc9301b85db36fc309dd478ac721c4a7c36cc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 11 Jan 2025 02:05:05 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[Science Robotics 通过培养多元化和包容性领导力来加快机器人技术的创新步伐]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1pHwF6p5ibNgTFXaQHdIFXN9UGzbvCRKnWNn8DIGbBkV8GFxDQA470OpjQVankH2rHMEQr5lPCzfEw/640?wxtype=jpeg&amp;wxfrom=0"/><p>机器人技术领域是高度跨学科的，从机械和电气工程到材料科学、计算机科学、神经科学和生物学。在这方面，机器人社区是学术多样性的倡导者。然而，尽管文献表明团队多样性与包容性领导相结合推动了科学领域的颠覆性创</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501234&amp;idx=1&amp;sn=1e02358a1d5cd478048ff510ff177a84&amp;chksm=fdce5efeac2b01c6630046c2c7d541aad476804a1b13b7bada651bf04a4eca7b5af4a19f63ba&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[IF=24.5! 综述：机器人纹理识别触觉感知和机器学习进展]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1qf2yv78fFLibiaqTwko8aUwwX1LTmfZaWswGicFsLWGd5XaWUlyP9p1ice4rSciay1UYJgov2mRNJCeJg/640?wxtype=jpeg&amp;wxfrom=0"/><p>      最近，人形机器人在学术界和工业界都引起了极大的关注。这些机器人正变得越来越复杂和智能，在医疗保健、教育、客户服务、物流、安全、太空探索等领域都可以看到。这些技术进步的核心是触觉感知，这是类</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501157&amp;idx=1&amp;sn=6061056c77a13c964a95f4ec2cf68c0c&amp;chksm=fdbc449942a02fbfe8f2fcb8046973bac64f8093fb2182dd0eba0b78b2a2016ab85bbdb6e738&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 14:24:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[《麻省理工科技评论》2025年“十大突破性技术”正式发布]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/JJtKEey0hPbTBVCIGIQAoUGdqYktCyTAg1Nic2cIpt2V2nWvnfoQEP7asibdPYONdiciaIbzugyicFXOvQIclBeofAA/300?wxtype=jpeg&amp;wxfrom=0"/><p>作为全球最具影响力的科技智库之一，《麻省理工科技评论》凭借其独特的观察力和专业视角，始终站在科技创新的最前沿。为挖掘那些可能改变世界的创新技术，自 2001 年开始了“十大突破性技术”（10 Brea</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501157&amp;idx=2&amp;sn=e35d9fea6921b7f16c397c8a635916fe&amp;chksm=fd00384533032e4d0f7ff2a5408481b29c70c992e8065234b32e8a116ce808f64d8ecfcdbf5d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 14:24:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Nature Communications 纸基功能材料做的触觉传感器]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1r4oMpbFhozovxhpdaNBiaOy4kN1ylkYVhFodzsUZiaMIaswqwZp0aazEFCPEQXnWmfuXlOW0fZpUnw/640?wxtype=jpeg&amp;wxfrom=0"/><p>01研究背景在人工智能与机器人技术快速发展的背景下，触觉感知系统作为机器人与环境进行智能交互的关键接口，其重要性日益凸显。传统触觉传感器虽然能在常温环境下有效工作，但在高温等极端环境中往往难以保持稳定</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501156&amp;idx=1&amp;sn=fb92c575cbac90ddfcdfa41e710e93c4&amp;chksm=fdf0e6649c0feaea680e18d49fa9ed71bf784bdec9a89628f254e4b74c9c1467095d52043be1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 00:26:09 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[斯坦福大学李飞飞教授团队ARCap: 利用增强现实反馈收集高质量的人类示教以用于机器人学习]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1qf2yv78fFLibiaqTwko8aUww6oOHRibjhCMzG8Ktsp2FIaOk0WxmjpW3N3eoqITiaHwZ4tsx5T9GELsA/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，通过人类示范进行模仿学习在教授机器人操控技能方面取得了令人瞩目的进展。为了进一步扩大训练数据集的规模，近期的研究开始采用便携式数据采集设备，无需依赖物理机器人硬件。然而，由于在数据采集过程中缺</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501156&amp;idx=2&amp;sn=3163dcc2b0074fa8aff70037450af4aa&amp;chksm=fd3edd9930db6ff1eb3c41c81ff6366392a96be4585e852ac8d9ca2c84d86f27a7004c75f960&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 00:26:09 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Science Advances 普渡大学开发了新型机器人变形软体表面]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1r4oMpbFhozovxhpdaNBiaOyXbjfIvSq7aiaFq13tMS2xQl9bxAqyXiaWUauYg2ktZNJKibJ5IqibDfckQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文链接：https://www.science.org/doi/full/10.1126/sciadv.adg8019技术背景传统刚性机器人结构在形变自由度和实时响应上存在诸多局限，而软体机器人则凭</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501124&amp;idx=1&amp;sn=2b1583f2b6fe4bdb39f6cac2947b50e3&amp;chksm=fd5bfcf06b094add3fda01d6e186c9456ceb8b438edbc2a8feee5f2e29452358d65533203f4b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 23:30:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Nature Review Materials 提出了针对柔性可变性结构的评估指标]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1r4oMpbFhozovxhpdaNBiaOyTtLZcRicBdibr5gZC33o3fyATscN4Mge3rNibknUBuwQWHou7F8e3pJicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>普渡大学Jue Wang和Alex Chortos针对可变型结构的性能缺乏统一的评估标准，不同技术平台之间难以客观比较。提出了针对柔性可变性结构的评估指标。文章发表与Nature Review Mat</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501124&amp;idx=2&amp;sn=9c491c6d2f7db4573f70c38c29f9e97a&amp;chksm=fd5b7a5eee3e2448cc41f67b1c4ae81060f12c47df1b4d7d8d25b0646184ec4f0a9f06769248&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 23:30:34 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[CMU卡内基梅隆大学「软体机器人动态手旋转笔」]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1rHU2msicGqITGicLvJlWNl0fk4icrGaiaibhMclk6HHog09mhtv1vdpWXqJAKzqFgqQ8aXk5ZEBqGhT5A/640?wxtype=jpeg&amp;wxfrom=0"/><p>动态的手内操作仍然是软体机器人系统面临的一个挑战，尽管这些系统在安全合规交互中展现了优势，但在高速动态任务中仍然存在困难。在本研究中提出了SWIFT，一个使用软体且符合机器人手的动态任务学习系统。与依</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501091&amp;idx=1&amp;sn=8be811b0fe0d120508b6b1ab42241ab4&amp;chksm=fd146bdb7488c5e033c3df3b2a833b425a72fa4203b92bc8b368d267036d03f389fbfd010ba2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[普林斯顿大学和斯坦福大学联合开发家庭服务机器人TidyBot++]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1r4oMpbFhozovxhpdaNBiaOyjppzicM9Femcice680CBD75CDQSMKcKy3fSBEBDJIHfQVExZXYkRpuxA/300?wxtype=jpeg&amp;wxfrom=0"/><p>机器人利用模仿学习进行移动操作需要收集大量人工示教。本文提出了一种开源设计，用于一种廉价、强大且灵活的移动机械手，它可以支持任意手臂，从而实现广泛的实际家庭移动操作任务。至关重要的是，设计使用动力脚轮</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501091&amp;idx=2&amp;sn=dc22a2e3cd0b03b7a35523762879f1d3&amp;chksm=fdfe34aa8c3670ae2a939bbc483d11acf96a81990c7863ae55136cd4a1a0cf29a326c131c903&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 14:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华大学、字节跳动等单位联合发布最新视觉语言动作模型RoboVLMs]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1rHU2msicGqITGicLvJlWNl0fXG6gQYgfjDpWZvqbJ4Sgdeq3NTI3H7gNX2ialmPulsC7icN3HM6Jhprg/640?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，视觉语言基础模型（Vision Language Models, VLMs）大放异彩，在多模态理解和推理上展现出了超强能力。现在，更加酷炫的视觉语言动作模型（Vision-Language-A</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501046&amp;idx=1&amp;sn=2bbb85cc2b189fa6c879c6e49cc78747&amp;chksm=fd59bea120de0934f1c5a855c1e34b3448487276ebf39ae66d8aec61c1942ea41b1bb53a694c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 03 Jan 2025 14:30:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[百万真机数据集开源项目AgiBot World，也是全球首个基于全域真实场景、全能硬件平台、全程质量把控的大规模机器人数据集]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ibic16QV7BQ1rHU2msicGqITGicLvJlWNl0ffHFnsWD2ibH7IUdic0HgAicVwHuIkY5D2gNE6qvibw6p71mibcgDuQawibOQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>百万真机数据集开源项目AgiBot World，也是全球首个基于全域真实场景、全能硬件平台、全程质量把控的大规模机器人数据集。该项目由稚晖君具身智能创业项目智元机器人，携手上海AI Lab、国家地方共</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&amp;mid=2247501046&amp;idx=2&amp;sn=492024269dcb1db433395514d7d8436f&amp;chksm=fd5754ac4cc2f5e13c7f44f2bccb109838e511b6a6a5fe80b24bf7ba9085949a48399a565f3d&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 03 Jan 2025 14:30:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
