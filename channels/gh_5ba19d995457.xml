<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[图像着色还能这样玩？上交联合哔哩哔哩提出图像着色框架MT-Color，实现AI着色实例级精准控制！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8r1mbBOtrNsSTkhqjMvnHWjLkcJFGlibz11aFcugwvSrOib6WzsoF2XXkqKoz5uzEoF0aMS4I6Kfw/640?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍过图像上色方法，感兴趣的小伙伴可以点击下面链接阅读～阿里达摩院提出开源AI图片上色模型DDColor:可以为黑白照片、人物、动漫风景等一键上色!超越阿里DDColor! 复旦</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494146&amp;idx=1&amp;sn=0c485898f691f1956cf5b0f33d0c083f&amp;chksm=fd977912cff868e5f7f8b83e1adb90c1c99f815d9fdbe0b6e1e78c542e38d94a4bb4b954236d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里达摩院提出开源AI图片上色模型DDColor:可以为黑白照片、人物、动漫风景等一键上色!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emSxAhfwGrF5xDyQho3K1KHs5BPR4ic9nBrD4MlgCC5ibUfic09OiajZVFthOcVSdugCDCmu33gKAffhA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DDColor 可以为历史黑白老照片提供生动自然的着色。它甚至可以对动漫游戏中的风景进行着色/重新着色，将您的动画风景转变为逼真的现实生活风格！相关链接项目：github.com/piddnad/DD</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494146&amp;idx=2&amp;sn=ad90c1e88289266b8d218a8d0e7ef275&amp;chksm=fd6137544915e31ad537f408838a8bede7b016dc65c8c5ed103e4064c45b06b0baee612a1e78&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超越阿里DDColor! 复旦提出MultiColor，一键将黑白图还原上色，效果逼真！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkkuWrNlw62n8iayUtU0k8ysnLxORVO7LzAmV1lNsDfmFXPkA5uOJ40XnPiclcq5NNo1jUIFoJLDpQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍过阿里提出的图像上色方法DDColor，感兴趣的小伙伴可以点击下面链接阅读～阿里达摩院提出开源AI图片上色模型DDColor:可以为黑白照片、人物、动漫风景等一键上色!最近，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494146&amp;idx=3&amp;sn=687675ea3abc43481351314e57f0de9e&amp;chksm=fd085aa0ba84e708b64f73a6da79fd1a3da6c408652c6718e2a7ecde15b203a2d0c0859945a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源文本编辑框架FluxText：轻松应对多语言多场景文本编辑挑战, 海报|广告|游戏|文案编辑轻松搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8r1mbBOtrNsSTkhqjMvnHA3l9PourHLbs4icMEsVsuPWfFWhxiaESVMM2sxiac1nib3sib54N9KicTMtg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过许多关于文字编辑和生成的方法，感兴趣的小伙伴可以点击下面链接阅读！字体控狂喜！Liblib AI 黑科技 RepText：无需理解文字，AI就能 1:1 复刻多国语言视觉</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494126&amp;idx=1&amp;sn=2c432b258506a69dead9ef7a30ba2a99&amp;chksm=fd4d54bda29e86c0b4144ae8bd986dc04910b6e149736e72cfac42b43d214e375b9299254c6a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字体控狂喜！Liblib AI 黑科技 RepText：无需理解文字，AI就能 1:1 复刻多国语言视觉效果。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elFfbYTqwA595BOINVFyGzKJTeUTfexNWrNdN8IAiaUICEpfK2hvFm6G9wMRKkN6XcT63ldibkLQRdg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Liblib AI提出了 RepText，可以使预训练的单语文本转图像生成模型能够以用户指定的字体准确渲染，或者更准确地说，复制多语种视觉文本，而无需真正理解这些字体。这样不管是中文、日文、韩文还是其</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494126&amp;idx=2&amp;sn=e7b34b6ac90b00fe79daa31995f3ba83&amp;chksm=fdaebaf59109379c324cbd7b82b195157a530d1842739388f53e892c9bcf20fef58ba7c15c97&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里推出AnyText: 解决AI绘图不会写字的问题，可以任意指定文字位置，且支持多国语言！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enhlwbkXXgvfvia0MwvrA6EkNr74L5Sd2bibHPDFnOjpqFHxJ9EvHbsUPrecM5KCxxENAory6R3TP0w/300?wxtype=jpeg&amp;wxfrom=0"/><p>        近年来，随着AIGC的爆火，图片生成技术得到飞速发展，当前AI生成的图片已达到真假难辨的高保真度。不过，当合成图片中出现文字内容时，仍能够使AI露出马脚，因为当前主流方法尚无法在图片中</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494126&amp;idx=3&amp;sn=ea92c976fbbce15598da66337cf1a599&amp;chksm=fd31e76e31fa4f1222fcd80c4650273a6f850c78467b3fb8c890cd74914d8bf1c751e67b6659&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TextCraftor：无需额外数据集即可改善图像质量与文本对齐。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekwq8DyYB3khl7kib52osbicL8ldp29lN3TjiaJJJN2Sey095wWNoT7IJPCvSNoqicd4p28k8Dk5G5OxQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>TextCraftor是一种创新的文本编码器微调技术，能够显著提升文本到图像生成模型的性能。通过奖励函数优化，TextCraftor是一种创新的文本编码器微调技术改善了图像质量与文本对齐，无需额外数据</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494126&amp;idx=4&amp;sn=16f5f7c039769379d6a6c7b4a0fc551c&amp;chksm=fd0ad0ed91599c1c4c9235e4aa6e9cc5babac6632f644e87d062ce733946e910c621e5e46c65&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 中山大学提出交互式运动编辑算法MotionDiff，零样本、无需训练，有效保持多视角的一致性。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8r1mbBOtrNsSTkhqjMvnHH26lGNJIcjcqnXwwX3om3hRv3QibJK8f7DiaicfbREQoL4xSytRYkxWiaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章来自公众号读者投稿，由中山大学智能工程学院完成的论文 MotionDiff: Training-free Zero-shot Interactive Motion Editing via Fl</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494125&amp;idx=1&amp;sn=f4a3119c5e07bdc191741d820b830af1&amp;chksm=fdb152569af8abef57f310ae998fe0b83f12e709b8b3994f47d24a74a021b5202e6ae9eceb5c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[手机上实时跑3D数字人？阿里开源MNN-TaoAvatar，打造本地离线智能数字人新标杆。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8O7Mx0HicAQzYnr62ZEJLwjCaTF4Xg9G65OJibjU82ibBkicGN8Zdt93yM9ibvqO1zSU5WvX0ehVP4QA/300?wxtype=jpeg&amp;wxfrom=0"/><p>TaoAvatar 是由阿里巴巴淘天 Meta 技术团队研发的 3D 真人数字人技术，这一技术能在手机或 XR 设备上实现 3D 数字人的实时渲染以及 AI 对话的强大功能，为用户带来逼真的虚拟交互体</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494125&amp;idx=2&amp;sn=b834f499b4832977e8c60bbae9400a74&amp;chksm=fdfd444c3b5a1637523be653da12e3b8824ae43ede24fd45c3d42fb4047c2fc4249b88ff0f29&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[达摩院提出ReSpace！自回归文本驱动3D室内场景合成与编辑新框架！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IUS026bgrHtl19k8iaTzNl8icef5pd4T4TvpwHoxzu1cyROia6klKjBkbZgib9aibULqBb20gpjfNRAAw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：ReSpace: Text-Driven 3D Scene Synthesis and Editing with Preference Alignment论文链接：https:</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494125&amp;idx=3&amp;sn=b833658dc330a7d9aa2c14f3cc5ebc68&amp;chksm=fd2225dd06b743ecfffacd81b4d85474db6f576529e2b5184935daea5aaa89304929d2b9343b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICIR2025 | CubeDiff：无需考虑失真，重新利用基于扩散的图像模型来生成360°全景图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6qavvqaKicyhfbe1wrRfKuEmZbfJ8LvrOgQJMgZYG5CztqNUPPASQbtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给大家介绍过许多关于3D生成的文章，感兴趣的同学可以点击公众号菜单栏查看3D生成专栏，创作不易，欢迎大家点点赞和在看~CubeDiff是一种使用基于扩散的图像模型生成 360° 全景</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494125&amp;idx=4&amp;sn=f67cdffa168745dcc23032a36ed4fc88&amp;chksm=fd64c876e8dd602a0dc951963e673beddca82c380ec58cec4849fb6c6f8752b2219a70185c87&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一句话开启高效图像编辑新时代！TeleAI SmartFreeEdit，打造图像编辑新方案，解决推理指令与分割难题。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKibiah2ldIaVhKqwicV967dTrx4b0lHrzlxzbCo5bstbMH7ERVSrgFAwvtWptIDnolIg4HTBCicomtw/640?wxtype=jpeg&amp;wxfrom=0"/><p>TeleAI 推出了一个图像理解编辑修复模型 SmartFreeEdit，用来解决图像编辑中推理指令和分割的挑战，从而提升 AI 编辑的实用性。该方法可以有效地处理一些语义编辑操作，包括添加、移除、更</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494076&amp;idx=1&amp;sn=3a2ffe969eea7afc02b2f07198fb3b0c&amp;chksm=fdc155f8fa74a5d8d61ffc7bcfffe1f173fc8bf8979ff04175df45de50371b2ac7b75780f375&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LightRAG：颠覆传统AI问答，一张“知识网”让大模型真正开窍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIoKghGBpvdlrGNMQe58LqzvwhL0dbqckzE76dLAvn3Dke60UcVLuSc0LPCD5hAicc6gnAXYGUK9Edw/300?wxtype=jpeg&amp;wxfrom=0"/><p>还在为AI回答支离破碎而头疼？LightRAG用一张“知识网”让大模型真正理解复杂关系你是否遇到过这样的场景：向企业知识库提问“新能源汽车电池技术路线对供应链的影响”，却得到一堆割裂的电池参数和物流术</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494076&amp;idx=2&amp;sn=a8716122909cbe6c69f83ae6c5ebc470&amp;chksm=fd84457f2bea89286f7934ce365532d3dd0b88800c874097310bb15aa480f3e3a84a0975e462&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Google DeepMind 发布最强视频生成工具 Veo 3, 可为作品添加音效、环境噪音、对话，文中附体验链接。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcnWs2mR9uePicbSxmgsNGYEOvC44lWnQUfBAMbv2Kgy7vDib4ee4tlF1R091cfagJqdQWc10PdkUA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天跟大家介绍谷歌的视频生成模型 Veo 3，可为作品添加音效、环境噪音甚至对话，所有音频均可原生生成。它还能提供一流的音质，在物理效果、真实感和快速响应方面均表现卓越。相比 Veo2 的改变Veo </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494076&amp;idx=3&amp;sn=6a2e08fd410d4fed83b28c0d13d370b3&amp;chksm=fddfe3bc70777b3c25b56a20e49d521d9cbc4adf34edcae47a6136269837eb4364c7f149dc05&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[海报设计革命,开源媲美部分商用！港科大&amp;美团等提出PosterCraft：让AI实现「构图自由」]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojx7obK332sQIu5tPib8HDKTSVyn11kSVibT6WeicxNgpicMIibvCvN1yUSHKhAxtClydJbaPlds1MjvRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Paper：https://arxiv.org/abs/2506.10741 Daily Paper: https://huggingface.co/papers/2506.10741 Github：</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494076&amp;idx=4&amp;sn=2ac829988f28de7d346aa337a18e04c3&amp;chksm=fd85bdac2a9df76839045dde8929b3d28bc878110a39135a266dd9491b07796acbc6945d5fba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[突破高分辨率3D建模算力瓶颈！南大&amp;复旦提出 Direct3D‑S2：8卡即可训练，革新 1024³ 分辨率3D生成格局！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnnibKbtwkfQH4wt4miaD9ltwEVcbK2fR9bxibXxuHKTtr0qEAr49WVVsnag/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍 在 3D 生成领域，高分辨率建模长期受算力限制，传统方法以符号距离SDF函数等体积表示生成 1024³分辨率 3D 形状，计算与内存压力巨大，成本高昂。而今天给大家介绍的 Direct3D‑S2</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494075&amp;idx=1&amp;sn=147c356db39943cc7fb08a357242e08d&amp;chksm=fd0dcd08de36c9a7a51e3bd58b16e7238105081c501f88ab990bb137a3d65c330eb3ad6ca5cf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[不是P图！用ComfyUI复原老照片，像素级重生太惊艳了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE62umia43diaibQHp3ufyS7wiaxIEibtXWGdYtMcl71rnkX5MWXjibQMdn9RUbu6m0NMMfLoryHo7Tqzluw/300?wxtype=jpeg&amp;wxfrom=0"/><p>过去的一张张老照片，承载着无数回忆，也记录着一个时代的光影。但随着时间的流逝，那些泛黄、破损、模糊的老照片正一点点被遗忘。幸运的是，AI图像处理的浪潮正悄然改变这一切。而在这股浪潮中，一个名字正在悄然</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494075&amp;idx=2&amp;sn=c28265ab8a4b4dc5a7167d017884f464&amp;chksm=fd5f516b3b48b87be4f9dd969d1575f54e6e625858c876cdb210d57ac40a8ece741e3750d468&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[香港中文大学 MMLab 提出文生图模型 T2I - R1，文生图进入 R1 时刻！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1XALE57UTLoPLT6xjsxJW5tiaoo8VJdc0HMQQUAGdaNID9L9wkBMspWA/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学 MMLab 提出了一种基于双层次 CoT 推理框架与强化学习的新型文本生成图像模型 T2I-R1，该模型结合了语义级和 token 级的链式思维（CoT）推理过程，并通过强化学习进行增强</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494075&amp;idx=3&amp;sn=6264bd1bdcf5b4c107eba06604c08d6c&amp;chksm=fd187835686e151b8cf89afe32632b05a5f5078b1ce9f8beae5f5f9086f685c53445f82366ae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Apple提出UniGen！多模态理解生成统一xii新架构！CoT - V提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KqpbKjwyf8GDnoGZ1ANRZVHSofem5JIanFIxSibozXUibNxHviaUIPE6FTh1nw9lCf16QMqWDaqf7cg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniGen: Enhanced Training&amp;Test-Time Strategies for Unified Multimodal Understanding and </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494075&amp;idx=4&amp;sn=2fe977012559e15117cf37e638495192&amp;chksm=fd74501aff7793888a8fc6a827263500ba8d75a14c2bbc58c3531e7944eaad72bd6ad9c59ea4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[手机上实时跑3D数字人？阿里开源MNN-TaoAvatar，打造本地离线智能数字人新标杆。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8O7Mx0HicAQzYnr62ZEJLwjCaTF4Xg9G65OJibjU82ibBkicGN8Zdt93yM9ibvqO1zSU5WvX0ehVP4QA/640?wxtype=jpeg&amp;wxfrom=0"/><p>TaoAvatar 是由阿里巴巴淘天 Meta 技术团队研发的 3D 真人数字人技术，这一技术能在手机或 XR 设备上实现 3D 数字人的实时渲染以及 AI 对话的强大功能，为用户带来逼真的虚拟交互体</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494074&amp;idx=1&amp;sn=95271422a4ac0638179f300d2647b01e&amp;chksm=fdb5ef90e7380d3348a1cf29a189c4388ab52586a87b704ea96971c1fa6b7cabdab23c3e9040&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494074&amp;idx=2&amp;sn=dd17d1ecf5eba14fa77c88ee8bad5b71&amp;chksm=fde17bafd60cf74c1b58238ae475153aecb124c24babc76bfbe1de86e6f282eb3a3fdcd0e864&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[东京大学 | Adobe 提出InstructMove，可通过观察视频中的动作来实现基于指令的图像编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsa4uWnhrMawFt9HHkxP0mNsA8WZRJb5wtxFQzRMjAicAjmryxF8Yliamw/300?wxtype=jpeg&amp;wxfrom=0"/><p>InstructMove是一种基于指令的图像编辑模型，使用多模态 LLM 生成的指令对视频中的帧对进行训练。该模型擅长非刚性编辑，例如调整主体姿势、表情和改变视点，同时保持内容一致性。此外，该方法通过</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494074&amp;idx=3&amp;sn=38203794495b0b81d545166888d06d84&amp;chksm=fd28a56f9498393fe3309b5397157569487156383ec8183decba71bb11027f9e4b8382ce1def&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像定制大一统？字节提出DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等任务，有效解决多泛化性冲突。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1Zrf8JKiaMovMsw9t4ZW4pibcVZlWM8AF7GsajlXAPWl5IJgnfQRpnvoA/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出了一个统一的图像定制框架DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等多项任务，不仅在广泛的图像定制场景中取得了高质量的结果，而且在适应多条件场景方面也表现出很强的灵活性。现在已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494074&amp;idx=4&amp;sn=da3f96838bedbd4c24711779e594f19e&amp;chksm=fd548f7d4c09a88ef04dde50786d4416c5e917fc8a53344489f4f0005627bd291711e14aa2f7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源 30 亿参数统一模型 Ovis-U1，多模式理解、文生图、图像编辑样样精通，多项学术基准测试领先。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuDmLq7R1rRFldNX6Em3MD3ic6VVyQ7fibbkHSDXdsLJJKPKURibic6bQdSKAoTkLHaP0dHSb0n5P6Zw/640?wxtype=jpeg&amp;wxfrom=0"/><p>Ovis-U1 建立在 Ovis 系列的基础上，是一个拥有 30 亿参数的统一模型，它在一个强大的框架内 无缝集成了多模式理解、文本到图像生成和图像编辑。亮点统一能力：单一模型擅长三大核心任务：理解复</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494061&amp;idx=1&amp;sn=6e63e5a9e52130e0d451caaf7d201703&amp;chksm=fdb9244830660ea611169875bc921b09846518ac4573ac7472ea32484db367308977311154af&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[达摩院提出ReSpace！自回归文本驱动3D室内场景合成与编辑新框架！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IUS026bgrHtl19k8iaTzNl8icef5pd4T4TvpwHoxzu1cyROia6klKjBkbZgib9aibULqBb20gpjfNRAAw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：ReSpace: Text-Driven 3D Scene Synthesis and Editing with Preference Alignment论文链接：https:</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494061&amp;idx=2&amp;sn=36d78943e4aa37d67e89084802b839f5&amp;chksm=fdb6f9d980f7a2b4459b2ffa0348e06f782ae9a3f6fed30e4a75d271ffddb6c4d58611b9cf36&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节推出统一多模态模型 BAGEL，GPT-4o 级的图像生成能力直接开源了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRre72SQ3NTx8amQXBMt77z295uWjzKl5kweQFLEMa31vXicZ35AvS4Lfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节推出的 BAGEL 是一个开源的统一多模态模型，他们直接开源了GPT-4o级别的图像生成能力。（轻松拿捏“万物皆可吉卜力”玩法~）。可以在任何地方对其进行微调、提炼和部署，它以开放的形式提供与 G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494061&amp;idx=3&amp;sn=0acc483b588836cdca3563b42db99f50&amp;chksm=fdcc48a323133b7d6d279cee7f016b11f9d36c026be8efa1ae14fe51f4f914f5bb6af9aa218c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TMM 2025 | 超越SOTA！AdaMesh用10秒视频生成个性化语音动画，表情生动性提升40%。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48sD3er0mq7FL0guJnKjkMSPVhPLjFIJ4elWF7POpyFVoOcRqfjLRoPw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在虚拟角色与数字人技术中，如何生成兼具真实感与个性化的语音驱动面部动画仍是关键挑战。现有方法往往依赖海量数据或通用模型，难以捕捉用户独特的说话风格（如微表情、头部动态）。为此，由清华大学深圳国际研究生</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494061&amp;idx=4&amp;sn=99a4f1161c03b733c1c2d4a651862c55&amp;chksm=fdfd74c9064c552a78965f19ea14baf7fe9d06e533249dac463be16b3c394330111a169734ad&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 16:05:00 +0000</pubDate>
    </item>
  </channel>
</rss>