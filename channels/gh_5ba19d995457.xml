<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[字节提出高效文生图新框架FlowTok，可实现文本和图像无缝衔接比，比PixArt 快3倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECxwAibKNhTZ8hJo5SVEib892Bw9ibAqiavicF5qn1bjb71Z4qShC1Wdka5Xw/640?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出了一个精简却强大的框架FlowTok，通过将图像编码为紧凑的一维 token 表示，实现文本和图像之间的无缝衔接。FlowTok内存效率极高，所需的训练资源显著减少，采样速度也显著提升，同时性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492325&amp;idx=1&amp;sn=4be16a8063a2b985e1fd99e70dabcba5&amp;chksm=fd9a3c5219d1b9c17e9cb204527797ba2d31706cc3feb0afefa17d73ed497642d06dd5a93a9a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[重磅突破！只需一张图，一键生成沉浸式4D全景世界！HoloTime重塑VR/AR体验（北大等）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogEQhMxTpcKl9HOR9TzDQaPT45zyr698A5aD6iaDhBAAywD0P7R5TakNMbMSMEZbJCm0CooRytvdsw/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2504.21650 主页链接：https://zhouhyocean.github.io/holotime/ 代码链接：https://gith</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492325&amp;idx=2&amp;sn=137ce893c6df7c8ba3a221d16f9ee21c&amp;chksm=fd7d78b6b0fd607f678e905211b357ccb64701489a06e3f21845ebfa039ccb953dc0c4193991&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里EMO2重磅升级！手部动作生成+超逼真表情，音频驱动人像视频生成再进化！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGYiaHtTElCkzOGD9sY0N1Qp8FDJqnDN5BkTWSW0TSu1sYeAgQzRiaicMcRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的音频驱动的人像视频生成方法EMO，感兴趣的小伙伴可以点击下面链接阅读~阿里最新EMO：只需要提供一张照片和一段音频，即可生成会说话唱歌的AI视频此外公众号的底部</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492325&amp;idx=3&amp;sn=c119b9339ce1be9a0c507905ddabb8a4&amp;chksm=fd5edc42e40ac31b32e549dea46da99915def15adf7d941687599975d186f0364e507e4df7bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文了解：大模型 Agent 开发框架有哪些？它们的区别是什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIr8DNP5MR3eP0zlA9JsT0hBHpz7mIT9yRpuDv80p9ANexpSib1fao2maWhK8nPVqlRMv4h1P6M8ia8Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>——大模型时代，如何选择适合的 Agent 开发工具？引言随着大模型技术的爆发，AI Agent（智能代理）逐渐成为落地应用的核心载体。它不仅能理解语言，还能自主规划、调用工具、执行任务，真正让大模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492325&amp;idx=4&amp;sn=6c223ebb631fd99d843621c3e55df620&amp;chksm=fd763ade105ef21f0c0fb57468b41091cae6a92bff6a22602afbbe0b0777cb4cfeafa1c8ca72&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR2025 | 同济提出无需训练的肖像动画框架FaceShot，让表情包、动漫人物、玩具等“开口说话”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECN5vlsQZr9AOKKvriaYqbhSHH5y8IBJg25HQaMqclHrVZ7Dp9ObVuiaww/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天和大家分享同济大学的最新研究FaceShot: 一举打破肖像动画模型“驱动真人”的局限，FaceShot 的动画效果可应用于各个领域的角色，包括 3D 动漫、表情符号、2D 动漫、玩具、动物等等。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492288&amp;idx=1&amp;sn=42c7b4a8c8241a17a56a0f20b5d3e4ee&amp;chksm=fd251729c065f10c423aadf985697cfa3dbcd2cb9170de9e37a1954703a1b33561241bc16d56&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 16:08:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 Highlight | 清华提出一键式视频扩散模型VideoScene，从视频到 3D 的桥梁，一步到位！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en6YOGtn3XXJMye1oxLXOtQDu8lVia8rZmBpsouclpUQ8eY6ebkIhqsCQhQiabYLqW83mluezLMicI1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华大学的研究团队首次提出了一种一步式视频扩散技术 VideoScene，专注于 3D 场景视频生成。它利用了 3D-aware leap flow distillation 策略，通过跳跃式跨越冗余</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492288&amp;idx=2&amp;sn=7b987747ea46801d8a9c8217d4b9eac1&amp;chksm=fdbf72c12a933ddee3c505db6195413c32efad4ec5cdc60ca2a52443bfaf2e778c9e034bb402&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 16:08:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Qwen3发布，再次登顶全球大模型开源王座，再见DeepSeek。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NZTI0d3fFk1nSJ44lvqzpibvN6pGVwcafWz269r3hd0VjByWXH94FyS8CvTxq2UJ47eIIia3iaN2iaBaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日凌晨，Qwen3终于发布。网友直呼“等得好苦”。我也想说，明知道大家都在等着，你今天才发布，咋不等五一大家都放假了再发布呢？？？？？Qwen系列也是超越众多模型再次登顶开源王座。旗舰模型 Qwen</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492288&amp;idx=3&amp;sn=fdea136ae01c7e014331e0ef1750f593&amp;chksm=fdbb0086e657e21e2ddc7253e43b9db79f83dd208b9eb9f96fea841ef5b2e1d78fdaccfbd944&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 16:08:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 艺术工具通讯]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2rrZo6MvQMib3yaV5BITXF7CQorbzEicSeSiaBVwm9FpIicKhJ3TeBW7JsFmeMmjr8CqMt5ibicJRkEmjnQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>创刊号 🎉AI 领域的发展速度令人惊叹，回想一年前我们还在为生成正确手指数量的人像而苦苦挣扎的场景，恍如隔世 😂。过去两年对开源模型和艺术创作工具而言具有里程碑意义。创意表达的 AI 工具从未像现在这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492288&amp;idx=4&amp;sn=369b17783cba4a801940499bdde312ca&amp;chksm=fda3bfe263ceae4039731ec67c1b32b8e2923e0bfdf2c7a17c206991a8dca9b7b9f170e76eae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 16:08:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[月之暗面开源音频模型Kimi-Audio，从「语音转文字」到「读心对话」，让AI听懂人类 “弦外之音”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNEC7g7nZPhc47aJoHlH9ymyhbNzAvibM4Zam09k4hqrh7JZEIVIibOtic48A/640?wxtype=jpeg&amp;wxfrom=0"/><p>近期，Kimi在语音交互领域发布了Kimi-Audio模型，这是一个开源音频基础模型，在音频理解、生成和对话方面表现出色。AI让机器不仅 “听到” 声音，更能 “听懂” 语言背后的情感、意图和语境。K</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492287&amp;idx=1&amp;sn=92def84f0ac1d364a13d26c853b9a39a&amp;chksm=fde6d6362b85c6e1325bd0fefa0084043da9dbaee17b52ae355f2b42c087b11fbcf99f06c86e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑革命，万物皆可插入！浙大/哈佛/南洋理工提出Insert Anything，告别PS抠图，AI让世界无缝生长。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7Ficnb2ehPShfDudYtibS1fkY0Su3IFmdP3MkS9KDH1gsquQnXh8Ku6TPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学、哈佛大学、南洋理工大学联合提出了统一的图像插入框架Insert Anything，支持多种实际场景，包括艺术创作、逼真的脸部交换、电影场景构图、虚拟服装试穿、配饰定制和数字道具更换，下图展示</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492287&amp;idx=2&amp;sn=2066bf4a0c95d1c2ea4fa6ce5d95d39d&amp;chksm=fd29478572360d392afff4550e2784fe0447f9ea2630546e69b12341d44ab46fb10e70d2da0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI编程神器Cursor，保姆级教程来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2hb9jqgpc7UzDRY9moSN30Gu953gF5tc8bQ8g3TMX1lth40K1FeMuKw/300?wxtype=jpeg&amp;wxfrom=0"/><p>一、下载与安装（很丝滑~）Cursor 是什么？想象一下，你有一个能把你的创意变成现实的造梦 AI 助手。不管你是想利用 AI 提高办公效率、开启科研提效模式，还是做一个小游戏、开发一个网站，甚至自己</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492287&amp;idx=3&amp;sn=9e95273e2e2b4defd0ac7e661a883cb7&amp;chksm=fd98f335a66322a2c14e466dce4a6492c019aa59132e5a60afb57888e407e9fe9a101f9cbe90&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字体控狂喜！Liblib AI 黑科技 RepText：无需理解文字，AI就能 1:1 复刻多国语言视觉效果。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elFfbYTqwA595BOINVFyGzKJTeUTfexNWrNdN8IAiaUICEpfK2hvFm6G9wMRKkN6XcT63ldibkLQRdg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Liblib AI提出了 RepText，可以使预训练的单语文本转图像生成模型能够以用户指定的字体准确渲染，或者更准确地说，复制多语种视觉文本，而无需真正理解这些字体。这样不管是中文、日文、韩文还是其</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=1&amp;sn=c8dde389ff8a0f42b34061cab88073b6&amp;chksm=fdf0f9eb452a4892b7f82eb19acd65b1e14c37788d677c80c74ef52200b5b244326f795075eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[142页深度解析：DeepSeek-R1的推理技术综述，AI的“思考”秘密大公开]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic74EgPzUnjibrG5SK0JmT8ksETRvVrR1XcCZjqetgGsxyQHiaa0hCYjVTIMhicnh9kAXbQjIYxYwDkxQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek-R1 就像是AI界的“思考者”，能够像人类一样进行复杂的推理和思考。在数学、编程、科学推理这些超难的任务上，它的表现简直逆天，直接对标OpenAI的o1正式版，妥妥的推理界“学霸”！</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=2&amp;sn=079a63c4faae9de36a250d6ab0172ab5&amp;chksm=fdbe448b6fa60dbe059c47e784aa4264a1e74e7ad1e11a13ef38aca213bf9d42b93cff16ca52&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港大&amp;Adobe联合提出图像生成模型PixelFlow，可直接在原始像素空间中运行，无需VAE即可进行端到端训练。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em57kq23EbSGQ52kUcSia6n8oTIJOicficBicZpibaJQgm7tEpQJ6psVkrLse6pjDUwqiaktvnGSEiaL6xPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港大学和Adobe联合提出了一种直接在原始像素空间中运行的图像生成模型PixelFlow，这种方法简化了图像生成过程，无需预先训练的变分自编码器 (VAE)，并使整个模型能够端到端训练。通过高效的级</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=3&amp;sn=03fb4e2b61fadb948acca9a182753435&amp;chksm=fd2f4f32850f34ec24a30633e9d9a6b5dc40c34fe93c497fee4fda605c32e158e15136caa975&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[英伟达提出最强「描述一切」模型 (DAM)，可生成图像或视频特定区域的详细描述，拿下7个基准SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECib2BYEbUlY3dMInZdicOKQibQAMwDLHA4kgviaROXJC16pncBthoyHBQJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达提出「描述一切」模型 (DAM)，这是一个强大的多模态大型语言模型，可以生成图像或视频中特定区域的详细描述。用户可以使用点、框、涂鸦或蒙版来指定区域，DAM 将提供这些区域的丰富且符合上下文的描</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=4&amp;sn=f87c6e35673a2de357f72417d46f40f5&amp;chksm=fdfe4ee608f84dfdbcaa172b57b0a824299ec9506d3453fbedd94f7f78e5c142221d1f694654&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别"纸片人"试衣！阿里&amp;浙大提出3DV-TON，用3D几何骨架+动态纹理场，让虚拟模特"活"出真实衣褶！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECFZTEAl6XrNJIs6kBFtCKh4H4USr1Odbdw4IOg8SSgUfrQQVgR52lmA/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里联合浙大提出3DV-TON，可生成高保真度和时间一致的视频试穿结果，3DV-TON是一种基于几何和纹理 3D 引导的新型扩散框架。 可处理各种类型的服装和身体姿势，同时准确还原服装细节并保持一致的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492245&amp;idx=1&amp;sn=160b95e244bf15f744324d221dc1dd79&amp;chksm=fdab9b8eeb0c58bd47cbac63040faf64c489e4abf3f0c42c0b6e22004deca12ce38d5d437ee7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌研究院联手牛津大学推出Bolt3D！7秒内单GPU生成高保真3D，推理成本直降300倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LR8w1T4XSJwAUg3UkzLpMRYxbTOuSXUEpxZVs5u18QTNFMFHe41E6SY6vfhMbJicRDetQWdibB3Nicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Bolt3D: Generating 3D Scenes in Seconds论文链接：https://arxiv.org/pdf/2503.14445开源代码：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492245&amp;idx=2&amp;sn=44b4076684d67ccb8491aae4497914ab&amp;chksm=fd7833f99e5a68599ff7aa5385ccc22036a213863ca81ce63f08c58154bc30754eef5b1f7e09&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[如何使用DeepSeek进行科研图表绘制？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsFkhhJibgYhskdb4vjUEaTlFuY2pp216d97E3UsjQZuBJkB8oBHK2OrmMP1t3zaSDLBxT6GhVGv5rQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>有时候我们写论文或者看 blog，看到别人画的很好看的结构图，觉得自己肯定画不了这么好。但是现在可以让大模型来帮我们结构图。一共需要用到两个工具：大模型、Draw.io。下面的示例会使用 Claude</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492245&amp;idx=3&amp;sn=5be82eee7d99fa053a202314f30e008e&amp;chksm=fd56add71bd4b4380107f11e0c1ff35383155d3ea37144bd199060773f3ae69066116af486a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[英伟达提出最强「描述一切」模型 (DAM)，可生成图像或视频特定区域的详细描述，拿下7个基准SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECib2BYEbUlY3dMInZdicOKQibQAMwDLHA4kgviaROXJC16pncBthoyHBQJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达提出「描述一切」模型 (DAM)，这是一个强大的多模态大型语言模型，可以生成图像或视频中特定区域的详细描述。用户可以使用点、框、涂鸦或蒙版来指定区域，DAM 将提供这些区域的丰富且符合上下文的描</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492244&amp;idx=1&amp;sn=b29d92197b4fb4155641dc59dc163c18&amp;chksm=fd16304a81081ad78b64487745ecbf79bd08d89cc4f25f2195e2805f9b946adeaad94b48399a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FramePack-F1：敏神全新算法重大更新！低显存ComfyUI可体验长视频生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGQdbH5tvxzar5TAtTxFX4G9Q9nTTmDOUmW2D7RDQfQTgEAkgeSRpgiaLL0F0qMLAoUcd96ndJ2Esmw/300?wxtype=jpeg&amp;wxfrom=0"/><p> FramePack-F1：全新算法和模型更新FramePack-F1简介在昨天的文章已经介绍过敏神最新基于混元视频的力作FramePack-F1模型，这是仅从前向帧预测未来帧的 FramePack </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492244&amp;idx=2&amp;sn=1832a2f7e1cc7f2a165d33af13b2533e&amp;chksm=fde265d7ccf7f1a05ed0e7220443693ca35085d784f94f5791c692253a729b499f917214a9ef&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492244&amp;idx=3&amp;sn=72f4f1941e206d1c9e970d1158ae4853&amp;chksm=fd58037ce5f18449fe170da1f968009f9173051ecebc102c1953b962a338611ff90ff89ba112&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源项目FastAPI-MCP，一键将FastAPI转换成MCP服务器，以后API=MCP。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5Nb69coNJjYwLrdDicA1kP6DUhlXhePTVYrhoZAuibXQhPthJOnFxIiaZvibmjL3GjGytM1LVUhBq7tJDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是我这个月看过的最有价值的开源项目了。MCP发布之后，很多粉丝朋友都有疑问，MCP跟API有什么区别呢？简单来说，MCP就是规定格式的API，这样才可以被AI模型来调用。现在有海量的API，但都没有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492244&amp;idx=4&amp;sn=c70bd2059be5dfbe50a13c4c97fe579d&amp;chksm=fda87d247f2afc2225aee2db0f6556669b81b280b43abbbae38f512e46c714f120e66852d512&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI界新王炸，输入提示词秒变PS大神？阶跃星辰开源图像编辑模型Step1X-Edit：19B参数对标GPT-4o。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el0tf0f2Ybm2uFN97TrfHYoqefkVHtmLwhySToicQuQpmNJTBkEoLFpYZ12wzayha9Qna8FEyr9LfQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>阶跃星辰公司近期宣布开源自家图像编辑领域模型Step1X-Edit，它使用多模态大语言模型处理参考图像和用户的编辑指令，提取潜在嵌入并与扩散图像解码器集成以获得目标图像。Step1X-Edit凭借其强</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492032&amp;idx=1&amp;sn=5c754023d6997a893f7fa731883665c6&amp;chksm=fd74a45ff856c873493409a686d49648c7965c05a638b6759328d53f219606b2c9fe1ceb8a83&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI视频生成新突破！字节提出一致性视频生成方法Phantom：通过跨模态对齐生成主题一致的视频，超多应用场景。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7FjUDMtLDDzOxeRDTsjoBO7nWymp4ibfUg4ngicJhNSbFdrgXOp81mHMKg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Phantom 是一个统一的视频生成框架，适用于单主题和多主题参考，基于现有的文本转视频和图像转视频架构构建。它通过重新设计联合文本-图像注入模型，利用文本-图像-视频三元组数据实现跨模态对齐。此外，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492032&amp;idx=2&amp;sn=dc9669111d07b5f21250912084085296&amp;chksm=fd9fa1d1bdeb829ba531bac91c217255a2739c078beb6a2dfd9862e786ff93bd1a2fb53f4299&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[GitHub高星精选！十大MCP开源项目，让AI开发效率翻倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIo9DPdialhPibJ7DTfOC3LKTAsac5ElxFbtZZzIbVJBNAichgiaXldG96fwibUCoTkVHmExKYq6n85wvibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>导语2025年，MCP（Model Context Protocol）作为连接AI模型与现实世界的核心协议，正在重塑智能应用的开发范式！今天为大家盘点GitHub上10个高星MCP开源项目，覆盖聊天助</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492032&amp;idx=3&amp;sn=e4c9145106694d220902686a1d033a24&amp;chksm=fd1a5cbca6e992cfb95bbab1b07af724e7b62844043b9990774b77e53a0b67c173aa8a54dc4e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦大学提出GenPTW！AIGC水印技术新标杆！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IkWicmfRJFB8Rhcm9pq12BDzLM21lBkN6dAG83v6ib9Ea7Q7zka1iagUuP1kNYXWCiaOkzficiabqzOZVw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：GenPTW:In-Generation Image Watermarking for Provenance Tracing and Tamper Localization论文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492032&amp;idx=4&amp;sn=220abde172d331505b4e9319f3f1c9a7&amp;chksm=fd7890cd8382820bec2c3358e788f545b8a6c773353eff3b7beeec2fce018cbe5580149e4170&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 May 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>