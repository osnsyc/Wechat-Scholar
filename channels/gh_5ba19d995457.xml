<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    




























    <item>
      <title><![CDATA[图像超分辨新SOTA！南洋理工提出InvSR,利用大模型图像先验提高SR性能, 登上Huggingface热门项目。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emvRmmSX73ApBN83mPSIUnndGUoqrp8dTsfo3BKVIVGVNf5sWoXGauJCgAEaaCQm9Qb7QfuM34qZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>Zongsheng Yue南洋理工大学的研究者们提出了一种基于扩散反演的新型图像超分辨率 (SR) 技术，可以利用大型预训练扩散模型中蕴含的丰富图像先验来提高 SR 性能。该方法的核心是一个深度噪声预</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489619&amp;idx=1&amp;sn=f182985655b722a6b28af1786f859571&amp;chksm=fdbc675665c75a8ea94a8f7b610b9b037cad7eb123e6362921c03687fe1e7665adf82e833a11&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 25 Dec 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[腾讯提出ViewCrafter：一张图像就可以制作影视特效和游戏画面！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPOajsP01qNvmwKPWKzicOsEEbzBxMRtYWNicS7fSTCWsMB1YH3tWIYmKrNLzGfsI0qOR2rIwTbN4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>北大和港中文联合腾讯人工智能实验室提出了 ViewCrafter，这是一种利用视频扩散模型的先验从单个或稀疏图像合成一般场景的高保真新视图的新方法。可以简单理解为将复杂的图像转换成新角度的图像版本。首</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489619&amp;idx=2&amp;sn=dc67cf591a46e2150d13b00de98b73ff&amp;chksm=fdae0c285f441ba5991e81d8edbf83059683056fc5ea8043688b9b8ede786ba3d67e7ad8e943&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 25 Dec 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[腾讯 | 中科大提出Make-It-Animatable：一秒内可将任何3D人形模型变成动画角色]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgeG73PxwM4k72wVClKXaAf0yPYtOtKUjLgb02frh2Xh9vAawfNd5XlA/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯联合中科大提出了一种用于动画 3D 角色制作的新型框架Make-It-Animatable，可以在不到一秒的时间内使任何 3D 人形模型准备好进行角色动画制作，支持各种 3D 表示且生成质量和速度</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489619&amp;idx=3&amp;sn=f110c42876046cc736ed5007fbf41cf1&amp;chksm=fd93a6797762f9f6b4034cc8c563c5ac1f1708cc1b8629eb6908a8f1ff1c2e2bc797b69ab156&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 25 Dec 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489619&amp;idx=4&amp;sn=6e5b4127d53c33675b51b3f9f032089f&amp;chksm=fddd382a70616c2204bec85e723206b35c8f3361803c638b6088921c0828c765b039773d190e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Wed, 25 Dec 2024 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[Huggingface Trending！可控人物图像生成统一框架Leffa，可精确控制虚拟试穿和姿势转换！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emvRmmSX73ApBN83mPSIUnnw4qVp8X9ONMxpUQDBiaYSIRDzOCoVkXLaTPVaE68iceCFZ392Kf5RIrA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个Huggingface上虚拟试穿的热门项目Leffa，Leffa是一个可控人物图像生成的统一框架，可以精确操纵外观（即虚拟试穿）和姿势（即姿势转换）。从效果看生成效果很不错！unse</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489618&amp;idx=1&amp;sn=5650938e5dfb4b7cae5f6332248d43a8&amp;chksm=fd56b7afacd586da1bca5e2ba6ecd149324ad285ce83a3b2f13b6f115720221ed66909414938&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 16:22:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[快手可图上线一键换衣Kolors Virtual Try-On，直冲开源项目Top 1！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enWSibOOIL5olEVr4QGiapQjV2hBCzbZIzmXNjBtLkqG3ndIHVUZLFsPYXXXTBsmL3ojSmdUZztnn5w/300?wxtype=jpeg&amp;wxfrom=0"/><p>前几天，快手可图团队在HuggingFace上面搭建了一个虚拟试衣Demo,本周该项目的火热程度已经冲到了HuggingFace的Top 1。那么Kolors Virtual Try-On 到底有什么</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489618&amp;idx=2&amp;sn=899bdd8828512e8c20fb7a8ca1be8518&amp;chksm=fd485cd11a954ad216359cf5192e06bb1a9be4127e6ed8cef9f8d1f3929131f70201ddc4c0c2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 16:22:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文生图像编辑来了！英伟达提出Add-it，无需训练，可根据文本提示向图像添加对象。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emmkDiagtskaHJodPFibMTUYJZY50N6JpzSdpSqpDMMdhm1JHxUv7E3vPPDa6XmXuygFoa0eiaBct3Bg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Nvidia提出了Add-it，这是一种无需训练的方法，可根据文本提示向图像添加对象。Add-it 适用于真实图像和生成的图像。该方法利用现有的文本转图像模型 (FLUX.1-dev)，无需额外训练。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489618&amp;idx=3&amp;sn=7c9705d9e6e007ca6b69fcff90dcaad4&amp;chksm=fdae9ffee1f075d90261eb89d50d3b0a87af92faecebb0267931044a8a7810fb6c114cd26ce6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 16:22:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Haper SD Lora: 8步就可以用 Flux-dev生成图片!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eksy31uial7qPUM1bKGJAsI4BP97gdj3Ez3f9MI6ahElq7FZkQBowmnJAu1mBM0rOdWlon0wCb0tibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>2024 年 8 月 26 日,字节开源了 FLUX Dev 的 Haper SD Lora。只需要 8 步或者 16 步就可以用 FLUX 生成图片，大幅减少 FLUX 的生成时间。建议 LoRA </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489618&amp;idx=4&amp;sn=dfd78622d906312f68c2b0ed5955a264&amp;chksm=fd27903edaf8a39334e7be2706fbedf385c1ab86eb40a7737181d9d9ddcc4bfecb9858b24067&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 16:22:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[何恺明团队在文生图领域的最新突破性工作Fluid，刷新文生图质量纪录。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enguULNRdFY490TCSZibjWdBDtzjb1fnISWIUibYKVtZZjzibCWozIpuLNnibvGv0UaoHrF8HjA40xKIA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍何恺明团队的在文生图领域的最新突破性工作，论文中详细讨论了在视觉领域和文生图任务中自回归模型的扩展行为，并提出了使用连续token和随机顺序生成的新模型Fluid。 Fluid模型在MS</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489594&amp;idx=1&amp;sn=264a2e4aab1801d1d23d933bfa68b057&amp;chksm=fd758292fcb2aefe3058ede4a2936f4f1c9fc8a65e9dd17219245da75f3da177a04090a20d76&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[北航 | 多功能即插即用适配器MV-Adapter：实现多视图一致图像生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfSL2lH1ru1uCJuUuA21YKHU5ia5SLlWu0BztQtHU3YSeZIYv3K9nGSHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>北航提出了第一个多功能的即插即用适配器MV-Adapter。可以在不改变原有网络结构或特征空间的情况下增强T2I模型及其衍生模型。MV-Adapter 在 SDXL 上实现了高达768分辨率的多视图图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489594&amp;idx=2&amp;sn=f32c41aa32c472ee77ef9d69e021ba22&amp;chksm=fd435f023a602392265cce46e40935ecd8b7d628d9cf444766f47c25e7ac91c624f68c82dd3f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Face2QR:可根据人脸图像生成二维码，还可以扫描，以后个人名片就这样用了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDXLyhv5gUBA9w7NggpzadO1jATGuCxxia6dLEgQBFVb37eWtav37qYkiabubYa9vGGTHlEWmbql9w/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是一种专为生成个性化二维码而设计的新方法Face2QR，可以将美观、人脸识别和可扫描性完美地融合在一起。下图展示为Face2QR 生成的面部图像（第一行）和二维码图像（第二行）。生成的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489594&amp;idx=3&amp;sn=dbe5de5778895cc172e896343e01a71f&amp;chksm=fd91d41eb0ac9041c3144da7e4b24647c006430b4794930430857212e22708d85eeabcfe3909&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一图看尽AI文生图未来，北大发布文生图十年综述：超440项工作回顾。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDXLyhv5gUBA9w7NggpzadRrialXnXJ0hpkUPylInNS5ibB5unS9uBgxThVxDiaMNn2QsZM4tTQg5Fw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的文章来自北大发布的文生图十年综述，文章回顾了超过440项相关工作，重点探讨了生成对抗网络（GAN）、自回归模型（AR）和扩散模型（DM）在T2I任务中的应用和演变。还涉及了T2I技术的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489594&amp;idx=4&amp;sn=b9d11eda3f0e446b5cc6c761535e21f2&amp;chksm=fdbfded8c580d4ec9f71d1372bd869855aeaa878b4f10e17cd9b37d10b6c2171882b7ba4d5fc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[单图可生成虚拟世界？约翰霍普金斯大学提出GenEx，一张图片即可创建可探索360° 3D世界！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enEtibxlukPrYKiah0Ke78WycKUONRrjNlEFSNapJEh6SJ1d66ng13nsbGzI0AOOoofHoVQwXlLWo7w/640?wxtype=jpeg&amp;wxfrom=0"/><p>约翰霍普金斯大学团队提出的GenEx是一种 AI 模型，仅通过一张图片即可创建完全可探索的 360° 3D 世界！用户可以以交互方式探索生成的世界。借助这个想象的世界，GenEx 在想象空间中推进了具</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489578&amp;idx=1&amp;sn=573fd177918ab994fda27691c4739e98&amp;chksm=fd4ec9e45b9597ba8742e1986c4b21b7f84bec1da89ea27a398b2a8b83be42045258fc4b88e3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 16:18:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[智谱AI联合清华开源视频生成模型CogVideoX-5B。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>A golden retriever, sporting sleek black sunglasses, with its lengthy fur flowing in the breeze, spr</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489578&amp;idx=2&amp;sn=7176679ee2df2432e7e5fcccc7b7166f&amp;chksm=fd9810b90b426bb593537a3315a76d33ddad549bd3e03e0763049809742553abf42382eb6926&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 16:18:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯震撼发布！MOFA-Video：表情随心换，运动由你控，视频创作由你做主！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eluznmN5hhFpzms6Qx3Wv5eLBPz0lIKurfh4NGn76ysqzAfKFb3JzIZhVtcMibPQfcYW5Yfg4jSDSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯开源了一个非常全面的视频控制方式 MOFA-Video。支持通过箭头控制视频内容的运动方向，类似运动笔刷。还支持将原有视频的面部表情迁移到新生成的人脸视频上。上面两种控制方式也可以同时在一个画面中</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489578&amp;idx=3&amp;sn=562e65ad208d27254e48aa744416df38&amp;chksm=fdae0b253b23267b3967abfb17b4d9fdd1f8853b6f4515e9cdeb72141be75d5f779911906f05&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 16:18:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[超越IP-Adapter！字节提出MoMA，一种即插即用、无需调优的快速个性化生成方法！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcDtU5TRWR4b0ttfgqrxKDOQAmDscucEyJqSeHYUm1lVuU1IS2LukibibiaoOxpibhtu00EDvRCvPshQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出一种即插即用的快速个性化生成方法-MoMA。不需调优，只需一张主体的图像(下图蓝色圈出)，就可以生成文本对齐的、保留身份的同一主体的新图像，只需要一次向前传递。我们的模型既支持重新语境化，即相</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489578&amp;idx=4&amp;sn=7a4979cf208eac34556944947479fe8e&amp;chksm=fda70c63cea7a112055f8371101cc66dd97226a0d1d1c8655ba2ffe8a2c7b9c2a0f24922145a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 16:18:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[重磅！Grok 宣布对所有人免费开放使用！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enEtibxlukPrYKiah0Ke78WycE6iby25ZkyiabnY17CC6vsR44Rt0UCdF2KxFrFnrYfQjdpynXJwFfcicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>AI工具又多了一个选择！ Grok 宣布对所有人免费开放使用！马斯克说Grok集成了X上的数据，因此在回答最新信息方面的问题是最厉害的！Grok 现在将𝕏实时洞察与网络搜索相结合，以获得及时、准确的答</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489577&amp;idx=1&amp;sn=cd58000f62fc0263567d57f3a2485d37&amp;chksm=fd67627f4b8d9b1b84a37942fb0514e805087c8c9bb963da237f34b214fb2af25da0d1069d07&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 16:52:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[释放你的想象！支持25种复杂编辑类型！浙大等提出AnyEdit：统一高质量图像编辑框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogvQmU85Kosfv2RDCta999EbyF8VGjNflEKL8rzY2kCTLkHufbCjRTU5ianGMict4uibvsA4bKvfblyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIGC Studio”文章链接：https://arxiv.org/pdf/2411.15738 项目链接：https://dcd-anyedit.github.io/亮点直击从</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489577&amp;idx=2&amp;sn=09802db03a0d6e8d15ee6d5c8b90a5c7&amp;chksm=fd2d348bd27ed63b646cdceccff45ed1f71437ba44dc662b7ee02f0445a40736407a4dfb97c3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 16:52:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[11.6k星星！Facebook开源的儿童手绘AI转动画项目，儿童艺术创作赛道可落地。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NYTuBbaNon2vjiaAUMWgpNkZmZ2WywhPia4Ryk9Fw4H7g4BxlLIvmicicW46SSfW3fUm1JCFZKwgCRIBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐的是Facebook开源的AnimatedDrawings。主要功能是让儿童简笔画里的主体角色动起来。这个AI项目落地场景很不错，儿童艺术创作领域。儿童对人物形象的描绘非常富有表现力且多</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489577&amp;idx=3&amp;sn=73a35feba30f7392947f829f153a1f1a&amp;chksm=fd52de476a64f7cf61d277c40c15d2ccc0a7ed1896698eeeec1a40a3e9c3193d9bdceab5d261&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 16:52:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InstantX 重磅开源 FLUX.1-dev-IP-Adapter 模型，文中附模型和comfyui工作流下载。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eltYhV1JmK1ib9FbmIt2gIyP6xwE5MPwewm6kG9gwsXpPEaHHTOicBN3XsV2LsRvJ5qWf00gn2UwKaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>InstantX 团队的研究人员开源了 FLUX.1-dev-IP-Adapter，这是一个常规 IP-Adapter，新层被添加到 38 个单块和 19 个双块中。使用siglip-so400m-p</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489577&amp;idx=4&amp;sn=5aa81bfb5326c9774a8bf37628d7d4fa&amp;chksm=fd8ef22c7c19c7ebab990f7cff86a0cfa05269e021c49386bdba24accb2cc69734374864b29a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 16:52:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[你要跳舞么？复旦&amp;微软提出StableAnimator：可实现高质量和高保真的ID一致性人类视频生成]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcSnOoT1icicSWQibicicqfkyEg0pWxDqMplvkr6CkMHxsZoRegYlaQmYz6ah0rQewI1UFbTMjpYhWh4Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>由复旦、微软、虎牙、CMU的研究团队提出的StableAnimator框架，实现了高质量和高保真的ID一致性人类视频生成。StableAnimator 生成的姿势驱动的人体图像动画展示了其合成高保真和</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489536&amp;idx=1&amp;sn=7b608cfbaa080786a0104a65070ca564&amp;chksm=fd4659a89b841753c630ad6fd4a96680cb25aa9c2f2e1cc6d2ada812a97e6fd5faa908ecf6f8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[FLUX.1 Tools，为创作者提供了更强大的控制能力。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eltYhV1JmK1ib9FbmIt2gIyPDOrcibpBhOX3OVdibquclM6ib7Tsxn7qhfDiclnY9wlicfpKLJib4fLuY7Og/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI 图像编辑昨晚迎来了一次重大升级！ BlackForestLabs 发布了 FLUX.1 Tools套件，为创作者提供了更强大的控制能力。FLUX.1 Tools套件介绍这次发布包括四项新功能：F</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489536&amp;idx=2&amp;sn=674c72c869791006aa9e7a62a2df76fd&amp;chksm=fdd0f1cf8c9cfec103b5826488276acb6df4e154de922a8365e529834d740819e4fe8f37f09e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达发布Edify 3D生成模型，可在两分钟内生成可用于生产的 3D 资源、UV 贴图、4K 纹理和 PBR 材质。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elxgthgBxxwQlaTIxWuApiamicib5ZgIVOibFe3QVhqnvlTZsicUc8Qic16ZXdmpShcAV4jbk9vZib9Yh0MA/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达发布 Edify 3D 生成模型，可以利用 Agents 自动判断提示词场景中需要的模型，生成后将他们组合为一个场景。Edify 3D 可以在两分钟内生成详细的、可用于生产的 3D 资源、生成有</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489536&amp;idx=3&amp;sn=4158fc78e9df141cfb1d9628997b42eb&amp;chksm=fd1ad5510025a87a55316dfd6bae0c3a39e5f1a53b77081bf1cbd5f1eb316ee5fa9fe6d78227&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Adobe提出RGB↔X：可由图片直接输出AO、法线、roughness等，再也不用PS分层了！已开源]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el2gcPqyiclMWPWUZdmfKRIs9kMSga9RK7vVJdYR3SezDnSGSKr5S8MYpXvQLTvOxa2LothopykbpQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐一篇今年 ACM SIGGRAPH 的论文《RGB↔X: Image Decomposition and Synthesis Using Material- and Lighting-a</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489536&amp;idx=4&amp;sn=0db2a90c9c3207e168ac8be466fb54fe&amp;chksm=fd8642ec94cdbc8c319f9b21ae05497af5fdd87651c5a83e0a358d3d723e9259772f1851a242&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 20 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[北航 | 第一个多功能即插即用适配器MV-Adapter：轻松实现多视图一致图像生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfSL2lH1ru1uCJuUuA21YKHU5ia5SLlWu0BztQtHU3YSeZIYv3K9nGSHQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>北航提出了第一个多功能的即插即用适配器MV-Adapter。可以在不改变原有网络结构或特征空间的情况下增强T2I模型及其衍生模型。MV-Adapter 在 SDXL 上实现了高达768分辨率的多视图图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489490&amp;idx=1&amp;sn=2f5ceaf10f43bd2074c45735daa26d91&amp;chksm=fd5675a3ba0a0a41c410f790cbad2610d58f0372db6fcbc13c8863f4869607153260ad0bfcaa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 16:05:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Google发布Gemini2.0，“Agent时代”最强大的AI模型！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NbyjcY6R4PICML3ylBblKicx7wRU9ODC5RRyTZ42g2sxvzcC94gF7pTZHDYqh28rqf1tJxsLUiaK5TA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Gemini2.0是“Agent时代”最强大的AI模型，这是Gemini2.0自己给自己做的定义。起初我是有点质疑，但是！！当我看了一上午，慢慢的去了解它、与它接触，我又想起来Gemini2.0给自己</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489490&amp;idx=2&amp;sn=0646ed3e771ddad08c72762447b90d43&amp;chksm=fd02f288c2f925166b3ef9c5450b2caff803431397f9d5dec5f9ce74d1c9dd90ed943336a8c2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 16:05:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[音频驱动肖像动画新方法LetsTalk,可生成与音频一致的逼真视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgfkcDFOIyH4xJ5xG8Ar9Y0Uvicw6xicJzbmEtb2yOzCDNqYMjzkS4eYpw/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍过许多关于音频驱动的肖像图像生成动画方法，感兴趣的小伙伴可以点击下面链接阅读~复旦开源Hallo：只需输入一段音频和一张照片就可以让人物说话。开源EMO再升级！复旦|百度|南</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489490&amp;idx=3&amp;sn=8ba78d17cda32016c840b193621de181&amp;chksm=fde4cad7a3cecf8002b41350cdcc9bd9adf436b34c19ffb84bd6c4656c21c0c9d30e9fc81ba2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 19 Dec 2024 16:05:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
