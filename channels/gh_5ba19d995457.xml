<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[港大&amp;Adobe联合提出图像生成模型PixelFlow，可直接在原始像素空间中运行，无需VAE即可进行端到端训练。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em57kq23EbSGQ52kUcSia6n8oTIJOicficBicZpibaJQgm7tEpQJ6psVkrLse6pjDUwqiaktvnGSEiaL6xPg/640?wxtype=jpeg&amp;wxfrom=0"/><p>香港大学和Adobe联合提出了一种直接在原始像素空间中运行的图像生成模型PixelFlow，这种方法简化了图像生成过程，无需预先训练的变分自编码器 (VAE)，并使整个模型能够端到端训练。通过高效的级</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492013&amp;idx=1&amp;sn=3c38d3566ba2a051b9a6249542f88100&amp;chksm=fdf437987c7594b284eb1c095eb65f7d76071ff182f8058541825051472ee74849b073d8a75f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Apr 2025 00:21:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯混元&amp;InstantX开源InstantCharacter，跨角色外观、姿势和风格个性化生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2mVMulTo5LC5G2oFcJtOgsuJWSCokK4anUcgT9xP5mIuHTqbM9wOvIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元联合InstantX团队提出全新角色定制生图框架 InstantCharacter，与当前的SoTA方法GPT4o取得了相当的结果，然而，GPT4o并未开源。相比之下，InstantChara</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492013&amp;idx=2&amp;sn=8f5f6febef92481a2b999c2fff41427d&amp;chksm=fd07af082c6d60eee9dd5d85ee214171bb404cccbcd16257004423970ae4de4fe22bbf898323&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Apr 2025 00:21:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文了解：大模型 Agent 开发框架有哪些？它们的区别是什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIr8DNP5MR3eP0zlA9JsT0hBHpz7mIT9yRpuDv80p9ANexpSib1fao2maWhK8nPVqlRMv4h1P6M8ia8Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>——大模型时代，如何选择适合的 Agent 开发工具？引言随着大模型技术的爆发，AI Agent（智能代理）逐渐成为落地应用的核心载体。它不仅能理解语言，还能自主规划、调用工具、执行任务，真正让大模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492013&amp;idx=3&amp;sn=13fdff9d31ba4868f91e6ee2891648da&amp;chksm=fd4a42092e74fd6078388092c013ba877536c98c0f735073624ab085686913da0e01cb78520d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Apr 2025 00:21:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI视频生成新突破！字节提出一致性视频生成方法Phantom：通过跨模态对齐生成主题一致的视频，超多应用场景。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7FjUDMtLDDzOxeRDTsjoBO7nWymp4ibfUg4ngicJhNSbFdrgXOp81mHMKg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Phantom 是一个统一的视频生成框架，适用于单主题和多主题参考，基于现有的文本转视频和图像转视频架构构建。它通过重新设计联合文本-图像注入模型，利用文本-图像-视频三元组数据实现跨模态对齐。此外，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491990&amp;idx=1&amp;sn=0e7cbde823de9dd220b56220b969fca2&amp;chksm=fd9be49fcac89c813fc4d08e7d5866fbbda3597767b9e9a6c38b9813412a1adc107dd7344744&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[昆仑万维开源首个无限时长AI电影生成模型SkyReels V2，未来AI生成电影就像生成小说一样简单。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NafqBpS39V3QaPPMhicGiaAnJaibic3t8plxpmyDboODf79YPcdd4kw0Rjrskd93Gy5XGf196bJVZzTvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI视频最近很卷啊，开源的都这么卷。效果还不错的模型都在慢慢开源了，不知道开源项目的质量什么时候会追平闭源。我感觉是很快了，起码会慢慢缩小差距。今天给大家推荐的SkyReels V2，很有噱头啊，无限</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491990&amp;idx=2&amp;sn=eea7bf70da764981f60fd5f9807c6676&amp;chksm=fdae17e39f99a08c5042900477184250286d435510d119d6b7cb5602700cd279bf0455e33c9c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 Highlight | 清华提出一键式视频扩散模型VideoScene，从视频到 3D 的桥梁，一步到位！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en6YOGtn3XXJMye1oxLXOtQDu8lVia8rZmBpsouclpUQ8eY6ebkIhqsCQhQiabYLqW83mluezLMicI1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华大学的研究团队首次提出了一种一步式视频扩散技术 VideoScene，专注于 3D 场景视频生成。它利用了 3D-aware leap flow distillation 策略，通过跳跃式跨越冗余</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491990&amp;idx=3&amp;sn=2b79fa4aa3d3d957a1d84dc8d5f02cfa&amp;chksm=fd9906e6a69bb06c9e8bbe7194b15e492ce8675bacd31163cee3a09919319c5df30517faa5f2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Ostris重磅发布Flex.2-preview：ComfyUI的图像生成神器，来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE6GD7M9ia43KfxsQB2yZoVfsFEaItKEQTLWerXjQ5TvLVBx6huV6BtYyticl7A5fkL8xgP5s2ov4icIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击蓝字关注我吧！在AI生成图像领域，一款新星模型横空出世——Flex.2-preview，由Ostris团队推出。这个拥有8亿参数的文本到图像扩散模型，不仅开源、轻量、强大，而且专为ComfyUI生</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491990&amp;idx=4&amp;sn=4652b4b436488f55ef952ed21dc632fa&amp;chksm=fd3c6a527ffdcded6f68fae26a0f5c1525346d372112e04c62923e7d3d2b5c8a5af917baf038&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[GigaAI发布全球首个解耦式人体视频生成框架HumanDreamer，可生成由文本到姿态到人体的高质量视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7F3dWu899ia30B7OUIZdlXFicRk96bnw8CxvB7cawibZFt7o1OsHwARZWlw/640?wxtype=jpeg&amp;wxfrom=0"/><p>由GigaAI、北大、港中文联合提出了一个解耦的人体视频生成框架HumanDreamer，可以根据文本提示生成各种姿势，然后利用这些姿势生成人体运动视频。此外论文还提出了用于人体运动姿势生成的最大数据</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491989&amp;idx=1&amp;sn=42555d0c20bdcd6b547b8b17c64194be&amp;chksm=fd5ad6ba9959c8e0b23bfb929746fc7ac55e091082016b6ffcd9630d038827381fea5694bba1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491989&amp;idx=2&amp;sn=b1829f57c48f2d95f12acdef3d8d7b6e&amp;chksm=fde7f93e3aa2e2d030cebf58238bba42ac7f2ddecda177b006edc2e4fdac61902679484bd8ac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里EMO2重磅升级！手部动作生成+超逼真表情，音频驱动人像视频生成再进化！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGYiaHtTElCkzOGD9sY0N1Qp8FDJqnDN5BkTWSW0TSu1sYeAgQzRiaicMcRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的音频驱动的人像视频生成方法EMO，感兴趣的小伙伴可以点击下面链接阅读~阿里最新EMO：只需要提供一张照片和一段音频，即可生成会说话唱歌的AI视频此外公众号的底部</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491989&amp;idx=3&amp;sn=b87c7197898e439ed6b7f88693b127b5&amp;chksm=fdcfdaeb6c6c957a2ef0af1f848b3bed48ab26616f3356c085901568baddd22d2b0f15146b26&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动提出Pixel-SAIL!单一Transformer实现三大突破，性能不降反升！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7FaBqSnQoJ9kCcgiaLM8xcMAdQ0wHUuCOjSJTlKTZnXGTL0jj8qibLthSw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding论文链接：https://arxiv.org/pd</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491989&amp;idx=4&amp;sn=af423aa641522e463b0d30f7f5f46f5c&amp;chksm=fdb0b6ae78295899a61b8305e175353ed54b1fb52c95ad2db72d6dc887e319a9cef34e75bfbc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑革命，万物皆可插入！浙大/哈佛/南洋理工提出Insert Anything，告别PS抠图，AI让世界无缝生长。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7Ficnb2ehPShfDudYtibS1fkY0Su3IFmdP3MkS9KDH1gsquQnXh8Ku6TPQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学、哈佛大学、南洋理工大学联合提出了统一的图像插入框架Insert Anything，支持多种实际场景，包括艺术创作、逼真的脸部交换、电影场景构图、虚拟服装试穿、配饰定制和数字道具更换，下图展示</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491988&amp;idx=1&amp;sn=785202fb8a751012c85e5dff39224c49&amp;chksm=fd9320464a923f22a0617cc6492ca9354454ae74fe08e2eaa3504f91c2b4efffcaaffb2672b3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大提出Turbo2K！2K视频生成的效率革命！20倍加速+VAE蒸馏，4K级画质触手可及！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5L3TwauXAyuAgh1Bpxlpf7qvZlS0Lvz5aNJNCTblRfiaCxEIINia2EHfd2DdfWKfLLBzfITOic5MYmzw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Turbo2K: Towards Ultra-Efficient and High-Quality 2K Video Synthesis论文链接：https://arxiv.o</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491988&amp;idx=2&amp;sn=f9250b3e490fdd7d7724add58f4fd3f1&amp;chksm=fdbaf3d6f1283d2af2b0975f04202ca23104d429bcc515384ade67c180c2de7043a7d9bbb502&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491988&amp;idx=3&amp;sn=4e5aefe3b82295bad1fa2fe3dc8d31a6&amp;chksm=fdc70d2bf4a1f38f814e84c056fbcf3a20d2bc9271cdd9b05521e0a18fc58faca996b41ef913&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[不会画画也能做动漫线稿！ComfyUI图像转线稿神器实测来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE744CtZ4PAzy9aTudVVLx79rU6ATpwibxSEM5fo5HEROy3eMzqy1a7MsXAyannXQXSdMIK4KJF4TkQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>🎨还在为不会画画却想搞定线稿发愁？现在，用AI一键出线稿已经不是梦！最近，图像处理圈里又杀出一匹“黑马”——ComfyUI图像转线稿工作流（Anyline+MistoLine），让我们这些“手残党”也</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491988&amp;idx=4&amp;sn=4c1b76ffdf5ae902b7ee702adfe60025&amp;chksm=fde4f734f5bda0e64011973e40de2a4efa9fd1aa04aff4f3dde33a3944654c63d3b6672b3de3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 25 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 Highlight | 清华提出一键式视频扩散模型VideoScene，从视频到 3D 的桥梁，一步到位！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en6YOGtn3XXJMye1oxLXOtQDu8lVia8rZmBpsouclpUQ8eY6ebkIhqsCQhQiabYLqW83mluezLMicI1g/640?wxtype=jpeg&amp;wxfrom=0"/><p>清华大学的研究团队首次提出了一种一步式视频扩散技术 VideoScene，专注于 3D 场景视频生成。它利用了 3D-aware leap flow distillation 策略，通过跳跃式跨越冗余</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491917&amp;idx=1&amp;sn=65d18a4a2942f2595b32f2c2bb12373e&amp;chksm=fd36e4db7762f4c7a81d9c6279f4a1061fb27946bb47de6597658f5d253114fdb383708d36a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[11个ComfyUI隐藏技巧，老司机都在用，第7个你绝对想不到！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE4UIKMD6jmia4ia5vQAuLEeoicPsQOcBhia8j8UYzVx2WClT9FwvRAGfODMYq21VicYPWGsNDrRhiaRvNJA/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击蓝字关注我吧！大家好，今天为你带来一份硬核但不过分烧脑的 ComfyUI 使用指南！如果你也在用 ComfyUI，无论是日常出图、插件调试、节点编排，还是大模型工作流搭建——本文这11个技巧都值得</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491917&amp;idx=2&amp;sn=3ad6546ea9e5a3d890a9a979739d5089&amp;chksm=fd39f3030784bec5b7b8e973f9009c1b1313169eca547e91bd3942e1b0ed6bed38cd42c00278&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里提出文生卡通新方法Textoon：一分钟内生成丰富多彩、可交互的Live2D格式角色。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMLBRnvtbr9hh7W1ccXtbHzL0fHklZwvXTHFm3tjgJJcKpq3IlwIZMDiaQUpT6AgMaBYsXg4BObLQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里提出了一种基于文本描述生成多样化2D卡通角色的新方法Textoon， Textoon利用先进的语言和视觉模型，能够在短短一分钟内生成丰富多彩、可交互的Live2D格式角色。这种方法不仅提高了生成效</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491917&amp;idx=3&amp;sn=3a00b08f2efbbf56cc69a1f2faad97d4&amp;chksm=fd2b2a2ba44538a8aa81e0efd6bbdd50df350feaac45424ba6fe77668b2e5b182caf8ad9c945&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491917&amp;idx=4&amp;sn=2a137a4d6488147f95a018152b32acaf&amp;chksm=fdac85de35f32dd3ec77bc418c1c83296bbbd1da170dd346aaab5cbebb78855c642435e5bb75&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491916&amp;idx=1&amp;sn=4ea56c7ef212c03aafe58a705bf754e9&amp;chksm=fde5c0ea964257ccd012db7745bc71a40df150d8b780a1bb9156a2b0c6c5732e9d9bee259841&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源项目FastAPI-MCP，一键将FastAPI转换成MCP服务器，以后API=MCP。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5Nb69coNJjYwLrdDicA1kP6DUhlXhePTVYrhoZAuibXQhPthJOnFxIiaZvibmjL3GjGytM1LVUhBq7tJDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是我这个月看过的最有价值的开源项目了。MCP发布之后，很多粉丝朋友都有疑问，MCP跟API有什么区别呢？简单来说，MCP就是规定格式的API，这样才可以被AI模型来调用。现在有海量的API，但都没有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491916&amp;idx=2&amp;sn=0d562e2519be09f89594e2817c42f897&amp;chksm=fd2cc98de2b5bbea6026bb2c0c2aa1f0239c4d07234ef3756712bf7647a7a5eb78e10ddbbff1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[100行代码讲透MCP原理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Z6bicxIx5naKuiafCtyF9icibwMCms6KxKgjSUDiajzIYfNuq5mEOiaDgITUQArGsx5eg6yibh8d7rfYBhoeu5l61icpFA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里妹导读本文通过100行代码看到MCP的核心原理并不复杂，但它的设计巧妙深入理解使我们能够超越简单的SDK使用，创建更强大、更灵活的AI应用集成方案。当我开始研究 Model Context Pro</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491916&amp;idx=3&amp;sn=7dc92a4432626222af9b3db4e140ea55&amp;chksm=fd490668e800658e4c892829c557c407357d54a674054968330034c6b7db2c97e50020d97499&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文带你了解，MOE 架构是什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIrjh2Jy92UibXavMpGEKRelbCqXiaEc6hkxXvNNtIibfW3p5bo1jGWB6icwh68qvkWZsqN65HicvwiaN28w/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言：从“全能大脑”到“专家团队”你是否想过，为什么ChatGPT能回答复杂问题，而手机语音助手却常“卡壳”？答案或许藏在一种名为**MOE（Mixture of Experts，混合专家模型）**的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491916&amp;idx=4&amp;sn=5831dbe4829208a0ef75a02be9688546&amp;chksm=fd3e9ed88e87966ccacad514d2e205e8c74b98565e1911aba42b66934f8e628a2c1c05f42306&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里EMO2重磅升级！手部动作生成+超逼真表情，音频驱动人像视频生成再进化！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGYiaHtTElCkzOGD9sY0N1Qp8FDJqnDN5BkTWSW0TSu1sYeAgQzRiaicMcRw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的音频驱动的人像视频生成方法EMO，感兴趣的小伙伴可以点击下面链接阅读~阿里最新EMO：只需要提供一张照片和一段音频，即可生成会说话唱歌的AI视频此外公众号的底部</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491887&amp;idx=1&amp;sn=eccb959bef4a92d52871c1fc9d75ef6c&amp;chksm=fdb9e72434abf67020fb315d86c912b7f6c4aa5538df1a14a489d010b4d1bac6f1c59303ef1c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 最强吉卜力风格工作流EasyCN来袭，风格统一+操作简便+输出稳定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE6xg4dG7Ndtia8iag86UJ7LAcFTmCaJMwrHhZMoY5Fjia4QeyYvmmygPtEbYjX3d9emmuUYf6flou1YA/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近的ComfyUI圈子，可谓是“神仙打架”级别的热闹。就在你还在研究ControlNet怎么接线、LoRA怎么调风格时，一套堪称“傻瓜级”的全自动吉卜力风格生成流程，已经在社区悄悄流行开来。Easy</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491887&amp;idx=2&amp;sn=f041acf88c2814cb02ef9586e9b3c3de&amp;chksm=fda4ca31923e49555d440e8d959a32510218d066b2e7d03d532c60c175d5ad4c14317cd4da62&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大提出Turbo2K！2K视频生成20倍加速+VAE蒸馏，4K级画质触手可及！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5L3TwauXAyuAgh1Bpxlpf7qvZlS0Lvz5aNJNCTblRfiaCxEIINia2EHfd2DdfWKfLLBzfITOic5MYmzw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Turbo2K: Towards Ultra-Efficient and High-Quality 2K Video Synthesis论文链接：https://arxiv.o</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491887&amp;idx=3&amp;sn=85c6c046af1416ecd74aa50291ac78b3&amp;chksm=fd99881eb9023587959e3b871b4b6bb3ea1c7b93b5657037ef70246ff5f724ba12605e86ccba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[olmOCR：重塑PDF文本处理，让语言模型更智能、更强大！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4IAQ3D7RpAMNb2namtUvCm06G4XyBQk2BvFF6sibwR50ffvQBeE8kk0ZM9vwsVG26eMLdZ9kcia7w/300?wxtype=jpeg&amp;wxfrom=0"/><p>olmOCR，这是一个高性能工具包，旨在将 PDF 和文档图像转换为干净、结构化的纯文本。 olmOCR的主要特点包括：高精度文本提取：经过大量多样化PDF内容的训练，采用独特的提示技术，显著提高文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491887&amp;idx=4&amp;sn=f29e5d2e22a2eb84aed11a084666ae54&amp;chksm=fd9d23aa592e8ad04686ffdd286e70f05143d6be863165fd92d97e9c1c5fd8b9691dbd571dbf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Apr 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>