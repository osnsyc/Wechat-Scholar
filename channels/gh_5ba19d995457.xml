<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[复旦联合百度发布Hallo4：让AI肖像“活”起来！新型扩散框架实现高保真音频驱动动画生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq56s1kIaYWsxKESfb9riaHUQVlW3JfPib9AP6mL8Hk0Ec5R0f43HYJ8aw/640?wxtype=jpeg&amp;wxfrom=0"/><p>复旦联合百度发布扩散框架Hallo4，实现了准确的唇音同步、自然的面部表情，并能够稳健地处理各种角色身份和环境场景中快速的语音节奏和突然的上身运动。相关链接论文：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493382&amp;idx=1&amp;sn=39ffd852e2ccd283cb9c564d565ba08f&amp;chksm=fd339e12fb401aa3f0a1b511e037be5faae1d733d59e62e6dbb2fefda798cdfbd64653043195&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型再现黑马！英伟达开源Llama-Nemotron系列模型，效果优于DeepSeek-R1。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafoC1ibJ7eE1fvbrtrICXG1kaXfiaqibBmibzznCUHyiaB4NGTibwK6pmBM0hA/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，英伟达推出了 Llama-Nemotron 系列模型（基于 Meta AI 的 Llama 模型构建）—— 一个面向高效推理的大模型开放家族，具备卓越的推理能力、推理效率，并采用对企业友好的开放</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493382&amp;idx=2&amp;sn=e165a22ba5dbade025d8e720714e318d&amp;chksm=fd41db51e43660c6a273cbf3ca9bf8a6361499eea144951b7ce0b8a8ced43f2cab4df595a1c6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦&amp;腾讯优图提出基于扩散的情感说话头像生成方法DICE-Talk，可为说话的肖像生成生动多样的情感。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekBUypVTojw9NicChAveibQcTccRrbh6qA2W0fWIHSYHibiaqHEFxVLBnicZtkEricIgpsqDf5wqctkvqRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>复旦大学和腾讯优图联合提出DICE-Talk，这是一个用于生成具有生动、身份保留的情感表达的谈话头部视频的新框架。可以为会说话的肖像创作出生动多样的情感表达。相关链接论文：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493382&amp;idx=3&amp;sn=fa8393a66c634f95b73f0c58e8a5fb7b&amp;chksm=fd769d4f98388a5e69c7bfbbeb0f415a537a271920c9068baabb38ff4756569ce14291045159&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别"纸片人"试衣！阿里&amp;浙大提出3DV-TON，用3D几何骨架+动态纹理场，让虚拟模特"活"出真实衣褶！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECFZTEAl6XrNJIs6kBFtCKh4H4USr1Odbdw4IOg8SSgUfrQQVgR52lmA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里联合浙大提出3DV-TON，可生成高保真度和时间一致的视频试穿结果，3DV-TON是一种基于几何和纹理 3D 引导的新型扩散框架。 可处理各种类型的服装和身体姿势，同时准确还原服装细节并保持一致的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493382&amp;idx=4&amp;sn=810a8f2ed7e85962c691485b3f4ee9d2&amp;chksm=fdfebe94aa4a5e24ae593709f6e5cba5ccad19f711b823cade08a1892c78a25b46ddb98f6645&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北大开源音频编辑模型PlayDiffusion，可实现音频局部编辑，比传统 AR 模型的效率高出 50 倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrNiaI7jyJY1V0kehM0SnqlBl50OPjfm0JQ5fD6SvsSa8sDtR2Rb2UIng/640?wxtype=jpeg&amp;wxfrom=0"/><p>北大开源了一个音频编辑模型PlayDiffusion，可以实现类似图片修复(inpaint)的局部编辑功能 - 只需修改音频中的特定片段，而无需重新生成整段音频。此外，它还是一个高性能的 TTS 系统</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493344&amp;idx=1&amp;sn=cd7a033f01702d16ab78e468a4e2ea51&amp;chksm=fdeaaea0054f3933cdf4c0455051ba3f156109c7ef2186a7f906b56877f208ab80faa4188e7d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌研究院联手牛津大学推出Bolt3D！7秒内单GPU生成高保真3D，推理成本直降300倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LR8w1T4XSJwAUg3UkzLpMRYxbTOuSXUEpxZVs5u18QTNFMFHe41E6SY6vfhMbJicRDetQWdibB3Nicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Bolt3D: Generating 3D Scenes in Seconds论文链接：https://arxiv.org/pdf/2503.14445开源代码：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493344&amp;idx=2&amp;sn=c41ba28a98ad5d0b2fb6f80ac5ea9a8d&amp;chksm=fde434eabd8222f83b984fe11435d0f3be3475f0dc5e176b346abd57376eeed73771f97419b6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI界新王炸，输入提示词秒变PS大神？阶跃星辰开源图像编辑模型Step1X-Edit：19B参数对标GPT-4o。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el0tf0f2Ybm2uFN97TrfHYoqefkVHtmLwhySToicQuQpmNJTBkEoLFpYZ12wzayha9Qna8FEyr9LfQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>阶跃星辰公司近期宣布开源自家图像编辑领域模型Step1X-Edit，它使用多模态大语言模型处理参考图像和用户的编辑指令，提取潜在嵌入并与扩散图像解码器集成以获得目标图像。Step1X-Edit凭借其强</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493344&amp;idx=3&amp;sn=7fee0720d3c728783d312c47692b869b&amp;chksm=fd5ba1f342e98cd98b1b6ac9d1dd2101dba2dbbd690df6c53f6da9586c4e81af08c0fb18142b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493344&amp;idx=4&amp;sn=2f36e4d56dad64b11164f209abe8ae5a&amp;chksm=fd9a52830e4b5da0eda48b5555649bc2e7ea5c6578e14f25cdfc045dc3d86ef1c8650c2ead05&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大&amp;快手提出统一上下文视频编辑框架 UNIC，各种视频编辑任务一网打尽，还可进行多项任务组合！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrbAeApibeaxibS3pqDl8gmHOmyuzVnspI2tpOfRwXqcA6LGNdsjAjUyWg/640?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、快手科技提出的UNIC（统一上下文视频编辑）是一个简单而有效的框架，它以上下文的方式统一单个模型中的各种视频编辑任务。从此，视频编辑用着一个工具就够了！ID插入ID交换删除ID相机控制</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493298&amp;idx=1&amp;sn=d87b5597b0df1fad80a5bbb050c9d119&amp;chksm=fdfdd7153586f15e1380a4a7ec94b36a5a87173c1297c5013112a1b7ddd81728b56c5f35be45&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出从单一主题发展到多主题定制的通用框架UNO，通过情境生成释放更多可控性。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elo3s89icGNibsPQVXGhctg9WDrsYXyWyFSyqXzUDm6eOsD3G2Z7XbSMUPZrQw19LsCTpuzPx9KiaCWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节跳动的智能创作团队提出了一个从单一主题发展到多主题定制的通用框架UNO，从少到多的泛化：通过情境生成释放更多可控性。能够将不同的任务统一在一个模型下。在单主题和多主题驱动的生成中都能实现高度一致性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493298&amp;idx=2&amp;sn=f9e4b5f9594e2496705f42effee6d6e4&amp;chksm=fd9c79d502f7a140c1ecaf6f4bf83b3521b02002ab0ea6d4430d0be9d59195bcef6e97216b89&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[小红书提出新面部视频交换方法DynamicFace，可生成高质量且一致的视频面部图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4wY9icyCBJHtpRNSEtIVu23ib2dMfGUzdVZH7hKlE7v6ZRLfdk46k3hHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>DynamicFace是一种新颖的面部视频交换方法，旨在生成高质量且一致的视频面部图像。该方法结合了扩散模型的强大能力和可插拔的时间层，以解决传统面部交换技术面临的两个主要挑战：在保持源面部身份的同时</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493298&amp;idx=3&amp;sn=b294673d9395fc252326e0a052a41250&amp;chksm=fd8a4164387bd306acf66453ba0544270e786d094c309cdf5f3823c4276f46447c879891d3d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯混元&amp;InstantX开源InstantCharacter，跨角色外观、姿势和风格个性化生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2mVMulTo5LC5G2oFcJtOgsuJWSCokK4anUcgT9xP5mIuHTqbM9wOvIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元联合InstantX团队提出全新角色定制生图框架 InstantCharacter，与当前的SoTA方法GPT4o取得了相当的结果，然而，GPT4o并未开源。相比之下，InstantChara</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493298&amp;idx=4&amp;sn=7e5a577ea9daf9fb97e6944db710b072&amp;chksm=fdb3785291cae3796b3b1990d3513e8280fd7fd66527d74f725f6152b278c9ef574732b77c36&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Ctrl-Crash 助力交通安全：可控生成逼真车祸视频，防患于未然]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrPLRrD1QZ9zibv4a5SaD1ia2jKGyHkiaBTqokY1CyAp4XtkGfscoppegZg/640?wxtype=jpeg&amp;wxfrom=0"/><p>视频扩散技术虽发展显著，但多数驾驶数据集事故事件少，难以生成逼真车祸图像，而提升交通安全又急需逼真可控的事故模拟。为此，论文提出可控车祸视频生成模型 Ctrl-Crash，它以边界框、碰撞类型、初始图</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493297&amp;idx=1&amp;sn=12ed43995c160a7091085cca6bcb1538&amp;chksm=fdc82cb44c0a5a715da2fe56dcfc62d60588684d6b06260eb09b40f6fc4bcca6eb164dbca1bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 08 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动提出Pixel-SAIL!单一Transformer实现三大突破，性能不降反升！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7FaBqSnQoJ9kCcgiaLM8xcMAdQ0wHUuCOjSJTlKTZnXGTL0jj8qibLthSw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding论文链接：https://arxiv.org/pd</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493297&amp;idx=2&amp;sn=bd1eb99fea1fa657a1093fdbc36025a6&amp;chksm=fde353a956d09ab014351e47b2d32fef8034f03ae9d0364aabff20b5ed72d42526d9ab98eecc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 08 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493297&amp;idx=3&amp;sn=16004a996874ff96455e6be6f78240ed&amp;chksm=fd5a55d724d55f68883c0e46053db7a37e4d18bdeaf044007ea69016f5c5dc09ec9892085120&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 08 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICIR2025 | CubeDiff：无需考虑失真，重新利用基于扩散的图像模型来生成360°全景图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6qavvqaKicyhfbe1wrRfKuEmZbfJ8LvrOgQJMgZYG5CztqNUPPASQbtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给大家介绍过许多关于3D生成的文章，感兴趣的同学可以点击公众号菜单栏查看3D生成专栏，创作不易，欢迎大家点点赞和在看~CubeDiff是一种使用基于扩散的图像模型生成 360° 全景</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493297&amp;idx=4&amp;sn=c6ae1c1a55b6d18894ca513ea308bae4&amp;chksm=fd4ea9e692da8e4bdccf9377b9fd1600757f3af322e501df337ed301be40dc440c61bae87d9a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 08 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SIGGRAGH 2025 | AI视频生成黑科技！港大&amp;达摩院发布分层视频生成LayerFlow：再也不用视频抠图了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrOLuSb7ibEOeR0QxWLzfAOwCiaOpIxJgUv6jqX41ckXO1MREb9QUViaYibA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章来自公众号读者投稿，论文提出了一个统一的分层视频生成解决方案 LayerFlow，给定每一层的提示词，LayerFlow 能够生成带有透明alpha通道的前景、干净的背景以及二者结合的全景视频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=1&amp;sn=6fe5a49d65ebe5aac00e62de40e181b1&amp;chksm=fdaa8f60082a9d6302f07f6900a756203e40fef0ae7e5b9974851e02da33fb27b4258eee8d96&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[StepFun提出Step-Video-T2V！300亿参数视频生成大模型！可生成204帧视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcJicm2I75ZP1rkl1ZMqicoKfreYnRFLqFBbibqBpPJl9LzNL6OUXy1tmllZuicN8KGIYIbPRjfSZnnOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model论</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=2&amp;sn=c768d79299959655b4272ee4b124ede9&amp;chksm=fd2722a27debec182008aa67bfcc307595d7eb751fb7b436036fbcc933ef1c41e87edb1efd07&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Apple提出UniGen！多模态理解生成统一xii新架构！CoT - V提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KqpbKjwyf8GDnoGZ1ANRZVHSofem5JIanFIxSibozXUibNxHviaUIPE6FTh1nw9lCf16QMqWDaqf7cg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniGen: Enhanced Training&amp;Test-Time Strategies for Unified Multimodal Understanding and </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=3&amp;sn=28e556b89d07c4427a34551cadd23fea&amp;chksm=fdeabdd2736c698ef95a36cbabc7eb5eca25ba66a0061008e277a99da139857b0f9b6fba4bca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=4&amp;sn=61c41a21175f84251746b6916b89e5ed&amp;chksm=fd174d6754a6b7bcacf613ccb28dc88773d58bd162049590cfc7e0a98c6170df1dfd588dd656&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[科研人神器，论文秒变海报！Paper2Poster：一键生成顶会级学术Poster，再也不用为赶会熬夜做PPT啦。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ele6MdnMwUcFcDzM1rn9UbH2rVZPFxHmzrmY7icJmAlfTmrY7niam10ibJeWm7Lrk76urBe1ZJ7MZftA/640?wxtype=jpeg&amp;wxfrom=0"/><p>由滑铁卢大学、新加坡国立大学、牛津大学提出的面向科学论文的多模式海报自动化生成方法Paper2Poster，主要解决了如何根据论文创建海报以及如何评估海报。AI能否根据论文设计出精美的海报？GPT-4</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493165&amp;idx=1&amp;sn=f80d94b583f1f121d7c81b7255426171&amp;chksm=fdfe52e4d437e21ebeedeecbf1e5bed09c293692b767d0862b481f61463ed939e9cf6b57041c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 06 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源换脸写真模型InfiniteYou，可实现零样本身份ID一致保持，无缝集成FLUX、ControlNets、LoRAs！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFB9QEic6a0icic21hdjU7tWMfgnZWZ32D1adHqJcD4Z8fvzhEvH6KNghsZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个字节刚开源的换脸写真新模型InfiniteYou，这是一种先进的零样本身份ID一致性保持模型，由字节跳动基于文生图领域最强开源模型FLUX模型研发的。InfiniteYou专注于利用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493165&amp;idx=2&amp;sn=f315cae10211d59cdd6a32edd4dbba9c&amp;chksm=fd5dabd07c2cd74c7a2b12b7cc8d2a756c8ad71a27c8658a408e29d8a25e8481faf8ee56f511&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 06 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像定制大一统？字节提出DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等任务，有效解决多泛化性冲突。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1Zrf8JKiaMovMsw9t4ZW4pibcVZlWM8AF7GsajlXAPWl5IJgnfQRpnvoA/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出了一个统一的图像定制框架DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等多项任务，不仅在广泛的图像定制场景中取得了高质量的结果，而且在适应多条件场景方面也表现出很强的灵活性。现在已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493165&amp;idx=3&amp;sn=628ad5b2dfa6439f0314a5b391213982&amp;chksm=fd7d9d7f05ecefbe6385bfede6812424cd9532567c03a695ac89e63fa614b9d24b214db445c4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 06 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[7k星星爆火！用微信聊天记录训练一个自己的数字分身回信息，还能克隆声音回复语音消息。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NarO1FqtJTNnAkBYibHt0foxa0Fe75VZQRCPicXrJ4JdcyBcfXfytFdyEnQK4gfA5aQ6UicqjUDAHFrA/300?wxtype=jpeg&amp;wxfrom=0"/><p>早就想拥有一个AI来帮我回消息，最好是能跟我说话风格极其相似的。今天发现一个好玩的开源项目，能根据微信的聊天记录，给自己做一个“数字分身”。而且，它不只是能回消息，还能学习你的音色回复语音消息。这难道</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493165&amp;idx=4&amp;sn=4bab2a7df63038d51cc8b24de7b64078&amp;chksm=fd411ee4597871cb3b0ce632b413d95cc77300eb94c5183e55ca1786a1d20496c23fa59aea8e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 06 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节 DreamFit 虚拟试衣：任意服装随心试，多风格人体模特一键匹配生成，轻量级即插即用！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1Sdlhwzib8OsMLEPMO37XskQtAwVfcflGHCc0lfCW6bzSeuACrjlKia8g/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天跟大家介绍一款由字节提出的新的虚拟试衣框架：DreamFit，这是一款结合了一种专门为以服装为中心的人类生成量身定制的轻量级任何服装编码器。DreamFit具有三个关键优势：轻量训练：只需8340</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493080&amp;idx=1&amp;sn=92b06cd8d24f3cf800b1f08e732210ce&amp;chksm=fd2f16bcdaf3755d40fabc6c5d209cab9cab4fdb18f307739c841c7442fda3f93477007feefc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 字节DreamFit: 多主题电商服装迁移！轻量级即插即用任意服装模特匹配]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGSxicUBwA56Pek0VwHmNacVsMhP7pROSIyva554J3rL1LBI4t5lpvM0icF2YaPAtfrN22ICPibd001Fg/300?wxtype=jpeg&amp;wxfrom=0"/><p> DreamFit:为服装增加电商模特DreamFit简介今天文章介绍一款新的虚拟试衣框架：DreamFit，这是一款结合了一种专门为以服装为中心的人类生成量身定制的轻量级任何服装编码器。DreamF</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493080&amp;idx=2&amp;sn=7f5938c50b5bd2e9ed6188f30ab9d5d7&amp;chksm=fdda9279a34aa0ab91f7aad4692b0a213d19a1ce792b02f4940613a8c0f86c5b467f2372d2e0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科&amp;腾讯&amp;清华提出全球首个多模态Mamba生成框架ACTalker，支持多信号输入，数字人嘴型同步再升级！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enM1R1hvr6fIvNPnJ8HAkjER32Qr4uJljRDnNXhyE9UPgfaB2EKia2QjfDCSEHzibXgefW4NfoP8eNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由港科大、腾讯、清华联合发布的全球首个多模态Mamba驱动框架ACTalker，它是一个端到端的视频扩散框架，支持多信号控制和单信号控制，用于生成说话头部视频可以实现单/多信号随心切换，虚拟人嘴型同步</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493080&amp;idx=3&amp;sn=309efd86db3e772e1bdb93cd12dac6f2&amp;chksm=fd2ce92a3c25c3c18f368bb2a6a798f62957bec6a63f032885dd18f03764f0382ffd5d6b9dfe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出新框架ImageRAG！RAG+AIGC提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JK3j8AP855QOPLGKEpd37E3bPLWmIOj4bSM2oUxbcSEQ3NFVFyqRhEKjhBGvFkPMAwAaMsbszianQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation论文链接：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493080&amp;idx=4&amp;sn=c316ee50398a65e166e433a7ece927d7&amp;chksm=fd3a9eb7e9cc4f6f006699bbfa82de8e721c67ea4caf3901a1cee00f4763defdd9f121e4501f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>