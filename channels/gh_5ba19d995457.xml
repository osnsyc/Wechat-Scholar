<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[手机上实时跑3D数字人？阿里开源MNN-TaoAvatar，打造本地离线智能数字人新标杆。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8O7Mx0HicAQzYnr62ZEJLwjCaTF4Xg9G65OJibjU82ibBkicGN8Zdt93yM9ibvqO1zSU5WvX0ehVP4QA/640?wxtype=jpeg&amp;wxfrom=0"/><p>TaoAvatar 是由阿里巴巴淘天 Meta 技术团队研发的 3D 真人数字人技术，这一技术能在手机或 XR 设备上实现 3D 数字人的实时渲染以及 AI 对话的强大功能，为用户带来逼真的虚拟交互体</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494074&amp;idx=1&amp;sn=95271422a4ac0638179f300d2647b01e&amp;chksm=fdb5ef90e7380d3348a1cf29a189c4388ab52586a87b704ea96971c1fa6b7cabdab23c3e9040&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494074&amp;idx=2&amp;sn=dd17d1ecf5eba14fa77c88ee8bad5b71&amp;chksm=fde17bafd60cf74c1b58238ae475153aecb124c24babc76bfbe1de86e6f282eb3a3fdcd0e864&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[东京大学 | Adobe 提出InstructMove，可通过观察视频中的动作来实现基于指令的图像编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsa4uWnhrMawFt9HHkxP0mNsA8WZRJb5wtxFQzRMjAicAjmryxF8Yliamw/300?wxtype=jpeg&amp;wxfrom=0"/><p>InstructMove是一种基于指令的图像编辑模型，使用多模态 LLM 生成的指令对视频中的帧对进行训练。该模型擅长非刚性编辑，例如调整主体姿势、表情和改变视点，同时保持内容一致性。此外，该方法通过</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494074&amp;idx=3&amp;sn=38203794495b0b81d545166888d06d84&amp;chksm=fd28a56f9498393fe3309b5397157569487156383ec8183decba71bb11027f9e4b8382ce1def&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像定制大一统？字节提出DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等任务，有效解决多泛化性冲突。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1Zrf8JKiaMovMsw9t4ZW4pibcVZlWM8AF7GsajlXAPWl5IJgnfQRpnvoA/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出了一个统一的图像定制框架DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等多项任务，不仅在广泛的图像定制场景中取得了高质量的结果，而且在适应多条件场景方面也表现出很强的灵活性。现在已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494074&amp;idx=4&amp;sn=da3f96838bedbd4c24711779e594f19e&amp;chksm=fd548f7d4c09a88ef04dde50786d4416c5e917fc8a53344489f4f0005627bd291711e14aa2f7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 10 Jul 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源 30 亿参数统一模型 Ovis-U1，多模式理解、文生图、图像编辑样样精通，多项学术基准测试领先。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuDmLq7R1rRFldNX6Em3MD3ic6VVyQ7fibbkHSDXdsLJJKPKURibic6bQdSKAoTkLHaP0dHSb0n5P6Zw/640?wxtype=jpeg&amp;wxfrom=0"/><p>Ovis-U1 建立在 Ovis 系列的基础上，是一个拥有 30 亿参数的统一模型，它在一个强大的框架内 无缝集成了多模式理解、文本到图像生成和图像编辑。亮点统一能力：单一模型擅长三大核心任务：理解复</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494061&amp;idx=1&amp;sn=6e63e5a9e52130e0d451caaf7d201703&amp;chksm=fdb9244830660ea611169875bc921b09846518ac4573ac7472ea32484db367308977311154af&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[达摩院提出ReSpace！自回归文本驱动3D室内场景合成与编辑新框架！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IUS026bgrHtl19k8iaTzNl8icef5pd4T4TvpwHoxzu1cyROia6klKjBkbZgib9aibULqBb20gpjfNRAAw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：ReSpace: Text-Driven 3D Scene Synthesis and Editing with Preference Alignment论文链接：https:</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494061&amp;idx=2&amp;sn=36d78943e4aa37d67e89084802b839f5&amp;chksm=fdb6f9d980f7a2b4459b2ffa0348e06f782ae9a3f6fed30e4a75d271ffddb6c4d58611b9cf36&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节推出统一多模态模型 BAGEL，GPT-4o 级的图像生成能力直接开源了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRre72SQ3NTx8amQXBMt77z295uWjzKl5kweQFLEMa31vXicZ35AvS4Lfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节推出的 BAGEL 是一个开源的统一多模态模型，他们直接开源了GPT-4o级别的图像生成能力。（轻松拿捏“万物皆可吉卜力”玩法~）。可以在任何地方对其进行微调、提炼和部署，它以开放的形式提供与 G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494061&amp;idx=3&amp;sn=0acc483b588836cdca3563b42db99f50&amp;chksm=fdcc48a323133b7d6d279cee7f016b11f9d36c026be8efa1ae14fe51f4f914f5bb6af9aa218c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TMM 2025 | 超越SOTA！AdaMesh用10秒视频生成个性化语音动画，表情生动性提升40%。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48sD3er0mq7FL0guJnKjkMSPVhPLjFIJ4elWF7POpyFVoOcRqfjLRoPw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在虚拟角色与数字人技术中，如何生成兼具真实感与个性化的语音驱动面部动画仍是关键挑战。现有方法往往依赖海量数据或通用模型，难以捕捉用户独特的说话风格（如微表情、头部动态）。为此，由清华大学深圳国际研究生</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494061&amp;idx=4&amp;sn=99a4f1161c03b733c1c2d4a651862c55&amp;chksm=fdfd74c9064c552a78965f19ea14baf7fe9d06e533249dac463be16b3c394330111a169734ad&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 09 Jul 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[高质量开源二次元风格图像生成模型Neta Lumina，从Furry到国风，全方位赋能动漫创作新体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnnuuc8trMqQZdXicVSnCicAT0JorhOHp7RZ0picPcQW6vmQULK0icb6qeo3A/640?wxtype=jpeg&amp;wxfrom=0"/><p>Neta Lumina是由 Neta.art 实验室开发的高质量动漫风格图像生成模型。基于上海人工智能实验室 Alpha-VLLM 团队发布的 开源Lumina-Image-2.0，利用大量高质量动漫</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494060&amp;idx=1&amp;sn=a20eebec1beb20ed911d356094ecb7a2&amp;chksm=fdde39531d16ffa08c3cd377398230d383667a06fdb8e0a459a44e0032ce817e5b6b0bd008fe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OmniAvatar：让静态照片“活”过来，音频驱动全身动态视频生成新纪元！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHjoNmnhIZ1WlEINYQPhBVwHtIicGD7DRHo7WEJn1mYDaiaRkEf8ES1uzXk9uBREDlwHfWKdLcqs2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>OmniAvatar：“全能”的数字人视频生成。OmniAvatar 是一个基于LoRA的高效的音频驱动全身人像视频生成系统，支持从音频 + 单张图像 + 提示语生成自然、表达丰富的视频，仅需一条音频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494060&amp;idx=2&amp;sn=aeb5da8b53d66ac305bfc902eaafa605&amp;chksm=fd719e47eb741df63ed88601e8d70ffececaa704bbb794ce2797fc95f4e20c72891c6c1a0fb3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494060&amp;idx=3&amp;sn=c0d6d8df9cdd570fabd8b3a50b45ebec&amp;chksm=fdb45ed38b6035a6f69ebd8e54ea86d965c59e78e40e525e58c664a1bc9a958f213fac466355&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DreamActor-H1，让产品与模特“一键生成”高保真交互视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48RPbNymvllhYib3H7VZyk223eWwAma3ovH2vTKZCY7Hg7zPurzD9kpqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DreamActor-H1 是一个基于扩散变换器 (DiT) 的创新框架，能够根据配对的人与产品图像生成高质量的人与产品演示视频。DreamActor-H1 基于大规模混合数据集进行训练，并结合多类别</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494060&amp;idx=4&amp;sn=d54c16d65743a821708f577633e48ffc&amp;chksm=fd889d72b8c82aed489631733801718df7075762d62a1393cbde5a5bf0ade9a21ba6cd2da13b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[重磅！黑森林实验室开放 FLUX.1 Kontext [dev]权重，120 亿参数黑科技，重塑图像编辑格局！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnn2bgzfAyBa1WiaESib9rM1Nz4l8rxIE1JdrFUviauFI2D6iaYeqtn00kOdA/640?wxtype=jpeg&amp;wxfrom=0"/><p>迄今为止，所有功能强大的生成式图像编辑模型都只能作为专有工具使用。如今，黑森林实验室发布了 FLUX.1 Kontext [dev]，这是FLUX.1 Kontext [pro]的开发者版本，它在一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494059&amp;idx=1&amp;sn=fc21ac36afe7b0218348f3015e41e238&amp;chksm=fdc36173e8147a5a9a5e64906f8abfe7d24a04324397e01c13a0b8e48ac02b6c7c3e5dce989b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI界的"六边形战士"！港科大×字节提出ComfyMind：生成/编辑/推理三连冠，开源领域再掀狂潮]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elI7B3IZQkA99hvyeKlzPzyeqYm9eaK3j5oUNFlRDs6yaz4YvOHWYMnpeWHk5ic5s7zDkXrP7RYtBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、字节跳动提出的一款基于 ComfyUI 平台构建的协作式 AI 系统ComfyMind，旨在实现稳健且可扩展的通用生成功能。在 ComfyBench、GenEval 和 Reason-</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494059&amp;idx=2&amp;sn=8d9f8a6f9061de481329f1e0d96d617f&amp;chksm=fd17c05448ec1253f445f517389231c19c486253683c8744c28853ec65b65d5bd2680b4efcc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工力作Sparc3D：开启三维重建可微分优化与高效生成新纪元。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enhd8Da8niase1WltgKePj289UYQ2FkGK7uxrgpyoOIA6cIHk7jU4q6hvNUWTsCz3qI24ic8ibqQ8GjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>由南洋理工大学推出 Sparc3D 是一个统一的框架，它将稀疏可变形行进立方体表示Sparcubes与新型编码器Sparconv-VAE相结合。Sparcubes 通过将有符号距离和变形场散射到稀疏立</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494059&amp;idx=3&amp;sn=8c6a99ce9411602bf664cb73a62c0ec0&amp;chksm=fd20362e1ed8d53767b53e3882be7f8ce1c3e07e470c4a57fdc50f2a30e277f64f16e8c247e5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OmniConsistency: 一种基于扩散模型的风格一致性插件，用于高质量图像风格化。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic6Yl0kTibHR6qeAggicnWLicFJTdTmKJibxibXDMjL83Ixvlciaqcwyoro532IvxIK9M3hB7eZ096Yw6jVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>OmniConsistency 提出一种基于扩散模型的风格一致性插件，通过两阶段训练策略和滚动LoRA 银行机制，实现了在多种风格下的风格一致性和内容保真度，性能接近商业级模型 GPT-4o。在图像风</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494059&amp;idx=4&amp;sn=fc6159a5f08a18af583e896a2cf38ef2&amp;chksm=fd4e96f03c4ec6d6591ea8c971fde95953d56bda3cc451c6f6b100781d47d21430cc98acb9fc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[清华大学&amp;IDEA推出GUAVA：单幅图像生成实时可动画3D上半身，渲染速度突破0.1秒，表情与动作实时同步。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48yKhiadt9NN3KPxkMsuNZZxMYJMZSYDV5RsGLlXBfUxecaFP3xYF5UHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>由清华大学深圳国际研究生院、国际数字经济学院（IDEA）联合提出的 一个用于快速可动画的上半身 3D 高斯形象重建框架GUAVA，对于每张图像，GUAVA 可以在亚秒级时间内通过前馈推理重建 3D 上</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494058&amp;idx=1&amp;sn=0a6f42b794c38bb573c59adfe8cd2ae9&amp;chksm=fd124426eb50aca6d46b2fc5ce2eac358a446692a1a4cb644e9e7529bcceedd67924708a19f6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICIR2025 | CubeDiff：无需考虑失真，重新利用基于扩散的图像模型来生成360°全景图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6qavvqaKicyhfbe1wrRfKuEmZbfJ8LvrOgQJMgZYG5CztqNUPPASQbtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给大家介绍过许多关于3D生成的文章，感兴趣的同学可以点击公众号菜单栏查看3D生成专栏，创作不易，欢迎大家点点赞和在看~CubeDiff是一种使用基于扩散的图像模型生成 360° 全景</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494058&amp;idx=2&amp;sn=c93a9d4ab69d09a23e7384d37105f8a9&amp;chksm=fdbff2ea7f542dd2e1f8c5738a2ff62344f9cf6d648c4c03e29c466520c3888ceb0cba733b10&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D 生成新 SOTA！SECERN AI 提出 方法 SVAD，单张图像合成超逼真3D Avatar！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJczQ6xAAgVU8NYrMphwhLiaiajhcsCMja0TDYcr6RulFp9C6Yt1mtcbiamA/300?wxtype=jpeg&amp;wxfrom=0"/><p>SECERN AI提出的3D生成方法SVAD通过视频扩散生成合成训练数据，利用身份保留和图像恢复模块对其进行增强，并利用这些经过优化的数据来训练3DGS虚拟形象。SVAD在新的姿态和视角下保持身份一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494058&amp;idx=3&amp;sn=2562b52332304d65038e31251952fbb4&amp;chksm=fd2d3fa43371e2a3374595cc0325976e353f38dcdb581953cb534868eebbca7f3dae4816a101&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多领域SOTA诞生！Vid2World：打通视频扩散到世界模型的“任督二脉”｜清华、重大]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaeFVcHGjGc24PwYRxSa3SRzxraaxquD1Y4eiapCrHo7GN2pjc3L4XfolskYUicsqxRONc0Q9o3iaR8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文链接：https://arxiv.org/pdf/2505.14357 项目链接：https://knightnemo.github.io/vid2world/ 生成效果速览亮点直击首个系统性探索</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494058&amp;idx=4&amp;sn=b2abc84cbc6080c2bc07b54c10edd3b8&amp;chksm=fdfc65e9780900b97eeaf1eed8bd085da6eb997732c926db0b89d1ca9836d8ebb8b225257c06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态图像生成新宠 Janus-4o？ShareGPT-4o-Image 打造数据集新标杆，将图像生成与 GPT-4o 对齐。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuDmLq7R1rRFldNX6Em3MD70vY7fwf61HKoCJgXp8J9PtlYAbkvyRcqskzia0Ubz28BAkMOjkHS3w/640?wxtype=jpeg&amp;wxfrom=0"/><p>ShareGPT-4o-Image 是一个大规模、高质量的图像生成数据集，其中所有图像均由 GPT-4o 的图像生成功能生成。该数据集旨在将开放式多模态模型与 GPT-4o 在视觉内容创作方面的优势相</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494021&amp;idx=1&amp;sn=5fd1fe324eda2fe504110c9a3f6d9ef4&amp;chksm=fd4e97e7d22d1d01a086db85cb5ae3525fea8293523cf959b286ad100ba5221c49870bb5049f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节、港理工提出超强统一视觉生成模型 Many-for-Many，支持10+任务，8B参数“逆袭”商业视频生成引擎。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXr1okRdYbDMkiaMBJd2BP7Rly0sBNFZKib2sPFdbSs7MvfFpF6hn5uyKnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节、港理工提出超强统一视觉模型 Many-for-Many，如何凭它让 8B 模型“逆袭”商业引擎？字节跳动与香港理工大学提出统一框架 Many-for-Many，它借助众多视觉生成和操作任务的训练</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494021&amp;idx=2&amp;sn=7210e41ce700c1e1b20db9b0b42bd12b&amp;chksm=fd6851ad4579aaa3a8d7c9067859bc2d486b1921539a9e39948242b0311dc7467f5ea1c8ee4e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[集成 R1 后的 GroundingDINO 究竟强在哪？一文带你看清 DINO-R1 的性能变革]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ3cCzjflZrObrcGTNoJJwzrOXe4jyYx9eDs8QIOJ4W5grQyGf2tTwtS8ooDFDop2w2gcbw8UuNhCw/300?wxtype=jpeg&amp;wxfrom=0"/><p> 导读在开始今天的分享之前，我们不妨先思考一个问题：为什么大语言模型，如 GPT 系列、DeepSeek 等，在数学推理、代码生成等任务中能够展现出强大的泛化能力和对人类意图的良好对齐？除了依赖海量高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494021&amp;idx=3&amp;sn=d84421a27f13e41d22b529de5ec09a82&amp;chksm=fd4b6e2c19f64a1d14a6d23410cecb13ece5ddcf45fde5c16eb23d893cd403551716555f93a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 | 解锁虚拟试衣新姿势！智象未来提出SPM-Diff，大幅提升真实性、可控性，让衣服“贴身”又自然！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrh9ic75wTHs9dqezVrp8tteQeOdKicBiciaVprFFxw2NDD0xvwlGbvdtfzxm3Z3f8AmbzvLDk7lMYeg/300?wxtype=jpeg&amp;wxfrom=0"/><p>网购衣服总担心“买家秀”和“卖家秀”天差地别？虚拟试衣不自然、细节难还原的问题一直困扰着消费者。智象未来团队提出SPM-Diff算法，成功攻克虚拟试衣两大难题，论文《Incorporating vis</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494021&amp;idx=4&amp;sn=5434bd393c199b75f811d3585e0d1caf&amp;chksm=fd569f4b686bf769e1507fe0f59890f5c1d8bdb5317e804741c980ca5d10e0c4f7254af5f0a8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从文本到3D动画：AnimaX 前馈 3D 动画框架，解锁任意骨骼动画无限可能。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPbvzXyQzXhAWo1QdPyhvibR2nOgLfk3jfXRCH64V0YMReDLI4nZbR5kKceDeR0YnSEialEZiahJyQQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>AnimaX 是一个前馈 3D 动画框架，它将视频扩散模型的运动先验与基于骨骼的动画的可控结构连接起来。传统的运动合成方法要么局限于固定的骨骼拓扑结构，要么需要在高维变形空间中进行昂贵的优化。相比之下</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493998&amp;idx=1&amp;sn=f19ff6bcd77a2bca4c99181ac7c4b3a0&amp;chksm=fdfb18b45bb8cd9b39a6f24dc1d44996569d640ee1c5d39d502476016ae7c2880f4270f8ba28&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[BLIP3-o：融合自回归与扩散模型的统一多模态架构，开创CLIP特征驱动的图像理解与生成新范式!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek5oLyjfCjICEWyMhWNvFXDN37WVtXa4JeBibibTSdNGmBP0wSFhuUAJkiaz9qNwiccNW4SuNJ7FvduuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>BLIP3-o 是一个统一的多模态模型，它将自回归模型的推理和指令遵循优势与扩散模型的生成能力相结合。与之前扩散 VAE 特征或原始像素的研究不同，BLIP3-o 扩散了语义丰富的CLIP 图像特征，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493998&amp;idx=2&amp;sn=81a73478e596f3370618d8cc0ab8bae1&amp;chksm=fdebc27e7fa0b7ce3000088f794e21d901d158b9ce4741ffb90e9e968f3905c7a4f1a4e7894c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Hallo4：让AI肖像“活”起来！新型扩散框架实现高保真音频驱动动画生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq56s1kIaYWsxKESfb9riaHUQVlW3JfPib9AP6mL8Hk0Ec5R0f43HYJ8aw/300?wxtype=jpeg&amp;wxfrom=0"/><p>复旦联合百度发布扩散框架Hallo4，实现了准确的唇音同步、自然的面部表情，并能够稳健地处理各种角色身份和环境场景中快速的语音节奏和突然的上身运动。相关链接论文：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493998&amp;idx=3&amp;sn=dc3d781c7cf0f889a0b6cd0fbf4a4a54&amp;chksm=fd6140987112ba35f2c6669f35f18469a2a62f0b408ba0a49d72e276ba001d295a690b0fb933&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>