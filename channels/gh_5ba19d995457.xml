<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[CVPR2025 | 图像生成加速新突破！南开大学提出Loopfree，1步编码+4步解码，重塑图像生成速度与质量。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibWvnfl5ezdTp2XA9hLiadicTgKTsPJdJ0Nwj7SmRVCWh0AKGke0VtfXQIEC1J9YlyOvDSiaticOjguw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在图像生成领域，文本到图像（T2I）扩散模型近年来取得了显著进展，但推理速度与图像质量之间的权衡始终是制约其广泛应用的一大难题。南开大学等在CVPR2025上发表了《Loopfree: 时间无关的统一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494233&amp;idx=1&amp;sn=a6bf23792f504600c2769a8739f886c4&amp;chksm=fda1d9b0f1f3cbdde94fd8322537ef191ea7293d7fccb8c92f06560e21d0b3982d101d69d095&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494233&amp;idx=2&amp;sn=110208784ecb00375803f6f89f900a04&amp;chksm=fd33e67efc6a25cf56bd577096dbb1b364f371f7561fec32d811329d2e8d252ab001aca5bb5e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从文本到3D的“零训练”革命！英伟达&amp;康奈尔大学提出 ArtiScene：通过2D中介实现高保真3D场景合成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48HPJzGndEliaF6RR9oS2mcY6tk1tO13iaxO3UHzBrtzwlN2jFlpv4651g/300?wxtype=jpeg&amp;wxfrom=0"/><p>由英伟达和康奈尔大学提出的 ArtiScene 是一种无需训练、语言驱动的 3D 场景生成流程，它可以根据文本提示，设计出丰富多样、美观且易于编辑的场景，涵盖各种类别和风格。下图中展示了四种结果，并附</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494233&amp;idx=3&amp;sn=18ee43b1ea84497d0abb49d1d00ffebb&amp;chksm=fd954c15347c4dbf8c253de7e064bc558fbac050060142d9f77b17f533df56f68f404377e7df&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[碾压开源与商业模型！腾讯开源一致性视频生成框架HunyuanCustom：可同时实现音频同步与视频编辑！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrh9ic75wTHs9dqezVrp8ttuUVmic8QW7affiaZjHpsxtibwNLZzmTDHNHfticnBcXHEWnBic45icRHnibicQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯提出了一个多模态定制视频生成框架HunyuanCustom，该框架强调主题一致性，同时支持图像、音频、视频和文本条件。基于HunyuanVideo，该模型首先通过引入基于LLaVA的文本图像融合</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494233&amp;idx=4&amp;sn=58e033ee81cc1426fe3fe06738f8ef40&amp;chksm=fd3ba2e905594ab15b73bf279989575a953da8a2e08271c7c3444b3a7205b9b58136f9445afc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[数字人新突破！FantasyPortrait：高德阿里北邮携手，开启肖像动画“幻境”之旅！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em0AmDO6mb5DLoAgCkVm29EcIEITkjGUbAiczNzPZIsINt6VeribQHhib2bppp56iayPt5g3HIad5VbUQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>由高德、阿里、北邮联合提出的FantasyPortrait，提供一张肖像图像和一段参考动态视频，在交叉重演过程中生成逼真的动画肖像。无论单人还是多人，它都能实现高保真的面部动态和自然的头部动作。uns</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494222&amp;idx=1&amp;sn=904751cfd592fadccc037e19273db616&amp;chksm=fd84a750404b7dbc3d5210257a9ea4a0212063429e1d05131c559a84c8437bf574be7c63c6c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 21 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[美团LLIA登场，让照片“开口说话”不卡顿：低延迟、高帧率，音频驱动肖像视频进入实时交互时代！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48pVRHuhqxC0rZetfMaQO9vH1icmibhHy1HIl7coV7ubJl4gO4TZRJKv4w/300?wxtype=jpeg&amp;wxfrom=0"/><p>美团提出了一种基于扩散模型的音频驱动人像视频生成框架LLIA。该方法实现了低延迟、流畅且真实的双向通信。在NVIDIA RTX 4090D显卡上，该模型在384×384分辨率下最高帧率可达78 FPS</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494222&amp;idx=2&amp;sn=cdc624f0856408d57ded40e2ed138c32&amp;chksm=fd95350b8f98fc6228bca765d5a7ace30abd87797ad445a05234438b63e493a3eaae13dede2d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 21 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源FluxText：轻松应对多语言多场景文本编辑挑战, 海报|广告|游戏|文案编辑轻松搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8r1mbBOtrNsSTkhqjMvnHA3l9PourHLbs4icMEsVsuPWfFWhxiaESVMM2sxiac1nib3sib54N9KicTMtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过许多关于文字编辑和生成的方法，感兴趣的小伙伴可以点击下面链接阅读！字体控狂喜！Liblib AI 黑科技 RepText：无需理解文字，AI就能 1:1 复刻多国语言视觉</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494222&amp;idx=3&amp;sn=0d10391e6defb53fbfc547f601de6d1e&amp;chksm=fd877b2c5c4752e5248ce77dd7ca549c7b7feeb821642035bc7d16f02bd1c386163297aa224c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 21 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[200M参数吊打商业巨头！浙大-哈佛开源ICEdit，用1%资源实现图像编辑自由！一句指令生成海报级修图方案。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekBUypVTojw9NicChAveibQcTLDAqzMNvNlVcY8Qyp0Uw8xV4We94zZVeNGOiaduoVu37rdJoZlxoibZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学联合哈佛大学提出一种高效的基于指令的图像编辑框架ICEdit，与以往的方法相比，ICEdit仅需1%的可训练参数（200M）和0.1% 的训练数据（50k），就展现出强大的泛化能力，能够处理各</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494222&amp;idx=4&amp;sn=e4cbcdb102fa7be477357cc758bcd231&amp;chksm=fd2b2555e57a3f02298aa07bca96a235a2d2b5a81ae8b9e3578b68222d7fe72156fedceeebdf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 21 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[让静态照片“活”过来！OmniAvatar：LoRA 赋能，解锁音频驱动全身人像视频生成新密码。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHjoNmnhIZ1WlEINYQPhBVwHtIicGD7DRHo7WEJn1mYDaiaRkEf8ES1uzXk9uBREDlwHfWKdLcqs2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>OmniAvatar：“全能”的数字人视频生成。OmniAvatar 是一个基于LoRA的高效的音频驱动全身人像视频生成系统，支持从音频 + 单张图像 + 提示语生成自然、表达丰富的视频，仅需一条音频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494186&amp;idx=1&amp;sn=0d7d10fc2a1e18ca1fe882705684930d&amp;chksm=fde724b63482dc0fe4d936b20ffc41ed53261d8e8f37d2b7454180dc0ed9df7dbb1914d0ec01&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 20 Jul 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文搞懂大模型时代的Agent：方法论、应用与挑战]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic5px0fSndBD2GIVIzRDOXKqBib4cgWWxqiceO15Zp3U2X3KkEx0iaZKvQMuTmjTliagvqkof4ibrME5SSQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>“写在前面【从零走向AGI】旨在深入了解通用人工智能（AGI）的发展路径，从最基础的概念起，逐步构建完整的知识体系。项目地址：https://github.com/AI-mzq/From-Zero-t</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494186&amp;idx=2&amp;sn=362b98ad57267d32169520a377b98f05&amp;chksm=fd414362c66861b7a7d09a9b51f3b940e0de793d1294fe2d728cf03869f6e12b34928d976bed&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 20 Jul 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Tora2震撼发布！阿里巴巴首创视频多角色「外观+运动」同步定制，告别视频角色错位！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojC01mC63A6Ct1xfHLt8tlNgDeAiauMvOdnh0sPX1YebicwQ3j1aGaeib56Sjst9hO8c37azBjrtMKBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>亮点直击Tora2，首个支持多实体定制化的视频扩散Transformer框架。如图1所示，Tora2 支持外观和运动轨迹的双重控制。引入了一种解耦的个性化提取器（Decoupled Personali</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494186&amp;idx=3&amp;sn=09be64fea36efc9997fa9262e7744a13&amp;chksm=fd1f3d05b093c0ee9795012d314d34ae6af79843f26f848c9e17e4cc20e16a273a676b617616&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 20 Jul 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[用ComfyUI复原老照片，像素级重生太惊艳了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE62umia43diaibQHp3ufyS7wiaxIEibtXWGdYtMcl71rnkX5MWXjibQMdn9RUbu6m0NMMfLoryHo7Tqzluw/300?wxtype=jpeg&amp;wxfrom=0"/><p>过去的一张张老照片，承载着无数回忆，也记录着一个时代的光影。但随着时间的流逝，那些泛黄、破损、模糊的老照片正一点点被遗忘。幸运的是，AI图像处理的浪潮正悄然改变这一切。而在这股浪潮中，一个名字正在悄然</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494186&amp;idx=4&amp;sn=4bde151136f623d010c7b412f80c2074&amp;chksm=fd089ca651bb54ac76be20ebc4b7dd573f4a2d01dda60eda4f94e63220aec8a98ca01c7fb778&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 20 Jul 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[人机交互动画制作新突破！文本驱动扩散框架HOIDiNi：一句话驱动虚拟人高精度操作物体。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKibiah2ldIaVhKqwicV967dT1sIM1Fp2cOZVSwYwa6MN7rFE0yC7GRXAazMHfQ7D56MYzIJaS7HqJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在人机交互、动画制作等领域，如何生成逼真且符合严格约束的人体 - 物体交互（HOI）一直是科研人员努力攻克的难题。今天给大家分享一个文本驱动扩散框架——HOIDiNi，它不仅满足 HOI 的严格约束，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494184&amp;idx=1&amp;sn=e56ebc05c812853d918c61980edd5b6d&amp;chksm=fd743772efcdf7809f5308858d0419a91abed715a1f9bf1295d98b1381c2cbc332a41e9e48a8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 19 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[中科院提出图像定制方法MCA-Ctrl，无需调优的即可使用文本和复杂的视觉条件实现高质量的图像定制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1KFwReqeCxk2s3eVTGWZJ0ibicT6EGpGzrsJ4W6jtTm4fLh17icB9CJNyg/300?wxtype=jpeg&amp;wxfrom=0"/><p>中国科学院计算技术研究所研究团队提出了多方协作注意力控制方法( MCA - Ctrl )，这是一种无需调优的方法，能够使用文本和复杂的视觉条件实现高质量的图像定制。MCA-Ctrl 可用于文本驱动的主</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494184&amp;idx=2&amp;sn=ef454362b62ef73bd1fedd431456c3a4&amp;chksm=fd4ea415cba8098f581a5a35813b32afef6a24ab428edf91232dc03b24b24dee9b1d47095748&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 19 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[200M参数吊打商业巨头！浙大-哈佛开源ICEdit，用1%资源实现图像编辑自由！一句指令生成海报级修图方案。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekBUypVTojw9NicChAveibQcTLDAqzMNvNlVcY8Qyp0Uw8xV4We94zZVeNGOiaduoVu37rdJoZlxoibZg/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学联合哈佛大学提出一种高效的基于指令的图像编辑框架ICEdit，与以往的方法相比，ICEdit仅需1%的可训练参数（200M）和0.1% 的训练数据（50k），就展现出强大的泛化能力，能够处理各</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494184&amp;idx=3&amp;sn=a1d21f3d1831bacaff99250cecc9324d&amp;chksm=fddc0da1a9a9606592dd0555c618e6c35b68b286c1f54a4ca6127d2989b9fda2bd9a42793765&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 19 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出 DreamActor-H1，让产品与模特“一键生成”高保真交互视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48RPbNymvllhYib3H7VZyk223eWwAma3ovH2vTKZCY7Hg7zPurzD9kpqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DreamActor-H1 是一个基于扩散变换器 (DiT) 的创新框架，能够根据配对的人与产品图像生成高质量的人与产品演示视频。DreamActor-H1 基于大规模混合数据集进行训练，并结合多类别</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494184&amp;idx=4&amp;sn=bc7834ff61e4d94e8d0b051c070ecaf4&amp;chksm=fd02b3b195ea602d0055dfb50bc7bf122606c0439775a83a8d6708007a29ca2e8553c9da99db&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 19 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 帮你搭 AI 工作流！阿里提出 ComfyUI-Copilot 让 ComfyUI 效率飙升 300%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek72NCt8icz7EEKQMvXAicxhxH3v67yopUGDlmqjARrLtQK7owmVAumTib6aBQakJ64J0PicbcC1PgA0w/640?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyUI-Copilot 是阿里巴巴开发的智能助手插件，专为优化 ComfyUI 工作流设计。通过自然语言交互简化和增强 AI 算法的调试和部署过程。无论是生成文本、图像还是音频，ComfyUI</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494183&amp;idx=1&amp;sn=92e8b202a2e0d31399b3ba8999cde3e9&amp;chksm=fd4a53486d9e71b35cfe97d3763160cec8d612be8a13ab2dcd749a52df94dbfd88defcfc9dfd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 18 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[清华大学&amp;IDEA推出GUAVA：单幅图像生成实时可动画3D上半身，渲染速度突破0.1秒，表情与动作实时同步。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48yKhiadt9NN3KPxkMsuNZZxMYJMZSYDV5RsGLlXBfUxecaFP3xYF5UHA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由清华大学深圳国际研究生院、国际数字经济学院（IDEA）联合提出的 一个用于快速可动画的上半身 3D 高斯形象重建框架GUAVA，对于每张图像，GUAVA 可以在亚秒级时间内通过前馈推理重建 3D 上</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494183&amp;idx=2&amp;sn=8766fbf81172b0c0a8737d5289a4b944&amp;chksm=fd3903c161670cc2e54da23711fc52a25f019cc3679f2d8d4f2ce91d623d5b809cf43a338333&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 18 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态任务大一统！蚂蚁推出Ming-Omni：图像、文本、语音三模态无缝融合，一网打尽复杂任务！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48J6PaQ6vvBzg7xSUic6gUlNictqMXib837dJ3ia9U0lib3hc3BMuQHGGd8fA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Ming-lite-omni 是 Ming-omni 的轻量版本，源自 Ling-lite，具有28亿激活参数。Ming-lite-omni 是一个统一的多模态模型，能够处理图像、文本、音频和视频，并</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494183&amp;idx=3&amp;sn=1ce302b608f3b04c98ebbaa1b2d275d2&amp;chksm=fd04da7a83c21084b1c3ce5a6c7bc704b6b62bb96d42c5a8ec9c229ea6530c6123b5cdf5bca2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 18 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源语音黑科技！SenseVoice：50+语言识别、听懂你的情绪，速度超Whisper 15倍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIoYgiabFF6GEeGdauiaiaTxCoCBH01vZHfNlwJYrs133ibV4nls7DmjxUv6LlXeqVgrBZwcgJnicZlFQSA/300?wxtype=jpeg&amp;wxfrom=0"/><p>------语音识别的新高度，情感与事件尽在掌握在人工智能飞速发展的今天，语音识别技术已成为人机交互的核心入口。阿里巴巴通义实验室开源的语音理解模型——SenseVoice，将语音识别技术推向了全新的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494183&amp;idx=4&amp;sn=5870999031721514bf48a663f7e75bc9&amp;chksm=fd4483b07e6acd7306fc761ec2c3b9ac72307f4bc75473a51143060efaf2be7d9bca037aca16&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 18 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出海报生成框架DreamPoster，一张图+一句话即可生成精美海报，功能即将上线APP，点击文章超前试用体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eld6nEW0EO7hEwtazL961ZYRicxA7OBszH1iblTicbrTqicgcbwg1Ty1D8CrPVm2ialAicd0afIuAOfHf2A/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给打击介绍过许多关于海报生成的方法，感兴趣的小伙伴可以点击下面链接阅读，撰写整理不易，欢迎大家多点赞收藏！阿里开源文本编辑框架FluxText：轻松应对多语言多场景文本编辑挑战, 海</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494157&amp;idx=1&amp;sn=5ac466e02c157f4844e4c37643bead30&amp;chksm=fd59d7ca0f7d43726af0bf363a10792a04faa8582c4eea11b864d64a543222fbed9950ddeb2b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[月之暗面开源万亿参数“王炸”Kimi K2，混合专家语言模型新标杆。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emxKcHGB2hPnXXJ9OhBE8NC0lvS4qIR2kiatic5rrGuNL3Q5vNbr7AD4Z2uOC24Hh6BqHptyIPTzqlg/300?wxtype=jpeg&amp;wxfrom=0"/><p>7月11号，月之暗面推出了 Kimi K2，这是一款先进的混合专家 (MoE) 语言模型，拥有 320 亿个激活参数和 1 万亿个总参数。Kimi K2 采用 Muon 优化器进行训练，在前沿知识、推</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494157&amp;idx=2&amp;sn=57d0474398365bebe5be44ded9daee2c&amp;chksm=fd2b9ead8808879ae81955a6e1f5bb4d50f7dd9c871f50f521a3f346803d410d372bf484f873&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源文本编辑框架FluxText：轻松应对多语言多场景文本编辑挑战, 海报|广告|游戏|文案编辑轻松搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8r1mbBOtrNsSTkhqjMvnHA3l9PourHLbs4icMEsVsuPWfFWhxiaESVMM2sxiac1nib3sib54N9KicTMtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过许多关于文字编辑和生成的方法，感兴趣的小伙伴可以点击下面链接阅读！字体控狂喜！Liblib AI 黑科技 RepText：无需理解文字，AI就能 1:1 复刻多国语言视觉</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494157&amp;idx=3&amp;sn=2f0d05553a79cb08933f986c770c15a0&amp;chksm=fd7ac834edb81edf4e4a758e03aba9ac69127e3caf9004cb021258e08e41d3ec02a88b12c060&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一句话开启高效图像编辑新时代！TeleAI SmartFreeEdit，打造图像编辑新方案，解决推理指令与分割难题。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKibiah2ldIaVhKqwicV967dTrx4b0lHrzlxzbCo5bstbMH7ERVSrgFAwvtWptIDnolIg4HTBCicomtw/300?wxtype=jpeg&amp;wxfrom=0"/><p>TeleAI 推出了一个图像理解编辑修复模型 SmartFreeEdit，用来解决图像编辑中推理指令和分割的挑战，从而提升 AI 编辑的实用性。该方法可以有效地处理一些语义编辑操作，包括添加、移除、更</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494157&amp;idx=4&amp;sn=15434feccc369152b9ba12d07c7ce270&amp;chksm=fd035262938fa2832524afdfcd473078878294e63422cf04f84a43f5c9a4a1a9ad8c45d30a5d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像着色还能这样玩？上交联合哔哩哔哩提出图像着色框架MT-Color，实现AI着色实例级精准控制！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8r1mbBOtrNsSTkhqjMvnHWjLkcJFGlibz11aFcugwvSrOib6WzsoF2XXkqKoz5uzEoF0aMS4I6Kfw/640?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍过图像上色方法，感兴趣的小伙伴可以点击下面链接阅读～阿里达摩院提出开源AI图片上色模型DDColor:可以为黑白照片、人物、动漫风景等一键上色!超越阿里DDColor! 复旦</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494146&amp;idx=1&amp;sn=0c485898f691f1956cf5b0f33d0c083f&amp;chksm=fd977912cff868e5f7f8b83e1adb90c1c99f815d9fdbe0b6e1e78c542e38d94a4bb4b954236d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里达摩院提出开源AI图片上色模型DDColor:可以为黑白照片、人物、动漫风景等一键上色!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emSxAhfwGrF5xDyQho3K1KHs5BPR4ic9nBrD4MlgCC5ibUfic09OiajZVFthOcVSdugCDCmu33gKAffhA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DDColor 可以为历史黑白老照片提供生动自然的着色。它甚至可以对动漫游戏中的风景进行着色/重新着色，将您的动画风景转变为逼真的现实生活风格！相关链接项目：github.com/piddnad/DD</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494146&amp;idx=2&amp;sn=ad90c1e88289266b8d218a8d0e7ef275&amp;chksm=fd6137544915e31ad537f408838a8bede7b016dc65c8c5ed103e4064c45b06b0baee612a1e78&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超越阿里DDColor! 复旦提出MultiColor，一键将黑白图还原上色，效果逼真！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkkuWrNlw62n8iayUtU0k8ysnLxORVO7LzAmV1lNsDfmFXPkA5uOJ40XnPiclcq5NNo1jUIFoJLDpQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍过阿里提出的图像上色方法DDColor，感兴趣的小伙伴可以点击下面链接阅读～阿里达摩院提出开源AI图片上色模型DDColor:可以为黑白照片、人物、动漫风景等一键上色!最近，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494146&amp;idx=3&amp;sn=687675ea3abc43481351314e57f0de9e&amp;chksm=fd085aa0ba84e708b64f73a6da79fd1a3da6c408652c6718e2a7ecde15b203a2d0c0859945a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Jul 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>