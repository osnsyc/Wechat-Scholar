<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[CineMaster: 用于电影文本到视频生成的 3D 感知且可控的框架。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMLBRnvtbr9hh7W1ccXtbHEFc26iarR5N2r9CO0FlrI8VbA3yicts8jmfYqQu9BHcgSCETWsJ0PawQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>CineMaster是一种 3D 感知且可控的文本到视频生成方法允许用户在 3D 空间中联合操纵物体和相机，以创作高质量的电影视频。相关链接主页：cinemaster-dev.github.io论文介</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490520&amp;idx=1&amp;sn=b217a6ebc742080bf81796c7b1d162f3&amp;chksm=fd91b7e8d4d682b2260cb1e4b5840f5c283885f577ac646ff12dc8073a9b37d7e095ed7e33f2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 16:14:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态图像生成模型Qwen2vl-Flux，利用Qwen2VL视觉语言能力增强FLUX，可集成ControlNet]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYHx9RLCm1u1zJr61WGBPZZicviaGPyXN8y5ZTaZE9jpPcdNSX1nmUlib5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2vl-Flux 是一种先进的多模态图像生成模型，它利用 Qwen2VL 的视觉语言理解能力增强了 FLUX。该模型擅长根据文本提示和视觉参考生成高质量图像，提供卓越的多模态理解和控制。让 F</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490520&amp;idx=2&amp;sn=6bf63f8435ec46ef939e7efe6be4eab5&amp;chksm=fdf7179b55ec937165122670235b77f765b563fca797aebb071e5e5da28a1b6f5cc8c1430ecd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 16:14:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北航 | 第一个多功能即插即用适配器MV-Adapter：轻松实现多视图一致图像生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfSL2lH1ru1uCJuUuA21YKHU5ia5SLlWu0BztQtHU3YSeZIYv3K9nGSHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>北航提出了第一个多功能的即插即用适配器MV-Adapter。可以在不改变原有网络结构或特征空间的情况下增强T2I模型及其衍生模型。MV-Adapter 在 SDXL 上实现了高达768分辨率的多视图图</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490520&amp;idx=3&amp;sn=f9665d89e6f81c9dde852d80d8f13cb4&amp;chksm=fd6fe66eaec98737528c0dabbb57943ea004b1a494a053c058eed9885c6c4c74553d59150972&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 16:14:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大 | 腾讯 | 华为提出视频生成框架VideoMaker，可由参考图实现Zero-shot定制化视频生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekaVfDRjALdOCj5889F1MpALuqg2wbFklkt9TIVHLSyQfTQ65do3Pe4Szhc0sWs0dMVTLfiavGbvRQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙大联合腾讯和华为提出了一种新的定制化视频生成框架——VideoMaker，利用VDM的内在能力，实现高质量的zero-shot定制化视频生成。该方法通过直接输入参考图像到VDM中，利用其固有的特征提</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490520&amp;idx=4&amp;sn=199e3c48ba0303fb009601951f9095dc&amp;chksm=fd6b19616f89fcb8f99d323d5487af5c993ef74ef8dc5ab141118c2e84983ac3c4aff5ca958f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 16:14:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大提出视频生成方法VidSketch：可从手绘草图和简单的文本描述生成高质量视频动画。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMLBRnvtbr9hh7W1ccXtbHgw4aIUWZuDmaia40dSE9oXFEapMjdUy4355HjGBNbH33XBwB6vDxFhg/640?wxtype=jpeg&amp;wxfrom=0"/><p>浙大提出的VidSketch是第一个能够仅通过任意数量的手绘草图和简单的文本提示来生成高质量视频动画的应用程序。该方法训练是在单个 RTX4090 GPU 上进行的，针对每个动作类别使用一个小型、高质</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490519&amp;idx=1&amp;sn=79506d6c5873f4175f9df966ed1a80b0&amp;chksm=fda06817e332ac2250802f0818d3a4e66a6ff27eb46e41c260e83e1d4701d4c19184c7021053&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出新框架ImageRAG！RAG+AIGC提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JK3j8AP855QOPLGKEpd37E3bPLWmIOj4bSM2oUxbcSEQ3NFVFyqRhEKjhBGvFkPMAwAaMsbszianQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation论文链接：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490519&amp;idx=2&amp;sn=ce3026b5dc7d195a19f51fe317ba1385&amp;chksm=fd147c133a8857326f4b8c8e6df4d5078903fc221cd5359c784e4fc58a5f118b817c03fd35a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[电商领域利器来了！港大&amp;阿里提出MimicBrush，可模仿参考图进行零样本图像编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enu15BEdxn8DpEdshmGPMicepiaSYu1INiahHv6ZdWxcTRjT1UexEYITfITVC8uhS6hWlib4Wodyfrr3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里和港大提出的MimicBrush可以通过对参考图模仿进行零样本图像编辑。将一张图片的某一部分融合到领一张图片上去。用在电商商品展示上或者单纯的图片编辑和内容迁移很有用。从官方演示来看效果也很好。M</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490519&amp;idx=3&amp;sn=554d23556191e02c38f336b2e29245b2&amp;chksm=fd99c66c9c358101f2bdb8d4e9d28aab08764a11e762a9e442bd5e1d1680274c2ade741e9264&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta提出Fast3R！多视角快速3D重建新SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAdQicl6tFbm7xyZxj3Q91AjRBzA4Vrr5253RCiabI6uiaibZMIdTyoq6TZdXe8AotLRlkE2pkJyqGQLfQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass论文链接：https://arxiv.org/pdf/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490519&amp;idx=4&amp;sn=a905ede7d9d76c9eb1adde9699ad71ef&amp;chksm=fdb0c30ddfa289234019713b54d6e1b9b4fe9f44d346186c9fe1e1512781ae161dd27d7a2d2c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[理想汽车提出LDGen！颠覆多语言图像生成的革命性突破，美学与精准度的双重飞跃！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5J2tFEUOXbXSxBx5j1nBibbqn6qQJanWaRSGLup9KjBMUuBeGtw9u98Ciby4QTibN7lhYm3tXW8VRYtQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：LDGen: Enhancing Text-to-Image Synthesis via Large Language Model-Driven Language Repres</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490518&amp;idx=1&amp;sn=0d857ab42f69e5602facfafbb7c204a6&amp;chksm=fdb56048253a4a043578daf9389e6cbb4080331c1c96ab2b82fe7346b5fbcb6b3c6a48d7a558&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[[ComfyUI]阿里WanX2.1：最强开源视频模型易主！静待社区生态开源直逼闭源，Vbench榜首第一]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGR4iczdl1w1JCwWwhHibiaD9umzM0GtLxG8EhR3dUBt02neC4QvYYvoFicjM1FhMAten8AeAnfhcCtHYA/300?wxtype=jpeg&amp;wxfrom=0"/><p> 阿里WanX2.1：文生和图生视频模型ComfyUI体验WanX 2.1简介在昨天的文章（阿里Wan2.1：最强开源视频，本地部署优先体验！Vbench榜首第一，超越Sora&amp;混元&amp;Gen3&amp;Pik</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490518&amp;idx=2&amp;sn=9c99b1e013fc8f80eb22c83791380f17&amp;chksm=fd756053974066717edb6b862bda3c4f25fc0dc9b540dc4da291aff994aeafe6e17d3d19b792&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[国科大提出SayAnything！高保真语音驱动说话人视频生成神器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5K5KErGYAcboNZ5g1ickzvcVkQLCcDMsCQcyM5NbvALsSFic6AIQm1WH4bTtNZ1icfTrh6g2j7b1kRhQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：SayAnything: Audio-Driven Lip Synchronization with Conditional Video Diffusion论文链接：https://arxiv</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490518&amp;idx=3&amp;sn=08f579474fa9039499e89b2edb4eef86&amp;chksm=fd335b9684d893bd98ef6e53003dcfa7f998338818814130cf59e08b6ec23795b01114a3fe72&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[深度长文｜一文读懂多模态大模型：强化学习技术全面解读 SFT、RLHF、RLAIF、DPO]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic5T2TV2orhwficRDibGUTU3xn1xoCPq7bx5xr0CM1pbwH7Q9gYicdPZRiaIOKTsVKHicyuQGUA524jqibYQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注「魔方AI空间」公众号本文从强化学习如何增强大语言模型（LLMs）的视角，进行系统性全面解读，涵盖强化学习的基础知识、流行的RL增强LLMs、基于奖励模型的RL技术（RLHF和RLA</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490518&amp;idx=4&amp;sn=c1b8d72b7aeed8f82ef479147ca2c62b&amp;chksm=fd9877c87e2dd912188fcd009b0994a3529a6a99f84b7d11506f4c693dcd7eff289a31f90974&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CoT推理赋能文生图！港中文首次提出文生图的o1推理和inference scaling新范式。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXWzRbkGicoW9wRTQdn5jpBylMxyUibNONP7beA15qfJAiaWbUMRib5uibEibuA/640?wxtype=jpeg&amp;wxfrom=0"/><p>OpenAI的o1模型凭借思维链（Chain-of-Thought, CoT）技术，在推理能力上实现了质的飞跃，引领了大模型理解领域的新风尚。然而，这一创新的火花能否照亮图像生成领域？近日，来自香港中</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490516&amp;idx=1&amp;sn=c04492b3873d61a81130be583ccc6711&amp;chksm=fd8ebd3a031bab7d52b54b8eb347e9d95b1cb231dd677636925b18fa83eb399792501d7553ba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源版Deep Research，一句话创建Agent工作流帮你完成电脑上的复杂操作，股票分析也轻松实现。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NZM99XBibic0ksT7p0zTFpQHQT2lY40u4GloUhxMpWMlQLDWe9ic4uibxzibicD0eiauVkGszvokib9MfuhLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI刚出来的时候就不断在说，后面非常多的工作就不需要人去做了，都是AI在做。之前很多人不相信，现在已经有很多公司在裁员了，而且裁员后业绩反而更好了。当然，我们平时也不愿意做一些繁琐重复的工作，让AI去</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490516&amp;idx=2&amp;sn=6cfaea30a2d7581b563d98db44762ab0&amp;chksm=fd5055e8d964e4d1088829294bcb7638676142cddb43a8e9adcea551dc54c971e732006e1495&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IC-Portrait：打造逼真个性化肖像的新纪元！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6tZI0cwKFL48OjADTdSoL7AChsEwU2ZueiasNW7Rv9TMPIZMsldYJjmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在数字内容创作、虚拟形象、游戏和增强现实等领域，肖像生成已成为计算机图形学研究的热点。尽管近年来肖像生成模型取得了显著进展，能够生成越来越逼真和吸引人的肖像，但仍面临诸多挑战。今天，给大家介绍一种个性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490516&amp;idx=3&amp;sn=4d1d9b0d74fd2b7cecdef2ca1bcbb0d2&amp;chksm=fd0f4c5652d525054df68b55be8d38a8389cfba7d049401afeccd6adde91132e84a40dd7366a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek将开启大模型免费潮？ChatGPT和文心一言相继宣布全面免费开放！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekAuUNNvuhqhCqoRTbKeLmgGsbjAiciaibfrfRhuw7eaB9AtkL5GxPITtVb9wtxXb6szDDbLGD55syWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期DeepSeek等开源AI模型的爆火，引发了全球AI产业的变革。文心一言和ChatGPT也即将全面免费开放，这将有助于推动人工智能技术的普及和应用，进一步促进产业的发展和创新。在北京时间2月13日</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490516&amp;idx=4&amp;sn=15bf9233f452e13e64d9b653b11f3324&amp;chksm=fdc98203bc76871898678b33b2bc80f8153620795c84378bad48950cb4960269fac99fa6a1e0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[香港科技大学提出YuE：Suno级别开源音乐生成模型，支持中文！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZsukicic1pwKicvO5kl9ea5rGcBfEiaHiaQP2qUjqPV3wDPziblkH7xOuXdRw/640?wxtype=jpeg&amp;wxfrom=0"/><p>YuE是港科大提出的一个开源的音乐生成基础模型，专为音乐生成而设计，专门用于将歌词转换成完整的歌曲（lyrics2song）。它可以生成一首完整的歌曲，时长几分钟，包括朗朗上口的声乐曲目和伴奏曲目。Y</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490515&amp;idx=1&amp;sn=f021bcbbbb5608142e8a4cd9104b9e94&amp;chksm=fdf994841a673d36f40b4ce99ac89d3625ad2c3763a34ea3c9af2ba572c5cf8c80ff4aea1489&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[马斯克疯了？Grok3 突然免费！还说让大家“用到服务器崩溃为止”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/QFmOy9B4XPW93brzPiaQQlVAqCHrRsnnJGIBGkAOnKSFHtHzBJjfZ1vzicEpnmNNa0haIM0RlY8Mx7mNfJaoApmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>就在 2 月 18 日，马斯克旗下 xAI 公司宣布推出其最新 AI 模型 Grok 3。2 月 20 日，xAI 宣布 Grok 3 即日起向全球用户免费开放使用，直至服务器达到崩溃为止。（也可以理</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490515&amp;idx=2&amp;sn=97c2c95f08e7e6086eeebc627e4e1d1e&amp;chksm=fd399f822bbc1511c77bdfc5c799dc64f82c0259600194e2a730ec1826f7efd163f6b3b74237&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[解决文生图质量和美学问题，字节跳动提出VMix：多维度美学控制方法，一键提升图像美学。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcic6UBBbFKhnQGPNFnt0uNP0icQj44gWuVMkaK2nsqNia2kicW5icETqKKVMA/300?wxtype=jpeg&amp;wxfrom=0"/><p>为了解决扩散模型在文生图的质量和美学问题，字节跳动&amp;中科大研究团队提出VMix美学条件注入方法，通过将抽象的图像美感拆分成不同维度的美学向量引入扩散模型，从而实现细粒度美学图像生成。论文基于提出的方法</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490515&amp;idx=3&amp;sn=9fc95478aa6836ff42fe8756bc3c7daf&amp;chksm=fd9b6503871087dbd5ac836db098d63223877f0170297e62420f85416e897f6fab3e5aa41c02&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[国科大提出SayAnything！高保真语音驱动说话人视频生成神器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5K5KErGYAcboNZ5g1ickzvcVkQLCcDMsCQcyM5NbvALsSFic6AIQm1WH4bTtNZ1icfTrh6g2j7b1kRhQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：SayAnything: Audio-Driven Lip Synchronization with Conditional Video Diffusion论文链接：https://arxiv</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490515&amp;idx=4&amp;sn=c488ccbd4604631c9afe07161e4ad7bf&amp;chksm=fd78a3f46b6634445e111c13d7be1830c26517f23e8bfb5f2c6491875ac3f1f97ac993849d5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LuminaBrush 在图像上绘制照明效果的构建交互式工具。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emstfptCQxwPFVbYI1WNOA3hBPXy2a1MjMxRyibAmc4FtFqLVcy56JI8l8XdNxdSFPyAw6H06p4Xuw/640?wxtype=jpeg&amp;wxfrom=0"/><p> LuminaBrushLuminaBrush 是一个构建交互式工具以在图像上绘制照明效果的项目。该框架采用两阶段方法：第一阶段将图像转换为“均匀照明”的外观，第二阶段利用用户涂鸦生成照明效果。相关链</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490513&amp;idx=1&amp;sn=9061a763dc13527ddafa414a73823c9b&amp;chksm=fd0ecc5c519367b5bd47350e1ea243c3a8230b624cdaefa19daa6d841785a043dbda49aa93ff&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI 迎来重大更新：原生支持 Lumina Image 2.0，解锁极致图像生成体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE4wDn16WHKLZgNuLEibJtk3l1Z7eg0ERD9iafAP0MSxU9wTK5wLficV8WFuWqq0KZ2jYcpooQ5gwdZOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在 AI 视觉创作的浪潮中，ComfyUI 再次迎来重要升级——原生支持 Lumina Image 2.0！这意味着，你现在可以在 ComfyUI 中无缝体验 Lumina-Image-2.0 强大的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490513&amp;idx=2&amp;sn=2f883bf224d210e191df2ceb22c5a5f4&amp;chksm=fd9b85e56931c56d571b9cefc0477da891c1c62bcefa261815fab85e81ddd22a218423893738&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[国科大提出SayAnything！高保真语音驱动说话人视频生成神器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5K5KErGYAcboNZ5g1ickzvcVkQLCcDMsCQcyM5NbvALsSFic6AIQm1WH4bTtNZ1icfTrh6g2j7b1kRhQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：SayAnything: Audio-Driven Lip Synchronization with Conditional Video Diffusion论文链接：https://arxiv</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490513&amp;idx=3&amp;sn=ec8fbdbb5d06916b50f5e06363704689&amp;chksm=fd4b2211282a456b682c4c3007266861586e5be4bd9b1f91dbbc7fd9e34696ea0a9135865806&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[YuE：用于完整歌曲生成的开放音乐基础模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p></p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490513&amp;idx=4&amp;sn=0b849dd72b983ad39ed1af004ca8d40c&amp;chksm=fde1b23f4b54b7ae5dc7bd769a1ca3d22e784bc5b5fb018e598686ce99bd37b911c54ed5e3d9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Feb 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[魔发奇缘，3D发型生成新突破！TANGLED：可用任意样式和视点的图像生成 3D 发束]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekpCyj06iactRk96xGc32gLwfpjZlTjjCSbXm0Lib95G5D5yo7ElFr9uxtoh3BdCt4nr4ht1wrCGWWw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在数字时代，发型不仅是时尚的标志，更是个人文化身份的彰显。但传统3D发型生成技术往往难以捕捉复杂发型的细腻之美。为此，上海科技大学和华中科技大学推出了ANGLED技术，能从任意风格、视角的图像中，轻松</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=1&amp;sn=08ea1babf6f4a250fc1a070192d94a58&amp;chksm=fd18769d857fb9c659af26deb5e1e6cf9712edb5c11525b839cabbf45aedad95c9ac5643f482&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Feb 2025 22:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[澳门大学提出DC-ControlNet！解耦控制条件！灵活性和精度超过ControlNet！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IJObOoyvhRkCaPGyos7d8xL9KBFJiaWYgoicVEkmuuB7slvPLj3SIW9jx5pace0iagDibDDTLU1P3Lwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：DC-ControlNet: Decoupling Inter- and Intra-Element Conditions in Image Generation with Diffusion</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=2&amp;sn=de121316a3123aa0581f09725abe2bd6&amp;chksm=fd0068d3835af5ba38f14f910e10993f3a78f8da58fc4d63e8db4101161d28881299658a7a8b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Feb 2025 22:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源版Deep Research，一句话创建Agent工作流帮你完成电脑上的复杂操作，股票分析也轻松实现。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NZM99XBibic0ksT7p0zTFpQHQT2lY40u4GloUhxMpWMlQLDWe9ic4uibxzibicD0eiauVkGszvokib9MfuhLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI刚出来的时候就不断在说，后面非常多的工作就不需要人去做了，都是AI在做。之前很多人不相信，现在已经有很多公司在裁员了，而且裁员后业绩反而更好了。当然，我们平时也不愿意做一些繁琐重复的工作，让AI去</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=3&amp;sn=ebb27cdf7263a50217dd05d142035047&amp;chksm=fd3d55f1d3f84c431f8200a0e71d5b1cd624efc7849f4dd65cec876ccc1dedb7d71aceea768b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Feb 2025 22:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[小红书提出新面部视频交换方法DynamicFace，可生成高质量且一致的视频面部图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4wY9icyCBJHtpRNSEtIVu23ib2dMfGUzdVZH7hKlE7v6ZRLfdk46k3hHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>DynamicFace是一种新颖的面部视频交换方法，旨在生成高质量且一致的视频面部图像。该方法结合了扩散模型的强大能力和可插拔的时间层，以解决传统面部交换技术面临的两个主要挑战：在保持源面部身份的同时</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=4&amp;sn=cf008a19b978ab7f5ca27c2f67b893ea&amp;chksm=fd0052e96469409dee07028c56d34eb9f9ca3e3ce152f5eed389aaa7f0af9935412864f20402&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Feb 2025 22:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>