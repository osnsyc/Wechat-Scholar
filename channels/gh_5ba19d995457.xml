<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/XzhF92tBcezMLGZN5TwHm01JzyB611PyibhFUMaiaE6xaTcU7nCAumRAicJowUjC4ntxOOAkSvxOK0/132</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[港科大开源 World-To-Image，让T2I模型提示准确率狂飙8.1%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnlicYMzw1WzNwt5le6iaI9cR5171t9co0Zibr73NZDzQxwk0fJaUicmJoQYiaW8ehHCWpPqAaRke2Dwg/640?wxtype=jpeg&amp;wxfrom=0"/><p>文章：https://arxiv.org/pdf/2510.04201代码：https://github.com/mhson-kyle/World-To-Image虽然文本转图像 (T2I) 模型可以</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=1&amp;sn=ee8c1871b4541c9cb5c837f88c61467e&amp;chksm=fd96fcbce34d36925205eb0e9cf3169fadc4c64ab288fcdeb4ea2de02b65dcff7be3c824a960&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[当一群清华学霸开始较真扫地机算法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/DOQ3oqzSJUGgRpf0B3qbE2C9X7xdq25icUWNmwCVAMceibXUAcZcn7a2LBCqiaYwhhqusRvHibDP5TBvOVYxFFY1fQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在追觅，最聪明的大脑盯上最琐碎的家务。作者｜王彬封面｜Unsplash扫地机作为消费品的故事，常常被归类于“消费升级”的一个注脚。最初，这只是一个新鲜的小电器，消费者尝鲜后就束之高阁。可在步入消费市场</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=2&amp;sn=555da5207619b12816baedfc471c676c&amp;chksm=fdebb3499cc6a6d4c587b8ae4e700f3c6c175f073772efa54293e8abadeb7dd1cf9307011120&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[清华&amp;字节开源HuMo: 开启多模态可控人物视频生成新方向，输入文字/图片/音频即可生成电影级视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPl5fon0zqaCYa1WAGMKib43ibDcv8gDnvjAAPXvsT4Mkr1cgVcibJpA2nLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由清华大学、字节跳动提出的 HuMo 是一个统一的、以人为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=3&amp;sn=c40267d37a9ba71c12471265c6731882&amp;chksm=fd655001fa6a46812132eb35ae6cea96b6426fd038209b251309ead711ccdd1a837ceaf07369&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[耶鲁大学和Adobe提出SynthLight：智能重塑人像照明，打造完美光影！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPyLquFq9rYTicjFkPwyh9fFVDfMwbeuJFlesWohTUXxZRSXxUpCJVwUUib0mdhjaia5sa6Ciaibic8AQg/300?wxtype=jpeg&amp;wxfrom=0"/><p>耶鲁大学和Adobe提出一种用于人像重新照明的扩散模型SynthLight，该方法将图像重新照明视为重新渲染问题，其中像素会根据环境照明条件的变化而变化。在真实肖像照片上可以产生逼真的照明效果，包括颈</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=4&amp;sn=0c2034f136a5fa25ca13fcd3084a0cc8&amp;chksm=fd217a2d42814ad6edb3c5d53b5e47a5dbb3a6a5c62fb2a78a358e54d747c0530bd13abe85f1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[PractiLight：无需大规模微调，扩散模型重新照明图像的“隐藏密码”是啥？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnlicYMzw1WzNwt5le6iaI9cTAtDXqeQhLib2EX5oj6diaoeWrR70g9ysxhaoNYpWZY23iakey176zJZA/640?wxtype=jpeg&amp;wxfrom=0"/><p>标题:PractiLight: 使用基础扩散模型进行实用光控制论文：https://arxiv.org/pdf/2509.01837项目：https://yoterel.github.io/Pract</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496333&amp;idx=1&amp;sn=4708adde1bf709723339c66879be6ce0&amp;chksm=fd60cff4b847e1cffef8e580201dfcb46e0b60497821e0a553940a43c6679ace17e9532f9ee2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 22 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[国产AI模型GLM-4.6硬刚Claude Sonnet 4！200K上下文窗口+工具增强推理，重新定义多任务AI代理。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ensv02pBKeqkonEQJOUXibY7hzAbyZn7bwmuBUKUeOolM1ExcrLibyiaGAibN6bSJb55S90be9iaWL1V3w/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！与 GLM-4.5 相比，GLM-4.6 带来了几项关键改</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496295&amp;idx=1&amp;sn=c682887be4121733436548a3b7b3e234&amp;chksm=fd2583c5956faa2f4b01816518c2e22398a5e270717e0eeb04ea9e4091f845c7233db1921f12&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq5BIttmnJoy6onMGT6hEJiblmfujJkZFpZjpO6usAYRtw7aj1tZbJZYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元团队提出的 HunyuanVideo-Avatar 是一个基于多模态扩散变换器（MM-DiT）的模型，能够生成动态、情绪可控和多角色对话视频。支持仅 10GB VRAM 的单 GPU运行，支持</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496295&amp;idx=2&amp;sn=9e15f1b4badd4cdf160a087d591e516c&amp;chksm=fdb569fad9336fcba00277cae803d58900eb685f11000ea3ac0dcad6c3e770c7cc1925cc3f7f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta 开源视觉大模型 DINOv3，尖端图像表征，无需人工监督即可训练，数十个视觉榜单准测试性能SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emC8TzOo0tTPOfwjIibibRDG0V8FDngTwB5bIGKr0RDuL4kJibH8eGgHeZFrbt39SzRkrsY30LsWE7iaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Meta 发布了 DINOv3，它可以扩展图像的自监督学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496295&amp;idx=3&amp;sn=025d3c182b179c92ac5463ef6b871574&amp;chksm=fd93a5fefb1b9cdf22c0614518a7a3f3ef68b221f7e778927a9d2e5440531a32680317b54045&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出X-Streamer：引领多模态智能响应潮流，打造跨文本、语音、视频的实时数字人！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enlgSVEo2CkoPRMLkJWUSx7fVAdpE1JtBXXX6nHHPhLI2VUagXFo575vzOSXIdMeYRC3Xx62Fibk2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496271&amp;idx=1&amp;sn=5ccc9bf8ea01e680c2144895c1048295&amp;chksm=fd534c8b520063260408315d71a33b2ced31b83cc6d9869f58b5fa43ef4986e9906b97dcc9a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[还在担心不会写提示词？腾讯混元提出PromptEnhancer，可自动进行提示词改写生成高保真且风格多样图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPlFcEKrb9MGqy2aH6grpJkAOykmexaibpb6FRIiasyV3LGEBz8ZqX2d3Wg/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Hunyuan-PromptEnhancer 是一款基于腾</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496271&amp;idx=2&amp;sn=44a315ed27e355bb9c078d460fc4f9f0&amp;chksm=fdd360f420593a13856d6bdad29d2d33be0930c2b5559121ebf7be8796d0dcdf0a79e7a6807d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[手机跑AI，25轮对话耗电不到1%！谷歌开源Gemma 3 270M，适用于多个领域的最佳且最小的LLM]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQiavic0RLHKWwicCvLR9emF1icwlibibegD35clic0yQMgcIAy3AFP5Ziak3CVpypiaUSQ4uoaqZTs5dibnN1wQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>适用于端侧任务的Gemma小模型Gemma3-1B、Qwen3-0.6B这种小模型有什么实际意义和用途吗？如果你接触过真正的线上服务，尤其是搜索推荐这类每天跑千万级请求的系统，你会发现，它这种小参数量</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496271&amp;idx=3&amp;sn=dcb5fc5ac5eb12f8d4aa9e862f819c09&amp;chksm=fd4b58aa455434313149ebdc1d81d9b495945b73dddfabe7d170ba3fcf526fa34ac158674ca7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一个无解码器的分割框架？南洋理工&amp;字节提出文本即掩码新范式，纯文本生成实现精准图像分割！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQhGsVbibiaaIKZVlmUPbRX8sicN7cpGUoAHZK4L4pKFqDJZ6qtxkGA500DicCkCNbUykZP8wia8nX1zO2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>多模态大语言模型如何重塑计算机视觉任务？大模型时代下的图像分割怎么做？还有什么更优雅的新范式？过去，开放世界图像分割的研究多基于 SAM、DINO 等视觉模型架构展开。今天我们重新聚焦于多模态大语言模</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496271&amp;idx=4&amp;sn=f06cde6b1db30381364f9562df75aec6&amp;chksm=fd9bc82f955eb66edf9cfc38ca05a3c1cc14dad542c5e4bf6e10a995337ebd71158ee270a587&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[国产AI模型GLM-4.6硬刚Claude Sonnet 4！200K上下文窗口+工具增强推理，重新定义多任务AI代理。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ensv02pBKeqkonEQJOUXibY7hzAbyZn7bwmuBUKUeOolM1ExcrLibyiaGAibN6bSJb55S90be9iaWL1V3w/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！与 GLM-4.5 相比，GLM-4.6 带来了几项关键改</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496238&amp;idx=1&amp;sn=d792f933fbb3e252892d87c81a6377a5&amp;chksm=fd9e70095b76517568b92ceec85aa653d2d733ffd8fe6f3956b314e7b7aee74c668a854eba24&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 00:16:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq5BIttmnJoy6onMGT6hEJiblmfujJkZFpZjpO6usAYRtw7aj1tZbJZYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元团队提出的 HunyuanVideo-Avatar 是一个基于多模态扩散变换器（MM-DiT）的模型，能够生成动态、情绪可控和多角色对话视频。支持仅 10GB VRAM 的单 GPU运行，支持</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496238&amp;idx=2&amp;sn=afd0901abc75269ba93ee5e7e1bd64cb&amp;chksm=fd9141007b21558009c30b5759f0096f5bc7c45179a72eee6fda50b886f8ab475d1e85188232&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 00:16:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta 开源视觉大模型 DINOv3，尖端图像表征，无需人工监督即可训练，数十个视觉榜单准测试性能SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emC8TzOo0tTPOfwjIibibRDG0V8FDngTwB5bIGKr0RDuL4kJibH8eGgHeZFrbt39SzRkrsY30LsWE7iaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Meta 发布了 DINOv3，它可以扩展图像的自监督学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496238&amp;idx=3&amp;sn=654f39079bcfbe9e964dedc5fe388be8&amp;chksm=fd91cdd9eb9d2fd2b93627bd2014dc60459d2f5b5ad30def153769b5bfe05e93754ad928e5b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 00:16:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 复旦大学提出Seg2Any：赋能分割掩模到图像生成，开启精准控制新时代。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekGicBXM3YuJldcx9kQib4alcegEwE0vptrxNZWKa3mNsgf6g8KUJNgtictmrNCuGQHiafibkUZ9ic7Vxvw/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496162&amp;idx=1&amp;sn=0a33ae1b128a4ce5901dc96d87d681cd&amp;chksm=fd81cbe632f68a148166dd88a15d4eaf819767f8e38bdab1ab4458081e7501e05820a05a8eed&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑进入视频时代！字节Seed&amp;新国大提出VINCIE，视频驱动扩散模型，概念合成效率提升300%。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ennrAAVlvm6a2ndtb8NAAAehQOd2pAp8oOdmjraUibFjm5UwibicaIfLZpvl4licgd3FvIqQuDnyebylw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在图像编辑领域，如何让模型真正理解并响应动态变化的上下文需求，始终是横亘在技术落地前的关键挑战。传统方法依赖专家设计的任务流程与分割修复等辅助模型，不仅数据标注成本高昂，更难以应对复杂多变的编辑场景。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496162&amp;idx=2&amp;sn=b1504b0e2a09b52e7a5f743db3f710d9&amp;chksm=fda2cb0cec8a4868df49599ff2c48fd6c25739eee768fb603c590356d68455f4e0b697a280e2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[清华&amp;字节开源HuMo: 开启多模态可控人物视频生成新方向，输入文字/图片/音频即可生成电影级视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPl5fon0zqaCYa1WAGMKib43ibDcv8gDnvjAAPXvsT4Mkr1cgVcibJpA2nLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由清华大学、字节跳动提出的 HuMo 是一个统一的、以人为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496162&amp;idx=3&amp;sn=b081f9794e9d1613f567f1f1b959e3ec&amp;chksm=fd68b1af5363d2415a12dda5abfe89d399c95d85ef9e23607f2cf74b370a513e08a0ac8407ea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[突破高分辨率3D建模算力瓶颈！南大&amp;复旦提出 Direct3D‑S2：8卡即可训练，革新 1024³ 分辨率3D生成格局！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnnibKbtwkfQH4wt4miaD9ltwEVcbK2fR9bxibXxuHKTtr0qEAr49WVVsnag/300?wxtype=jpeg&amp;wxfrom=0"/><p>介绍 在 3D 生成领域，高分辨率建模长期受算力限制，传统方法以符号距离SDF函数等体积表示生成 1024³分辨率 3D 形状，计算与内存压力巨大，成本高昂。而今天给大家介绍的 Direct3D‑S2</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496162&amp;idx=4&amp;sn=4b6d90269cfa332490a68999a4c88ba4&amp;chksm=fd645ffeb11971d1ad23d9b0ca2b286f0ee0172e2c5e0da1f786e09331abf89816c99d8486c4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Huggingface热门榜第一名！当TTS不再依赖GPU：一个开源模型如何让全球开发者集体‘真香’？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ensv02pBKeqkonEQJOUXibY7QkIQRvythemWeCUuwibxgY2BtSk43akTPVBykvicaibkWx43PbiagXKISg/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！NeuTTS Air 由 Neuphonic 于 2025</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496118&amp;idx=1&amp;sn=8c67696b5bf928c01f5cc64b302a3904&amp;chksm=fdf7549f0469d2170fdeaafb3285e244752f0f60a4c0a95f133cf512ab25db0f01d19a56fca2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工大学与Netflix Eyeline Studios梦幻联动：8K图像、4K视频电影级高清生成来场“免费革命”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em7A7COb17nQf31AE47sosc4L7RZKDseEZ4cC6VyZUSs31ZiahjEg62tIOzTy16NCzmEKHLv3NBuQQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>南洋理工大学S-Lab与Netflix Eyeline Studios研究者合作，提出全新推理范式CineScale，以解决视觉扩散模型生成高分辨率图像和视频的核心难题。受训练数据和计算资源限制，多数</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496118&amp;idx=2&amp;sn=804c828624f1899aa15ff62d81def4f9&amp;chksm=fd8678345179fc0f1d1ab41501a09a6baf399fac0d1220a537931c8969c38437760a02ad0266&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌研究院联手牛津大学推出Bolt3D！7秒内单GPU生成高保真3D，推理成本直降300倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LR8w1T4XSJwAUg3UkzLpMRYxbTOuSXUEpxZVs5u18QTNFMFHe41E6SY6vfhMbJicRDetQWdibB3Nicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Bolt3D: Generating 3D Scenes in Seconds论文链接：https://arxiv.org/pdf/2503.14445开源代码：https:/</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496118&amp;idx=3&amp;sn=84addaa7d96d61a524dfade5dbeb4073&amp;chksm=fd4db35a73e65cb0d2a85d3a50ec51a135133432417778935ec8b6b022afd9f7282449656edb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[静态脸秒变表情帝！高德&amp;阿里&amp;北邮携手提出FantasyPortrait，破解多角色动画难题，效果惊艳超想象！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekOicvEwNdEEX8G6p02iaJaXicxVAqGEwYxicWQGnlho1EfH8Mk0qXyXtn4M4ChesVyxc7lxyOicGyLEFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>让静态照片里的脸“活”起来，还能精准表达各种细腻情绪，甚至能同时让多个角色“动”起来？这听起来像魔法，但高德地图、阿里巴巴集团和北京邮电大学联合研究团队真的做到了！他们提出FantasyPortrai</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496118&amp;idx=4&amp;sn=0b1b3916731a8e93c1bdf8bbfd2ce3a1&amp;chksm=fd01202de0692222a1be5a58bf6fc9af03360157339cc22415733dbe5f815ba8af88d7cfbef9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 12 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Huggingface热榜前五！企业出海12种语言通吃！Granite-4.0-H-Small的多语言对话与代码任务一站式解决。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ensv02pBKeqkonEQJOUXibY7IshyjbmRNO5pcahaUUlTrLUIUgvPcIZez3YaJRB1G7lf8mbd37P0Cg/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由Granite 和 IBM 发布的 Granite-4.</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496085&amp;idx=1&amp;sn=34996930479174857a718c22fa31a7a2&amp;chksm=fd27bc644c92b89ac8a923b9b6ec16887757f2e90ca36d223f2ed4325ab1b6df8460250a7c4e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[耶鲁大学和Adobe提出SynthLight：智能重塑人像照明，打造完美光影！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPyLquFq9rYTicjFkPwyh9fFVDfMwbeuJFlesWohTUXxZRSXxUpCJVwUUib0mdhjaia5sa6Ciaibic8AQg/300?wxtype=jpeg&amp;wxfrom=0"/><p>耶鲁大学和Adobe提出一种用于人像重新照明的扩散模型SynthLight，该方法将图像重新照明视为重新渲染问题，其中像素会根据环境照明条件的变化而变化。在真实肖像照片上可以产生逼真的照明效果，包括颈</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496085&amp;idx=2&amp;sn=2aeb1634194d830a694d8b25bc5dc782&amp;chksm=fd5d7099ad929f2255ad29b9ff89a103c7a1f9e76660e55acdc03adf4744b393fcc94f4ff538&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[重构图像编辑！ComfyUI 原生支持 HiDream E1.1，真正开启「自然语言改图」新时代。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE5NTaVjpZ3bk5vDpSbE1hBc7keDkNib2UkUne9RfxEoRwQWTr6U6ZNLicQmWoBibs9fclxMl6m3no0og/300?wxtype=jpeg&amp;wxfrom=0"/><p>你有没有想过，未来的图像编辑，不再是鼠标点点涂抹，而是像跟设计师对话一样——你说一声“把这只猫变成火箭侠”，AI立马给你实现？现在，不是“未来”了，这已经被 HiDream E1.1 搬到了 Comf</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496085&amp;idx=3&amp;sn=9f3785142d3beb3242d5bbd34b85098d&amp;chksm=fd0b6b5d15dd332d336569d5a88e734f2a3a3392f6be6f408a5738e57d1559c7742bbc176692&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大&amp;美团提出PosterCraft，文字渲染与艺术融合，从创意到成品只需一步！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elRPnxm15EcjBGoXOC5AYqzmibC3IibyVqwj02b3JZwTrRYibZ5X4eYgJcibSRkrEYHSF6tueI2pO8OFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一款由香港科技大学和美团联合开发的创新性海报生成模型框架：PosterCraft，其擅长精确的文本渲染、抽象艺术的无缝集成、醒目的布局和风格的和谐。PosterCraft 的设计理念是统</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496085&amp;idx=4&amp;sn=295964345e901e598db6671b314b7bb9&amp;chksm=fd4e1a000d5799ff859d30d48da3ddb27335e6d68060c7939e5e184f38b1c353636e043bffc2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 11 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[80B参数炸场！腾讯Hunyuan Image 3.0开源：全球最大多模态生图模型挑战闭源霸权。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek3ORJ88CbY3YmZiao4rvXjCbCWggEtV03yBMa3uKILXjBee2ibWYxTzeBkEtfib4Nj3nT0HiaHyIiahjA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！2025年9月28日，腾讯开源首个开源商用级原生多模态生图</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496044&amp;idx=1&amp;sn=c46f0bebd57b914650384467effad9d9&amp;chksm=fd4039b9392ce26331f8d7950fe78e8f332848afe334874744b17c5430bec6f4f7474a149005&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 00:15:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Stable Audio 2.5 入驻 ComfyUI！2 秒生成 3 分钟音乐，AI 音频创作进入快车道]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE4ia4OAkJK7glACGu7xXJ3B5iagArfWst2e6wev6vuzW2ej4DzLaSM6mLwQm4UUH4kgpBicQUMBicuZ9g/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击蓝字关注我吧！在过去几个月，大家对 AI 生成图像、视频的关注度飙升，但有一个领域一直相对“冷门”——音频。直到 Stable Audio 2.5 的出现，这个局面正在悄然发生改变。9 月 10</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496044&amp;idx=2&amp;sn=61cef79beed9d0edee6076471ffa9542&amp;chksm=fdf0bbf881f4a29e62936f3fc3ef2f6e6da369a489e0e3239ff7e4c4c6c3a4099ea08b15828e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 00:15:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AIGC 进入「长剧情」时代！复旦&amp;微软开源StableAvatar: 首个端到端无限时长音频驱动人物视频生成新框架!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elUF9IVtYeIfxAic6O2PVdkZ6ibicJqGRtRialuUn0SquuKwJ2YMicpK76EO8sxcXRtosfDEcZ1jDd3icPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由复旦大学、微软亚洲研究院、西安交通大学以及腾讯混元联合提</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496044&amp;idx=3&amp;sn=fa3d2502ac48679e55fadc8e56436ff6&amp;chksm=fdf9304c97e4907792ab127be36aeff22beaa5064ad3388d6cf03688991660199eeb79219f3e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 00:15:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[开源多模态生成模型新标杆！OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496044&amp;idx=4&amp;sn=e00ee740577721573afe43f4b035dc29&amp;chksm=fd47de86134d9dba77c47d930976d4038787003827b904d22cf93681ef176a730db680a38c67&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 10 Oct 2025 00:15:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从分割到生成：腾讯Hunyuan3D Part凭P3-SAM与X-Part，解锁部件级3D全流程创新]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek3ORJ88CbY3YmZiao4rvXjCpM8pdPtposKB9nL68n5O9q1nqeHqFjeal5u14kUIy3lricCAuo5WqicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！腾讯混元提出了一个新的 3D 部件生成流程，包含两个关键组</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495959&amp;idx=1&amp;sn=b6b4ae33ab5f0b234627f5defac29c7d&amp;chksm=fdcf5e33f1fc35a3219bb083225d03c7e60ea16c0c81d045e70462e59d268c258a84aa404c9e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[上交提出单图生成3D场景方法SceneGen：单图输入，多资源输出，3D 合成性能飙升的“秘密武器”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em7A7COb17nQf31AE47soscfGBWricCrgS9TPputfthWWicucnmu3IL6bfvSdLnZAiaR44mJslicyUWyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>上海交通大学推出单图像生成3D场景方法SceneGen，它以单个场景图像与目标资源蒙版为输入，在一次前馈中就能同时合成多个具备结构、纹理及相对空间位置的 3D 资源。通过结合专用视觉和几何编码器提取资</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495959&amp;idx=2&amp;sn=72638f61f36669beb2637dfd0106bf6c&amp;chksm=fd41f9ffebce72881d1925fa789e8e551200c9978ade6400bc053b3f37a6014404e9dda27b2c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[从文本到3D动画：AnimaX 前馈 3D 动画框架，解锁任意骨骼动画无限可能。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPbvzXyQzXhAWo1QdPyhvibR2nOgLfk3jfXRCH64V0YMReDLI4nZbR5kKceDeR0YnSEialEZiahJyQQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>AnimaX 是一个前馈 3D 动画框架，它将视频扩散模型的运动先验与基于骨骼的动画的可控结构连接起来。传统的运动合成方法要么局限于固定的骨骼拓扑结构，要么需要在高维变形空间中进行昂贵的优化。相比之下</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495959&amp;idx=3&amp;sn=b7826d5fae3eb38fe29596f39fb48da4&amp;chksm=fd4999faa3f7321c3f5b73d09f941c1957f91ce25dc2a1c46f6fffe1df33884e00cd84fb4d99&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 09 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Qwen3-Omni：新一代原生全模态大模型！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekl1EHZfZ0ywDeufmk1KVoELsCOic2JZtyKmsIwiaovN1UXcPoAdUt9VvxxaDvmKn8niaHMd9MW6O4rA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Qwen3-Omni是新一代原生全模态大模型，能够无缝处理</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495940&amp;idx=1&amp;sn=1e7cc6e9e5a35e4ff8eb5c12171f7408&amp;chksm=fdadcf3726a8175c108ce40cc874f8b88e10c39ccd89817db2d4a55fc6b17cd0dea87b148c9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 05 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[上交提出单图生成3D场景方法SceneGen：单图输入，多资源输出，3D 合成性能飙升的“秘密武器”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em7A7COb17nQf31AE47soscfGBWricCrgS9TPputfthWWicucnmu3IL6bfvSdLnZAiaR44mJslicyUWyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>上海交通大学推出单图像生成3D场景方法SceneGen，它以单个场景图像与目标资源蒙版为输入，在一次前馈中就能同时合成多个具备结构、纹理及相对空间位置的 3D 资源。通过结合专用视觉和几何编码器提取资</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495940&amp;idx=2&amp;sn=967a31f535185898a885de33fc24dfab&amp;chksm=fd9d81400d580db4ee2e580dd1435ed6b2fad12caa73c2c4c4e698eddbdacf5093f6169f3cab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 05 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta 开源视觉大模型 DINOv3，尖端图像表征，无需人工监督即可训练，数十个视觉榜单准测试性能SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emC8TzOo0tTPOfwjIibibRDG0V8FDngTwB5bIGKr0RDuL4kJibH8eGgHeZFrbt39SzRkrsY30LsWE7iaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Meta 发布了 DINOv3，它可以扩展图像的自监督学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495940&amp;idx=3&amp;sn=bc6a2e3a1e7ad82cbfac905d355acd09&amp;chksm=fdc6b6b2cdd21418b840ad98744c640fdcabf5cef6e0a44276f40118f3648498ee476d8c4db0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 05 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频重新照明新突破！北大&amp;中科大&amp;浙大等提出重照明方法Lumen：一句话让视频秒变电影级光影。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPlPUo9FAlxicNH0mqLqNbNRe7p0MH9e53Q0QRUickuBPHjH1GPbF9J5Q1w/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习资料！</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495927&amp;idx=1&amp;sn=40e0e2e97f74e1dde4d2916368115504&amp;chksm=fd95c52694d93bd41d45f4216f7aaaaeb8a75df1306716df9cb8db2584a216cb29156efca1be&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 04 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里最强代码模型Qwen3-Coder发布：多尺寸选择，开启编码新体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em9xtmb1LYQQ3l0fNDDWpS4R9kV73WWUJibv1BBPEzpA4GiczgHXPoApCNSWLpvhlypT6L0bvGhTEUA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里推出了迄今为止最具代理性的代码模型Qwen3-Coder，Qwen3 -Coder有多种尺寸可供选择，首先推出的是最强大的版本：Qwen3-Coder-480B-A35B-Instruct。它具有</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495927&amp;idx=2&amp;sn=f100ecee3e68b42974581ef5d1ef61af&amp;chksm=fdccc776f1255300ba9c451d1b0f12c3a62b325d05b0d60d312126e13e389415ce59f01236a4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 04 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里&amp;北邮提出基于Wan2.1的音频驱动数字人FantasyTalking，只需输入肖像、语音和文字即可生成动画。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en6YOGtn3XXJMye1oxLXOtQU407yMKvXQv0r7RibwF9tY6RoaWiaXTsGib66ALF1tYibibzZZ51ibfTjibCA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由高德地图、阿里巴巴、北邮联合提出首个基于Wan2.1的音频驱动数字人FantasyTalking，只需输入肖像图像、语音和文字，即可生成表情丰富、肢体动作自然且具有身份特征的动画肖像。此外，Fant</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495927&amp;idx=3&amp;sn=c79f1020f78c0509e1005bd081528f63&amp;chksm=fd9eadb64d89fb949b5b4bbee854a55ffb423f63e5178d6039ba441531b6d89aeade46151a63&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 04 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节&amp;港中文等提出Captain Cinema，当「无限记忆」打破〈盗梦空间〉的第四面墙。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ennrAAVlvm6a2ndtb8NAAAeECKiaXibgWMfXuoBib9zKibRu3JMzPKAibRp6rfe0wartxB8M8rwGXMibnyw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由约翰霍普金斯大学、字节跳动，斯坦福大学、香港中文大学联合提出的 Captain Cinema旨在创作具有专业电影级品质的多场景电影，同时 通过超长上下文记忆保持角色和场景的一致性。你可以成为导演，用</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495927&amp;idx=4&amp;sn=d5f93b6ef3d3f009cda206ff6a6d879a&amp;chksm=fde680b7db9591f0f5ac53bc33a58b5e4b85999da2e8a0bba1b8285cd734b214b47bb68fa6e6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 04 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[上交提出单图生成3D场景方法SceneGen：单图输入，多资源输出，3D 合成性能飙升的“秘密武器”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em7A7COb17nQf31AE47soscfGBWricCrgS9TPputfthWWicucnmu3IL6bfvSdLnZAiaR44mJslicyUWyA/640?wxtype=jpeg&amp;wxfrom=0"/><p>上海交通大学推出单图像生成3D场景方法SceneGen，它以单个场景图像与目标资源蒙版为输入，在一次前馈中就能同时合成多个具备结构、纹理及相对空间位置的 3D 资源。通过结合专用视觉和几何编码器提取资</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495926&amp;idx=1&amp;sn=cda40589d34bfcd03b045916b78c7c02&amp;chksm=fda5566d430fb21d4053027b985ba70d261876800e6a2d6a9c075467eb1c2b20ccba208a6473&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频虚拟试穿新SOTA！浙大&amp;VIVO提出MagicTryOn，空间建模+服装细节控制，超真实视频虚拟试穿效果。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ennPiayiaaeIG5CI2J0TCvA3rib3yqyGPDFnjddlfHCxqicYv2usHU7ypheicxs9vxcdPIQRFHFiagsdOwQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>由浙江大学、维沃移动通信有限公司联合提出的视频虚拟试穿框架MagicTryOn，使用扩散 Transformer 替换了 U-Net 架构，并结合完全自注意力机制来联合建模视频的时空一致性。论文设计了</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495926&amp;idx=2&amp;sn=4c2d9b111d8a517fdf9614aaae914a08&amp;chksm=fd7383b525910b8b0603b76bbeb6a2d59c7ffdfefaed27740eea738ba06eb61987d34e752141&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[突破高分辨率3D建模算力瓶颈！南大&amp;复旦提出 Direct3D‑S2：8卡即可训练，革新 1024³ 分辨率3D生成格局！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnnibKbtwkfQH4wt4miaD9ltwEVcbK2fR9bxibXxuHKTtr0qEAr49WVVsnag/300?wxtype=jpeg&amp;wxfrom=0"/><p>介绍 在 3D 生成领域，高分辨率建模长期受算力限制，传统方法以符号距离SDF函数等体积表示生成 1024³分辨率 3D 形状，计算与内存压力巨大，成本高昂。而今天给大家介绍的 Direct3D‑S2</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495926&amp;idx=3&amp;sn=e5692f7ac5a2faf043abbca9b6f60266&amp;chksm=fd3d6359b6eb73902f01b11147431c741e53cd18fe66afaf1e002391e188cfd20b295618bcea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[开源多模态生成模型新标杆！OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495926&amp;idx=4&amp;sn=33a8affb321b00747999f1cb4a7ec5bb&amp;chksm=fdb439ffa604577c908979ae6837dbeff615807193c921a853d4dd85d47cee24342f62374eab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 01 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源视频修复方法Vivid-VR：以独特策略与架构革新，引领生成视频修复高质量可控新时代。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enYG3PNQkEic1zlJVgOZ3RSAc3G3qbIqb6OC9EunxC0MjLNibtpXLWAj6I6U9hJraBIO8SGbMUia9uNQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495925&amp;idx=1&amp;sn=a7ab779fc799c997a5afef21a624fdc0&amp;chksm=fd066f000504a6667d6e529a0b8bd96e46d114c5009affceb0f1e4fb1e6d30b4a07272233bde&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 00:03:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里最强代码模型Qwen3-Coder发布：多尺寸选择，开启编码新体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em9xtmb1LYQQ3l0fNDDWpS4R9kV73WWUJibv1BBPEzpA4GiczgHXPoApCNSWLpvhlypT6L0bvGhTEUA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里推出了迄今为止最具代理性的代码模型Qwen3-Coder，Qwen3 -Coder有多种尺寸可供选择，首先推出的是最强大的版本：Qwen3-Coder-480B-A35B-Instruct。它具有</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495925&amp;idx=2&amp;sn=a8b8d8228426effb2c656aab57edf3b1&amp;chksm=fdc67a279ee953d14be231d992f918c17b23d1ea191738d8f575ce7ace54313062965ad48a00&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 00:03:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[首个时尚Agent来了！清华&amp;字节等联合推出StyleTailor：时装设计、购物推荐和虚拟试穿功一键搞定。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elUF9IVtYeIfxAic6O2PVdkZetviag3tU3aQs3NXW5eoGdVzJJYCN5fLTYyInibibJX8v42RzoExTJoAg/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由清华大学、新加坡国立大学、字节跳动等提出的 StyleT</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495925&amp;idx=3&amp;sn=fd180dc91a59ef499afe62da9d361d5c&amp;chksm=fd73deb9d0209706173113530d1a0bb6ca7d41e8bc15b79448f13e2dd15a8316e7872a56fdb0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 00:03:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Hallo2，音频驱动4K肖像动画展示。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enYG3PNQkEic1zlJVgOZ3RSAU6GmYeDVpfjc2pBliaiakaKBVJD5mgAA55CEdm5TArSL66uZFsny2TlQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>#AIGC #音频生成 #EMO # Hallo2，音频驱动4K肖像动画展示（4K，最长 1 小时）@AIGC工作室 #AIGC Studio</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495925&amp;idx=4&amp;sn=9742f7a882e2b35049fde354b4087ad8&amp;chksm=fdf70a64d57ba72b955a485debac41f4eaeabfde1ce927e0fc928a6ab93d043282cd5b374e8a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 30 Sep 2025 00:03:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工大学与Netflix Eyeline Studios梦幻联动：8K图像、4K视频电影级高清生成来场“免费革命”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em7A7COb17nQf31AE47sosc4L7RZKDseEZ4cC6VyZUSs31ZiahjEg62tIOzTy16NCzmEKHLv3NBuQQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>南洋理工大学S-Lab与Netflix Eyeline Studios研究者合作，提出全新推理范式CineScale，以解决视觉扩散模型生成高分辨率图像和视频的核心难题。受训练数据和计算资源限制，多数</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495924&amp;idx=1&amp;sn=9fadf389b4dd6b481a5e881490e99833&amp;chksm=fdf89321006b5ea18f5b764d9d25dcb2ca4c91b2e178c834b9eb16935054efc2b04c94bb3430&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 29 Sep 2025 00:05:00 +0800</pubDate>
    </item>
  </channel>
</rss>