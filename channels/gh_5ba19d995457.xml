<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[效果炸裂！Controlnet作者新作FramePack颠覆视频生成编码，6G显存即可完成单图到60秒视频生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enVH0KHB0ibRLR8832tzUvuvUibuQww4kQjU0wfGW53cHlodyDyxiaOOdpiaia1bE6iaBV5JtOvtQrTaZZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，Controlnet作者又提出了一项效果炸裂的工作FramePack，它是一个预测下一帧（下一帧部分）的神经网络结构，可以逐步生成视频。FramePack 将输入上下文压缩为恒定长度，从而使生成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491758&amp;idx=1&amp;sn=c6d0a711beb71e4079e898e6e0372cd0&amp;chksm=fdaad40b0160133340cae79462fa0c14714b08e2aa82ce3f47c5674145045b15f5e90891e54c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[何恺明ResNet登顶！Transformer上榜，Nature揭秘21世纪引量用最多的论文！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enVH0KHB0ibRLR8832tzUvuvv61hliaCtCmwKxj7UnYBmnEjyQGdzZlWPCTFficm9IuyicCN1lurhYgVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文转载自公众号：小白学视觉 如有侵权，请联系删除~21世纪第一个25年，AI领域被引最高25篇论文都有哪些？近日，Nature头版独家文章，揭秘了不同科学领域最具影响力的论文。然而，令人意外的是，那</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491758&amp;idx=2&amp;sn=80e5d9127eaeac1c02f36008e753462c&amp;chksm=fd248ee85636e99d14a07739bc1e7379ce41dfdacfba0703a9aba13569d4548e655d8b23034a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌研究院联手牛津大学推出Bolt3D！7秒内单GPU生成高保真3D，推理成本直降300倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LR8w1T4XSJwAUg3UkzLpMRYxbTOuSXUEpxZVs5u18QTNFMFHe41E6SY6vfhMbJicRDetQWdibB3Nicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Bolt3D: Generating 3D Scenes in Seconds论文链接：https://arxiv.org/pdf/2503.14445开源代码：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491758&amp;idx=3&amp;sn=936f190bd28ac27b2c6c3b3900447811&amp;chksm=fdaa1a0bdd88e3c6a4eeb0c48031f9546be9aa562051b8df0b8745fc7ff5888ecd11b98c3fa8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科&amp;腾讯&amp;清华提出全球首个多模态Mamba生成框架ACTalker，支持多信号输入，数字人嘴型同步再升级！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enM1R1hvr6fIvNPnJ8HAkjER32Qr4uJljRDnNXhyE9UPgfaB2EKia2QjfDCSEHzibXgefW4NfoP8eNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由港科大、腾讯、清华联合发布的全球首个多模态Mamba驱动框架ACTalker，它是一个端到端的视频扩散框架，支持多信号控制和单信号控制，用于生成说话头部视频可以实现单/多信号随心切换，虚拟人嘴型同步</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491758&amp;idx=4&amp;sn=99758216ac460e8e82af4b4d2813cac0&amp;chksm=fd21d79c4abea941273c73e9270ba86f4e834aaf434540e11eec5e60c23e091bd6c7f88a828f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[国产大模型崛起！智谱发布GLM-4-32B-0414系列模型，以32B模型参数比肩GPT-4o和DeepSeek V3/R1。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrSjMIibqt135GUNpF74oSRYLehSt9CiaiaT3MS7ayLtSBpHpyh03jHVRicB4mTXFAFrcxYfczfgicIicw/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025年4月14日，中国AI领军企业智谱AI正式推出GLM-4-32B-0414系列大模型，以32B参数量实现全方位能力跃升。该系列创新性融合对话、推理、沉思等多元智能模块，在基准测试中展现出与GP</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491714&amp;idx=1&amp;sn=82390977ec0c5d9b2f26cba235883529&amp;chksm=fd842063da3889b18949bb45539ea5b2827b0f00fd2519b026041c77d9cc05c5eabe44af53f6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文了解 DeepResearch：AI 如何重塑深度研究与知识整合]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIo0ia75NSGFsObsIAKtZ35qIl2VrDtpaxMVkxU4QsGhZJdF0ZqOibRyJfONRdRTChR9oaFpPcAt00ug/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，AI 工具逐渐从“快速问答”向“深度研究”跃迁。DeepResearch（深度研究）正是这一浪潮中的代表性技术，它通过多步骤推理、海量信息整合与结构化报告生成，将原本需要数天的人工研究任务压缩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491714&amp;idx=2&amp;sn=07ae87a8d27c8761dc2c70e6d7744f4b&amp;chksm=fdca09e1e6d88745a2f753ca488a6dd8c5b3e71554d373e09e4b94056f926bcdeb5f88a76a19&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[亲测 Gamma：AI 3 分钟生成 PPT ？手残党终于告别熬夜做 PPT 了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/QFmOy9B4XPVTT2F1h8DGp36exXCjxbSoGz6F6HJzY55rxmSjdgMlpevllEeZeHeGIgw8U0h6mcoZ5EJ0BhIuBg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Gamma 是什么？Gamma 是 AI 驱动的智能内容生成工具，支持自动创建 PPT、文档、网页，具备智能生成、数据可视化及协作功能，适用于高效内容创作，用户超 2000 万。详细介绍请见：http</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491714&amp;idx=3&amp;sn=8d4124e35e8caa94cb51cf3b343c3774&amp;chksm=fdef506e580b841e1cc7d8c8b03926c92cd51a7b69d95dada060387125fa1faf50e37862ed8d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像自回归新范式！阿里达摩院提出FAR！基于频率渐进自回归的图像生成方法！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JPYPxZ0MuUMXoVibiaerdXl1DDoy0kTu2GjoCXlazeNXCg7hSOWlH2Ro8Hoa0ic6nBbib4HK1KxZqYfg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Frequency Autoregressive Image Generation with Continuous Tokens论文链接：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491714&amp;idx=4&amp;sn=51dc6f9906af47b9521d4abe0668a02b&amp;chksm=fd2a8e555f4b5013cf9b8b170d6fd239c6cdce544e24b47e50277f2c725da3c94e5226b01eab&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 16 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科&amp;腾讯&amp;清华提出全球首个多模态Mamba生成框架ACTalker，支持多信号输入，数字人嘴型同步再升级！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enM1R1hvr6fIvNPnJ8HAkjER32Qr4uJljRDnNXhyE9UPgfaB2EKia2QjfDCSEHzibXgefW4NfoP8eNA/640?wxtype=jpeg&amp;wxfrom=0"/><p>由港科大、腾讯、清华联合发布的全球首个多模态Mamba驱动框架ACTalker，它是一个端到端的视频扩散框架，支持多信号控制和单信号控制，用于生成说话头部视频可以实现单/多信号随心切换，虚拟人嘴型同步</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491672&amp;idx=1&amp;sn=1b625ac11a69f2a532a5bcb54f5386eb&amp;chksm=fd54553c80e45449bb8a43ae06c3c1f0292422b0cd17870fc031b77521e1ac54faac448b689e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动提出Phantom！跨模态对齐技术实现人物/多主体完美复刻，秒杀商业方案！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KzuUcZfmYlEFYZuGCx2cwAo1ZveWrPs09xOpJ6D7GNsfhvSKKkKfW9JFbCyn6Zib3Libdye5cVxqsg/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Phantom: Subject-Consistent Video Generation via Cross-Modal Alignment论文链接：https://arxiv.org/pdf</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491672&amp;idx=2&amp;sn=794fbe973cc97abf85486e5e257fce80&amp;chksm=fdae3139c8d3bd6ee620a77c6055f89df2ae282f4cb85c25ad9a7ff78c8f1884d6c084728f37&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[报名 | 参加AMD AI PC应用创新大赛，开启PC端大模型应用的无限可能]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enM1R1hvr6fIvNPnJ8HAkjEQZUFqNI9w4UPPYibGrzdkC9oCvIXIQQJ8U82VlW8xl0FpP383mU4d9A/300?wxtype=jpeg&amp;wxfrom=0"/><p>3月18日，由始智AI wisemodel开源平台与AMD AI PC应用创新联盟联合主办的 “AMD AI PC应用创新大赛” 正式拉开帷幕！本届大赛以“AI PC芯进化，始智AI塑应用”为主题，为</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491672&amp;idx=3&amp;sn=3d94627b3ff22f117a223788b74f6d2a&amp;chksm=fdf0e476ff0c8bfc2e7af732f7d17da5973263b94bcb5beb9eb5d05707f75f80395d2fa1649f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IC-Light升级，支持视频重打光! RelightVid可在多视频场景中重照明，支持文本提示、背景视频和HDR输入！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6QSiaic7OicOck7L6SeBvmG8KxGGhaK7IiaIoGtBJsFyM7LffJExAYwxgr09hKHicONPnN40NOq3Cib7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经和大家介绍过ControlNet作者关于图像重打光的工作IC-light，这篇论文也是获得了ICLR2025的满分评分，感兴趣的小伙伴可以点击下面链接阅读！ICLR 2025满分论文，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491672&amp;idx=4&amp;sn=337e337042840a1436e37c370ec43e5e&amp;chksm=fdf6000c8c2b14d4f1b2e1be09a956a11cd9d492b4415461859a5446544c9066766d30e64b0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 15 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IC-Light升级，支持视频重打光! RelightVid可在多视频场景中重照明，支持文本提示、背景视频和HDR输入！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6QSiaic7OicOck7L6SeBvmG8KxGGhaK7IiaIoGtBJsFyM7LffJExAYwxgr09hKHicONPnN40NOq3Cib7A/640?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经和大家介绍过ControlNet作者关于图像重打光的工作IC-light，这篇论文也是获得了ICLR2025的满分评分，感兴趣的小伙伴可以点击下面链接阅读！ICLR 2025满分论文，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491630&amp;idx=1&amp;sn=03162a462c4025c65ae6f1d7a1ad332f&amp;chksm=fdd66edf643561fcdb3550f052fa3a4a03ae607d41b489c2b4b33c3c40a85cbf3fd028d8697e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491630&amp;idx=2&amp;sn=15446b06bd235afeb8b1687101b53c1d&amp;chksm=fde32da14e44d2e2dd046ec0f179f1537ec939bceb2790abceeec9c73079e7e60bb14617723d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[重磅更新！微信电脑版终于能发朋友圈了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/ufjNzkFC4A99CWiax2QiacLHCY4N1ZenUOyGOkz05mBgURtBNZNNzb1O4snXCdrRxOMl544oYzZIE9FmmDZ4J5Qg/300?wxtype=jpeg&amp;wxfrom=0"/><p>小伙伴们，注意啦！注意啦！微信搞了个大动作！是不是早就受够了每次想在电脑上分享点啥，还得费劲传到手机上才能发朋友圈？是不是觉得手机屏幕太小，编辑图片、输入文字都不够痛快？现在，这些烦恼终于成为过去式了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491630&amp;idx=3&amp;sn=b28637cd9dd18ed1a0f6379477a067ae&amp;chksm=fdc34b3e8b3e41ae9457a50179122dcf13682397c2492c3ad0fff147d63b9430ee02e3db13b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 14 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[数字人技术再突破！阿里通义提出OmniTalker，从文本联合生成语音和说话视频，支持多种生成方式！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6QSiaic7OicOck7L6SeBvmG8JRgruibZuliaJSvFriclbaGicqlZbMYa8d9u3Ns893AfuuuFKCznZpHlIw/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里的通义实验提出了 OmniTalker，一个从文本联合生成语音和说话视频的统一框架，它减轻了现有方法中冗余计算、错误积累和视听风格不匹配的痛苦。支持零样本上下文多模态生成、情感表达生成、长视频一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491560&amp;idx=1&amp;sn=90072b66ce54651944fc35cff2e730f3&amp;chksm=fdcfda7e572ed1a7f47f0dc045f8b08a021f467839b1ba46f54ddcc128f4b1e3445523a20a35&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图生3D新SOTA！港中文&amp;字节&amp;清华联合提出Hi3DGen:通过法线桥接从图像生成高保真 3D 几何图形。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elT6Ok13J4tBFt6yibibVpmCofpeSCJb5Do6ZzCr2Yv2wPial5QS5sdppZe8K6ubyDPzv4yf6QNaOicHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学联合字节跳动和清华大学提出Hi3DGen，这是一个通过法线桥接从图像生成高保真三维几何体的全新框架。Hi3DGen 由图像到法线估计器、法线到几何学习方法以及三维数据合成流程三个关键组件组</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491560&amp;idx=2&amp;sn=172267fa27d10ec4a7a2e961d9075efd&amp;chksm=fd41f427233a1bc62bfe3cf79e41b2e462d4c565973871cfa7d813e4238314f4871ef5b5da4c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里千问发布QwQ-32B：性能肩比DeepSeek，只需DeepSeek的1/20参数，一张显卡就能跑！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elm4qdlMbfjmuJgIxhRCCZMUfMpZODzQtQmnYnAEn7bib3y95h2UThFE6yARUMTLib5icEnhmaaCf8BA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里云发布并开源全新的推理模型通义千问QwQ-32B。通过大规模强化学习，千问QwQ-32B在数学、代码及通用能力上实现质的飞跃，整体性能比肩DeepSeek-R1。在测试数学能力的AIME24评测集</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491560&amp;idx=3&amp;sn=1ac911cc6976d14827236d5b0b092f19&amp;chksm=fdf95ad06cd6c9989ac5c26051d7ebcfba164bd64e0b07456688c0fa43967514fadbee8e4bbb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 13 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出从单一主题发展到多主题定制的通用框架UNO，通过情境生成释放更多可控性。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elo3s89icGNibsPQVXGhctg9WDrsYXyWyFSyqXzUDm6eOsD3G2Z7XbSMUPZrQw19LsCTpuzPx9KiaCWg/640?wxtype=jpeg&amp;wxfrom=0"/><p>字节跳动的智能创作团队提出了一个从单一主题发展到多主题定制的通用框架UNO，从少到多的泛化：通过情境生成释放更多可控性。能够将不同的任务统一在一个模型下。在单主题和多主题驱动的生成中都能实现高度一致性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491559&amp;idx=1&amp;sn=639645a22228dab4764a6b5df4e3fa9d&amp;chksm=fd7564bf3ab25d3dc0847e77dff0f8e28edbdd1db4de7be7a667f0109847117cc6a917bb40c8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TripoSG:一键使用AI在数秒内生成3D设计,支持文本/图像/涂鸦等多种方式，引领3D生成潮流！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eks71KCI53QzfLjA27o9Yf3eNhhBOwNK1fL9KrI6VvmwpTtHQY75YN6kpUNFib9wnGUtDzn1YjAYicw/300?wxtype=jpeg&amp;wxfrom=0"/><p>TripoAI发布了最新3D生成模型 TripoSG，能够生成与输入图像精确对应的高保真 3D 形状样本。涵盖各种复杂结构、多样风格、富有想象力的设计、多对象组合以及细节丰富的输出，展现了其强大的生成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491559&amp;idx=2&amp;sn=71146edef2259a19c90e560617d2dd22&amp;chksm=fdec50a944a5b0be2617e59f3a56fceee9ef477180b93e71a1b3e18d052d115463539f4422f2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[olmOCR：重塑PDF文本处理，让语言模型更智能、更强大！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4IAQ3D7RpAMNb2namtUvCm06G4XyBQk2BvFF6sibwR50ffvQBeE8kk0ZM9vwsVG26eMLdZ9kcia7w/300?wxtype=jpeg&amp;wxfrom=0"/><p>olmOCR，这是一个高性能工具包，旨在将 PDF 和文档图像转换为干净、结构化的纯文本。 olmOCR的主要特点包括：高精度文本提取：经过大量多样化PDF内容的训练，采用独特的提示技术，显著提高文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491559&amp;idx=3&amp;sn=8c4ee79019ce09133bed581224fd4de2&amp;chksm=fd0fd92d375ba66e0550514a0046c848f3591377724d17135efc161d0382d9bc488bdcd0717a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里提出OmniTalker，从文本联合生成语音和说话视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>阿里的通义实验提出了 OmniTalker，一个从文本联合生成语音和说话视频的统一框架，它减轻了现有方法中冗余计算、错误积累和视听风格不匹配的痛苦。支持零样本上下文多模态生成、情感表达生成、长视频一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491550&amp;idx=1&amp;sn=9507ebb318c2c260cca1860542a91a27&amp;chksm=fd14c7201a7cd01a3ee64709429ef873d04dd2fb8159b038172b10f7450d23cacbb310e85f13&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 15:12:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[RelightVid：用于视频重照明的时间一致性扩散模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>IC-Light再升级，由上海人工智能实验室、复旦大学、上海交通大学、浙江大学、斯坦福大学和香港中文大学联合提出的关于视频重打光的工作RelightVid，通过将可训练的时间层策略性地插入到用于图像照</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491511&amp;idx=1&amp;sn=223eae92ebfbc8c760fdb57421c39bbf&amp;chksm=fdd0a00a30cee27a4344754dc5d1d078823ce360070499c7bdebeb6b8c2c7540050410007fe9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 12 Apr 2025 14:21:32 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像生成DeepSeek时刻？智象未来开源文生图模型HiDream-I1，17B参数，GenEval和DPG基准测试第一名！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elo3s89icGNibsPQVXGhctg9W5iczBicOxr6k4cDCticwRARx7pOBpia2hheia0mlyLr72FZAw8RVic6WBRdw/640?wxtype=jpeg&amp;wxfrom=0"/><p>来自国内的AI初创公司智象未来（HiDream.ai）开源了一个新的文生图模型：HiDream-I1。HiDream-I1是一个拥有17B参数的新型开源图像生成模型，能够在几秒钟内实现最先进的图像生成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491461&amp;idx=1&amp;sn=310f8f1306dd95df0796361bc8b7c397&amp;chksm=fd3771fdf85e345156a2c28da51037b792cdd309e927fc9a346877f0f82e98b1bdfc8d63650f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图生3D新SOTA！港中文&amp;字节&amp;清华联合提出Hi3DGen:通过法线桥接从图像生成高保真 3D 几何图形。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elT6Ok13J4tBFt6yibibVpmCofpeSCJb5Do6ZzCr2Yv2wPial5QS5sdppZe8K6ubyDPzv4yf6QNaOicHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学联合字节跳动和清华大学提出Hi3DGen，这是一个通过法线桥接从图像生成高保真三维几何体的全新框架。Hi3DGen 由图像到法线估计器、法线到几何学习方法以及三维数据合成流程三个关键组件组</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491461&amp;idx=2&amp;sn=1702a2cb23c2cad055bc9dbc0f871a6f&amp;chksm=fd2a8ff7759d34e825c8df6649064f1ab0f168e943826ca75b1b8885c5977b293b9ea4728955&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[奥特曼难以入睡！ChatGPT 解锁完整记忆，所有聊天记录 AI 全知道了，包过“黑历史”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/QFmOy9B4XPWNOCnGUSTE5ATyicG6XmmGJ68x9KZL1JB4AkhUnT4SReTibtRlnWicf0yopNdNmmEiaGLn9icNic9Ogtcw/300?wxtype=jpeg&amp;wxfrom=0"/><p>4 月 10 日深夜，OpenAI CEO 奥特曼发帖表示难以入睡……变相预告要搞事情。11 日凌晨一点多，他发帖公布了“答案”：ChatGPT 解锁记忆功能，可以参考过往所有对话。我们在 ChatG</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491461&amp;idx=3&amp;sn=0d9d8af4ae42da51be81bd11c756e2a1&amp;chksm=fdf32250a4aeb9c9629f3bb88f5d5befadb63427bd6a1bd077fbccb54248c88e1d665964f453&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 11 Apr 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>