<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/XzhF92tBcezMLGZN5TwHm01JzyB611PyibhFUMaiaE6xaTcU7nCAumRAicJowUjC4ntxOOAkSvxOK0/132</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[3DGS突袭牙科！3张照片搞定牙齿重建，以后看牙能省多少钱？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/rFGeIHcFicWdl0NlQrDf62AKUIicMQr1mhia1opB4iavfBwzrH2vkA9XGib3O5CiaFl3ruicAG2Pb1iaHoEzS8PiajR6zGw/640?wxtype=jpeg&amp;wxfrom=0"/><p>正畸治疗中，尤其是远程医疗场景，从多个视角观察患者的牙齿咬合情况，能帮助医生快速做临床决策。3D高斯溅射（3DGS）在3D重建和新视角合成上潜力巨大，但传统3DGS需要密集的多视角输入和精准的相机位姿</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496768&amp;idx=1&amp;sn=f59975f094665d9b233f159448f2d1ef&amp;chksm=fd223182dcb24b2d0ee2bb32eac7edf4808d5b7139ea83ae07f9438aacdc2ba4a6de49d6fc51&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 09 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[专为边缘和低功耗设备而设计！原生的端到端模型 YOLO26 来了！浅浅解读下这个更好、更快、更小的模型]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQgbIXEsrgOMkqgEp1QnDtlSRnzqvbmu3uIq58ZEIE7UzZE1Fo5VKeyqkmgptntkgdj5ZEjs6soVRg/300?wxtype=jpeg&amp;wxfrom=0"/><p>预计十月底正式全面发布本周，Ultralytics 预览了 YOLO26 ——可以分析和解释图像和视频，其精简的架构兼顾了速度、准确性和易部署性，且有望成为 YOLO 系列迄今为止最重要的版本之一！为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496768&amp;idx=2&amp;sn=06085ff874f7ffd6c2ed87b4623aaecb&amp;chksm=fdcd701c40a523f0a0e7eeb5171b27734de99d300ec8b4bb68c4ee81c6d6670cd73b42df585c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 09 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[国产AI模型GLM-4.6硬刚Claude Sonnet 4！200K上下文窗口+工具增强推理，重新定义多任务AI代理。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ensv02pBKeqkonEQJOUXibY7hzAbyZn7bwmuBUKUeOolM1ExcrLibyiaGAibN6bSJb55S90be9iaWL1V3w/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！与 GLM-4.5 相比，GLM-4.6 带来了几项关键改</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496768&amp;idx=3&amp;sn=e76f6631c93fd1ecba0bd77554fc1858&amp;chksm=fd079f75ca608aec768c0de62a36b7aa5c1734dd6b317d3d2a70a08712770dbf0f6a5f711f93&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 09 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta 开源视觉大模型 DINOv3，尖端图像表征，无需人工监督即可训练，数十个视觉榜单准测试性能SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emC8TzOo0tTPOfwjIibibRDG0V8FDngTwB5bIGKr0RDuL4kJibH8eGgHeZFrbt39SzRkrsY30LsWE7iaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Meta 发布了 DINOv3，它可以扩展图像的自监督学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496768&amp;idx=4&amp;sn=ed87582501ed4fe674e2ce0754d9b49c&amp;chksm=fdecfb3c9565ed57b0f6a06f498a194b71d0b039d207ebb2ee013375ba5e68c2ab2f4e3cf953&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 09 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq5BIttmnJoy6onMGT6hEJiblmfujJkZFpZjpO6usAYRtw7aj1tZbJZYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元团队提出的 HunyuanVideo-Avatar 是一个基于多模态扩散变换器（MM-DiT）的模型，能够生成动态、情绪可控和多角色对话视频。支持仅 10GB VRAM 的单 GPU运行，支持</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496768&amp;idx=5&amp;sn=a7da6e57855fdecbb5e5afe56ad53fd0&amp;chksm=fdffb9bd616a03d3792ff6ab9128730e9e5265e43f1428eeaeb1c3a187b82baf25e976b7bb25&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 09 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 华科&amp;国防科大提出首个水下多模态大语言模型NAUTILUS：专注水下场景理解，数据、模型已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldq5qbwYfiaaYm1UX1zcd4pQZNuvtW2toibycwCLgeHBnASv8Xic47VuD15NLTNY6n5tLOw3UXo2KgA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！华中科技大学与国防科技大学的提出的水下场景理解的大型多模态</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496752&amp;idx=1&amp;sn=cffbf520bee57540e8c7782a927b6695&amp;chksm=fddbfd84ce6ff19b7eff079ae85431294707f32063868f5fac4560cc78af37a7282bd6f661c9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Nov 2025 00:17:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[企业出海12种语言通吃！Granite-4.0-H-Small的多语言对话与代码任务一站式解决。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ensv02pBKeqkonEQJOUXibY7IshyjbmRNO5pcahaUUlTrLUIUgvPcIZez3YaJRB1G7lf8mbd37P0Cg/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由Granite 和 IBM 发布的 Granite-4.</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496752&amp;idx=2&amp;sn=3aa7a3025cab88df15f258bbbef3a8f7&amp;chksm=fdfc9f809419195aa98b7a1d0e0df4ee860beaaf1ff1c66070040453cb1280134154ee59cb69&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Nov 2025 00:17:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一文详解具身智能：世界模型（World Models）系统性综述。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic5pz1CM8LfC8yORHD0VTynbjNDWncib8icQlxHjBmzvBkXhHmyVvpTaPty0mG8HiaibJpWLxbia0IYVd0w/300?wxtype=jpeg&amp;wxfrom=0"/><p>经典文章回顾：一文梳理主流大模型推理部署框架：vLLM、SGLang、TensorRT-LLM、ollama、XInference一文梳理主流热门智能体框架：Dify、Coze、n8n、AutoGen</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496752&amp;idx=3&amp;sn=dcdb9f90c98f1fb55d459513a22444a2&amp;chksm=fdb047c0de93de19090835345a44e30afe96fd6eca8d84a63c48a2eae38f97e0cdaab7c584d0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Nov 2025 00:17:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯开源图像模型SRPO，真实感和美学质量提高了3倍，登Hugging Face趋势榜首！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enRCOcZd8CRVzXYG49RMN97ibJribFzxBFTwTyg1jpicjl2ia5ib90EbEicynEG6BFZptqSZRliceZd5yDhw/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！之前不少AI生成的图像画风“油腻”，效果不尽人意，而这一难</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496752&amp;idx=4&amp;sn=a9d16934f23f484d494f211d6e4592be&amp;chksm=fd591eea951f68639f8d079bffb001a7da783b557c6f90bb0c4d54e60b9877015bc9525496f3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Nov 2025 00:17:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[3万字长文！通俗解析大语言模型LLM原理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsF9IX893mLWvOX1icNGOEu8rqxnLlXRvSOvWuY8zfQr9TzNSmiaPxawVGgO4V6UkI4L9HTqMUXib3JbA/640?wxtype=jpeg&amp;wxfrom=0"/><p>为了便于大家更系统的入门和学习，最近，我们会为大家分享关于AI智能体的系列内容：《Hello-Agents》项目正式发布，一起从零学习智能体。第一篇：关于智能体（AI Agent）入门，一篇超详细的总</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496739&amp;idx=1&amp;sn=d6274e88a7e5a8c8699ec72697c69e83&amp;chksm=fd4dc2138e5dca7fbae9891f127874fa840bbae2849e350a1aca66070b5ac66ae05006710fea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Nov 2025 00:18:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI 上云了！告别烧显卡时代，Comfy Cloud 公测正式开启]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE5gw125WDQR6JkGA7JHM6IzQPAgMJjQOTtCjbCU8LMIiakg7QV647SzRQWKibuJYm9ESLXbRaEHvwWQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击蓝字关注我吧！今天要给大家带来一篇深度解析文章：当你还在为本地安装、显卡卡顿、版本冲突焦头烂额时，ComfyUI 母公司推出的云平台 Comfy Cloud 正悄然开启公测，无需等待等候名单即可加</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496739&amp;idx=2&amp;sn=60d99e18e64cf640a3c78f4609975ddf&amp;chksm=fdfb9137300929bf03968142f766dfc3deb85a65d72f01389cd4fbd620e59c0a49d26d3e2180&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Nov 2025 00:18:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 从分割掩码一键生成万物！复旦&amp;海信提出Seg2Any:图像合成新范式，颜色/纹理/文字全可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek3ORJ88CbY3YmZiao4rvXjCRD8YLULXKAFg4g7wHuibM1T7HDbxHWJlYjrWmhwIiateCCWicNibDicW1HA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！复旦大学、海信研究院联合提出的 Seg2Any 是一种新颖</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496739&amp;idx=3&amp;sn=133ead9dcdf7c229451349d3573bc07f&amp;chksm=fd167a232aa669e19ec1f024dc74e3ce581607d8ae8e997b760011983bbac95c1430fa2dff03&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Nov 2025 00:18:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[港大和字节携手打造WorldWeaver：以统一建模方案整合感知条件，为长视频生成领域带来质量与一致性双重飞跃。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em7A7COb17nQf31AE47sosc3PBhd8BUJBTSIw4pBEu72icufaSlsibUTsWicGB5DFhIbyib4vjd7Hby3Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>生成视频建模虽有进展，但长序列结构与时间一致性保障仍是难题。现有依赖 RGB 信号的方法，会使物体结构和运动在长时间累积误差。为此港大和字节提出了一个长视频生成框架 WorldWeaver，它在一个统</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496739&amp;idx=4&amp;sn=25331aef121e6af02c804a0cc2baa34b&amp;chksm=fd140aa9dfd776c80192515c3de76ed1081354534d6190b100100836d50ecd82379bea925306&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Nov 2025 00:18:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 多人生成新突破！复旦大学联合阶跃星辰提出WithAnyone，让 AI 合照不止“在一起”，更像真的“一起”。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emQKGZTwb4erK5UqoPicKiaNxVzoYkr79DnNXK3aKJJibRbwoLX7gecMfYQiaGQ17CtE0dzZv4ULHuqLQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！让 AI 合照，终于有了“在一起”的真实感。过去的“AI</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496738&amp;idx=1&amp;sn=3e7cb71675148f17870cf39186e7e540&amp;chksm=fd3c883c739eed6240c84497f06b5f5d4c6d12e71d63215e40b07d2b32cbaa49df4db35607a4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Nov 2025 00:13:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一文详解具身智能：世界模型（World Models）系统性综述。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic5pz1CM8LfC8yORHD0VTynbjNDWncib8icQlxHjBmzvBkXhHmyVvpTaPty0mG8HiaibJpWLxbia0IYVd0w/300?wxtype=jpeg&amp;wxfrom=0"/><p>经典文章回顾：一文梳理主流大模型推理部署框架：vLLM、SGLang、TensorRT-LLM、ollama、XInference一文梳理主流热门智能体框架：Dify、Coze、n8n、AutoGen</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496738&amp;idx=2&amp;sn=9fe40e472fac5cb9a8b3968905b253cd&amp;chksm=fd3bc16935e846c4124789bf3d4c297f1f64e6ccc45f49e87d30e6c9fb7a9d2dcdaafafdf017&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Nov 2025 00:13:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[手机上实时跑3D数字人？阿里开源MNN-TaoAvatar，打造本地离线智能数字人新标杆。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8O7Mx0HicAQzYnr62ZEJLwjCaTF4Xg9G65OJibjU82ibBkicGN8Zdt93yM9ibvqO1zSU5WvX0ehVP4QA/300?wxtype=jpeg&amp;wxfrom=0"/><p>TaoAvatar 是由阿里巴巴淘天 Meta 技术团队研发的 3D 真人数字人技术，这一技术能在手机或 XR 设备上实现 3D 数字人的实时渲染以及 AI 对话的强大功能，为用户带来逼真的虚拟交互体</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496738&amp;idx=3&amp;sn=b0398a90b2bb0c2efad9ea6f33402866&amp;chksm=fdf64a82f37f646a4e5fff7746bf657a66c347b547fc4cf910a97a6c3f9d3cba83a9727056bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Nov 2025 00:13:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[PlayerOne横空出世：港大×达摩院重塑虚拟世界交互范式，动作捕捉驱动AAA级场景自由探索。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enfUCFX9WW23BajIFJBpRq3xvD6IHNj8gocPOicHAPyQsE13dEpzsl31yyrObIKhz86FlHOmK6LtVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天介绍的文章来自公众号读者投稿，由香港大学与阿里达摩院联合研发的PlayerOne模型正式亮相。该技术突破传统虚拟场景构建范式，通过单张图像输入即可生成高保真动态虚拟世界，并支持用户以实时动作捕捉实</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496738&amp;idx=4&amp;sn=aef257145a5766b13835f8052899418a&amp;chksm=fd1df66bc9881447e4954a7f745f77717fc87160cf291a5615b697e0c13c1ebeb62d45ec35bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Nov 2025 00:13:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑迈向新高度！天津大学&amp;快手提出GRAG：4行代码搞定图像编辑精准控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emoK0Qlia1UfbJSCCnEc0R0Pe0jSiaicKfViaLawMO9H5PiakeJsByEWZNExJiaqQechJad9icicdzmlx7osQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！天津大学与快手科技的研究团队针对基于扩散变换器的图像编辑技</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496718&amp;idx=1&amp;sn=0bc3d69e431d6b7ade205022012d8b2e&amp;chksm=fdfe48f73b376c6c310a359fe393e01e46cee2cc623fef7479dfe854ac78087a3525758c8775&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[3万字长文！通俗解析大语言模型LLM原理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsF9IX893mLWvOX1icNGOEu8rqxnLlXRvSOvWuY8zfQr9TzNSmiaPxawVGgO4V6UkI4L9HTqMUXib3JbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Datawhale干货 作者：陈思州，Datawhale成员为了便于大家更系统的入门和学习，最近，我们会为大家分享关于AI智能体的系列内容：《Hello-Agents》项目正式发布，一起从零学习智能</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496718&amp;idx=2&amp;sn=23d991371d85d08d6416580e976976fc&amp;chksm=fdd53fd45772bce4afd1fd6dc1363dee87fea875a573e442d6e2b59a8cef96a35380212e8edc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 图像生成新宠！StepFun 开源 14B 参数自回归模型 NextStep - 1，图像生成与图像编辑一键搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emLic2Rhpf3QYj2hoRbhoUGYqUKvsakZV7mEREOapr4qUib9cuiaq32lm19qdE1FqCHAiaWqbRdYekc5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！在科技飞速发展的当下，AI 图像生成领域正经历着翻天覆地的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496718&amp;idx=3&amp;sn=1b5db3bf4febfe13b7b75115400a89e9&amp;chksm=fddaf9da7405d606ec7ead8acb0508c1af7792b5582befe6bc00a5dd642dfb91db85af8ba467&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[CLIP为何搞不定分割与检测？哈工大团队开源通用视觉任务新框架：突破开放词汇稠密感知瓶颈！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQhStl9HDM6GcOr3QDheUhWnTstzlpacic9HQc2VSI1YMX5Lafwo6gBia6Jqbia9MEWd5YYGYjR5Yu5Ow/300?wxtype=jpeg&amp;wxfrom=0"/><p>面向2D检测、3D分割、6D姿态估计的通用基础模型基础模型已经改变了计算机视觉领域：CLIP 首次将图像与文本连接起来，DINO 擅长捕捉语义结构，SAM 提供精确的分割掩码。视觉领域需求更广泛的任务</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496718&amp;idx=4&amp;sn=1ee4ba0fb5b311923c84dd34d2edf89b&amp;chksm=fdf72c6c4bab91a3336b868d6b4c8a64c62e52e7886d6409a2c17d66d098cbb76d1ae0c83eed&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UniVoice：首个在大语言模型中统一自回归语音识别和流匹配语音合成的框架。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elVvJqr6VPt6K3YBxNuIKgoJVth6pTQebiafMjJmYHFwu2B7mAMbokhUFImUX3oOrhYscl1nc6apsw/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！厦大联合上海创智学院等单位发布统一语音处理框架UniVoi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496707&amp;idx=1&amp;sn=7728bf3aa1786706cc7dcf052bd0a0c5&amp;chksm=fd29c2411fcdd31534fd8c596b006e183d2c7a377d14e99fadc266c57783fbe9a309ba2955d4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[达摩院提出ReSpace！自回归文本驱动3D室内场景合成与编辑新框架！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IUS026bgrHtl19k8iaTzNl8icef5pd4T4TvpwHoxzu1cyROia6klKjBkbZgib9aibULqBb20gpjfNRAAw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：ReSpace: Text-Driven 3D Scene Synthesis and Editing with Preference Alignment论文链接：https:</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496707&amp;idx=2&amp;sn=162b39804a40f1937a5bd3533f42ad4e&amp;chksm=fdd28c06900ca70089c3c9ebe47291f1b40d26d50cd73aa8b002bf09add5122830abecef0095&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496707&amp;idx=3&amp;sn=5d67e5585794f3f1bee7bb3f8e2491b9&amp;chksm=fddc1f6e9255ebbb23f46e930ce4e7e1a8627abf3062d9f24f1f3c5d7446fe0fa62ca0ad9a05&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源 DreamOmni2：多模态赋能突破传统局限，开启图像编辑与生成新高度。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emscrJryeqES6ReYP0UJe5EkqpQLGatVsmugRb4g89uJjGPQGQicLcM9ia3nWD6Tk4BLQRmypU88fSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！在图像编辑与生成领域，基于指令的编辑和主题驱动的生成虽有进</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496707&amp;idx=4&amp;sn=9e76c77760c6066cd30423480979d879&amp;chksm=fd135e0e0c520e1d0d0da949bc5c0bb0700f592f0b5f1bd2fc946d59092770f306e2ff8ddfb8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | DiffusionGS：将 3DGS 嵌入 Diffusion，高速高分辨3D生成框架，代码模型已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloAh0Z3Ac67GJibRojdPBlyBsYqYkVxV5a3O8glFeYcNxKwOL6t6Z2OegJRzO3SwARE1HH5DEiaWSw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！本文来自公众号读者投稿，作者是约翰霍普金斯大学计算机科学系在读博士，于2023年和2020年获得清华大学工程硕士和</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496701&amp;idx=1&amp;sn=392f65928c9eb267eb1914adc82692a8&amp;chksm=fdb6fb0ba0665560b145b4a4e3cc5a839df2007be741b5ee80f8cacc553012b3ed852c8cbd89&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 智能体简史（万字总结）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsEx7l2IYqNbMTWwMpv8BhFANYaKQPMo9ibG6yPicSoCfzRjAxhnmDORSROkakaMcRmmibiahIlDshwkOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Datawhale干货 作者：陈思州，Datawhale成员智能体是今年非常火的方向，2025年称为“智能体元年”。为了便于大家更系统的入门和学习，最近，我们会为大家分享关于AI智能体的实用内容：《</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496701&amp;idx=2&amp;sn=7a0f1c6a11caceb5108adc9b1a998c89&amp;chksm=fd03118a7d4256c6dc7bfcbd3e7cf642979daa65523b1eadccb629327a1b1aa1d3a36df34476&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[美团提出统一多模态模型OneCAT，一键搞定视觉问答/图像编辑/文生图任务，性能表现SOTA。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPlbWXgYsucwm25tHpGozZiadIia1cibavBMHkk3qMYjW7tFiaEna5OmM5ZcA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496701&amp;idx=3&amp;sn=fca13dceb4fa83bf073ae272f8cfb1e0&amp;chksm=fd1825241afb58b0456091a8845fdcc1f1102bb6314b40b3c9590f288e4b5ffff76ec06fd038&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别复杂命令行！微软 AI Shell 强势来袭，打造智能交互新体验。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPRJ5HXpW3eg5IdOCPZKiaIaVC28jfh8HaybK0oAsfZqADEItEUtNZSJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！今天要给大家分享一个微软刚推出的超厉害工具—AI Shel</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496701&amp;idx=4&amp;sn=6cda6e71bd5c32350456cd9c29b9545c&amp;chksm=fd987f1d4b3e698a09e73dd817aea8fa36aeb1ce211f95416dc8c3f3f4a119eb356630d59798&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯混元开源世界模型HunyuanWorld-Mirror：支持多视图及视频输入，单卡部署，秒级生成各种3D表示！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPdE96iaSHrBWejI3J1cH9ibC4lxLTGpHqTICOKwfsXz2heP3GpicHKxaaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！HunyuanWorld-Mirror 是一个多功能的前馈</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=1&amp;sn=9f9b287b5cb343b6f645345e478ead35&amp;chksm=fd40f74f2c5a17fe38ef0224cd6d1fdc0ef5dbb677fc470be6392e94f71a69fb2eab6157d335&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=2&amp;sn=eec7c1f06e194f07246a07954557b4e1&amp;chksm=fd86534c7ea92f798940090e3632dca0e343e3fa9380360c31c052504071adebed5437c2b372&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=3&amp;sn=90b3d0298ead36f5599f710fbd20d05e&amp;chksm=fdbb09b8efc28bee7b922bad692a3219c640f02358bc57d537cdac0a8153b160984c5ae3fa5a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek们的成本，是怎么计算的？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jEa2NN5eMic76LNKtDbp6JciaVMNpJ0DfXGyCBQINciblWxEtiaW2ibhfotlvKmwWXak89sQiabHFW56grOTBNPjGWfA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek彻底让全球都坐不住了。昨天，马斯克携“地球上最聪明的AI”——Gork 3在直播中亮相，自称其“推理能力超越目前所有已知模型”，在推理-测试时间得分上，也好于DeepSeek R1、O</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=4&amp;sn=56a38929c5bf94b5a36ca7ceccb1a48f&amp;chksm=fd7381a64090e5d742eb4a36d70cb8157bbdb83c4adc0acdbb49f52c17de3b27b621b3d30b15&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别复杂命令行！微软 AI Shell 强势来袭，打造智能交互新体验。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPRJ5HXpW3eg5IdOCPZKiaIaVC28jfh8HaybK0oAsfZqADEItEUtNZSJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！今天要给大家分享一个微软刚推出的超厉害工具—AI Shel</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=1&amp;sn=f0a8032cc0909389e09d443889b98204&amp;chksm=fd65c7afd4b16ee872daf77143478976e33f6d59df050686a87eb4ac3639cbd89542a0348efc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[智源开源EditScore：为图像编辑解锁在线强化学习的无限可能。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPK6iabtkXfBZFRVtgrsE2o1leI63ibKg939BgF4ooKUhWEfSZ10px65Vw/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章来源：读者投稿文字来源：机器之心如有侵权，请联系删除随着多模态大模型的不断演进，指令引导的图像编辑（Instruction-guided Image Editing）技术取得了显著进展。然而，现有</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=2&amp;sn=f01ed4e3a91164b1804e8e5949118192&amp;chksm=fdc5fe89fe469147d0db8f373a59d56c5351955dc9dc1684b989c5c44c96ba70db0a12054581&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布 Waver 1.0：一句话生成10秒1080p多风格视频，创作轻松一键达！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em7A7COb17nQf31AE47soscoy7aHU25oPTiaxHictLptYsN4iafwUx2b2iaBpowibOUZJFdBKXSRcC9ib3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出的 Waver 1.0 是用于统一图像和视频生成的下一代通用基础模型系列，它基于整流变压器构建，专为实现工业级性能而设计。一体化模型：在单一集成框架内同时支持文本到视频 (T2V)、图像到视频</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=3&amp;sn=cdb913c2adaa4af16794fdc99a110ffb&amp;chksm=fd6086403c80c511fb15da9deff091e56c77f7f7224a6b49cb46df07b17f02c20b54ad280aa5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPz0VreR3OZN1Te1uA2ypdJzkVTskDcl9xaYIsjI19fvRWodumj0UZ6w/640?wxtype=jpeg&amp;wxfrom=0"/><p>#视频生成 #数字人 #音频生成 #AIGC 腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=4&amp;sn=dfc65c48f30bbcbcc9c45e119bad03d4&amp;chksm=fdfb0bdfedd91753062647f5f2d2627111ba080e047f1c4bd8970bc13fc31f0fe70585f7a4fb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 图像生成新宠！StepFun 开源 14B 参数自回归模型 NextStep - 1，图像生成与图像编辑一键搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emLic2Rhpf3QYj2hoRbhoUGYqUKvsakZV7mEREOapr4qUib9cuiaq32lm19qdE1FqCHAiaWqbRdYekc5A/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！在科技飞速发展的当下，AI 图像生成领域正经历着翻天覆地的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=1&amp;sn=10d4184e016e0d4949a29fae0537bcbe&amp;chksm=fdadfec1f9ed081783ed4c81446e55e77b921a3b129fb134a3de0e262868ca43e8d306c65986&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Hallo4：让AI肖像“活”起来！新型扩散框架实现高保真音频驱动动画生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq56s1kIaYWsxKESfb9riaHUQVlW3JfPib9AP6mL8Hk0Ec5R0f43HYJ8aw/300?wxtype=jpeg&amp;wxfrom=0"/><p>复旦联合百度发布扩散框架Hallo4，实现了准确的唇音同步、自然的面部表情，并能够稳健地处理各种角色身份和环境场景中快速的语音节奏和突然的上身运动。相关链接论文：https://arxiv.org/p</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=2&amp;sn=a037eb00617587dd7061341aa19cd78b&amp;chksm=fdca80ba23508a175006b987deef38fc07c06f3f070bb78274abe4f1589e317dcd57e632fd5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布风格&amp;主题优化定制模型 USO，任何场景+任意主题自由组合，高保真一致性输出，模型代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elxI31iaYSzUGibFXibPx7ZT4tiafa1OQy2cwOTRicY23d73sOIEARSenF8FaojlXibI1Q8d3s4ciaNzpl8A/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节推出的USO是一个统一的风格-主题优化定制模型，也是 UXO 家族的最新成员。USO 可以在任何场景下自由组合任何主题和任何风格，输出具有高度主题/身份一致性和高度风格保真度的输出，同时确保自然、</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=3&amp;sn=bb858963bee25c27a8b7298478c7d4dd&amp;chksm=fd82fc63e4d9906fa9fec1e1044171706edf6179e7ceadc215ed6d511945e02a57dba2163f05&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ChatAnyone：实时交互式视频聊天。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFBvDo9xOjM1tdvD1dCdZr760dXoC4wLgicCauCgadtfian63zlxCvjB2iaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里通义实验室提出了一种风格化实时肖像视频生成框架ChatAnyone，使视频聊天从“会说话的头像”拓展到包含上半身交互的更具表现力和灵活性的形式。ChatAnyone方法支持高效、连续地生成分辨率最</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=4&amp;sn=91fd6e18725e32c71a9a1aedcd30d980&amp;chksm=fdc542faf74dacd7441049d7faa73e1d07fffe7e56a4bdfe1b2d48d2c8b745d55a191c824cae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[SIGGRAPH Asia 2025 | InfiniHuman：精确控制高保真3D虚拟形象生成，质量、速度、可控性新SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enOsWGSowG7dTvaQfLGpk8QicdBAs8Aib7va23bWsWpqu8icglxyMSNUvMZbiaDvbffJ5Il6VfmAZrQibA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！已有的问题训练 3D 人体生成模型需要大规模、多样化且注释</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=1&amp;sn=bf43f95276575507f9fe7b1bafa56ac1&amp;chksm=fd9dbe291e25197c12a19a945d8426d3a0284f0d323678c6d942275861363f3d440adf7dfe1c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[PractiLight：无需大规模微调，扩散模型重新照明图像的“隐藏密码”是啥？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnlicYMzw1WzNwt5le6iaI9cTAtDXqeQhLib2EX5oj6diaoeWrR70g9ysxhaoNYpWZY23iakey176zJZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>标题:PractiLight: 使用基础扩散模型进行实用光控制论文：https://arxiv.org/pdf/2509.01837项目：https://yoterel.github.io/Pract</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=2&amp;sn=8ef495b549f3e3a9c92b0dccab2d61a9&amp;chksm=fd9e4e6a5dcb964672d2df19778e1441b271d659edf07e1b8a3fe2443dcdbd1ecd205904459b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ComposeMe：可基于文本对多属性（单人&amp;多人）多属性（身份、发型和服饰）随意组合和解耦控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emWWjXopniaeJLQgrb3xQhEL7RSTXR33nIN4iaeIZzyicy21ek0qtCribmBzLEKIQKTXlZCuSFX5nE6gQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！ComposeMe 是一个以人为本的生成模型，能够对多个主</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=3&amp;sn=1818783d04017ce378e04da2cc13aed5&amp;chksm=fde80c8b9926fd0aeb0b2c32056521c9794613341a3db90171a63fed6d63575c14bf1906815e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[清华&amp;字节开源HuMo: 开启多模态可控人物视频生成新方向，输入文字/图片/音频即可生成电影级视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPl5fon0zqaCYa1WAGMKib43ibDcv8gDnvjAAPXvsT4Mkr1cgVcibJpA2nLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由清华大学、字节跳动提出的 HuMo 是一个统一的、以人为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=4&amp;sn=6564abd580965ba764cef195e76dbb88&amp;chksm=fd73bf6836dc9b17027c625fbfd75cf4e52e8d01b067031be52e06307f0bd7e3c0dbd09a948a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频编辑新突破！新加坡国立大学等提出视频编辑框架IMAGEdit，无需训练、即插即用，可实现任何主题的视频编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emLic2Rhpf3QYj2hoRbhoUGYVMUFb9T05FusR4LFekAEqguwQXicMNaz2b4xr4qqaicYzthFWJxjTGUQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由新加坡国立大学、南京理工大学、香港科技大学以及南京林业大</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=1&amp;sn=adcab57cca0b2c356cf78b25100d83ca&amp;chksm=fda4e414b31312459c984b050f560ac94752c0b1eed7b2398b03f615903f975de6de83c5db9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大×字节提出ComfyMind：生成/编辑/推理三连冠，开源领域再掀狂潮。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elI7B3IZQkA99hvyeKlzPzyeqYm9eaK3j5oUNFlRDs6yaz4YvOHWYMnpeWHk5ic5s7zDkXrP7RYtBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、字节跳动提出的一款基于 ComfyUI 平台构建的协作式 AI 系统ComfyMind，旨在实现稳健且可扩展的通用生成功能。在 ComfyBench、GenEval 和 Reason-</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=2&amp;sn=53b8a5337447606a825e005533fa6fa4&amp;chksm=fd80ce8c5374e1a0916cd33d73821748be34c8a4e743c48f022c31934b0a75289e3ed552afd6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一文带你了解，MOE 架构是什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIrjh2Jy92UibXavMpGEKRelbCqXiaEc6hkxXvNNtIibfW3p5bo1jGWB6icwh68qvkWZsqN65HicvwiaN28w/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言：从“全能大脑”到“专家团队”你是否想过，为什么ChatGPT能回答复杂问题，而手机语音助手却常“卡壳”？答案或许藏在一种名为**MOE（Mixture of Experts，混合专家模型）**的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=3&amp;sn=9cea44aea0eb7ea52fd0c928a228cee1&amp;chksm=fdb4d195c45c8ec21cef5697e144fc97bbff88541cf648ce3e24b3b9a37ef123ca8a8e62fc43&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UniRelight：用AI重新定义光影，一张图片也能“玩转”重光照！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic7KwJk2LgWQGVllkaSM8Yden54sxzolLeKOFFxwK9icp1NVTJKWB0YicQloE0ZSIvv1TppUDEibwHmGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>UniRelight 是一种基于视频扩散模型的新型重光照技术，能够在单次推理中联合估计场景的反照率并合成重光照输出，显著提升了跨场景的泛化能力和视觉效果。在视频处理领域，我们是不是经常因为缺乏高质量的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=4&amp;sn=eaa2b41cf41c3092b12fd7dbda307546&amp;chksm=fd5516fe692982b084b896cfd0ebb3b33b87b5a0464764f894da49b8409bca32d0f71a576014&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频风格迁移来了！PickStyle：使用上下文风格适配器进行视频到视频风格转换。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elEv3MSa6ccibpmEQKSzhgQ7UuWbPaLgc6zUuDRLlVC18cglPGyBxG5znGze4u2gwIy7ln9hKWS7Ug/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！利用扩散模型做视频风格迁移，想保留原视频内容的同时渲染成指</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496436&amp;idx=1&amp;sn=ec519cceab55c212ec4754abd6645bfc&amp;chksm=fd95784252e593a25c63614e4c1756d7c44400c3096f9f0a650e1a2339dab39e48381a763af1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0800</pubDate>
    </item>
  </channel>
</rss>