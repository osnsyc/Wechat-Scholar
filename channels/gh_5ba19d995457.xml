<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[哔哩哔哩再放大招！开源最强文本转语音模型Index-TTS，超真实语音克隆，可纠正发音、控制停顿。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekBSQolZZOuH0N3j03LsQJ4iaV41U2U7rc7sOzwoFzlxLhwic4zicGU7C9cnmslZt0afXNjyErakLib2Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>哔哩哔哩最新开源的 Index-TTS  是一个 GPT 风格的文本转语音 (TTS) 模型。它能够使用拼音纠正汉字发音，并通过标点符号控制任意位置的停顿。经过数万小时的数据训练，该方法达到了最佳性能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492718&amp;idx=1&amp;sn=00c7ca18ac08958d965bbcd3710a12b9&amp;chksm=fde412718fec897012e790e372142c946f89f22af26088cea3ef285ffd0a9c2ed66ada2cfc30&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[哔哩哔哩开源目前最强大的动漫视频生成模型Index‑AniSora，给二次元世界的献礼！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enSiccUGiblNd9QEDRcSD96fBURrzeY4wTV8PKUrO1z3OVvvWGu3cqBYg8yJTxdEbtefDDE4WXaYsLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是哔哩哔哩献给二次元世界的礼物——Index‑AniSora，目前最强大的开源动漫视频生成模型。它支持一键生成多种动漫风格的视频镜头，包括番剧片段、国创动画、漫画改编、VTuber 内</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492718&amp;idx=2&amp;sn=dd2451579f3a4d06f3c2f267cdb7f0fe&amp;chksm=fd74914dbcbccfc25938c9500780811abf1fdc4419d32f571103ac8c7693367367a76ca73551&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492718&amp;idx=3&amp;sn=68581704414edfc6e54f258fe6b8d9bb&amp;chksm=fd1086ac22cf95442d58ca39ae94c81e106809c6206ad0a4d0b09ee1ab64bc336610a674686a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492718&amp;idx=4&amp;sn=94f33d4bcd95ff84571c62fdc2a21909&amp;chksm=fdc8e99f181a2016d4e6daa373a48c9d088af9ac5f4c749e048444db6cc095435a4ff5e3e2b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[给二次元世界的献礼！哔哩哔哩开源目前最强大的动漫视频生成模型Index‑AniSora！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enSiccUGiblNd9QEDRcSD96fBURrzeY4wTV8PKUrO1z3OVvvWGu3cqBYg8yJTxdEbtefDDE4WXaYsLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是哔哩哔哩献给二次元世界的礼物——Index‑AniSora，目前最强大的开源动漫视频生成模型。它支持一键生成多种动漫风格的视频镜头，包括番剧片段、国创动画、漫画改编、VTuber 内</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492684&amp;idx=1&amp;sn=11915e42a737f6e39e8f2c198f1e09c9&amp;chksm=fd7a0ff4ea5d1b64ed619b8a816a6d4e5c270b3c63208be5b3f730ae1a5dae347b3a74336407&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型再现黑马！英伟达开源Llama-Nemotron系列模型，效果优于DeepSeek-R1。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafoC1ibJ7eE1fvbrtrICXG1kaXfiaqibBmibzznCUHyiaB4NGTibwK6pmBM0hA/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，英伟达推出了 Llama-Nemotron 系列模型（基于 Meta AI 的 Llama 模型构建）—— 一个面向高效推理的大模型开放家族，具备卓越的推理能力、推理效率，并采用对企业友好的开放</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492684&amp;idx=2&amp;sn=53439f12162dc38eaa0a30abfc172de5&amp;chksm=fd60209f088ba27da940c7793d562cdbb5d59ff8b667d3fffa235517abd3b6af4986c07650ae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D 生成新 SOTA！SECERN AI 提出 方法 SVAD，单张图像合成超逼真3D Avatar！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJczQ6xAAgVU8NYrMphwhLiaiajhcsCMja0TDYcr6RulFp9C6Yt1mtcbiamA/300?wxtype=jpeg&amp;wxfrom=0"/><p>SECERN AI提出的3D生成方法SVAD通过视频扩散生成合成训练数据，利用身份保留和图像恢复模块对其进行增强，并利用这些经过优化的数据来训练3DGS虚拟形象。SVAD在新的姿态和视角下保持身份一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492684&amp;idx=3&amp;sn=138e8a677e24ed57e53a688c5d73ce14&amp;chksm=fd5949abc21cb8519a499fe29b8595a728100de796632607638319a4878f7d07362b3119fb17&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[炸裂！ComfyUI 原生支持 HiDream-I1，全新文本转图神器来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2ibyrQzlh4BO0Xa83u0NI5WzuIBs5KCqMafPkjLwMiapJ0TVwXCaj6ibIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyUI 原生支持 HiDream-I1，全新文本转图神器来了！大家好，这不是演习！ComfyUI 终于官宣——原生支持 HiDream-I1 模型啦！对于熟悉图像生成的小伙伴来说，这可是一件值</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492684&amp;idx=4&amp;sn=af6ae14a7dc045db56ab03f34130ec73&amp;chksm=fd7c7c55b693485bf5cee443a91e8c84077dfe8006c93711954c4076f1dc09020c5aff106ce7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谢赛宁团队提出BLIP3-o：融合自回归与扩散模型的统一多模态架构，开创CLIP特征驱动的图像理解与生成新范式!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek5oLyjfCjICEWyMhWNvFXDN37WVtXa4JeBibibTSdNGmBP0wSFhuUAJkiaz9qNwiccNW4SuNJ7FvduuQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>BLIP3-o 是一个统一的多模态模型，它将自回归模型的推理和指令遵循优势与扩散模型的生成能力相结合。与之前扩散 VAE 特征或原始像素的研究不同，BLIP3-o 扩散了语义丰富的CLIP 图像特征，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492683&amp;idx=1&amp;sn=c6f9575a6347b0fd4f905f7ec64b54a8&amp;chksm=fd600ee6b8313e076506c578485f83d8dbd2740bd8b48a901f5bbd2e1cdad50b87393ed53add&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出从单一主题发展到多主题定制的通用框架UNO，通过情境生成释放更多可控性。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elo3s89icGNibsPQVXGhctg9WDrsYXyWyFSyqXzUDm6eOsD3G2Z7XbSMUPZrQw19LsCTpuzPx9KiaCWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节跳动的智能创作团队提出了一个从单一主题发展到多主题定制的通用框架UNO，从少到多的泛化：通过情境生成释放更多可控性。能够将不同的任务统一在一个模型下。在单主题和多主题驱动的生成中都能实现高度一致性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492683&amp;idx=2&amp;sn=81496eb2cd96b6ff6e0fa8df5de1039d&amp;chksm=fdc359d002107ded0b9eb0d26dafd4996bb6ab8b6de68d9e2245f5f1e088aad1d08f3d00bc2a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[太强了！浙大联合上海AI Lab提出视觉统一Diffusion架构DICEPTION！各种视觉任务一网打尽！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcb6XeOfGM7ic3jww1VGas5hyQ5UbdLhbhjcqHwrckdlwdXIvppjK9PlGZVkxMpOMiaT6tDJ32KOqiaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>数源AI 最新论文解读系列论文名：DICEPTION: A Generalist Diffusion Model for Visual Perceptual Tasks论文链接：https://arx</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492683&amp;idx=3&amp;sn=fe89aee75d03d8a8c22dd34f825f3347&amp;chksm=fd6a9663871f0b1d4837d084092f26a9cefa277e1abfe0013b771ff7f1d53142fe7659a98c06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI插件安装失败率90%？教你4种方法0踩坑]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE4krxeSSRPxaSdK57W0WTcKsAosmf2OLF7QQMa3t5LdSSntjJPTIZQgLlJTibnRCJGn820Ex6Odf4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击蓝字关注我吧！ComfyUI 作为一款高度模块化、节点式的 AI 图像生成工具，近年来在国内外社区圈粉无数。但要说它最常见的“劝退点”，那一定非插件安装莫属。很多新手兴冲冲地下载完工具，还没来得及</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492683&amp;idx=4&amp;sn=989d17002404a904cfe61c5f8937f2eb&amp;chksm=fdb16e7819c41c7376d16cd0c578ed36308137b733fae9c185c6fded42c06266a538d74f218b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布 Seed1.5-VL 视觉-语言多模态大模型，20B 参数狂揽 60 项公开评测基准中 38 项 SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1LeKLydiaFjmibN24FdeB4micypmdwFpFW83KWkU4txxbiaLmiannOs7mDHw/640?wxtype=jpeg&amp;wxfrom=0"/><p>5 月 13 日，火山引擎在上海搞了场 FORCE LINK AI 创新巡展，一股脑发布了 5 款模型和产品，包括豆包・视频生成模型 Seedance 1.0 lite、升级后的豆包 1.5・视觉深度</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492644&amp;idx=1&amp;sn=20ef8da40f03d8c1eb89596943cbf227&amp;chksm=fde476152116b27784b0e0190d70744efdc2d116fae42c1cdcf127fdc8164f1e83192ed58365&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布视频基础大模型Seaweed，70亿参数超越同类140亿参数视频模型效果，单GPU就可生成1080P！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrSjMIibqt135GUNpF74oSRXfm9iakLUsJ4cuaJkMv3pwe9GUibyujB4o5rb4L0I9e4f2iacOibCyryMg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Seaweed 是“Seed-Video”的缩写，是一项旨在构建视频生成基础模型的研究成果。该网页展示了拥有约 70 亿 (7B) 个参数的扩散变换器 (Diffusion Transformer)，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492644&amp;idx=2&amp;sn=befad8fec1e3bf3cec87e2005c14c182&amp;chksm=fd0bb9a5ea8d326b94c0d2396f985d522423bf268e71966c629cc19c63cbb616424fa0fa06ec&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[142页深度解析：DeepSeek-R1的推理技术综述，AI的“思考”秘密大公开]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic74EgPzUnjibrG5SK0JmT8ksETRvVrR1XcCZjqetgGsxyQHiaa0hCYjVTIMhicnh9kAXbQjIYxYwDkxQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek-R1 就像是AI界的“思考者”，能够像人类一样进行复杂的推理和思考。在数学、编程、科学推理这些超难的任务上，它的表现简直逆天，直接对标OpenAI的o1正式版，妥妥的推理界“学霸”！</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492644&amp;idx=3&amp;sn=e3093e335f8ab5d1103acd6cb7a881df&amp;chksm=fd967052e71265de1e1d424cd5ce28af2a7fe97813c3d4a0fb70cd250dc1697ebb3bd8388fca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492644&amp;idx=4&amp;sn=ad5c0aaddedcf6fa986d7c0e324fb96a&amp;chksm=fdb7f21cca0cdaad635c885ae1aaf15e9a1757ef87f361aade9ac5255843f8b627b4299dc91e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型再现黑马！英伟达开源Llama-Nemotron系列模型，效果优于DeepSeek-R1。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafoC1ibJ7eE1fvbrtrICXG1kaXfiaqibBmibzznCUHyiaB4NGTibwK6pmBM0hA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，英伟达推出了 Llama-Nemotron 系列模型（基于 Meta AI 的 Llama 模型构建）—— 一个面向高效推理的大模型开放家族，具备卓越的推理能力、推理效率，并采用对企业友好的开放</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492601&amp;idx=1&amp;sn=ecb9383177f7d466d07a987282c7285e&amp;chksm=fdf80a63cdcfa8d53ccf7754345e908c0544610e4e7bc5e77f8afe186f1b91ae7e3dba504a1d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492601&amp;idx=2&amp;sn=af46e60dcf607f1435a016a12da2d1e4&amp;chksm=fd9549acf167fb4e195f3fddebb93a144e3a6910a3d2449a3070d44419c739cf923be4cdc500&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 最强吉卜力风格工作流EasyCN来袭，风格统一+操作简便+输出稳定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE6xg4dG7Ndtia8iag86UJ7LAcFTmCaJMwrHhZMoY5Fjia4QeyYvmmygPtEbYjX3d9emmuUYf6flou1YA/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近的ComfyUI圈子，可谓是“神仙打架”级别的热闹。就在你还在研究ControlNet怎么接线、LoRA怎么调风格时，一套堪称“傻瓜级”的全自动吉卜力风格生成流程，已经在社区悄悄流行开来。Easy</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492601&amp;idx=3&amp;sn=72620a76e822279bf770c99f73ce6f48&amp;chksm=fd61e4b6a97087a395062d9be36991f0c516119946fb1bf12e39756438b41e737b7362c7ba5d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D 生成新 SOTA！SECERN AI 提出 方法 SVAD，单张图像合成超逼真3D Avatar！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJczQ6xAAgVU8NYrMphwhLiaiajhcsCMja0TDYcr6RulFp9C6Yt1mtcbiamA/640?wxtype=jpeg&amp;wxfrom=0"/><p>SECERN AI提出的3D生成方法SVAD通过视频扩散生成合成训练数据，利用身份保留和图像恢复模块对其进行增强，并利用这些经过优化的数据来训练3DGS虚拟形象。SVAD在新的姿态和视角下保持身份一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492475&amp;idx=1&amp;sn=684077a1fb1dad9e64d6fdcd3e8c82fc&amp;chksm=fddbf47c62a1ecae66a5eb7c05349793899cbd2ddacf707b79b81616c2a5622004b0f3117296&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | VACE-14B：效果炸裂，开源AI视频里程碑！稳定高质量wan2.1视频一体化编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGTEc51fic65mC5EsS2ljQDXDgX9HPib083UyrrTPSbd3PsgEQsKNckx6trWVq4oKNwScsBKH5zQt5Yg/300?wxtype=jpeg&amp;wxfrom=0"/><p> VACE：一体化视频创建和编辑VACE简介今天文章将介绍一款最新的最新视频编辑框架：VACE。这是一种一体化模型，能够在视频创建和编辑中使用。涵盖了多种视频编辑任务，包括参考到视频生成（R2V）、视</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492475&amp;idx=2&amp;sn=60197534d5087c421627a8375f184ea8&amp;chksm=fd820329f474e058b2a1d77cdad4210241096535a48abc0bada994f55e6bf608c25918ac5a06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492475&amp;idx=3&amp;sn=2b170059f628151b0930adb940bf4f34&amp;chksm=fd5367e3b876b0ddc19924e7bbd50eb8fe279c1233fa2ef0f0ab1e77c915f1323e229c922e5b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科&amp;腾讯&amp;清华提出全球首个多模态Mamba生成框架ACTalker，支持多信号输入，数字人嘴型同步再升级！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enM1R1hvr6fIvNPnJ8HAkjER32Qr4uJljRDnNXhyE9UPgfaB2EKia2QjfDCSEHzibXgefW4NfoP8eNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由港科大、腾讯、清华联合发布的全球首个多模态Mamba驱动框架ACTalker，它是一个端到端的视频扩散框架，支持多信号控制和单信号控制，用于生成说话头部视频可以实现单/多信号随心切换，虚拟人嘴型同步</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492475&amp;idx=4&amp;sn=f4d2bb5450498be100d1310f874db258&amp;chksm=fd94e945934d5fda91c0fbe7c4ecf3c2f49fae802dde3582a623a400bc5cf574962e69d36d6a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[6秒音频即可克隆AI语音！FLOAT数字人生成语音/口型/表情，情感同步超惊艳，文中附工作流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJcmBGicWjwiauMpFknBOofINibzHjBSIibjwDHKYvhnzulS1E2KIPicobCywA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的 FLOAT 是一种基于流匹配的音频驱动的说话肖像视频生成方法，可以增强语音驱动的情感运动。该方法唇形同步质量高，生成速度还很快。6秒音频完美生成语音/口型/表情。情绪转移由于 FLO</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492474&amp;idx=1&amp;sn=fa6b33eb473896fcf3eccb022abd3832&amp;chksm=fd9da99601dde29e74f19566ea111919b60f7de105d3a962b688570b4d8f29cad59946b755e8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 只要两张图，教你1分钟换出高级感背景图！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE58CmJ5ohiamgvGghUsrwCQU3JBVH5cq2PuOXrq4b8rfufFiceKmwL30bsRxZUpnlWcAiaA8ib6p4C6cw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击蓝字关注我吧！说到 AI 作图，大家对 ComfyUI 应该早已不陌生。这个基于 Stable Diffusion 的图形化工作流神器，用“节点搭积木”的方式，彻底解放了创作者的想象力。不管是图生</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492474&amp;idx=2&amp;sn=b59f710c73638dab57f91dbffbcb3ee2&amp;chksm=fd36f12c32476adc8449ba4b6a87c560af1780c7bb6a749bbd935a0f29e5b62b1a5f3438f854&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 Highlight | 清华提出一键式视频扩散模型VideoScene，从视频到 3D 的桥梁，一步到位！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en6YOGtn3XXJMye1oxLXOtQDu8lVia8rZmBpsouclpUQ8eY6ebkIhqsCQhQiabYLqW83mluezLMicI1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华大学的研究团队首次提出了一种一步式视频扩散技术 VideoScene，专注于 3D 场景视频生成。它利用了 3D-aware leap flow distillation 策略，通过跳跃式跨越冗余</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492474&amp;idx=3&amp;sn=6558758efa4710d730233e81c95af73f&amp;chksm=fd8e176896704e7dacd82dd635a1ea861b43787d5a42c09cebb148b4a117ab23a09144f13822&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图生3D新SOTA！港中文&amp;字节&amp;清华联合提出Hi3DGen:通过法线桥接从图像生成高保真 3D 几何图形。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elT6Ok13J4tBFt6yibibVpmCofpeSCJb5Do6ZzCr2Yv2wPial5QS5sdppZe8K6ubyDPzv4yf6QNaOicHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学联合字节跳动和清华大学提出Hi3DGen，这是一个通过法线桥接从图像生成高保真三维几何体的全新框架。Hi3DGen 由图像到法线估计器、法线到几何学习方法以及三维数据合成流程三个关键组件组</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492474&amp;idx=4&amp;sn=ededb0fa30bcde935104feb30130a45b&amp;chksm=fd7d89ebc5ac99a2fb2b874686cf48088a954c5ff0903eb7eb19edc4b46b5a7baf3f961f27d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 15 May 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>