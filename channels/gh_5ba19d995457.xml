<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    





























    <item>
      <title><![CDATA[手把手带你实战部署DeepSeek-R1大模型在手机安卓端、linux端、windows端 ！没有GPU也行！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/IHicdx3TSo7XsCCkeNuk3yA97F2wOsBrE99r8I7nb2PG5hV6VvF4QTUSgR3ztD2EhAib3ga3LD4PnM3jmjTHNbcg/640?wxtype=jpeg&amp;wxfrom=0"/><p>前言为什么要离线部署，好处有: 1.数据安全，可以部署自己私有大模型，避免数据泄露。2.可以进行功能定制，实现更多自定义的功能。3.随时随地可用，无需联网。之前给大家分享利用python代码来部署De</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490139&amp;idx=1&amp;sn=5fc8463c832f6b6b5c71ec7342439134&amp;chksm=fdf5447b6bd70fbff5f0365b49b432f6150aa751d8be4a48c9c3477f7c574b4d0a30c645787d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 06 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[使用阿里云 PAI 平台云上一键部署 DeepSeek-V3 模型教程。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekrOwzVBbmRn3dchAI3UqeGiasnNd4IOvBr2Mjt51hZ0gCwAsDTib4meGmBJUsbB7BXFGGe5Bsfm6WA/300?wxtype=jpeg&amp;wxfrom=0"/><p>unsetunsetDeepSeek-V3 模型简介unsetunsetDeepSeek-V3 是 DeepSeek 发布的 MoE（Mixture-of-Experts）大语言模型，总参数量为671</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490139&amp;idx=2&amp;sn=824c57bb9980bf9f4a8edaf8a840eb35&amp;chksm=fd35d3f3411cb6a66819bf7050f42f7bee4b16b4db408da9ed2e8a6eb59a985dc679eb81780a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 06 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[DeepSeek开源多模态模型Janus-Pro的ComfyUI使用教程，文中附模型和工作流下载。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enb5zKF6gvurVAmOLrPRAhFLvb45xtbwKzvDHEfDoJNyqQeAWoiaN8o3QOQZeARnWnmvTZdNh0ABsQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍DeepSeek发布的Janus-Pro模型的ComfyUI实践教程，包含ComfyUI安装，模型下载，工作流下载等，欢迎大家一起交流学习，也欢迎添加公众号小助手加入读者交流群，一起探索</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490139&amp;idx=3&amp;sn=04287cc458e6d02ccb48bc0c3d96affa&amp;chksm=fd408432f234ba4923c47e1a1cef5c0fea5900b10f7a7092150355100490b5e860d3fb4b8d2b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 06 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[DeepSeek开源Janus-Pro-7B：多模态AI模型性能超越DALL-E 3 和 Stable Diffusion 3!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enb5zKF6gvurVAmOLrPRAhFcaHiaiclO2A4p8xHMlrzicfJTT2YRJ96xcpxAialNYX1udoHkp8paKetdA/300?wxtype=jpeg&amp;wxfrom=0"/><p>中国人工智能公司 DeepSeek 的 R1“推理”人工智能已经引起了广泛关注，位居应用商店排行榜首位并改变了股市。随后DeepSeek又宣布开源新一代多模态模型Janus-Pro-7B，该模型在图像</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490139&amp;idx=4&amp;sn=09ddff30d40bbce105105664fa061c1b&amp;chksm=fd22130ed69807cfcf726491cbaf32e78cc66cf303bf42421d441562ede36282cc7c0ac7ff77&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 06 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[DeepSeek-V3 正式发布，已在网页端和 API 全面上线，性能领先，速度飞跃。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsVQ8iaD3eY0RibaYkYGTf6mgibWMibTiaiccjeVMM6rnIOdfQ4sLtwbuJJ1iaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek-V3 在推理速度上相较历史模型有了大幅提升。在目前大模型主流榜单中，DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。unsetunset简介unset</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490139&amp;idx=5&amp;sn=9b09043623db2edaf66abae6bf964991&amp;chksm=fd3f3504706b447e794c6b2d5a34b1adb1a21d5802113748bbbdcd7d58ef3057e2369b30a799&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 06 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[小红书提出新面部视频交换方法DynamicFace，可生成高质量且一致的视频面部图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4wY9icyCBJHtpRNSEtIVu23ib2dMfGUzdVZH7hKlE7v6ZRLfdk46k3hHw/640?wxtype=jpeg&amp;wxfrom=0"/><p>DynamicFace是一种新颖的面部视频交换方法，旨在生成高质量且一致的视频面部图像。该方法结合了扩散模型的强大能力和可插拔的时间层，以解决传统面部交换技术面临的两个主要挑战：在保持源面部身份的同时</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490109&amp;idx=1&amp;sn=bd25db7abbd8911b522b545eb2084905&amp;chksm=fd3a30a41bd9ead5132e4af77103fb04819ac9c68398abdcec478b915cd193a9347278544d0f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 05 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Google发布新AI工具Whisk：使用图像提示代替文本，快速完成视觉构思。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2end3mWUdomxapVIqKPBfrWChHLuwfMCvRvq1l8Kl6qfOOlq9YUxzPEdzMibDSUo0R5owCSicTJLumBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Google发布了新的AI工具Whisk，Whisk 是 Google Labs 的一项新实验，可使用图像进行快速而有趣的创作过程。Whisk不会生成带有长篇详细文本提示的图像，而是使用图像进行提示。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490109&amp;idx=2&amp;sn=c2a171cc1f1a4b60d3baaf0f70af229e&amp;chksm=fdb49ad794a38ccaf37ab83c4d905bd7efce2cdd8806d219166fef5279adcce60fd892ef06ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 05 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Github热门机器学习笔记:「从零构建大型语言模型」]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emtHS7t5ic0uQWb1AOhKNDRVQe1ibV5hcbvDj7icpDN1BtRicibpaHbuszyA75wydLlzCvmBKSLia5XJSLQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐一份GitHub上很火的机器学习学习笔记《从零构建大型语言模型》，目前已经收获1.4K stars，，这份笔记完美展示了从零构建LLM的技术路线图，既有理论深度，又包含实践要点。每个核心</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490109&amp;idx=3&amp;sn=26c52b0be0cac5485feda1909986b5ec&amp;chksm=fde14fd8163dc6a8dc7ab9dcb626793e05643cbbefb05b62d5f557960254681cbc236aac0ee0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 05 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多模态图像生成模型Qwen2vl-Flux，利用Qwen2VL视觉语言能力增强FLUX，可集成ControlNet]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYHx9RLCm1u1zJr61WGBPZZicviaGPyXN8y5ZTaZE9jpPcdNSX1nmUlib5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2vl-Flux 是一种先进的多模态图像生成模型，它利用 Qwen2VL 的视觉语言理解能力增强了 FLUX。该模型擅长根据文本提示和视觉参考生成高质量图像，提供卓越的多模态理解和控制。让 F</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490109&amp;idx=4&amp;sn=fbe92ac441012d79dfa14596f0b701f8&amp;chksm=fd764b3ce7e7d289a5a000b0588b12ea01f5bf5d36012992cdfa59b928162943063bc4611031&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 05 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Chirpy3D：用于创意 3D 鸟类生成的连续部分潜在特征]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4lMln2LbWadvjMkDrI7ibrh99jvyryugwPj1qqcWjQZFyvLicjUXMCIicg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Chirpy3D框架可以将细粒度的2D图像理解提升至3D生成的全新境界。当前的3D生成方法往往只关注于重构简单的对象，缺乏细致的特征和创造性。Chirpy3D通过结合多视角扩散模型和连续的部件潜在空间</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490107&amp;idx=1&amp;sn=c9154ba5d944009b29129841ae5fd925&amp;chksm=fd7a40a23fce33e35609220a95c77fdb157dbdcb242f4e6c18e35c5cc88545a7a73a0294f598&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 04 Feb 2025 13:15:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[实时高保真人脸编辑方法PersonaMagic，可根据肖像无缝生成新角色、风格或场景图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsExUD85bPCqAicxMSnpMibzPacGZ2JJmvUibAHrezkU5Now3FS5ib9Ibg1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是一个高保真实时人脸编辑方法PersonaMagic，通过分阶段的文本条件调节和动态嵌入学习来优化人脸定制。该技术利用时序动态的交叉注意力机制，能够在不同阶段有效捕捉人脸特征，从而在生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490107&amp;idx=2&amp;sn=b973ff28b57ef6ca3d0ca467957bba10&amp;chksm=fd181da143bd2f4f5277e0e9363cfe67729a597450290a03cc558d4b2288c8c9ae08bf887b03&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 04 Feb 2025 13:15:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[厦门大学联合网易提出StoryWeaver，可根据统一模型内给定的角色实现高质量的故事可视化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcSnOoT1icicSWQibicicqfkyEgocfw6Age4Y0U1AOuZS8cHib80ewP5RdXmZjaprD8L6TqR9iasUM3VUVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>厦门大学联合网易提出StoryWeaver，可以根据统一模型内给定的角色实现高质量的故事可视化。可根据故事文本生成与之匹配的图像，并且确保每个角色在不同的场景中保持一致。本文的方法主要包括以下几个步骤</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490107&amp;idx=3&amp;sn=a781367bad01284635521d351a702f3c&amp;chksm=fd5f5623fddde5bea00c1211af265fa1e633626115dbca69e2b8ccabfd5580e51ab4331a1d90&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 04 Feb 2025 13:15:44 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[拖动图像编辑再省级！北大、腾讯提出DragonDiffusion，在扩散模型上启用拖动式操作。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emtHS7t5ic0uQWb1AOhKNDRVue2DuQtBzYWulYezda8dsItznwxGaPWCUmiafhNgHsVonAIj1dwlFlA/640?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中给大家介绍过许多关于通过拖拽实现图像和视频编辑的方法，感兴趣的小伙伴可以点击👇链接阅读和收藏，整理不易，欢迎大家给文章点点赞和在看！StableDrag：一种基于Diffusion模型的图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490105&amp;idx=1&amp;sn=220d2e76698f5b337c75715cff7675fb&amp;chksm=fd052f603fd5858253f42dece65215f687ba267c5d23b8b53a54eaa5cb734db162de2eef57c6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[超越DragDiffusion!哈工程联合南大提出FastDrag：可以几秒内完成基于拖动的图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el1M9OhKbp7aVFqDIicZqBo4KKdolgwrn8m3yECIn5VrcqNnCuNxG4ud1KNvKlkWI1InpekwGDSGUQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中给大家介绍过许多关于通过拖拽实现图像和视频编辑的方法，感兴趣的小伙伴可以点击👇链接阅读和收藏，整理不易，欢迎大家给文章点点赞和在看！StableDrag：一种基于Diffusion模型的图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490105&amp;idx=2&amp;sn=2e65e8c4a4accd1a111e7994a51e9362&amp;chksm=fd7d82c5db9f36ddf7ca45aaa6ad9b78da0bde63c9564f44bb4fa9de75d782748e64c12dde11&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InstantDrag：仅需图像和拖动指令作为输入，在大约一秒内实现高质量的图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUN5oqyRgSButjKACUwRIlhd5Nc45XUYrH3ObILevzKlkNBTefTonWaZ4DyOGSj1tZib6XntPhrg/300?wxtype=jpeg&amp;wxfrom=0"/><p>InstantDrag是一种无需优化的框架，旨在提高拖动式图像编辑的交互性和速度。InstantDrag结合了一个基于光流的生成器和一个运动条件的扩散模型，仅需图像和拖动指令作为输入，便能在大约一秒内</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490105&amp;idx=3&amp;sn=68ab9b6af22e050ce22c4bc84186e614&amp;chksm=fd95e8a2cb2e9c0ca6cfa2d5a06c3a7d5ca30069f04cda37aebb6352c7c16a9eb51f49742efe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[StableDrag：一种基于Diffusion模型的图像编辑，可一键拖拽生成，DragGAN被革新了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emot8tDk0AwUNQicGF0zUfVOjhBQnahjqXeS7PyDah1icwybuWk1XpiaObsiahH3JfCf1lviaSCfXQEQow/300?wxtype=jpeg&amp;wxfrom=0"/><p>大家还记得DragGAN吗？只要点击拖拽，用户就可以“改变汽车的尺寸或者将人物的笑容变成皱眉”。这给图像编辑领域带来了非常大的革新，然而也存在一些缺点如生成速度慢，不能自己自定义外部图片等。基于Dif</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490105&amp;idx=4&amp;sn=c43b677c5007ff1e5308ef2ef54bc56b&amp;chksm=fd8ff709616f50d0796998db3d2ecb2fb791ac87caa7261e0d2ad10f3a34ca4ba737183e7ca3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[快手发布DragAnything，拖动锚点精准控制视频物体和镜头运动，视频运动控制技术革命性更新]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek1lQtWAgjC0vMrpw2bZUxP0dY8Togkx9JR7ljibSgulNqsJ2TxN2icRMGWibZEfOCgOOHBbbs5f6cDA/300?wxtype=jpeg&amp;wxfrom=0"/><p>快手联合浙江大学、新加坡国立大学发布了DragAnything ，利用实体表示实现对任何物体的运动控制。该技术可以精确控制物体的运动，包括前景、背景和相机等不同元素。该项目提供了对实体级别运动控制的新</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490105&amp;idx=5&amp;sn=dd000fe5a231dec4ea2bd5564521b5d8&amp;chksm=fdb6b9c21c6e9e07130e00d2b4eabe24b5fc275e68f4e9b90f11c340448e0ed5a0d999479156&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 03 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用阿里云 PAI 平台云上一键部署 DeepSeek-V3 模型教程。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekrOwzVBbmRn3dchAI3UqeGiasnNd4IOvBr2Mjt51hZ0gCwAsDTib4meGmBJUsbB7BXFGGe5Bsfm6WA/640?wxtype=jpeg&amp;wxfrom=0"/><p>unsetunsetDeepSeek-V3 模型简介unsetunsetDeepSeek-V3 是 DeepSeek 发布的 MoE（Mixture-of-Experts）大语言模型，总参数量为671</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490104&amp;idx=1&amp;sn=082d58c054f40cecfbc8e157bfea5a95&amp;chksm=fd1a4c2fa48124b71bd29afbe8538403cff86c033fafb8f1ba6d0fe6d7da9fdb282d9aa5f3f4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek开源多模态模型Janus-Pro的ComfyUI使用教程，文中附模型和工作流下载。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enb5zKF6gvurVAmOLrPRAhFLvb45xtbwKzvDHEfDoJNyqQeAWoiaN8o3QOQZeARnWnmvTZdNh0ABsQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍DeepSeek发布的Janus-Pro模型的ComfyUI实践教程，包含ComfyUI安装，模型下载，工作流下载等，欢迎大家一起交流学习，也欢迎添加公众号小助手加入读者交流群，一起探索</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490104&amp;idx=2&amp;sn=eb9312d9029141533dac64b63d979091&amp;chksm=fdb523bb58e00d70d4d9c7052885b6347170ce47b48c1b9519169a01ee53d3da8f3d37d2353c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek开源Janus-Pro-7B：多模态AI模型性能超越DALL-E 3 和 Stable Diffusion 3!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enb5zKF6gvurVAmOLrPRAhFcaHiaiclO2A4p8xHMlrzicfJTT2YRJ96xcpxAialNYX1udoHkp8paKetdA/300?wxtype=jpeg&amp;wxfrom=0"/><p>中国人工智能公司 DeepSeek 的 R1“推理”人工智能已经引起了广泛关注，位居应用商店排行榜首位并改变了股市。随后DeepSeek又宣布开源新一代多模态模型Janus-Pro-7B，该模型在图像</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490104&amp;idx=3&amp;sn=39c56a0e3e680725c8bd2303c0e6f7d9&amp;chksm=fd06b8aee80985fc51fd767fbb6abc35ec75d5f9d93a6c3c34c469762cb13522359563f12650&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek-V3 正式发布，已在网页端和 API 全面上线，性能领先，速度飞跃。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsVQ8iaD3eY0RibaYkYGTf6mgibWMibTiaiccjeVMM6rnIOdfQ4sLtwbuJJ1iaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek-V3 在推理速度上相较历史模型有了大幅提升。在目前大模型主流榜单中，DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。unsetunset简介unset</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490104&amp;idx=4&amp;sn=25b2b91a55e5c2867616ce0a48720e17&amp;chksm=fd61eff75088303dc725168cd2786867d175f1712c9c12ae1c2be432d6a9559207d9e00aba59&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 02 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[使用阿里云 PAI 平台云上一键部署 DeepSeek-V3 模型教程。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekrOwzVBbmRn3dchAI3UqeGiasnNd4IOvBr2Mjt51hZ0gCwAsDTib4meGmBJUsbB7BXFGGe5Bsfm6WA/640?wxtype=jpeg&amp;wxfrom=0"/><p>unsetunsetDeepSeek-V3 模型简介unsetunsetDeepSeek-V3 是 DeepSeek 发布的 MoE（Mixture-of-Experts）大语言模型，总参数量为671</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490101&amp;idx=1&amp;sn=cf062bbce4b208c5b48d39e618bc2b01&amp;chksm=fd5027f1dc9e1704cfd88a565be50480c3ae3f01d47e31435be502a0247e5dd3a83ebbb3d8ea&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek开源多模态模型Janus-Pro的ComfyUI使用教程，文中附模型和工作流下载。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enb5zKF6gvurVAmOLrPRAhFLvb45xtbwKzvDHEfDoJNyqQeAWoiaN8o3QOQZeARnWnmvTZdNh0ABsQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍DeepSeek发布的Janus-Pro模型的ComfyUI实践教程，包含ComfyUI安装，模型下载，工作流下载等，欢迎大家一起交流学习，也欢迎添加公众号小助手加入读者交流群，一起探索</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490101&amp;idx=2&amp;sn=64b08331d8ea28856ddc7448312052cb&amp;chksm=fd7f131586d317f4220b01a99a43601e6a3e81f855b84a6fc22792bb12cfbc85ff5d18f0ef4a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek开源Janus-Pro-7B：多模态AI模型性能超越DALL-E 3 和 Stable Diffusion 3!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enb5zKF6gvurVAmOLrPRAhFcaHiaiclO2A4p8xHMlrzicfJTT2YRJ96xcpxAialNYX1udoHkp8paKetdA/300?wxtype=jpeg&amp;wxfrom=0"/><p>中国人工智能公司 DeepSeek 的 R1“推理”人工智能已经引起了广泛关注，位居应用商店排行榜首位并改变了股市。随后DeepSeek又宣布开源新一代多模态模型Janus-Pro-7B，该模型在图像</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490101&amp;idx=3&amp;sn=82c728c4d9159eccc88e4a94b504c572&amp;chksm=fdf92482c777dedd5ba03e3f3feac640e60e2a2d6af60e52f93bdbba597ee66edbcb425fc815&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek-V3 正式发布，已在网页端和 API 全面上线，性能领先，速度飞跃。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsVQ8iaD3eY0RibaYkYGTf6mgibWMibTiaiccjeVMM6rnIOdfQ4sLtwbuJJ1iaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek-V3 在推理速度上相较历史模型有了大幅提升。在目前大模型主流榜单中，DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。unsetunset简介unset</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490101&amp;idx=4&amp;sn=431649dc98372026795d020ceadb44a8&amp;chksm=fd522d635e4ce3f42ba143997462a6fbf62ebbe861f0539d8a1856e6afe2c257a95b00ef089f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[革新在线购物体验：CatV2TON引领虚拟试穿技术新纪元。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPyLquFq9rYTicjFkPwyh9fqoMCzGFkTKibqfibbp0PHsEMaCzm6IAgmnBoZwnb3S50vNq1UoP83sbQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在这个数字化飞速发展的时代，图像与视频合成技术正以前所未有的速度重塑着我们的生活，尤其在在线零售领域，一场关于购物体验的革命正在悄然上演。想象一下，无需亲自试穿，仅凭一张照片或一段视频，就能精准预览任</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490092&amp;idx=1&amp;sn=85ced1e42ec66067ffd5c9eb6b0bc602&amp;chksm=fd720709bcc9d320d75f3a0517aa27e022340739d1ae4af28bdbddce9190288868a9f874f830&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NVIDIA提出虚拟试衣新方法EARSB，让时尚与科技完美融合！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2empB05GMsROweibZLQdTRdryhxs0ChYaSb8Q7MXgpODuC675ClEZrLFicPt5eWjzKjxOHWcsP2ic7rBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在数字化浪潮席卷全球的今天，科技正以前所未有的方式融入我们的生活，包括我们追求时尚的方式。想象一下，无需亲临实体店，只需轻点屏幕，就能轻松试穿心仪的衣物，这不再是遥不可及的梦想。NVIDIA联合波士顿</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490092&amp;idx=2&amp;sn=dfd629a49ee42b3a8a9cf94a06f4795f&amp;chksm=fddd551d9a37a61f7736713d0b9a83010d25012a325183eea07a523a61bfa690d9663ea2b84e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[厦门大学联合网易提出StoryWeaver，可根据统一模型内给定的角色实现高质量的故事可视化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcSnOoT1icicSWQibicicqfkyEgocfw6Age4Y0U1AOuZS8cHib80ewP5RdXmZjaprD8L6TqR9iasUM3VUVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>厦门大学联合网易提出StoryWeaver，可以根据统一模型内给定的角色实现高质量的故事可视化。可根据故事文本生成与之匹配的图像，并且确保每个角色在不同的场景中保持一致。本文的方法主要包括以下几个步骤</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490092&amp;idx=3&amp;sn=b212c625fb40463f1ba65e20ed904d80&amp;chksm=fdf25c8a923b3c92365c3253f9c0c5701c7d831b08b058c43ca41d68acb3dda94f55b6e73339&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 01 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[耶鲁大学和Adobe提出SynthLight：智能重塑人像照明，打造完美光影！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPyLquFq9rYTicjFkPwyh9fFVDfMwbeuJFlesWohTUXxZRSXxUpCJVwUUib0mdhjaia5sa6Ciaibic8AQg/640?wxtype=jpeg&amp;wxfrom=0"/><p>耶鲁大学和Adobe提出一种用于人像重新照明的扩散模型SynthLight，该方法将图像重新照明视为重新渲染问题，其中像素会根据环境照明条件的变化而变化。在真实肖像照片上可以产生逼真的照明效果，包括颈</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490091&amp;idx=1&amp;sn=0af9c93268a6d0844956ab9c938e7c2f&amp;chksm=fd53a4268483f78fd1fbfa8861a5ad309c5f2f69c1d82061df23fc6eabcfc845ed6f140771f0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 31 Jan 2025 16:06:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像超分辨新SOTA！南洋理工提出InvSR,利用大模型图像先验提高SR性能, 登上Huggingface热门项目。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emvRmmSX73ApBN83mPSIUnndGUoqrp8dTsfo3BKVIVGVNf5sWoXGauJCgAEaaCQm9Qb7QfuM34qZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>南洋理工大学的研究者们提出了一种基于扩散反演的新型图像超分辨率 (SR) 技术，可以利用大型预训练扩散模型中蕴含的丰富图像先验来提高 SR 性能。该方法的核心是一个深度噪声预测器，用于估计前向扩散过程</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490091&amp;idx=2&amp;sn=4dc0b538c54b41c3b34a4c459df58440&amp;chksm=fd49edaabcfe442e6ce5d3e134d8326ee67c4b4d930dab40c0726b961add8efcf540c4c4eaac&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 31 Jan 2025 16:06:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[单幅图像合成 360° 3D场景的新方法：PanoDreamer，可同时生成全景图像和相应的深度信息。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el8quKicUEibqsQFrF8ttU8UZJIaZuVsUww2Z2IDLp7MYqLaIsWuo5dAG2Y1iaHf8AibCjXj4KFPbTv3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文介绍了一种从单幅图像合成 360° 3D 场景的新方法。该方法以连贯的方式生成全景图及其相应的深度，解决了现有最先进方法（如 LucidDreamer 和 WonderJourney 的局限性。这</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490091&amp;idx=3&amp;sn=ed3ac3460df34ad5bda0b1417ee34ae2&amp;chksm=fdc5168728878e9751498a26501068f269281c161becc4ac67fb5d699390bc8253024f8704ce&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 31 Jan 2025 16:06:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯 | 中科大提出Make-It-Animatable：一秒内可将任何3D人形模型变成动画角色]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgeG73PxwM4k72wVClKXaAf0yPYtOtKUjLgb02frh2Xh9vAawfNd5XlA/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯联合中科大提出了一种用于动画 3D 角色制作的新型框架Make-It-Animatable，可以在不到一秒的时间内使任何 3D 人形模型准备好进行角色动画制作，支持各种 3D 表示且生成质量和速度</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490091&amp;idx=4&amp;sn=b429704b55c313585472b82fd2b535e0&amp;chksm=fdfec11be242e860fdaf91dddd0e8c2a44d56528dfc640b0634e24efecc479604345e1d3a78f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 31 Jan 2025 16:06:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
