<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/XzhF92tBcezMLGZN5TwHm01JzyB611PyibhFUMaiaE6xaTcU7nCAumRAicJowUjC4ntxOOAkSvxOK0/132</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[腾讯混元开源世界模型HunyuanWorld-Mirror：支持多视图及视频输入，单卡部署，秒级生成各种3D表示！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPdE96iaSHrBWejI3J1cH9ibC4lxLTGpHqTICOKwfsXz2heP3GpicHKxaaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！HunyuanWorld-Mirror 是一个多功能的前馈</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=1&amp;sn=9f9b287b5cb343b6f645345e478ead35&amp;chksm=fd40f74f2c5a17fe38ef0224cd6d1fdc0ef5dbb677fc470be6392e94f71a69fb2eab6157d335&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=2&amp;sn=eec7c1f06e194f07246a07954557b4e1&amp;chksm=fd86534c7ea92f798940090e3632dca0e343e3fa9380360c31c052504071adebed5437c2b372&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=3&amp;sn=90b3d0298ead36f5599f710fbd20d05e&amp;chksm=fdbb09b8efc28bee7b922bad692a3219c640f02358bc57d537cdac0a8153b160984c5ae3fa5a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek们的成本，是怎么计算的？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jEa2NN5eMic76LNKtDbp6JciaVMNpJ0DfXGyCBQINciblWxEtiaW2ibhfotlvKmwWXak89sQiabHFW56grOTBNPjGWfA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek彻底让全球都坐不住了。昨天，马斯克携“地球上最聪明的AI”——Gork 3在直播中亮相，自称其“推理能力超越目前所有已知模型”，在推理-测试时间得分上，也好于DeepSeek R1、O</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=4&amp;sn=56a38929c5bf94b5a36ca7ceccb1a48f&amp;chksm=fd7381a64090e5d742eb4a36d70cb8157bbdb83c4adc0acdbb49f52c17de3b27b621b3d30b15&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别复杂命令行！微软 AI Shell 强势来袭，打造智能交互新体验。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPRJ5HXpW3eg5IdOCPZKiaIaVC28jfh8HaybK0oAsfZqADEItEUtNZSJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！今天要给大家分享一个微软刚推出的超厉害工具—AI Shel</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=1&amp;sn=f0a8032cc0909389e09d443889b98204&amp;chksm=fd65c7afd4b16ee872daf77143478976e33f6d59df050686a87eb4ac3639cbd89542a0348efc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[智源开源EditScore：为图像编辑解锁在线强化学习的无限可能。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPK6iabtkXfBZFRVtgrsE2o1leI63ibKg939BgF4ooKUhWEfSZ10px65Vw/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章来源：读者投稿文字来源：机器之心如有侵权，请联系删除随着多模态大模型的不断演进，指令引导的图像编辑（Instruction-guided Image Editing）技术取得了显著进展。然而，现有</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=2&amp;sn=f01ed4e3a91164b1804e8e5949118192&amp;chksm=fdc5fe89fe469147d0db8f373a59d56c5351955dc9dc1684b989c5c44c96ba70db0a12054581&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布 Waver 1.0：一句话生成10秒1080p多风格视频，创作轻松一键达！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em7A7COb17nQf31AE47soscoy7aHU25oPTiaxHictLptYsN4iafwUx2b2iaBpowibOUZJFdBKXSRcC9ib3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出的 Waver 1.0 是用于统一图像和视频生成的下一代通用基础模型系列，它基于整流变压器构建，专为实现工业级性能而设计。一体化模型：在单一集成框架内同时支持文本到视频 (T2V)、图像到视频</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=3&amp;sn=cdb913c2adaa4af16794fdc99a110ffb&amp;chksm=fd6086403c80c511fb15da9deff091e56c77f7f7224a6b49cb46df07b17f02c20b54ad280aa5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPz0VreR3OZN1Te1uA2ypdJzkVTskDcl9xaYIsjI19fvRWodumj0UZ6w/640?wxtype=jpeg&amp;wxfrom=0"/><p>#视频生成 #数字人 #音频生成 #AIGC 腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=4&amp;sn=dfc65c48f30bbcbcc9c45e119bad03d4&amp;chksm=fdfb0bdfedd91753062647f5f2d2627111ba080e047f1c4bd8970bc13fc31f0fe70585f7a4fb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 图像生成新宠！StepFun 开源 14B 参数自回归模型 NextStep - 1，图像生成与图像编辑一键搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emLic2Rhpf3QYj2hoRbhoUGYqUKvsakZV7mEREOapr4qUib9cuiaq32lm19qdE1FqCHAiaWqbRdYekc5A/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！在科技飞速发展的当下，AI 图像生成领域正经历着翻天覆地的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=1&amp;sn=10d4184e016e0d4949a29fae0537bcbe&amp;chksm=fdadfec1f9ed081783ed4c81446e55e77b921a3b129fb134a3de0e262868ca43e8d306c65986&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Hallo4：让AI肖像“活”起来！新型扩散框架实现高保真音频驱动动画生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq56s1kIaYWsxKESfb9riaHUQVlW3JfPib9AP6mL8Hk0Ec5R0f43HYJ8aw/300?wxtype=jpeg&amp;wxfrom=0"/><p>复旦联合百度发布扩散框架Hallo4，实现了准确的唇音同步、自然的面部表情，并能够稳健地处理各种角色身份和环境场景中快速的语音节奏和突然的上身运动。相关链接论文：https://arxiv.org/p</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=2&amp;sn=a037eb00617587dd7061341aa19cd78b&amp;chksm=fdca80ba23508a175006b987deef38fc07c06f3f070bb78274abe4f1589e317dcd57e632fd5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布风格&amp;主题优化定制模型 USO，任何场景+任意主题自由组合，高保真一致性输出，模型代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elxI31iaYSzUGibFXibPx7ZT4tiafa1OQy2cwOTRicY23d73sOIEARSenF8FaojlXibI1Q8d3s4ciaNzpl8A/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节推出的USO是一个统一的风格-主题优化定制模型，也是 UXO 家族的最新成员。USO 可以在任何场景下自由组合任何主题和任何风格，输出具有高度主题/身份一致性和高度风格保真度的输出，同时确保自然、</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=3&amp;sn=bb858963bee25c27a8b7298478c7d4dd&amp;chksm=fd82fc63e4d9906fa9fec1e1044171706edf6179e7ceadc215ed6d511945e02a57dba2163f05&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ChatAnyone：实时交互式视频聊天。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFBvDo9xOjM1tdvD1dCdZr760dXoC4wLgicCauCgadtfian63zlxCvjB2iaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里通义实验室提出了一种风格化实时肖像视频生成框架ChatAnyone，使视频聊天从“会说话的头像”拓展到包含上半身交互的更具表现力和灵活性的形式。ChatAnyone方法支持高效、连续地生成分辨率最</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=4&amp;sn=91fd6e18725e32c71a9a1aedcd30d980&amp;chksm=fdc542faf74dacd7441049d7faa73e1d07fffe7e56a4bdfe1b2d48d2c8b745d55a191c824cae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[SIGGRAPH Asia 2025 | InfiniHuman：精确控制高保真3D虚拟形象生成，质量、速度、可控性新SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enOsWGSowG7dTvaQfLGpk8QicdBAs8Aib7va23bWsWpqu8icglxyMSNUvMZbiaDvbffJ5Il6VfmAZrQibA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！已有的问题训练 3D 人体生成模型需要大规模、多样化且注释</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=1&amp;sn=bf43f95276575507f9fe7b1bafa56ac1&amp;chksm=fd9dbe291e25197c12a19a945d8426d3a0284f0d323678c6d942275861363f3d440adf7dfe1c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[PractiLight：无需大规模微调，扩散模型重新照明图像的“隐藏密码”是啥？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnlicYMzw1WzNwt5le6iaI9cTAtDXqeQhLib2EX5oj6diaoeWrR70g9ysxhaoNYpWZY23iakey176zJZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>标题:PractiLight: 使用基础扩散模型进行实用光控制论文：https://arxiv.org/pdf/2509.01837项目：https://yoterel.github.io/Pract</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=2&amp;sn=8ef495b549f3e3a9c92b0dccab2d61a9&amp;chksm=fd9e4e6a5dcb964672d2df19778e1441b271d659edf07e1b8a3fe2443dcdbd1ecd205904459b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ComposeMe：可基于文本对多属性（单人&amp;多人）多属性（身份、发型和服饰）随意组合和解耦控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emWWjXopniaeJLQgrb3xQhEL7RSTXR33nIN4iaeIZzyicy21ek0qtCribmBzLEKIQKTXlZCuSFX5nE6gQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！ComposeMe 是一个以人为本的生成模型，能够对多个主</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=3&amp;sn=1818783d04017ce378e04da2cc13aed5&amp;chksm=fde80c8b9926fd0aeb0b2c32056521c9794613341a3db90171a63fed6d63575c14bf1906815e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[清华&amp;字节开源HuMo: 开启多模态可控人物视频生成新方向，输入文字/图片/音频即可生成电影级视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPl5fon0zqaCYa1WAGMKib43ibDcv8gDnvjAAPXvsT4Mkr1cgVcibJpA2nLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由清华大学、字节跳动提出的 HuMo 是一个统一的、以人为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=4&amp;sn=6564abd580965ba764cef195e76dbb88&amp;chksm=fd73bf6836dc9b17027c625fbfd75cf4e52e8d01b067031be52e06307f0bd7e3c0dbd09a948a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频编辑新突破！新加坡国立大学等提出视频编辑框架IMAGEdit，无需训练、即插即用，可实现任何主题的视频编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emLic2Rhpf3QYj2hoRbhoUGYVMUFb9T05FusR4LFekAEqguwQXicMNaz2b4xr4qqaicYzthFWJxjTGUQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由新加坡国立大学、南京理工大学、香港科技大学以及南京林业大</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=1&amp;sn=adcab57cca0b2c356cf78b25100d83ca&amp;chksm=fda4e414b31312459c984b050f560ac94752c0b1eed7b2398b03f615903f975de6de83c5db9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大×字节提出ComfyMind：生成/编辑/推理三连冠，开源领域再掀狂潮。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elI7B3IZQkA99hvyeKlzPzyeqYm9eaK3j5oUNFlRDs6yaz4YvOHWYMnpeWHk5ic5s7zDkXrP7RYtBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、字节跳动提出的一款基于 ComfyUI 平台构建的协作式 AI 系统ComfyMind，旨在实现稳健且可扩展的通用生成功能。在 ComfyBench、GenEval 和 Reason-</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=2&amp;sn=53b8a5337447606a825e005533fa6fa4&amp;chksm=fd80ce8c5374e1a0916cd33d73821748be34c8a4e743c48f022c31934b0a75289e3ed552afd6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一文带你了解，MOE 架构是什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIrjh2Jy92UibXavMpGEKRelbCqXiaEc6hkxXvNNtIibfW3p5bo1jGWB6icwh68qvkWZsqN65HicvwiaN28w/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言：从“全能大脑”到“专家团队”你是否想过，为什么ChatGPT能回答复杂问题，而手机语音助手却常“卡壳”？答案或许藏在一种名为**MOE（Mixture of Experts，混合专家模型）**的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=3&amp;sn=9cea44aea0eb7ea52fd0c928a228cee1&amp;chksm=fdb4d195c45c8ec21cef5697e144fc97bbff88541cf648ce3e24b3b9a37ef123ca8a8e62fc43&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UniRelight：用AI重新定义光影，一张图片也能“玩转”重光照！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic7KwJk2LgWQGVllkaSM8Yden54sxzolLeKOFFxwK9icp1NVTJKWB0YicQloE0ZSIvv1TppUDEibwHmGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>UniRelight 是一种基于视频扩散模型的新型重光照技术，能够在单次推理中联合估计场景的反照率并合成重光照输出，显著提升了跨场景的泛化能力和视觉效果。在视频处理领域，我们是不是经常因为缺乏高质量的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=4&amp;sn=eaa2b41cf41c3092b12fd7dbda307546&amp;chksm=fd5516fe692982b084b896cfd0ebb3b33b87b5a0464764f894da49b8409bca32d0f71a576014&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频风格迁移来了！PickStyle：使用上下文风格适配器进行视频到视频风格转换。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elEv3MSa6ccibpmEQKSzhgQ7UuWbPaLgc6zUuDRLlVC18cglPGyBxG5znGze4u2gwIy7ln9hKWS7Ug/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！利用扩散模型做视频风格迁移，想保留原视频内容的同时渲染成指</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496436&amp;idx=1&amp;sn=ec519cceab55c212ec4754abd6645bfc&amp;chksm=fd95784252e593a25c63614e4c1756d7c44400c3096f9f0a650e1a2339dab39e48381a763af1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UIUC 提出视频虚拟试穿生成方法 Dress&amp;Dance，可直接生成 5 秒 24 帧 1152×720 分辨率试穿视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elxI31iaYSzUGibFXibPx7ZT4tBLMjqKcIp1dlicic4aiaiaHmttztn5oIPkYWibFSwfMWCgR2sdIddrNXBUA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在一系列示例中（包括随附视频中展示的示例），该方法生成了 时间连贯且逼真的结果，通常能够捕捉到细微的动态，并与输入提示保持高度一致。同一模型在各个任务中具有良好的泛化能力，展现出强大的组合性和对各种条</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496436&amp;idx=2&amp;sn=05d9319c9d4ed2a81a3f972c2090defd&amp;chksm=fd7b39e29362bfd6e2883f845ffbb6bc32caa491704f955b50e4ac073f6b2060bf8311a73240&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TripoSG:一键使用AI在数秒内生成3D设计,支持文本/图像/涂鸦等多种方式，引领3D生成潮流！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eks71KCI53QzfLjA27o9Yf3eNhhBOwNK1fL9KrI6VvmwpTtHQY75YN6kpUNFib9wnGUtDzn1YjAYicw/300?wxtype=jpeg&amp;wxfrom=0"/><p>TripoAI发布了最新3D生成模型 TripoSG，能够生成与输入图像精确对应的高保真 3D 形状样本。涵盖各种复杂结构、多样风格、富有想象力的设计、多对象组合以及细节丰富的输出，展现了其强大的生成</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496436&amp;idx=3&amp;sn=ebf245d1e1bca9f593d46a91d99b45b5&amp;chksm=fdab3366473cd64fd694fe403adbcc572e86a08f58dad3086f2edf6ccea65bf8ab119da9603d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[超越SOTA！浙大&amp;斯坦福提出 DiffLocks，单图头发 3D 重建精度提升30%，首次支持非洲式卷发生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48OPjpkTnf2mQjjRuiawRZ5BrVMBtgVJ4QGZRnabuCSKficVh97iaqr4QzQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>由浙江大学、斯坦福大学等联合提出的DiffLocks，给定一张 RGB 图像，DiffLocks 使用扩散模型生成精确的 3D 发束。该模型基于一个包含 RGB 图像和相应 3D 发束的新型合成头发数</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496436&amp;idx=4&amp;sn=26a3324ffc4b1b009a9547460d0468f0&amp;chksm=fd733c28bce4f795bc8f2fb43499ed1ac0127985050eb288dc85ef6c740669b81e4f5fceb5b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[科研人福音！新加坡国立大学提出Paper2Video:可从学术论文自动生成演讲视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elEv3MSa6ccibpmEQKSzhgQ7Zy3hiaKHYib2lGSspRic4u1goQPDmRFrHAt8SY4ojfmAjmkgEjJryDqxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！新加坡国立大学推出了首个研究论文生成演示视频方法 Pape</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496397&amp;idx=1&amp;sn=d048d303f0963978f9001b982fd2b71b&amp;chksm=fda52a16bc1c8a7427649732be7c0036e3cee905c004c44a6c5dcf3802dba737113980a4bb0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源 30 亿参数统一模型 Ovis-U1，多模式理解、文生图、图像编辑样样精通，多项学术基准测试领先。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuDmLq7R1rRFldNX6Em3MD3ic6VVyQ7fibbkHSDXdsLJJKPKURibic6bQdSKAoTkLHaP0dHSb0n5P6Zw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Ovis-U1 建立在 Ovis 系列的基础上，是一个拥有 30 亿参数的统一模型，它在一个强大的框架内 无缝集成了多模式理解、文本到图像生成和图像编辑。亮点统一能力：单一模型擅长三大核心任务：理解复</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496397&amp;idx=2&amp;sn=8f3149189a584831eb339610c9b7a185&amp;chksm=fd1bbb35bc6fec02deb3a16aa3edbbbf85f7259704aa6c6bb6c3a18757e2c9e2ac0a76ac1ba1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南加大&amp;Adobe重磅发布Comprehensive Relighting：一键换光+背景融合，助力视频达成“光影自由”新高度。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPCjTfhE2exCxyco6laPao3eibod5YTwwibyAUooUJyItngDiaCLt2D05dpqXaf3zZNZU7L9YG4LZAA/300?wxtype=jpeg&amp;wxfrom=0"/><p>南加大&amp;Adobe重磅研究:一键换光+背景融合,视频也能"光影自由"了!南加州大学联合 Adobe 提出一个通用且一致的重光照和协调模型Comprehensive Relighting，它可以控制单个</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496397&amp;idx=3&amp;sn=13e9988e0cc7b1f1a2bb8b29865242ec&amp;chksm=fd4019640589ffb05adaffd4dca38d4dca0b6531eda038c24ebcd44cf2f10e6cab212900a21f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[FabricDiffusion：一种将织物纹理从单个服装图像迁移到任意形状的 3D 服装的方法。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elxI31iaYSzUGibFXibPx7ZT4t9zr8jgdgznSHBpr8KPFptQVyDibTicfx7btZAHHl7PFvrF98ZKzwDg4w/640?wxtype=jpeg&amp;wxfrom=0"/><p>#服装生成 #diffusion #服装建模 #3D服装 谷歌和CMU提出FabricDiffusion：一种将织物纹理从单个服装图像迁移到任意形状的 3D 服装的方法。@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496397&amp;idx=4&amp;sn=b0bd55e22855263868709c7cf77f6e17&amp;chksm=fd3a2a779ea6eaf49a92814f8a84fc158a124f597634656b3af33b8b8bbbd18c1abacfe6df7e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源 DreamOmni2：多模态赋能突破传统局限，开启图像编辑与生成新高度。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emscrJryeqES6ReYP0UJe5EkqpQLGatVsmugRb4g89uJjGPQGQicLcM9ia3nWD6Tk4BLQRmypU88fSg/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！在图像编辑与生成领域，基于指令的编辑和主题驱动的生成虽有进</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496382&amp;idx=1&amp;sn=698d79361bc1532c1f05d8f8d8d0f248&amp;chksm=fdf8a6a4392d1a15a488ea5930b8cacfa250516b679e60ac559cdbf41a74930c64f3241286b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一个无解码器的分割框架？南洋理工&amp;字节提出文本即掩码新范式，纯文本生成实现精准图像分割！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQhGsVbibiaaIKZVlmUPbRX8sicN7cpGUoAHZK4L4pKFqDJZ6qtxkGA500DicCkCNbUykZP8wia8nX1zO2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>多模态大语言模型如何重塑计算机视觉任务？大模型时代下的图像分割怎么做？还有什么更优雅的新范式？过去，开放世界图像分割的研究多基于 SAM、DINO 等视觉模型架构展开。今天我们重新聚焦于多模态大语言模</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496382&amp;idx=2&amp;sn=ee94c1e02f687d9c2660ccc4732ee37e&amp;chksm=fd8e11e5a54ccc56663bf579d0367955203624c3fa076bd5fae7bfb08b72c0f235791ef18d10&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[CLIP为何搞不定分割与检测？哈工大团队开源通用视觉任务新框架：突破开放词汇稠密感知瓶颈！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQhStl9HDM6GcOr3QDheUhWnTstzlpacic9HQc2VSI1YMX5Lafwo6gBia6Jqbia9MEWd5YYGYjR5Yu5Ow/300?wxtype=jpeg&amp;wxfrom=0"/><p>面向2D检测、3D分割、6D姿态估计的通用基础模型基础模型已经改变了计算机视觉领域：CLIP 首次将图像与文本连接起来，DINO 擅长捕捉语义结构，SAM 提供精确的分割掩码。视觉领域需求更广泛的任务</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496382&amp;idx=3&amp;sn=3e81bf0fd7d9e6d0044ad860b1c2be67&amp;chksm=fd926cf30aea9c66106f4c6d463cd1c6072dd8d5b2bbdcf6405c99de4bed625b5005f2b27d0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[实时交互世界模型新突破! Skywork AI 发布 Matrix-Game 2.0：多组件协同攻克交互式世界模型实时生成难题。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekx8zwpPTniaJZsAwfrtcHvicKUBVZ5ZRTP8MvpFhyoqpVrXwR4ymQc9sX55F2kbswy8bXWbkY2gH3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496382&amp;idx=4&amp;sn=9e97aa598e4a0fc62a0721db1f99a87a&amp;chksm=fddf84119841deedd3a755fdbb699b311d255d38388825c883872cbc21f70dcf02bd7b77e56b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大开源 World-To-Image，让T2I模型提示准确率狂飙8.1%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnlicYMzw1WzNwt5le6iaI9cR5171t9co0Zibr73NZDzQxwk0fJaUicmJoQYiaW8ehHCWpPqAaRke2Dwg/640?wxtype=jpeg&amp;wxfrom=0"/><p>文章：https://arxiv.org/pdf/2510.04201代码：https://github.com/mhson-kyle/World-To-Image虽然文本转图像 (T2I) 模型可以</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=1&amp;sn=ee8c1871b4541c9cb5c837f88c61467e&amp;chksm=fd96fcbce34d36925205eb0e9cf3169fadc4c64ab288fcdeb4ea2de02b65dcff7be3c824a960&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[当一群清华学霸开始较真扫地机算法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/DOQ3oqzSJUGgRpf0B3qbE2C9X7xdq25icUWNmwCVAMceibXUAcZcn7a2LBCqiaYwhhqusRvHibDP5TBvOVYxFFY1fQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在追觅，最聪明的大脑盯上最琐碎的家务。作者｜王彬封面｜Unsplash扫地机作为消费品的故事，常常被归类于“消费升级”的一个注脚。最初，这只是一个新鲜的小电器，消费者尝鲜后就束之高阁。可在步入消费市场</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=2&amp;sn=555da5207619b12816baedfc471c676c&amp;chksm=fdebb3499cc6a6d4c587b8ae4e700f3c6c175f073772efa54293e8abadeb7dd1cf9307011120&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[清华&amp;字节开源HuMo: 开启多模态可控人物视频生成新方向，输入文字/图片/音频即可生成电影级视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPl5fon0zqaCYa1WAGMKib43ibDcv8gDnvjAAPXvsT4Mkr1cgVcibJpA2nLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由清华大学、字节跳动提出的 HuMo 是一个统一的、以人为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=3&amp;sn=c40267d37a9ba71c12471265c6731882&amp;chksm=fd655001fa6a46812132eb35ae6cea96b6426fd038209b251309ead711ccdd1a837ceaf07369&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[耶鲁大学和Adobe提出SynthLight：智能重塑人像照明，打造完美光影！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPyLquFq9rYTicjFkPwyh9fFVDfMwbeuJFlesWohTUXxZRSXxUpCJVwUUib0mdhjaia5sa6Ciaibic8AQg/300?wxtype=jpeg&amp;wxfrom=0"/><p>耶鲁大学和Adobe提出一种用于人像重新照明的扩散模型SynthLight，该方法将图像重新照明视为重新渲染问题，其中像素会根据环境照明条件的变化而变化。在真实肖像照片上可以产生逼真的照明效果，包括颈</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=4&amp;sn=0c2034f136a5fa25ca13fcd3084a0cc8&amp;chksm=fd217a2d42814ad6edb3c5d53b5e47a5dbb3a6a5c62fb2a78a358e54d747c0530bd13abe85f1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[PractiLight：无需大规模微调，扩散模型重新照明图像的“隐藏密码”是啥？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnlicYMzw1WzNwt5le6iaI9cTAtDXqeQhLib2EX5oj6diaoeWrR70g9ysxhaoNYpWZY23iakey176zJZA/640?wxtype=jpeg&amp;wxfrom=0"/><p>标题:PractiLight: 使用基础扩散模型进行实用光控制论文：https://arxiv.org/pdf/2509.01837项目：https://yoterel.github.io/Pract</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496333&amp;idx=1&amp;sn=4708adde1bf709723339c66879be6ce0&amp;chksm=fd60cff4b847e1cffef8e580201dfcb46e0b60497821e0a553940a43c6679ace17e9532f9ee2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 22 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[国产AI模型GLM-4.6硬刚Claude Sonnet 4！200K上下文窗口+工具增强推理，重新定义多任务AI代理。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ensv02pBKeqkonEQJOUXibY7hzAbyZn7bwmuBUKUeOolM1ExcrLibyiaGAibN6bSJb55S90be9iaWL1V3w/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！与 GLM-4.5 相比，GLM-4.6 带来了几项关键改</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496295&amp;idx=1&amp;sn=c682887be4121733436548a3b7b3e234&amp;chksm=fd2583c5956faa2f4b01816518c2e22398a5e270717e0eeb04ea9e4091f845c7233db1921f12&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq5BIttmnJoy6onMGT6hEJiblmfujJkZFpZjpO6usAYRtw7aj1tZbJZYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元团队提出的 HunyuanVideo-Avatar 是一个基于多模态扩散变换器（MM-DiT）的模型，能够生成动态、情绪可控和多角色对话视频。支持仅 10GB VRAM 的单 GPU运行，支持</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496295&amp;idx=2&amp;sn=9e15f1b4badd4cdf160a087d591e516c&amp;chksm=fdb569fad9336fcba00277cae803d58900eb685f11000ea3ac0dcad6c3e770c7cc1925cc3f7f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta 开源视觉大模型 DINOv3，尖端图像表征，无需人工监督即可训练，数十个视觉榜单准测试性能SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emC8TzOo0tTPOfwjIibibRDG0V8FDngTwB5bIGKr0RDuL4kJibH8eGgHeZFrbt39SzRkrsY30LsWE7iaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Meta 发布了 DINOv3，它可以扩展图像的自监督学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496295&amp;idx=3&amp;sn=025d3c182b179c92ac5463ef6b871574&amp;chksm=fd93a5fefb1b9cdf22c0614518a7a3f3ef68b221f7e778927a9d2e5440531a32680317b54045&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 16 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出X-Streamer：引领多模态智能响应潮流，打造跨文本、语音、视频的实时数字人！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enlgSVEo2CkoPRMLkJWUSx7fVAdpE1JtBXXX6nHHPhLI2VUagXFo575vzOSXIdMeYRC3Xx62Fibk2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496271&amp;idx=1&amp;sn=5ccc9bf8ea01e680c2144895c1048295&amp;chksm=fd534c8b520063260408315d71a33b2ced31b83cc6d9869f58b5fa43ef4986e9906b97dcc9a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[还在担心不会写提示词？腾讯混元提出PromptEnhancer，可自动进行提示词改写生成高保真且风格多样图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPlFcEKrb9MGqy2aH6grpJkAOykmexaibpb6FRIiasyV3LGEBz8ZqX2d3Wg/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Hunyuan-PromptEnhancer 是一款基于腾</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496271&amp;idx=2&amp;sn=44a315ed27e355bb9c078d460fc4f9f0&amp;chksm=fdd360f420593a13856d6bdad29d2d33be0930c2b5559121ebf7be8796d0dcdf0a79e7a6807d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[手机跑AI，25轮对话耗电不到1%！谷歌开源Gemma 3 270M，适用于多个领域的最佳且最小的LLM]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQiavic0RLHKWwicCvLR9emF1icwlibibegD35clic0yQMgcIAy3AFP5Ziak3CVpypiaUSQ4uoaqZTs5dibnN1wQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>适用于端侧任务的Gemma小模型Gemma3-1B、Qwen3-0.6B这种小模型有什么实际意义和用途吗？如果你接触过真正的线上服务，尤其是搜索推荐这类每天跑千万级请求的系统，你会发现，它这种小参数量</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496271&amp;idx=3&amp;sn=dcb5fc5ac5eb12f8d4aa9e862f819c09&amp;chksm=fd4b58aa455434313149ebdc1d81d9b495945b73dddfabe7d170ba3fcf526fa34ac158674ca7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一个无解码器的分割框架？南洋理工&amp;字节提出文本即掩码新范式，纯文本生成实现精准图像分割！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQhGsVbibiaaIKZVlmUPbRX8sicN7cpGUoAHZK4L4pKFqDJZ6qtxkGA500DicCkCNbUykZP8wia8nX1zO2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>多模态大语言模型如何重塑计算机视觉任务？大模型时代下的图像分割怎么做？还有什么更优雅的新范式？过去，开放世界图像分割的研究多基于 SAM、DINO 等视觉模型架构展开。今天我们重新聚焦于多模态大语言模</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496271&amp;idx=4&amp;sn=f06cde6b1db30381364f9562df75aec6&amp;chksm=fd9bc82f955eb66edf9cfc38ca05a3c1cc14dad542c5e4bf6e10a995337ebd71158ee270a587&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[国产AI模型GLM-4.6硬刚Claude Sonnet 4！200K上下文窗口+工具增强推理，重新定义多任务AI代理。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ensv02pBKeqkonEQJOUXibY7hzAbyZn7bwmuBUKUeOolM1ExcrLibyiaGAibN6bSJb55S90be9iaWL1V3w/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！与 GLM-4.5 相比，GLM-4.6 带来了几项关键改</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496238&amp;idx=1&amp;sn=d792f933fbb3e252892d87c81a6377a5&amp;chksm=fd9e70095b76517568b92ceec85aa653d2d733ffd8fe6f3956b314e7b7aee74c668a854eba24&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 00:16:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq5BIttmnJoy6onMGT6hEJiblmfujJkZFpZjpO6usAYRtw7aj1tZbJZYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元团队提出的 HunyuanVideo-Avatar 是一个基于多模态扩散变换器（MM-DiT）的模型，能够生成动态、情绪可控和多角色对话视频。支持仅 10GB VRAM 的单 GPU运行，支持</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496238&amp;idx=2&amp;sn=afd0901abc75269ba93ee5e7e1bd64cb&amp;chksm=fd9141007b21558009c30b5759f0096f5bc7c45179a72eee6fda50b886f8ab475d1e85188232&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 00:16:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta 开源视觉大模型 DINOv3，尖端图像表征，无需人工监督即可训练，数十个视觉榜单准测试性能SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emC8TzOo0tTPOfwjIibibRDG0V8FDngTwB5bIGKr0RDuL4kJibH8eGgHeZFrbt39SzRkrsY30LsWE7iaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Meta 发布了 DINOv3，它可以扩展图像的自监督学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496238&amp;idx=3&amp;sn=654f39079bcfbe9e964dedc5fe388be8&amp;chksm=fd91cdd9eb9d2fd2b93627bd2014dc60459d2f5b5ad30def153769b5bfe05e93754ad928e5b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 14 Oct 2025 00:16:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2025 | 复旦大学提出Seg2Any：赋能分割掩模到图像生成，开启精准控制新时代。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekGicBXM3YuJldcx9kQib4alcegEwE0vptrxNZWKa3mNsgf6g8KUJNgtictmrNCuGQHiafibkUZ9ic7Vxvw/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496162&amp;idx=1&amp;sn=0a33ae1b128a4ce5901dc96d87d681cd&amp;chksm=fd81cbe632f68a148166dd88a15d4eaf819767f8e38bdab1ab4458081e7501e05820a05a8eed&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑进入视频时代！字节Seed&amp;新国大提出VINCIE，视频驱动扩散模型，概念合成效率提升300%。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ennrAAVlvm6a2ndtb8NAAAehQOd2pAp8oOdmjraUibFjm5UwibicaIfLZpvl4licgd3FvIqQuDnyebylw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在图像编辑领域，如何让模型真正理解并响应动态变化的上下文需求，始终是横亘在技术落地前的关键挑战。传统方法依赖专家设计的任务流程与分割修复等辅助模型，不仅数据标注成本高昂，更难以应对复杂多变的编辑场景。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496162&amp;idx=2&amp;sn=b1504b0e2a09b52e7a5f743db3f710d9&amp;chksm=fda2cb0cec8a4868df49599ff2c48fd6c25739eee768fb603c590356d68455f4e0b697a280e2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[清华&amp;字节开源HuMo: 开启多模态可控人物视频生成新方向，输入文字/图片/音频即可生成电影级视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPl5fon0zqaCYa1WAGMKib43ibDcv8gDnvjAAPXvsT4Mkr1cgVcibJpA2nLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由清华大学、字节跳动提出的 HuMo 是一个统一的、以人为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496162&amp;idx=3&amp;sn=b081f9794e9d1613f567f1f1b959e3ec&amp;chksm=fd68b1af5363d2415a12dda5abfe89d399c95d85ef9e23607f2cf74b370a513e08a0ac8407ea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 13 Oct 2025 00:00:00 +0800</pubDate>
    </item>
  </channel>
</rss>