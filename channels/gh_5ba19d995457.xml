<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[LBM：用于图像到图像直接快速转换，支持可控照明、图像恢复、物体移除等功能！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eniaAibjBDYoftj8VvjntaLlazzrjyAuCaxtUgTmwTpbpXdlUbj1mP1pmA9QicicVlSzvQAT83J2fYzAA/640?wxtype=jpeg&amp;wxfrom=0"/><p>LBM是一种新型、多功能且可扩展的方法，它依赖于潜在空间中的桥匹配来实现快速的图像到图像转换。该方法仅使用一个推理步骤即可在各种图像到图像任务中达到最佳效果。除了效率之外，该方法在不同图像转换任务（例</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491145&amp;idx=1&amp;sn=634fac8d9ea595075a47b53234a9bb6e&amp;chksm=fdd5ea90c709df77094ec95009f3bfc05b1c63bc308c459db6bc8df21dc5515d1d27c68bde06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 多实例扩散模型MIDI：可从单个图像创建高保真 3D 场景，模型&amp;代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emQH9S7pGDiaODq1bPiaoKg0UwQg0Pd1kyLMVicNPaNIDRbCcjvvBMqMbicEWI8LS5IVX4LjXG1tHR3Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>MIDI 是一种 3D 生成模型，用于从单幅图像生成合成 3D 场景。与依赖重建或检索技术的现有方法或采用多阶段逐个对象生成的最新方法不同，MIDI 将预训练的图像到 3D 对象生成模型扩展为多实例扩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491145&amp;idx=2&amp;sn=1fc54bdf95dfe0744559c199843bde39&amp;chksm=fd927151fd8eb3bbe9cbf32391801357cc9151e0ff890b22082dfee41432d0d7aaa8df0d2dc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491145&amp;idx=3&amp;sn=2ba230053e3532c4eaa82000472e9f44&amp;chksm=fdc6b343b7a3f3c4dbeee794937659987f7cdc636ec953cda7ae7a38e5415b491e1606e0b376&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从故事直接生成视频？一起来看DreamRunner如何重塑内容创作。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em0iaj7vmt3M8WRLr6mq22stzrb2ORCEYsI27cibQt41Hzt6FKUSn3V7ianSHVRapnj3w9FKpNt3jwDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天为大家介绍一种新的故事到视频生成方法-DreamRunner，它能够将文本脚本转化为长篇、多动作、多场景的视频，让故事跃然屏上。通过大型语言模型、检索增强技术和新颖的3D注意力模块，实现了对象精细</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491144&amp;idx=1&amp;sn=527085cf04e65dcc40786ac83f999b49&amp;chksm=fd0b62998addb3b9b1e4ac7a1a2c0e212795810c43f31a84ef65955f4af322d034cdcb888af3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[人类运动生成新方法MoMask：可将文本描述作为输入并生成相应的高质量人体运动动作]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enScf5fx9rxa1dXnvYHW4G8O9hft4BsqOTmwYEXsfgumPYvUYjCh2XTNsWpfHC7OEh6xL16D8nmMA/300?wxtype=jpeg&amp;wxfrom=0"/><p>该图展示了 MoMask （一种最先进的人体运动生成模型）生成的运动示例。MoMask 使用文本到运动范式进行操作，其中它将文本描述作为输入并生成相应的高质量人体运动。这种方法确保生成的动作准确反映给</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491144&amp;idx=2&amp;sn=b6c2ad0daa4abe41f377e4defea21fd3&amp;chksm=fd4391fd66eb48093f740f30f326c15465961868d925ea0432ffa11dbc53a7cb5e176e064051&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像超分辨新SOTA！南洋理工提出InvSR,利用大模型图像先验提高SR性能, 登上Huggingface热门项目。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emvRmmSX73ApBN83mPSIUnndGUoqrp8dTsfo3BKVIVGVNf5sWoXGauJCgAEaaCQm9Qb7QfuM34qZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>南洋理工大学的研究者们提出了一种基于扩散反演的新型图像超分辨率 (SR) 技术，可以利用大型预训练扩散模型中蕴含的丰富图像先验来提高 SR 性能。该方法的核心是一个深度噪声预测器，用于估计前向扩散过程</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491144&amp;idx=3&amp;sn=d449b3cd829b0149c870eee4453c8b52&amp;chksm=fdf6282d9b01e5e52e10a03f6ad5ee6937818f0b6f515f6122b8fa783f0255f0fde2c9d684af&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 多实例扩散模型MIDI：可从单个图像创建高保真 3D 场景，模型&amp;代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emQH9S7pGDiaODq1bPiaoKg0UwQg0Pd1kyLMVicNPaNIDRbCcjvvBMqMbicEWI8LS5IVX4LjXG1tHR3Ww/640?wxtype=jpeg&amp;wxfrom=0"/><p>MIDI 是一种 3D 生成模型，用于从单幅图像生成合成 3D 场景。与依赖重建或检索技术的现有方法或采用多阶段逐个对象生成的最新方法不同，MIDI 将预训练的图像到 3D 对象生成模型扩展为多实例扩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491095&amp;idx=1&amp;sn=85d958a51022cf7e925ab3491e2e5f45&amp;chksm=fd8b32da5366595615b3b53cde0812909af362b3d5b4e111c7e7db4451c470b5178731701cb9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 机器人双臂操控新突破！KStar Diffuser如何解决自碰撞与运动约束世纪难题？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojvz9clmicqUEHWru0TSQwicibDxwd6pXeiac1QbZwUoibnWeMnE5ib2jBibpdEXVK5T4bFCwMWWK9BcS4dg/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2503.10743亮点直击与现有方法仅在笛卡尔空间中优化末端执行器姿态不同，提出了一种新颖的时空机器人图，显式地建模机器人物理配置，以指导生成动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491095&amp;idx=2&amp;sn=a43ce9bacb8fc5cd2f97f6e717ed4f7a&amp;chksm=fd0102af1774207828e3b6cb374952fb09b1e8b687c2d11f2fe986c792e02429768661b93a8e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[利用多模态模型赋能，SONY团队完成音乐到音乐视频描述生成大突破！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Jn7gNOibialUb7ePwaNgQPKeSIN3Kfa1hwX15JM3vgCh8jl1Fm3ZyyqibhJ0YwwiaTxARyLn4ucxtkUw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Cross-Modal Learning for Music-to-Music-Video Description Generation论文链接：https://arxiv.o</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491095&amp;idx=3&amp;sn=f8a3a85cc2c4eeb581aeaf949bc70993&amp;chksm=fd79f8b1adb1359fe84e9e6f83543a09949da62d8477714ceed47192aadfd7b0965453f9e552&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大×月之暗面发布AudioX，文字/视频/图片秒变天籁！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>香港科技大学和月之暗面联合提出的专门用于从任意内容生成音频和音乐模型AudioX。该模型能处理多种输入模态,包括文本、视频、图像、音乐和音频,生成高质量的音频输出。核心创新在于多模态掩码训练策略,通过</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491095&amp;idx=4&amp;sn=25831a6d8744c0b9765b0d7d5e9f6ced&amp;chksm=fd3c592325e214ebf96d49d067b539b9c6417e29b03b34bbe3bf33f9f55c1aae6beac80e21e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 革新Transformer！何恺明联手LeCun提出DyT：归一化不再是必需？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1ooajMkbIFOmToYOkf8bGybVBib7s52Qh37f3FnLf24sWvTNFVjtzAMA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，何恺明与LeCun两大巨头联手，对传统Transformer模型提出了颠覆性的改进——他们发现，长期以来被视为必不可少的归一化技术，或许可以被一种更为简单的方法所替代。这一发现不仅挑战了现有的神</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491077&amp;idx=1&amp;sn=5b9cc94084c1f2c59d5ce0162c993798&amp;chksm=fdb3a784a1605c54ce89ee4eefb494c1a84c4b9207b5590fae69b7efb1bb9d624c576544fa6c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491077&amp;idx=2&amp;sn=c402cd18055206edd349bf70a3a01a99&amp;chksm=fd002a6475afbbed4992d83974755b8bd7d4828e1830b3b60d91603b1b590f666e9de03e3a32&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里推出升级版AI翻译工具：Marco MT 性能超越Google、DeepL和ChatGPT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvICGVGwvK1ZowHkm5otQN1GWBq1oKgOpXCvFcU6T8e0WgLCSBUqvcfmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里巴巴的国际业务部门于推出了一款升级版的AI翻译工具，名为Marco MT。这款工具在翻译性能上超越了Google、DeepL和ChatGPT的同类产品。该工具的目标是帮助商户更好地在全球市场销售，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491077&amp;idx=3&amp;sn=8ca6fdbcee6dcc29da4038d1497cfc5a&amp;chksm=fd3e2e82e9fa19254f2be3ec7d7c30b0e510cf264fb59c95bddc26bf4b030727f46105e4c3c5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出虚拟试衣新方法EARSB，让时尚与科技完美融合！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2empB05GMsROweibZLQdTRdryhxs0ChYaSb8Q7MXgpODuC675ClEZrLFicPt5eWjzKjxOHWcsP2ic7rBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在数字化浪潮席卷全球的今天，科技正以前所未有的方式融入我们的生活，包括我们追求时尚的方式。想象一下，无需亲临实体店，只需轻点屏幕，就能轻松试穿心仪的衣物，这不再是遥不可及的梦想。NVIDIA联合波士顿</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491077&amp;idx=4&amp;sn=eea9f97b23811a912c998e9adf84b343&amp;chksm=fd153d0336e0da365ecdaf5a939f9ec9e80e48c73ba68a2db9c0bcc75bcdff2d36315e194156&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[清华人大上交大教授领衔，DeepSeek时代中国生成式AI大会4月举行！Manus最强平替和杭州六小龙之一也来了]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enAqmicvH5JOXsTyWrTA6QL4RXBibNKEwVaCIEPibJhnUCbAVM5LXsGiaib0p4d09yWnzUXXfG3ox13rgg/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025年4月1-2日，2025中国生成式AI大会（北京站）将在北京中关村东升科技园万丽酒店举行。中国生成式AI大会已成功举办三届，现已成为国内人工智能领域最具影响力的产业峰会之一。本次大会继续由智一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491050&amp;idx=1&amp;sn=50e25020551f32659f566a9235034377&amp;chksm=fddfdb325bfd6c3ba45dd763a54ecd2cb3fe0aa47ace6ebea04193de5667ae31de21445fb338&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 17 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek的“开源周”汇总，大模型开闭源之争来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekabsI7MyRPhcqTEHwmEMZhzqPsTtNiamBmNv64uYmLGu5CEAiaA92FyHpRoIOpDticicWkrtTuwnczng/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章来源：https://www.pyspur.dev/blog/deepseek_open_source_weekDeepSeek 的“开源周”，宛如一颗重磅炸弹，在全球AI领域激起千层浪。然而，D</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491050&amp;idx=2&amp;sn=04718e8f86a07387379784262ee59f78&amp;chksm=fd06893f3d832d641397868ba0beeb654cbea587adf9b1d8948b0e6909031648a8d021c4d01f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 17 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491050&amp;idx=3&amp;sn=79b489501f3d502023a3487dd3b4fe2e&amp;chksm=fddbf7be8ecbff789bc1ae0e27a336252c6c25e30e0a8f4007c428b986a8109a013929283261&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 17 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OpenManus：5个人三小时复刻开源版Manus，不需邀请码, GitHub已获 8k+ star！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emMD5hHjQCsGyZibkezY8B2QF5NBwYrUdvsNHsYIucmvguy5CPoDhibY2oQo4DGuhVvjgddCicOTwXcg/300?wxtype=jpeg&amp;wxfrom=0"/><p>当全网还在求 Manus 邀请码的时候，结果有一个小团队用了 3 小时就做出了 Manus 的开源实现OpenManus ，而且不需要邀请码。OpenManus团队来自MetaGPT，团队成员只用了1</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491050&amp;idx=4&amp;sn=1aea8762bd44ecfa613352f6f1d280a2&amp;chksm=fdddcdc2bcb957a9824a8e8fe1f5f048d96178f0b52943c9616df485efb8bf65da312fb1db26&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 17 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大×月之暗面发布AudioX，文字/视频/图片秒变天籁！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>香港科技大学和月之暗面联合提出的专门用于从任意内容生成音频和音乐模型AudioX。该模型能处理多种输入模态,包括文本、视频、图像、音乐和音频,生成高质量的音频输出。核心创新在于多模态掩码训练策略,通过</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491076&amp;idx=1&amp;sn=b6d30ed44fb2bc35a7bdf693ca24b43f&amp;chksm=fdf76615b29e3b42f93b5a253b5b769128ff3dcdca96a92a5eb252aed386438eb97074330f84&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 17 Mar 2025 14:29:18 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek的“开源周”汇总，大模型开闭源之争来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekabsI7MyRPhcqTEHwmEMZhzqPsTtNiamBmNv64uYmLGu5CEAiaA92FyHpRoIOpDticicWkrtTuwnczng/640?wxtype=jpeg&amp;wxfrom=0"/><p>文章来源：https://www.pyspur.dev/blog/deepseek_open_source_weekDeepSeek 的“开源周”，宛如一颗重磅炸弹，在全球AI领域激起千层浪。然而，D</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491046&amp;idx=1&amp;sn=2645ff11e2d737509edb7e948dc450fd&amp;chksm=fd3d36d39cc8b79d289dd8c6191a1ec51b46a5eb2ac575ef178dee26aff7d6589af8f5758ecd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 16 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek们的成本，是怎么计算的？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jEa2NN5eMic76LNKtDbp6JciaVMNpJ0DfXv52YEQqq4xTf9WUrtSejmqicfnUDqnZjib7GrNrJnMw22eSMwgbg8odw/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek彻底让全球都坐不住了。昨天，马斯克携“地球上最聪明的AI”——Gork 3在直播中亮相，自称其“推理能力超越目前所有已知模型”，在推理-测试时间得分上，也好于DeepSeek R1、O</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491046&amp;idx=2&amp;sn=7486e3f168b101005456a55c9dad7206&amp;chksm=fd2a6bedc99b4f7ba08a0b052d1d22def008c66152f223c879e8b33a3b6c1008090cf8cad927&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 16 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里发布新开源视频生成模型Wan-Video, 支持文生图和图生图,最低6G就能跑, ComfyUI可用!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emELibL5kVkYibicFiaR0laM2LPanMoANDKaC5QVXWXiawVrJIjXcdbschfSzanarf8EbFZpGTOSicjTZAQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Wan-Video 模型介绍：包括 Wan-Video-1.3B-T2V 和 Wan-Video-14B-T2V 两个版本，分别支持文本到视频（T2V）和图像到视频（I2V）生成。14B 版本需要更高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491046&amp;idx=3&amp;sn=c82652bcf62f3d5f9a92305be4804226&amp;chksm=fdbbebbfaa9d4bee4c1145152e40f621fb05adb65f58cdfa238e9720331ece599d2931337da0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 16 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[【NeurIPS 2024】南理工提出IMAGPose！用于Pose引导人物图像生成的统一条件框架！照片级真实感！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JooJ8m08gwWicLZ77AltgwI2LoBqS4icyib8U6icnglekic9ldZ3sa3UHTLbicYVVZWl1kXwbpRYRiaXwGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>每日最新论文包含目标检测，图像分割，图像识别检索，视觉预训练，3D/点云/视频， 图像超分/去噪，GAN/Diffusion，LLM，ImageCaptioning，VQA，视觉语言预训练，MLLM，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491046&amp;idx=4&amp;sn=c19a87f50415aa9aca02f8898b088e45&amp;chksm=fd37b92a8d552f5942be918c2629a07a60c239d883306a275c340711e9d1c852f3d78d9e0616&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 16 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[创意图像编辑黑科技！Google上线Gemini 2.0 Flash 原生图像生成功能，动动嘴就能完成PS了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1qlcic2X1ic2VEGpv2B5cJk6b1ZX2r1ZgTdASkTDLbwxnQriaib23PtrqLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>Google 实验室展示了其多模式 Gemini 2.0 Flash 模型的新功能，展示了用户现在如何通过简单的点击和文本提示与图像进行交互。视觉和语言处理的结合实现了新的应用。Gemini 2.0 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491045&amp;idx=1&amp;sn=55ec65d05ef007814468822e91297b43&amp;chksm=fd41c3419f6198eda4992ad5fbe50dbec5128c1db9e472949d39f93d6e46101350900c4e52ae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 15 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港大&amp;Adobe提出UniReal：通过学习真实世界动态实现通用图像生成和编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfcOvKg4alghJicfViaQXPN3cGVy3SYtSRiaWE0jyTlhQNs1mRy2lUoe0Pw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的文章来自公众号粉丝投稿，由香港大学，Adobe提出的统一图像生产与编辑方法UniReal，将多种图像任务统一成视频生成的范式，并且在大规模视频中学习真实的动态与变化，在指令编辑、图像定</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491045&amp;idx=2&amp;sn=d1fc3e5085e5a10af4114c169917a153&amp;chksm=fdda1e4d47c929ee5726eb740a388edbc82ff7098de1902e3605c040f853bd36b8181a568620&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 15 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI可以模仿人类手写签名了？DiffusionPen：实现手写文本生成的风格控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMicu8qqTr4Ra93TPUibujQBTT1m6XAtI0Lo36oh8XreyaNhgMAjeddeib7QZPiaRcOYqaPJbfGkLRHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>AIGC时代很多东西包括图像，视频，音频等都可以用AI生成了，AI可以模仿你的样子、声音、动作，情绪。现在它也可以模型你的签名了！今天给大家介绍的是一种手写文本生成的方法DiffusionPen，它是</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491045&amp;idx=3&amp;sn=640725848fb57c3555a489d15e17ef1e&amp;chksm=fdcff98d147dde5b5fad4ff6fee540caac2b4db1e1c03e408750e9ce5204a91e50a559dc0b5c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 15 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACM TIST 2025 | 综述 GenAI 与时尚 | 港理工、AiDLab]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekwL7bBtjRiakD5gmicmnfguSjelQRT7IzMC9LJro65Bk6kpn0bibh5WdRYwLnDK29FQbZAib2uDaDEEQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章来自公众号粉丝投稿，由香港理工大学的AiDLab团队在ACM TIST 2025 发表了一篇关于生成人工智能 (GenAI) 在时尚行业的综述文章。该论文研究包括了对 470 多篇研究论文的全</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491045&amp;idx=4&amp;sn=8d74df5a14daf51f70370c938cd68553&amp;chksm=fd9df56b0001a91c338b1ca212c5c6a46ccf83d9f84e59567eb85c0fb698e87825434cb9f173&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 15 Mar 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>