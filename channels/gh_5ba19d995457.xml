<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    























    <item>
      <title><![CDATA[一键试衣or一键脱衣？TryOffAnyone：从人像输入中生成高质量平铺服装。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUnCMiaBjZZszIFmMq4b6eoaD7GTE6xt5Kkbz15pCGnYFBHiaXPN7qYcV79yBTU689jcMRI5dJd0g/640?wxtype=jpeg&amp;wxfrom=0"/><p>TryOffAnyone 是一种新颖的单阶段框架，旨在从穿着衣服的人的输入图像和覆盖服装区域的相应服装掩码合成高质量的平铺布料图像。在 VITON-HD 等基准数据集上实现了最先进的性能。该方法在为全</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489847&amp;idx=1&amp;sn=7db0f231ee4ad08a334358ad4ac04e99&amp;chksm=fdbef338250deefff0ec767862840950325fd06792b27e5a99789e611ffa6f00840ba70928f0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 11 Jan 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[NeurIPS 2024 | SHMT：通过潜在扩散模型进行自监督分层化妆转移（阿里&amp;武汉理工）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsjQl0sGle0TkYDcmMMuGmbtLXibkDVicOAa1tpYmub1EJgQJfZ41lm6WQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前的妆容转移技术面临两个主要挑战：缺乏成对数据，导致模型训练依赖于低质量的伪配对数据，从而影响妆容的真实感；不同妆容风格对面部的影响各异，现有方法难以有效处理这种多样性。今天给大家介绍的方法是由阿里</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489847&amp;idx=2&amp;sn=164295c163ad41f30fecbb828173872a&amp;chksm=fd7b4cf596f8808e7e921d7094310ff8bda60fe4ff600ecdb39a7874ed022deba46f6d12bbd2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 11 Jan 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[阿里达摩院提出开源AI图片上色模型DDColor:可以为黑白照片、人物、动漫风景等一键上色!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emSxAhfwGrF5xDyQho3K1KHs5BPR4ic9nBrD4MlgCC5ibUfic09OiajZVFthOcVSdugCDCmu33gKAffhA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DDColor 可以为历史黑白老照片提供生动自然的着色。它甚至可以对动漫游戏中的风景进行着色/重新着色，将您的动画风景转变为逼真的现实生活风格！相关链接项目：github.com/piddnad/DD</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489847&amp;idx=3&amp;sn=52d7b395e98127288238663caa2e670a&amp;chksm=fdb9add807338abab35e833abe48d4e167ec72251d091823166a4d926cd6ba1c72545eebdcbf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 11 Jan 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Adobe发布TurboEdit：可以通过文本来编辑图像，编辑时间<0.5秒！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKcprhHqENugIHSUTwb3EOiaaqictMa8fmmNEDqsoISMhGDZH4oZmh7vtMn5sov6khPdhIypPkhDZQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍Adobe研究院新的研究TurboEdit，可以通过文本来编辑图像，通过一句话就能改变图像中的头发颜色、衣服、帽子、围巾等等。而且编辑飞快，<0.5秒。简直是图像编辑的利器。相关链接项目</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489847&amp;idx=4&amp;sn=be6267976a155ad70190989ed35356e0&amp;chksm=fd7cc3d3e3c38548c43c7110d1c2a8ffd001e2601743e5752de8dfb6c77c5c8e995550e3b2a2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 11 Jan 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[2024 AI TimeLine 回顾（独家视角）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUnCMiaBjZZszIFmMq4b6euJ14V5ibkAcCZdmtRw3lykFcu3iafSO7319RSVydS3scYAgM0oASkKTw/640?wxtype=jpeg&amp;wxfrom=0"/><p>2024 AI TimeLine 回顾（独家视角）2024年，生成式人工智能已远远超越了仅仅作为一个流行词的范畴，它在实际应用和技术创新方面取得了显著进展，成为推动社会进步和产业变革的重要力量。以下是</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489813&amp;idx=1&amp;sn=51ebf152c0ae606b68387d40e64f97fb&amp;chksm=fd9d9b818faf50990536c705845570876d1321e1d63846cae890e6b333ec8df682c105046aa8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 16:44:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[东京大学 | Adobe 提出InstructMove，可通过观察视频中的动作来实现基于指令的图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsa4uWnhrMawFt9HHkxP0mNsA8WZRJb5wtxFQzRMjAicAjmryxF8Yliamw/300?wxtype=jpeg&amp;wxfrom=0"/><p>InstructMove是一种基于指令的图像编辑模型，使用多模态 LLM 生成的指令对视频中的帧对进行训练。该模型擅长非刚性编辑，例如调整主体姿势、表情和改变视点，同时保持内容一致性。此外，该方法通过</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489813&amp;idx=2&amp;sn=81bd57715905ef2609fb944745535e3f&amp;chksm=fd097f3583d779d5924d78fb290f7d78ac6518b7e55fcdca6724101fc29da25ff3244805dc94&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 16:44:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[提出街景定位大模型AddressCLIP：一张图实现街道级精度定位！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldKGCwibmhq5RSxC5rV78dDcVpQDWZ2qUibtJW2qRF8ehlmicnuSw3n5MdOVQ0NTovfOnPib1RNDwBibQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>中科院自动化所和阿里云一起推出了街景定位大模型AddressCLIP，只要一张照片就能实现街道级精度的定位。比如给模型看一张北京南锣鼓巷的街景之后，它直接给出了具体的拍摄位置，并列举了附近的多个候选地</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489813&amp;idx=3&amp;sn=d14a4948c82f4267521c7541e0e6c672&amp;chksm=fd9e61e7c96af6e00f0affd2b24d124ab8975f8ee9fe5649ab6eb51e1cb50cbad3ccb1520cfa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 16:44:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌DeepMind重磅推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emYIXZcOoWmiamNNy78gGxDxw4uWDBzPA32XByk1moUtrt0vCzrccsjPryianfay5w8IibgLtxibuRokQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 单目视觉4D重建再突破！谷歌DeepMind推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。单目视觉4D重建再突破！谷歌DeepMind等团队，推出了多视角视频扩散模型CAT4D，它支</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489813&amp;idx=4&amp;sn=d16d497c55111563269493ea006710e9&amp;chksm=fdeea1749619d169d76f7f703c8703cbef63fc1ead7203f12104502e34f29c588633a17da278&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 10 Jan 2025 16:44:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Open-Sora: 让所有人都能轻松制作高效视频,可生成16秒720P视频，模型代码全开源！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enY2jTeFu5rQt2UydQCHT1gGKk74exRM2eDyJFgQOlbVqSjHpGrT6kqYT3dcZjwM6KYia7EwWYBKNA/640?wxtype=jpeg&amp;wxfrom=0"/><p>Open-Sora是一项致力于高效制作高质量视频的计划。目的是让所有人都能使用模型、工具和所有细节。通过采用开源原则，Open-Sora 不仅使高级视频生成技术的使用变得民主化，而且还提供了一个简化且</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489786&amp;idx=1&amp;sn=ee7e8b582b01302891eba2a4368576d7&amp;chksm=fdc8e48e95432f6e0ec62b55d801e2850cff4e0ec48bc2c96df7d9b6095e6fb8c11311a14fc0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Face2QR:可根据人脸图像生成二维码，还可以扫描，以后个人名片就这样用了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDXLyhv5gUBA9w7NggpzadO1jATGuCxxia6dLEgQBFVb37eWtav37qYkiabubYa9vGGTHlEWmbql9w/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是一种专为生成个性化二维码而设计的新方法Face2QR，可以将美观、人脸识别和可扫描性完美地融合在一起。下图展示为Face2QR 生成的面部图像（第一行）和二维码图像（第二行）。生成的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489786&amp;idx=2&amp;sn=1007b4ba61e63232b5522d81da661a47&amp;chksm=fdb4f0550aa63331955fdf42d5efc19b79c3efb3457739784022b34ffa254d7176e40f6fb36c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AI生成大片，Movie Gen可以生成长视频并配上完美的音效，带给观众更好的观看体验。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en7hMnHYqLSuapj6C0Hn0mXm2ceUm9LDTsGCA6gVbwy08k2trThGZg7tajWXlicmTHopRclOZ90icwQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍了一些关于长视频生成相关的技术，AI生成大片已经越来越近了。感兴趣的小伙伴可以点击下面链接阅读~《泰坦尼克号》AI大片重生！浙大&amp;阿里发布MovieDreamer，纯AI生成</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489786&amp;idx=3&amp;sn=c8108c61c871901674d5c04f3200df3d&amp;chksm=fdd0a335d4b1db097c75b0893910120acb0f2615a425a2ff0509ba607d3d9833033400370550&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[组件可控个性化生成方法MagicTailor：生成过程可自由地定制ID。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en5zm71fQSgV6aaqPJln47UM68LBoxEpKSBewPN29AuBHv1SMicLD8losQPDWSsMKunkqyr9HuAUvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天的文章来自公众号粉丝投稿，文章提出了一种组件可控的个性化生成方法MagicTailor，旨在个性化生成过程中可以自由地定制ID的特定组件。相关链接论文阅读：https://arxiv.org/pd</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489786&amp;idx=4&amp;sn=45a753161405c5d9b9ac62d55ac8a39c&amp;chksm=fdfb8ab6e5e3c77aa629a7140bdd946f83d1cf5d291941d8de4ca22bacd0cce5006561f50148&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NVIDIA发布GeForce RTX 50 系列，图形性能翻倍，售价549美元起！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enY2jTeFu5rQt2UydQCHT1g7XMd6NDeb8ZT5rzibNdAxLUNRykvuRcwzibHBB6xZaqbXopc67ibCic4lg/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025 CES消费电子展（1月7日至10日，美国拉斯维加斯）正式开幕。北京时间1月7日 (星期二)上午10:30，NVIDIA举办主题演讲，穿着标志性皮衣的英伟达 CEO 黄仁勋勋担任主讲。正式发布</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489773&amp;idx=1&amp;sn=6eec23bcea666d4de8f26959339feda7&amp;chksm=fd8a4b1f6a235eff10a1cc52a2f7c4e65773443f3cc02993f85422f9c43c10fcf331655e1ebc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[实时高保真人脸编辑方法PersonaMagic，可根据肖像无缝生成新角色、风格或场景图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsExUD85bPCqAicxMSnpMibzPacGZ2JJmvUibAHrezkU5Now3FS5ib9Ibg1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是一个高保真实时人脸编辑方法PersonaMagic，通过分阶段的文本条件调节和动态嵌入学习来优化人脸定制。该技术利用时序动态的交叉注意力机制，能够在不同阶段有效捕捉人脸特征，从而在生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489773&amp;idx=2&amp;sn=6492860946c07d40c97cbe6d0b4e2bb2&amp;chksm=fd56d3f312bd40eb5a81700c335ba3646fefc75cb983e45ec36de7086633e93a55bb87f3b6e0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[参数减少99.5%，媲美全精度FLUX！字节跳动等发布首个1.58-bit FLUX量化模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoh2Zk3Iwj5tM5QKick9Eg7sMHzHPiazuE08RhyHwiaSIKLUWJPrCskqeBNbCda9jDPROSF1YrFkT9yyw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIGC Studio”文章链接：https://arxiv.org/pdf/2412.18653 项目链接：https://chenglin-yang.github.io/1.5</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489773&amp;idx=3&amp;sn=ec8174cc599f204050ac78eec0863f34&amp;chksm=fd8353dcc976fad3c8ef343870724ff90d2def2ab5cac7e08580c75d0aa2049c63daa97ed41c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复旦&amp;字节提出layout-to-image新范式，支持基于布局的MM-DiT架构下可控图像生成！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekXX8zYF4UxzjmCibmVsNeNfHdzvia0ykHy5vQljhxHZhBKib0DHCIdedbOAMsic8KZ423vtGia19o4Wow/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇分享论文CreatiLayout: Siamese Multimodal Diffusion Transformer for Creative Layout-to-Image Generation</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489738&amp;idx=1&amp;sn=2cf065c34c41615747d63740ddae1646&amp;chksm=fdf3090611fd71121f6404113458100ba4f42298da828a38af4afbebb99fe53f616f2995ccb8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MinT: 第一个能够生成顺序事件并控制其时间戳的文本转视频模型。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el8quKicUEibqsQFrF8ttU8UZh4icQduMVEEU78HQlZOU3Jzp7NeFwOc2OPJY7cjEn7Ed2h55fjhbhkw/300?wxtype=jpeg&amp;wxfrom=0"/><p>MinT 是第一个能够生成顺序事件并控制其时间戳的文本转视频模型。使用 MinT 生成时间控制的多事件视频。给定一系列事件文本提示及其所需的开始和结束时间戳，MinT 可以合成具有一致主题和背景的平滑</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489738&amp;idx=2&amp;sn=daabd37573fb55541bcfa404e1e53be8&amp;chksm=fd27d81cb4ef68f95d3dd0e1723580c463bd9a98b38600f31d3aab8be09f41da1d5d3c016001&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[单幅图像合成 360° 3D场景的新方法：PanoDreamer，可同时生成全景图像和相应的深度信息。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el8quKicUEibqsQFrF8ttU8UZJIaZuVsUww2Z2IDLp7MYqLaIsWuo5dAG2Y1iaHf8AibCjXj4KFPbTv3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文介绍了一种从单幅图像合成 360° 3D 场景的新方法。该方法以连贯的方式生成全景图及其相应的深度，解决了现有最先进方法（如 LucidDreamer 和 WonderJourney 的局限性。这</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489738&amp;idx=3&amp;sn=36308e0956fc1702674d3b576b65dd40&amp;chksm=fd5c6681e5bfb59abc788f05a58bf011b5af8233f73b2cf71bdc0463682bb4706d5063768dd5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[提出街景定位大模型AddressCLIP：一张图实现街道级精度定位！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldKGCwibmhq5RSxC5rV78dDcVpQDWZ2qUibtJW2qRF8ehlmicnuSw3n5MdOVQ0NTovfOnPib1RNDwBibQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>中科院自动化所和阿里云一起推出了街景定位大模型AddressCLIP，只要一张照片就能实现街道级精度的定位。比如给模型看一张北京南锣鼓巷的街景之后，它直接给出了具体的拍摄位置，并列举了附近的多个候选地</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489738&amp;idx=4&amp;sn=e05d13b852ad0b23efe0417175152968&amp;chksm=fd5114aef7bd0210e993064b523bace19438cfcce46eac91a9a03657fd2874cdbbe50bb0f6b0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[东京大学 | Adobe 提出InstructMove，可通过观察视频中的动作来实现基于指令的图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsa4uWnhrMawFt9HHkxP0mNsA8WZRJb5wtxFQzRMjAicAjmryxF8Yliamw/640?wxtype=jpeg&amp;wxfrom=0"/><p>InstructMove是一种基于指令的图像编辑模型，使用多模态 LLM 生成的指令对视频中的帧对进行训练。该模型擅长非刚性编辑，例如调整主体姿势、表情和改变视点，同时保持内容一致性。此外，该方法通过</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489737&amp;idx=1&amp;sn=c4193433e3543f854273203d259f44f2&amp;chksm=fd0bdaaf263426cf14bbedb14b218488556e15ee48ef1c8c582bbf2aeebec282271235195346&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌DeepMind重磅推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emYIXZcOoWmiamNNy78gGxDxw4uWDBzPA32XByk1moUtrt0vCzrccsjPryianfay5w8IibgLtxibuRokQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 单目视觉4D重建再突破！谷歌DeepMind推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。单目视觉4D重建再突破！谷歌DeepMind等团队，推出了多视角视频扩散模型CAT4D，它支</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489737&amp;idx=2&amp;sn=f0b17de000da4646c72cb18fc72cb942&amp;chksm=fd22f3161c3cf0417d799f9ae7e57695241a6e5b7eae4d7a455f098f792770325f41bc9b49ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ComfyUI | Flux实拍与卡通风格lora推荐, 用于一键生成创意图像，支持用户输入特定描述。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUw7TQJFGYa2znHnNaWuO6u1JkCEEpxpul3G7pL6Igu3mLQyxXGM5cvPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家分享一个非常可爱的flux lora，FLUX.1-dev-LoRA-One-Click-Creative-Template:能够一键生成4张同一角色的真实版图片+一个中间的卡通版Promp</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489737&amp;idx=3&amp;sn=76dd7558110f8d0c1dae35ef05c06f7b&amp;chksm=fdd22e69c0388cd2f49c440d36979165bf9fe00f5b680c7ce7da4cb30bb9fc6e0f46ef80d64a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[设计小白秒变大师？AnyDesign：你的时尚图像编辑神器！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emUwYVFBw0LHKV1UPHAgKIBKELWJNRURA6xrgAWatkn6BfxpFWhMGLXocarRVQ03FpehAsEKa7OJA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在AI时代很多行业都被颠覆了，建议大家在业余时间也尽量多学习一些AI工具的使用，提高效率的同时也去探索更多好玩的应用。今天给大家介绍一个非常好用的图像编辑方法-AnyDesign，适合时尚设计师以及普</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489737&amp;idx=4&amp;sn=8fe0271dded7bd9275ba5da55d14fa60&amp;chksm=fd347e0673c4e9b7d234900f2046da2c72a0697f13da535e27e05f7d538ccaff409681bc87fb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
