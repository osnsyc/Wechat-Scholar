<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    




























    <item>
      <title><![CDATA[谷歌推出PaliGemma 2 mix：用于多任务的视觉语言模型，开箱即用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZG3A9ureoTeOkRX7vpoweMqWfIXVPrnftNxPZXeKdfJFf3WSY8K2fGQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>去年 12 月，谷歌推出了 PaliGemma 2 ，这是Gemma系列中的升级版视觉语言模型。该版本包含不同大小（3B、10B 和 28B 参数）的预训练检查点，可轻松针对各种视觉语言任务和领域进行</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490439&amp;idx=1&amp;sn=e1ed5f5383dbd15a2b1868855ddebb2e&amp;chksm=fda2e81145b6732b62e028318fd1e653fd657372addb59c6b9b8f5915aefe3f7ff73bc2fead5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 20 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[DeepSeek们的成本，是怎么计算的？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jEa2NN5eMic76LNKtDbp6JciaVMNpJ0DfXv52YEQqq4xTf9WUrtSejmqicfnUDqnZjib7GrNrJnMw22eSMwgbg8odw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型混战，一边卷能力，一边卷“成本”。定焦One（dingjiaoone）原创作者 | 王璐编辑 | 魏佳DeepSeek彻底让全球都坐不住了。昨天，马斯克携“地球上最聪明的AI”——Gork 3在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490439&amp;idx=2&amp;sn=cfa845064014dd1e045e72acec82074a&amp;chksm=fdb1e75e0d2e6ceb23beb3d9f6b256bfb50b07e94580af413ef5b66e492f14aa141ead46d74a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 20 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[马斯克全新发布Grok3模型，坐拥20万张卡的新王！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsH9cZmp9X46ouoOXg3cwrPEkXVwv6oRupo8tbuYLibC6vwAv1LMw1M0JbUwyTMWlNibd2Obo6xhujiag/300?wxtype=jpeg&amp;wxfrom=0"/><p> Datawhale分享 最新发布：xAI，Grok 3刚刚，马斯克所说的“地表最强的 AI”终于来了。在 200 多万人的见证下，马斯克的 AI 公司 xAI 正式推出 Grok 3！“我们非常高兴</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490439&amp;idx=3&amp;sn=ba8e5136a610b5c1a8e8c705efa41a0b&amp;chksm=fd14e9ce05b7e0e09b18f35c67a9face2e3fa242e6048a61c293fb8579d35add9383f93930a9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Thu, 20 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[4w Star！一个低成本微调DeepSeek的开源方案，悄悄火了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em1HmyUKxNSkwicvdQ8NMBGYFcBaleAYz933cxSgezict1pspKaC1IcNtgBUtibWM48Zg6sczMR1bjlg/640?wxtype=jpeg&amp;wxfrom=0"/><p>文章来源：夕小瑶科技说 DeepSeek V3/ R1火爆全网，基于原始模型的解决方案和API服务已随处可见，陷入低价和免费内卷。如何站在巨人肩膀上，通过后训练（post-training）结合专业领</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=1&amp;sn=fa18deca3b2bcf128a387a31c301f781&amp;chksm=fd6ba6ac454e2dcf430747a6086c3bfe97b08d2e9d865e112e45e2d4bfa3165de0583adbcfeb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文搞懂DeepSeek的技术演进之路：大语言模型、视觉语言理解、多模态统一模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic6bZ8AZw730k5S06S2AKhSycdsVgq61HibHXoXHUxwbibkSa74Uib0srhbxdiaibHxADIxvDeRt0SNaoAw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文撰写路径比较清晰，意在初步梳理DeepSeek技术的演进及进化之路，主要包括三大方向：大语言模型、视觉语言理解模型、多模态统一模型！大语言模型系列论文：DeepSeek-LLM -> DeepSe</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=2&amp;sn=a24a6403f726263ce60a8f93588ba90e&amp;chksm=fd1b6428801aef67712a9607f6e748b0b12c894f77d95d649961afc416c53e937e257d82086a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[StepFun提出Step-Video-T2V！300亿参数视频生成大模型！可生成204帧视频！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcJicm2I75ZP1rkl1ZMqicoKfreYnRFLqFBbibqBpPJl9LzNL6OUXy1tmllZuicN8KGIYIbPRjfSZnnOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model论</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=3&amp;sn=c6f8a757ae9834ad9ad2df1d9a837a19&amp;chksm=fd9a0ac665a3826364f86b7a1a397f8103243bc2551b4cc0f96ce1c239d208e220ec1da784f3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekB7CXUYR45xqh1P2Q9zWuxgmicJiaO6JPkkhoaibkSARt6qftWXI9ofZjt9NK9vuibg0UrfhA2kTPRaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT今天介绍的文章来自公众号粉丝投稿，腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT，给定一个人像图像和一个衣物图像，就可以生成一个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=4&amp;sn=8aee6a1069da7fa31e1524099e7692d9&amp;chksm=fdfb049a20f36a4aae141e866751086f84cec821866f37a227a0037c0625275577a6a687e251&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Animate Anyone 2来了！角色动画与环境之间更具互动性，动画真实感和一致性更高。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXWFznUMicvLicvkDmEwFhC2ibGGPzYD6cjmOwxrY9X4Vbv4qexWHZ3R7hibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的角色图像动画方法Animate Anyone，感兴趣的小伙伴可以点击下面链接阅读~阿里Animate Anyone：让任何静态图像动起来，让C罗、梅西、内马尔一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490410&amp;idx=1&amp;sn=690c763931b8f47edbadd8e3645d87f5&amp;chksm=fd1d9f064b84d887400938ee1ede8d346ee9c1cbfec2f57268671088d566b22286f7ca59ad99&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达开源4K图像生成模型Sana，可在16G显存电脑部署，支持ComfyUI和LoRA训练。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6Zafxy9AicSRodyIcwlSHNT9mr6NOzfTpJPhveE41Xmh1RVMhhibAgXAt3qSb6eFx0HfpEYX74THA/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达开源了一个可以直接生成 4K 图片的模型 Sana。 Sana-0.6B 可以在 16GB 的笔记本电脑 GPU 上部署。生成 1024 × 1024 分辨率的图像只需不到 1 秒钟。官方已经支</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490410&amp;idx=2&amp;sn=c1c37a8e26cb942f19992c81a6fc1aeb&amp;chksm=fdba16fbec4f54f27d080e437a97106285842b2a1c7a2fb2fcb79abf7ecc37e32bf747546dfe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浙大提出RealCam-I2V！精确相机控制的新型视频生成I2V框架！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXW2QTHDiatN7k4pGOJfic1lBfxyVelPRsL0aibr9cCI1YRoX6z1QXcP1lKA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control论</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490410&amp;idx=3&amp;sn=bd09106b0864e0661e2988e6265dfc1c&amp;chksm=fdc91b76187c1db970054949b76ea411ab0368fc2437e05922e3e2eef5d88240b5779c41f0b4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多身份定制化视频创作新突破！Ingredients：可将多个身份照片整合进视频创作实现个性化视频生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcicdv0XZf04MKlYliaBmemOkIOtBU0wKu89VAd3lkLkDU9GOLfc5OIqIjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在当今这个数字内容爆炸的时代，视频创作已成为连接人与人、传递信息与情感的重要桥梁。然而，如何高效、高质量地实现多身份定制化视频创作，一直是视频制作领域的一大挑战。近日，北京昆仑研究院的研究团队提出了一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490410&amp;idx=4&amp;sn=f8b630700a48c69d68673a87989cfc5a&amp;chksm=fdd4e45d6b0ec8d3aea1d7fef328c9e781f091029a49ac94080a665e99c62996d33c1a63ce61&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[顶刊TPAMI 2025 | 北大、KAUST、字节联合提出“可逆扩散模型”赋能图像重建，代码已开源！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXWYNXSWW0ic0Bj4lKqjoib7L8uQGd6oeHPNRicIBXHIPPGrZicUPA2KEndsw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章来自公众号粉丝投稿，论文提出了一种可逆扩散模型（Invertible Diffusion Models，IDM）。这一方法通过引入（1）端到端的训练框架与（2）可逆网络设计，有效提升了图像重建</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490409&amp;idx=1&amp;sn=f1a8c96a032305419299f50c9c095e57&amp;chksm=fd011cd35eeab16e70c0860e9e79ec4b59bcb93dcf45bb1ea78910f7667f6ec156563f1a1b10&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[单张照片生成3D头部模型！Adobe提出FaceLift，从单一人脸图像重建360度头部模型。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4qXFbiaEqoEPejUQNwuqLOrpIE3WmoKJBxjrMnCoHDn3huArYyaCa7Ew/300?wxtype=jpeg&amp;wxfrom=0"/><p>FaceLift是Adobe和加州大学默塞德分校推出的单图像到3D头部模型的转换技术,能从单一的人脸图像中重建出360度的头部模型。FaceLift基于两阶段的流程实现:基于扩散的多视图生成模型从单张</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490409&amp;idx=2&amp;sn=a2acdb42e8ba50155a141df760964df9&amp;chksm=fdee2de69285e7b2ed8595bc8de656fce7160d9a6b5a593de414ee5e5b6bc144415b38562c37&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[引领图像编辑领域的新潮流！Edicho：实现跨图像一致编辑的新方法(港科&amp;蚂蚁&amp;斯坦福)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcicEKO56ibffMsiau7qrg2gcpibqTFwwB20Tz8hX6wXGcTC684He5MiazvvzA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在图像处理领域，如何实现跨图像的一致编辑一直是技术挑战。传统方法往往局限于单张图像的编辑，难以保证多张图像间编辑效果的一致性。香港科技大学、蚂蚁集团、斯坦福大学和香港中文大学联合提出Edicho，这一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490409&amp;idx=3&amp;sn=b5d4decc400b914d9ab7d11dd671418c&amp;chksm=fd8d5eb83c58f8301d428845e50c7fa9afc97368de92b7fdf3ce81186a6e8a8372617cc26c31&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[音频驱动肖像动画新方法LetsTalk,可生成与音频一致的逼真视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgfkcDFOIyH4xJ5xG8Ar9Y0Uvicw6xicJzbmEtb2yOzCDNqYMjzkS4eYpw/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍过许多关于音频驱动的肖像图像生成动画方法，感兴趣的小伙伴可以点击下面链接阅读~复旦开源Hallo：只需输入一段音频和一张照片就可以让人物说话。开源EMO再升级！复旦|百度|南</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490409&amp;idx=4&amp;sn=0157c71ca93e3294e9232f993dd79050&amp;chksm=fd02aa70c3320984dc9ec18edcead8362054eca29957661de3d858d2f9a0a2e2966d4c09a31a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[阿里提出文生卡通新方法Textoon：一分钟内生成丰富多彩、可交互的Live2D格式角色。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMLBRnvtbr9hh7W1ccXtbHzL0fHklZwvXTHFm3tjgJJcKpq3IlwIZMDiaQUpT6AgMaBYsXg4BObLQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里提出了一种基于文本描述生成多样化2D卡通角色的新方法Textoon， Textoon利用先进的语言和视觉模型，能够在短短一分钟内生成丰富多彩、可交互的Live2D格式角色。这种方法不仅提高了生成效</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490351&amp;idx=1&amp;sn=fde26ca14520e7be63a1e0d44feeb244&amp;chksm=fdb3674e389e30b465eaf01acc713a2de8751fa114f1433666bb775b3960b0dcbc1e7685c6a7&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[拖动图像编辑再升级！北大、腾讯提出DragonDiffusion，在扩散模型上启用拖动式操作。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emtHS7t5ic0uQWb1AOhKNDRVue2DuQtBzYWulYezda8dsItznwxGaPWCUmiafhNgHsVonAIj1dwlFlA/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中给大家介绍过许多关于通过拖拽实现图像和视频编辑的方法，感兴趣的小伙伴可以点击👇链接阅读和收藏，整理不易，欢迎大家给文章点点赞和在看！StableDrag：一种基于Diffusion模型的图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490351&amp;idx=2&amp;sn=d79810d355502b2e7ee24cd87d68527e&amp;chksm=fd43b13549365069791572447d8189d71d1e54448b06cd69a227cdc790afa43b55bccfaab014&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌DeepMind重磅推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emYIXZcOoWmiamNNy78gGxDxw4uWDBzPA32XByk1moUtrt0vCzrccsjPryianfay5w8IibgLtxibuRokQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 单目视觉4D重建再突破！谷歌DeepMind推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。单目视觉4D重建再突破！谷歌DeepMind等团队，推出了多视角视频扩散模型CAT4D，它支</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490351&amp;idx=3&amp;sn=9a8b0e1f317c32af9a8728e4961138f0&amp;chksm=fd4c82254919a5634dc33616d1f66d8c54b4298ad74a0edacf1ce5ea705a4f3287a97843297f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 16 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华大学出品《DeepSeek 从入门到精通》完整版手册下载和使用教程。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekAuUNNvuhqhCqoRTbKeLmgPHqs5kFUeYxHNXGIAJjaicb7Jz5AGCEKaGjBXBj1egXibBq21I3OvyDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>分享一份由清华大学新闻与传播学院新媒体研究中心元宇宙文化实验室的余梦珑博士后及其团队撰写出品的《DeepSeek 从入门到精通》手册。文档的核心内容围绕DeepSeek的技术特点、应用场景、使用方法以</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490350&amp;idx=1&amp;sn=85e80c43b97040d127de03a9b9ddd29c&amp;chksm=fdc68861f21404e8c7cfd15c8abe8cc539cbe33742aa2574f0f7a4dd2d2c1c933f6f42107fe1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 15 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[开源版Deep Research，一句话创建Agent工作流帮你完成电脑上的复杂操作，股票分析也轻松实现。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NZM99XBibic0ksT7p0zTFpQHQT2lY40u4GloUhxMpWMlQLDWe9ic4uibxzibicD0eiauVkGszvokib9MfuhLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI刚出来的时候就不断在说，后面非常多的工作就不需要人去做了，都是AI在做。之前很多人不相信，现在已经有很多公司在裁员了，而且裁员后业绩反而更好了。当然，我们平时也不愿意做一些繁琐重复的工作，让AI去</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490350&amp;idx=2&amp;sn=620b7457fb1b6e4dc1752bcb8f2ba6b1&amp;chksm=fdb19f117477dc7ac783b48c196f7c0c43e6176c88f80075848304ef0517bb52477f8322ed18&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 15 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多身份定制化视频创作新突破！Ingredients：可将多个身份照片整合进视频创作实现个性化视频生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcicdv0XZf04MKlYliaBmemOkIOtBU0wKu89VAd3lkLkDU9GOLfc5OIqIjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在当今这个数字内容爆炸的时代，视频创作已成为连接人与人、传递信息与情感的重要桥梁。然而，如何高效、高质量地实现多身份定制化视频创作，一直是视频制作领域的一大挑战。近日，北京昆仑研究院的研究团队提出了一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490350&amp;idx=3&amp;sn=69a131f55ec19007dfbf4a3425489e8a&amp;chksm=fdd2611755a5c1a74ca9d9de9fd2a3730989839be40e78a939a2abff6715e5970364476726d1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 15 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NVIDIA提出虚拟试衣新方法EARSB，让时尚与科技完美融合！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2empB05GMsROweibZLQdTRdryhxs0ChYaSb8Q7MXgpODuC675ClEZrLFicPt5eWjzKjxOHWcsP2ic7rBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在数字化浪潮席卷全球的今天，科技正以前所未有的方式融入我们的生活，包括我们追求时尚的方式。想象一下，无需亲临实体店，只需轻点屏幕，就能轻松试穿心仪的衣物，这不再是遥不可及的梦想。NVIDIA联合波士顿</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490350&amp;idx=4&amp;sn=a51286e520ba665fe3f36f4e6723d68f&amp;chksm=fd8149af80395546ea95686b79dd6cca9a0d17029fc6d8fd4d1a8130956018cf074d403d15f3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 15 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯发布混元-3D 2.0: 首个开源高质3D-DiT生成大模型，几何结构更加精致，纹理色彩更加丰富。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enScf5fx9rxa1dXnvYHW4G815SyibP84GYLJGItGoKdb7k8ibSoFf2UCRYRf4VJVbpVm4IevhxibbLDw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过腾讯HunYuan-3D 1.0，感兴趣的小伙伴可以点击下面链接阅读~腾讯发布HunYuan-3D，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。HunY</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490327&amp;idx=1&amp;sn=f72ceac5014716fca13cf6a9a1ca3773&amp;chksm=fd9493a8fa52ec49b90b5be74c4ad15e279c2a09293245e67313af282467f8039a95f7c08445&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 14 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯HunYuan-3D 1.0，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elMhPFZCKibTiaBKrjL4Yql4lFH5tVlYMlAnW2RYL3JiaF4vHrEFr3z5TWpyzCAENlicH9DuH5PnpYic3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>HunYuan-3D支持文本到3D和图像到3D功能，包括网格和纹理提取在内，整个过程在 10 秒内完成。文本到 3D：用户可以通过简单的文本描述生成 3D 对象。例如，描述一片绿叶或一把棕色吉他，模型</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490327&amp;idx=2&amp;sn=859d3d1bd500892deaa5e055b6dac4a4&amp;chksm=fd714d0d55463aec116437eedb612502bfa0e5aeaa39dde24edb5a821b9daa223540e91cbf01&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 14 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[统一图像生成模型OmniGen：可由多模态提示直接生成各种图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enjwj4Ry2OH6auaAn9DU954RGLVLiaJQhnSsUOPiaYkiaE5VPAB4AUAtmLI24PhQm9bK4JduBhT9ZjTQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个北京市人工智能研究院 提出的统一的图像生成模型OmniGen，可以使用它来执行各种任务，包括但不限于文本到图像生成、主题驱动生成、身份保留生成、图像编辑和图像条件生成。OmniGen</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490327&amp;idx=3&amp;sn=17e9411e995d928c757a4d296b68d7c2&amp;chksm=fd0aff591ff63991c4e05dd252faf6ea660ddb028b7ae9825d677880fd803c36fbd71e6673e8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 14 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像编辑大一统？多功能图像编辑框架Dedit:可基于图像、文本和掩码进行图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvIibC8Suae7poAtMSSVAkicNMibK5CyJB4RLSAKFiajeuqXiaiaib0vMibRiaSKCQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个基于图像和文本的编辑的框架D-Edit，它是第一个可以通过掩码编辑实现图像编辑的项目，近期已经在HuggingFace开放使用，并一度冲到了热门项目Top5。使用 D-Edit 的编</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490327&amp;idx=4&amp;sn=ec9177461f68392d13f4f18b50cf53b2&amp;chksm=fda29ca13353d13ae2db8b852b898aeb4a2bc558d9a2d625e3a01fd7b508ae5726e25c645864&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 14 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
