<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    























    <item>
      <title><![CDATA[2024 AI TimeLine 回顾（独家视角）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUnCMiaBjZZszIFmMq4b6euJ14V5ibkAcCZdmtRw3lykFcu3iafSO7319RSVydS3scYAgM0oASkKTw/640?wxtype=jpeg&amp;wxfrom=0"/><p>2024 AI TimeLine 回顾（独家视角）2024年，生成式人工智能已远远超越了仅仅作为一个流行词的范畴，它在实际应用和技术创新方面取得了显著进展，成为推动社会进步和产业变革的重要力量。以下是</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489813&amp;idx=1&amp;sn=51ebf152c0ae606b68387d40e64f97fb&amp;chksm=fd9d9b818faf50990536c705845570876d1321e1d63846cae890e6b333ec8df682c105046aa8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 10 Jan 2025 16:44:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[东京大学 | Adobe 提出InstructMove，可通过观察视频中的动作来实现基于指令的图像编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsa4uWnhrMawFt9HHkxP0mNsA8WZRJb5wtxFQzRMjAicAjmryxF8Yliamw/300?wxtype=jpeg&amp;wxfrom=0"/><p>InstructMove是一种基于指令的图像编辑模型，使用多模态 LLM 生成的指令对视频中的帧对进行训练。该模型擅长非刚性编辑，例如调整主体姿势、表情和改变视点，同时保持内容一致性。此外，该方法通过</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489813&amp;idx=2&amp;sn=81bd57715905ef2609fb944745535e3f&amp;chksm=fd097f3583d779d5924d78fb290f7d78ac6518b7e55fcdca6724101fc29da25ff3244805dc94&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 10 Jan 2025 16:44:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[提出街景定位大模型AddressCLIP：一张图实现街道级精度定位！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldKGCwibmhq5RSxC5rV78dDcVpQDWZ2qUibtJW2qRF8ehlmicnuSw3n5MdOVQ0NTovfOnPib1RNDwBibQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>中科院自动化所和阿里云一起推出了街景定位大模型AddressCLIP，只要一张照片就能实现街道级精度的定位。比如给模型看一张北京南锣鼓巷的街景之后，它直接给出了具体的拍摄位置，并列举了附近的多个候选地</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489813&amp;idx=3&amp;sn=d14a4948c82f4267521c7541e0e6c672&amp;chksm=fd9e61e7c96af6e00f0affd2b24d124ab8975f8ee9fe5649ab6eb51e1cb50cbad3ccb1520cfa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 10 Jan 2025 16:44:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[谷歌DeepMind重磅推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emYIXZcOoWmiamNNy78gGxDxw4uWDBzPA32XByk1moUtrt0vCzrccsjPryianfay5w8IibgLtxibuRokQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 单目视觉4D重建再突破！谷歌DeepMind推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。单目视觉4D重建再突破！谷歌DeepMind等团队，推出了多视角视频扩散模型CAT4D，它支</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489813&amp;idx=4&amp;sn=d16d497c55111563269493ea006710e9&amp;chksm=fdeea1749619d169d76f7f703c8703cbef63fc1ead7203f12104502e34f29c588633a17da278&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 10 Jan 2025 16:44:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[Open-Sora: 让所有人都能轻松制作高效视频,可生成16秒720P视频，模型代码全开源！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enY2jTeFu5rQt2UydQCHT1gGKk74exRM2eDyJFgQOlbVqSjHpGrT6kqYT3dcZjwM6KYia7EwWYBKNA/640?wxtype=jpeg&amp;wxfrom=0"/><p>Open-Sora是一项致力于高效制作高质量视频的计划。目的是让所有人都能使用模型、工具和所有细节。通过采用开源原则，Open-Sora 不仅使高级视频生成技术的使用变得民主化，而且还提供了一个简化且</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489786&amp;idx=1&amp;sn=ee7e8b582b01302891eba2a4368576d7&amp;chksm=fdc8e48e95432f6e0ec62b55d801e2850cff4e0ec48bc2c96df7d9b6095e6fb8c11311a14fc0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Face2QR:可根据人脸图像生成二维码，还可以扫描，以后个人名片就这样用了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDXLyhv5gUBA9w7NggpzadO1jATGuCxxia6dLEgQBFVb37eWtav37qYkiabubYa9vGGTHlEWmbql9w/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是一种专为生成个性化二维码而设计的新方法Face2QR，可以将美观、人脸识别和可扫描性完美地融合在一起。下图展示为Face2QR 生成的面部图像（第一行）和二维码图像（第二行）。生成的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489786&amp;idx=2&amp;sn=1007b4ba61e63232b5522d81da661a47&amp;chksm=fdb4f0550aa63331955fdf42d5efc19b79c3efb3457739784022b34ffa254d7176e40f6fb36c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[AI生成大片，Movie Gen可以生成长视频并配上完美的音效，带给观众更好的观看体验。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en7hMnHYqLSuapj6C0Hn0mXm2ceUm9LDTsGCA6gVbwy08k2trThGZg7tajWXlicmTHopRclOZ90icwQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍了一些关于长视频生成相关的技术，AI生成大片已经越来越近了。感兴趣的小伙伴可以点击下面链接阅读~《泰坦尼克号》AI大片重生！浙大&amp;阿里发布MovieDreamer，纯AI生成</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489786&amp;idx=3&amp;sn=c8108c61c871901674d5c04f3200df3d&amp;chksm=fdd0a335d4b1db097c75b0893910120acb0f2615a425a2ff0509ba607d3d9833033400370550&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[组件可控个性化生成方法MagicTailor：生成过程可自由地定制ID。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en5zm71fQSgV6aaqPJln47UM68LBoxEpKSBewPN29AuBHv1SMicLD8losQPDWSsMKunkqyr9HuAUvA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天的文章来自公众号粉丝投稿，文章提出了一种组件可控的个性化生成方法MagicTailor，旨在个性化生成过程中可以自由地定制ID的特定组件。相关链接论文阅读：https://arxiv.org/pd</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489786&amp;idx=4&amp;sn=45a753161405c5d9b9ac62d55ac8a39c&amp;chksm=fdfb8ab6e5e3c77aa629a7140bdd946f83d1cf5d291941d8de4ca22bacd0cce5006561f50148&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 09 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[NVIDIA发布GeForce RTX 50 系列，图形性能翻倍，售价549美元起！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enY2jTeFu5rQt2UydQCHT1g7XMd6NDeb8ZT5rzibNdAxLUNRykvuRcwzibHBB6xZaqbXopc67ibCic4lg/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025 CES消费电子展（1月7日至10日，美国拉斯维加斯）正式开幕。北京时间1月7日 (星期二)上午10:30，NVIDIA举办主题演讲，穿着标志性皮衣的英伟达 CEO 黄仁勋勋担任主讲。正式发布</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489773&amp;idx=1&amp;sn=6eec23bcea666d4de8f26959339feda7&amp;chksm=fd8a4b1f6a235eff10a1cc52a2f7c4e65773443f3cc02993f85422f9c43c10fcf331655e1ebc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[实时高保真人脸编辑方法PersonaMagic，可根据肖像无缝生成新角色、风格或场景图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsExUD85bPCqAicxMSnpMibzPacGZ2JJmvUibAHrezkU5Now3FS5ib9Ibg1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是一个高保真实时人脸编辑方法PersonaMagic，通过分阶段的文本条件调节和动态嵌入学习来优化人脸定制。该技术利用时序动态的交叉注意力机制，能够在不同阶段有效捕捉人脸特征，从而在生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489773&amp;idx=2&amp;sn=6492860946c07d40c97cbe6d0b4e2bb2&amp;chksm=fd56d3f312bd40eb5a81700c335ba3646fefc75cb983e45ec36de7086633e93a55bb87f3b6e0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[参数减少99.5%，媲美全精度FLUX！字节跳动等发布首个1.58-bit FLUX量化模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoh2Zk3Iwj5tM5QKick9Eg7sMHzHPiazuE08RhyHwiaSIKLUWJPrCskqeBNbCda9jDPROSF1YrFkT9yyw/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIGC Studio”文章链接：https://arxiv.org/pdf/2412.18653 项目链接：https://chenglin-yang.github.io/1.5</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489773&amp;idx=3&amp;sn=ec8174cc599f204050ac78eec0863f34&amp;chksm=fd8353dcc976fad3c8ef343870724ff90d2def2ab5cac7e08580c75d0aa2049c63daa97ed41c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 07 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复旦&amp;字节提出layout-to-image新范式，支持基于布局的MM-DiT架构下可控图像生成！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekXX8zYF4UxzjmCibmVsNeNfHdzvia0ykHy5vQljhxHZhBKib0DHCIdedbOAMsic8KZ423vtGia19o4Wow/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇分享论文CreatiLayout: Siamese Multimodal Diffusion Transformer for Creative Layout-to-Image Generation</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489738&amp;idx=1&amp;sn=2cf065c34c41615747d63740ddae1646&amp;chksm=fdf3090611fd71121f6404113458100ba4f42298da828a38af4afbebb99fe53f616f2995ccb8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[MinT: 第一个能够生成顺序事件并控制其时间戳的文本转视频模型。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el8quKicUEibqsQFrF8ttU8UZh4icQduMVEEU78HQlZOU3Jzp7NeFwOc2OPJY7cjEn7Ed2h55fjhbhkw/300?wxtype=jpeg&amp;wxfrom=0"/><p>MinT 是第一个能够生成顺序事件并控制其时间戳的文本转视频模型。使用 MinT 生成时间控制的多事件视频。给定一系列事件文本提示及其所需的开始和结束时间戳，MinT 可以合成具有一致主题和背景的平滑</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489738&amp;idx=2&amp;sn=daabd37573fb55541bcfa404e1e53be8&amp;chksm=fd27d81cb4ef68f95d3dd0e1723580c463bd9a98b38600f31d3aab8be09f41da1d5d3c016001&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[单幅图像合成 360° 3D场景的新方法：PanoDreamer，可同时生成全景图像和相应的深度信息。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el8quKicUEibqsQFrF8ttU8UZJIaZuVsUww2Z2IDLp7MYqLaIsWuo5dAG2Y1iaHf8AibCjXj4KFPbTv3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文介绍了一种从单幅图像合成 360° 3D 场景的新方法。该方法以连贯的方式生成全景图及其相应的深度，解决了现有最先进方法（如 LucidDreamer 和 WonderJourney 的局限性。这</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489738&amp;idx=3&amp;sn=36308e0956fc1702674d3b576b65dd40&amp;chksm=fd5c6681e5bfb59abc788f05a58bf011b5af8233f73b2cf71bdc0463682bb4706d5063768dd5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[提出街景定位大模型AddressCLIP：一张图实现街道级精度定位！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldKGCwibmhq5RSxC5rV78dDcVpQDWZ2qUibtJW2qRF8ehlmicnuSw3n5MdOVQ0NTovfOnPib1RNDwBibQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>中科院自动化所和阿里云一起推出了街景定位大模型AddressCLIP，只要一张照片就能实现街道级精度的定位。比如给模型看一张北京南锣鼓巷的街景之后，它直接给出了具体的拍摄位置，并列举了附近的多个候选地</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489738&amp;idx=4&amp;sn=e05d13b852ad0b23efe0417175152968&amp;chksm=fd5114aef7bd0210e993064b523bace19438cfcce46eac91a9a03657fd2874cdbbe50bb0f6b0&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 06 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[东京大学 | Adobe 提出InstructMove，可通过观察视频中的动作来实现基于指令的图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsa4uWnhrMawFt9HHkxP0mNsA8WZRJb5wtxFQzRMjAicAjmryxF8Yliamw/640?wxtype=jpeg&amp;wxfrom=0"/><p>InstructMove是一种基于指令的图像编辑模型，使用多模态 LLM 生成的指令对视频中的帧对进行训练。该模型擅长非刚性编辑，例如调整主体姿势、表情和改变视点，同时保持内容一致性。此外，该方法通过</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489737&amp;idx=1&amp;sn=c4193433e3543f854273203d259f44f2&amp;chksm=fd0bdaaf263426cf14bbedb14b218488556e15ee48ef1c8c582bbf2aeebec282271235195346&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌DeepMind重磅推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emYIXZcOoWmiamNNy78gGxDxw4uWDBzPA32XByk1moUtrt0vCzrccsjPryianfay5w8IibgLtxibuRokQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 单目视觉4D重建再突破！谷歌DeepMind推出多视角视频扩散模型CAT4D，单视角视频也能转换多视角了。单目视觉4D重建再突破！谷歌DeepMind等团队，推出了多视角视频扩散模型CAT4D，它支</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489737&amp;idx=2&amp;sn=f0b17de000da4646c72cb18fc72cb942&amp;chksm=fd22f3161c3cf0417d799f9ae7e57695241a6e5b7eae4d7a455f098f792770325f41bc9b49ca&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ComfyUI | Flux实拍与卡通风格lora推荐, 用于一键生成创意图像，支持用户输入特定描述。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzia0AxvG3w5jnu5Q1nyOUw7TQJFGYa2znHnNaWuO6u1JkCEEpxpul3G7pL6Igu3mLQyxXGM5cvPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家分享一个非常可爱的flux lora，FLUX.1-dev-LoRA-One-Click-Creative-Template:能够一键生成4张同一角色的真实版图片+一个中间的卡通版Promp</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489737&amp;idx=3&amp;sn=76dd7558110f8d0c1dae35ef05c06f7b&amp;chksm=fdd22e69c0388cd2f49c440d36979165bf9fe00f5b680c7ce7da4cb30bb9fc6e0f46ef80d64a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[设计小白秒变大师？AnyDesign：你的时尚图像编辑神器！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emUwYVFBw0LHKV1UPHAgKIBKELWJNRURA6xrgAWatkn6BfxpFWhMGLXocarRVQ03FpehAsEKa7OJA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在AI时代很多行业都被颠覆了，建议大家在业余时间也尽量多学习一些AI工具的使用，提高效率的同时也去探索更多好玩的应用。今天给大家介绍一个非常好用的图像编辑方法-AnyDesign，适合时尚设计师以及普</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489737&amp;idx=4&amp;sn=8fe0271dded7bd9275ba5da55d14fa60&amp;chksm=fd347e0673c4e9b7d234900f2046da2c72a0697f13da535e27e05f7d538ccaff409681bc87fb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 05 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[实时高保真人脸编辑方法PersonaMagic，可根据肖像无缝生成新角色、风格或场景图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsExUD85bPCqAicxMSnpMibzPacGZ2JJmvUibAHrezkU5Now3FS5ib9Ibg1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是一个高保真实时人脸编辑方法PersonaMagic，通过分阶段的文本条件调节和动态嵌入学习来优化人脸定制。该技术利用时序动态的交叉注意力机制，能够在不同阶段有效捕捉人脸特征，从而在生</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489722&amp;idx=1&amp;sn=b2f92abfd72f30a2c97c71956ed34636&amp;chksm=fd6800c47f0c2991ded408839135c22c38b0877dfe88876c4720a8184860e8bc69b411bc71c4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[厦门大学联合网易提出StoryWeaver，可根据统一模型内给定的角色实现高质量的故事可视化]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcSnOoT1icicSWQibicicqfkyEgocfw6Age4Y0U1AOuZS8cHib80ewP5RdXmZjaprD8L6TqR9iasUM3VUVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>厦门大学联合网易提出StoryWeaver，可以根据统一模型内给定的角色实现高质量的故事可视化。可根据故事文本生成与之匹配的图像，并且确保每个角色在不同的场景中保持一致。本文的方法主要包括以下几个步骤</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489722&amp;idx=2&amp;sn=969054662185f2223e25b429951ded30&amp;chksm=fd452d58f81ba824a385b3572cbed3099c51fad658e2cadeb3ff378178e1d6072d2d09d2e009&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[北航 | 第一个多功能即插即用适配器MV-Adapter：轻松实现多视图一致图像生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfSL2lH1ru1uCJuUuA21YKHU5ia5SLlWu0BztQtHU3YSeZIYv3K9nGSHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>北航提出了第一个多功能的即插即用适配器MV-Adapter。可以在不改变原有网络结构或特征空间的情况下增强T2I模型及其衍生模型。MV-Adapter 在 SDXL 上实现了高达768分辨率的多视图图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489722&amp;idx=3&amp;sn=94f038194ddc92abe4f1a2f30679938e&amp;chksm=fd98c87a4016f45531a7ad0e9dbba449558ccfcfe1870393fb6e3324dfeb487548746a9b39af&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 04 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
