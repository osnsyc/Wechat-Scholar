<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[字节开源换脸写真模型InfiniteYou，可实现零样本身份ID一致保持，无缝集成FLUX、ControlNets、LoRAs！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFB9QEic6a0icic21hdjU7tWMfgnZWZ32D1adHqJcD4Z8fvzhEvH6KNghsZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个字节刚开源的换脸写真新模型InfiniteYou，这是一种先进的零样本身份ID一致性保持模型，由字节跳动基于文生图领域最强开源模型FLUX模型研发的。InfiniteYou专注于利用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491377&amp;idx=1&amp;sn=fa61d3e8e637652ab2fa97aff5981df4&amp;chksm=fd3e2f3067e05d522ce5874a768f0a476b4ce174f0a73d8f18f67d677ca5205542411c791086&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FlashFace: 具有高保真身份保存的人像个性化方法，效果超越InstantID，人脸定制化更逼真了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekGB20aoopfDW9Ia72SmdXIpHxTUXCIsjaFY2ob7ymtpQcesNrLicxwJME93bc3QPGgQ9eWOpYd9VA/300?wxtype=jpeg&amp;wxfrom=0"/><p>FlashFace技术是由香港大学、阿里巴巴集团、蚂蚁集团共同研发的一项实用工具，用户可以通过提供一张或几张参考面部图像和文本提示，就可以轻松地即时个性化自己的相片。与现有的人像定制方法相比，Flas</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491377&amp;idx=2&amp;sn=8fd8e834937d0f3edceb033e6e5f33f4&amp;chksm=fdb38d454a8544e2d338e346850e8eff00b095b76346aef65151240be2e46c7e6fd64719a5b7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Google 发布最新开源模型 Gemma 3 性能超越DeepSeek V3、o3mini为全球第二强开源模型！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1Tx7TDib2JZlYSOcIeFibGx26nJ97mYDqomS6G9eBfNYd12uHm60HC3icw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Google 发布其开源模型系列最新模型 Gemma 3。Gemma 3是一个高性能、可移植的轻量级 AI 模型，适用于单 GPU 或 TPU 部署，支持多语言和复杂任务。 主要特点总结如下：支持 1</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491377&amp;idx=3&amp;sn=9fce60be3615a9c3af32a2305c00885c&amp;chksm=fd7b2557ffa6a8c742d6de17df0f422adfe0ccd7bed7454ebd977e1e6235aba3f61f00ac4d1a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里同义提出风格化实时肖像视频生成框架ChatAnyone，4090可实现实时交互式视频聊天。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFBcaE8LzVr31iakSoCNZjeSCMLCgDXTUn7DnnnvB7ptptnbkwkOrU19RQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里通义实验室提出了一种风格化实时肖像视频生成框架ChatAnyone，使视频聊天从“会说话的头像”拓展到包含上半身交互的更具表现力和灵活性的形式。ChatAnyone方法支持高效、连续地生成分辨率最</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491376&amp;idx=1&amp;sn=e971124575abf1cca36d4695408245b7&amp;chksm=fd79b1fd63bf557c7a1bc683482052fcc277b67d2154d2e625b1a52b14b4ccfb0fd052076022&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Apr 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D虚拟人ExAvatar：由简短视频建模转化为3D数字形象。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekzqB2EbDBmquHlenf6YcicAWMXQALDcXjabJaEKqR2IKMpyViauaiaoCFPWRkVQPGibAUElFHg6rBNzw/300?wxtype=jpeg&amp;wxfrom=0"/><p>ExAvatar是由DGIST和Meta公司的Codec Avatars Lab联合研发的一项技术，能够通过捕捉视频中的动作和表情，转化为栩栩如生的3D数字形象。这项技术解决了以往技术中的难题，提高了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491376&amp;idx=2&amp;sn=dfa2349bf57fdbc7403c89e0a46e6c85&amp;chksm=fdf5b5967908f93e017cb061cd070ecf0b554ff2fa445778f7ddfbb479bce1b8161bbc21df66&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Apr 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IBM提出多模式图像文本到文本模型SmolDocling，可实现代码 | 公示 | 图表 | 表格 | 标题 高效转换！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eniaAibjBDYoftj8VvjntaLlaylgswEom4XlMibkcGxuU4WPZLbljDmFWMIMhdEh2dicYGoicXToiaibicmeQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Docling团队联合IBM提出了一种多模式图像文本到文本模型SmolDocling，旨在实现高效的文档转换。它保留了 Docling 最受欢迎的功能，同时通过无缝支持DoclingDocuments</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491376&amp;idx=3&amp;sn=fae33c15c0bc314152c7a9b8cf7d5f9f&amp;chksm=fd26e54081d0723f293073febcdd5b44f41536a3da7c47d0f11d21867fecbf87cec90da6c10b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Apr 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/640?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491375&amp;idx=1&amp;sn=105c2bcde8378f9f21028ac20952dc0c&amp;chksm=fd48c0683251b2068f982ab1c580989d0ce53fff67285c5dcfffaee64eb61d8857c267eba9dc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 31 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TRELLIS：用于创建多功能、高质量的360°全景图生成方法，实现可扩展多功能3D生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsrcRtOibx92ZhEt1Z0UdQ7JsQibr17Y0WaD8O08DMM3XIor43XOZVMvXg/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华大学、中国科学技术大学、微软研究院联合提出T RELLIS，这是一个大型 3D 资产生成模型，可根据文本或图像提示（使用 GPT-4o 和 DALL-E3）以各种格式生成高质量的 3D 资产，可在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491375&amp;idx=2&amp;sn=8cb92d824567558ca4ed668af7b06243&amp;chksm=fd94bcf93d9f588473ae8bbc9742e1be75dda9590d9ac473739136568d7178dc52c187e0f2b5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 31 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里千问发布QwQ-32B：性能肩比DeepSeek，只需DeepSeek的1/20参数，一张显卡就能跑！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elm4qdlMbfjmuJgIxhRCCZMUfMpZODzQtQmnYnAEn7bib3y95h2UThFE6yARUMTLib5icEnhmaaCf8BA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里云发布并开源全新的推理模型通义千问QwQ-32B。通过大规模强化学习，千问QwQ-32B在数学、代码及通用能力上实现质的飞跃，整体性能比肩DeepSeek-R1。在测试数学能力的AIME24评测集</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491375&amp;idx=3&amp;sn=251af48d6af6054a27db7b51b697f770&amp;chksm=fdd56a38b0b929603cbc18381537d1aed111f7ffbcc1d8d3cd04d2f5f504e51e3b1ca124c2bc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 31 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里提出ChatAnyone，可实现实时交互式视频聊天。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>阿里通义实验室提出了一种风格化实时肖像视频生成框架ChatAnyone，使视频聊天从“会说话的头像”拓展到包含上半身交互的更具表现力和灵活性的形式。ChatAnyone方法支持高效、连续地生成分辨率最</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491372&amp;idx=1&amp;sn=cd6292f5ee44e1cbd4827fcc4b4f3474&amp;chksm=fd11d19fa54b59cdd8715685b23831b6f2bb08d3bfdede35da0b5297740a9a0a63867e3891fa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 31 Mar 2025 15:03:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[深入解读CrossFaceID：专为面部定制优化的高质量数据集，解锁面部定制新境界。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6eibpyvbYMVY9AibWGb1WPibwQB4jsFJwTbLvlFCGFE4jyVicWteQwBhtCQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给大家介绍过许多关于ID保持的文章，感兴趣的同学可以点击以下链接阅读，也可以在公众号菜单栏查看ID一致保持专栏，创作不易，欢迎大家点点赞和在看~CrossFaceID模型在训练过程中</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491312&amp;idx=1&amp;sn=02b83d02c405e9be9c958ea45cab500d&amp;chksm=fd706831582ee8d911d9d8505de2fbd4f0cc457518983e249e44147ac28c1dd8870bb8e8de66&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 30 Mar 2025 14:58:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[优于InstantID！中山大学提出ConsistentID：仅使用单个图像根据文本提示生成不同的个性化ID图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXp1E1oEylZGlBIMB34AHRd3oxKBhpAxdSrH93lsPx5PQLCJoiatLPvLckYlcwIdia0mfJvIY8yATw/300?wxtype=jpeg&amp;wxfrom=0"/><p>给定一些输入ID的图像，ConsistentID可以仅使用单个图像根据文本提示生成不同的个性化ID图像。效果看起来也是非常不错。相关链接Code:https://github.com/JackAILa</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491312&amp;idx=2&amp;sn=f7ff314d5f57b75446f73b04ea8cd8cf&amp;chksm=fd7dba6b10aaa6ffedfc31ec8823fd7559700ea70f53547f3a40a24de797be283e0912bb3e07&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 30 Mar 2025 14:58:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[小红书InstantID来了, 一张照片几秒钟就能生成个性化图片, 无缝衔接Stable Diffusion）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emOPECe9ppt8tbA7s5KWjLWm00ztjnY1S9WVElngFo83S9YvqG0NkX4D62C8TcICavvRI6PIYSl6Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>        最近一段时间基于扩散模型的图像处理方法遍地开花，接下来为大家介绍一种风格化图像的方法InstantID，可以仅通过一张人脸照片，几秒钟内生成不同风格的人物照片。与传统方法需要多张参考图</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491312&amp;idx=3&amp;sn=3a3c2feff633c7cf6d743fbce2fd139a&amp;chksm=fdc150ca0963228e5bc173b012285cdebc90979b5cf07fe6b29c022224a3b0a4d6ec36d79ecd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 30 Mar 2025 14:58:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里发布新ID保持项目EcomID, 可从单个ID参考图像生成定制的保ID图像，ComfyUI可使用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnGoicbmLL47YzLd4HWhjwazEmicf1F7ZjrxQSj4JNP3x3icluxM84Et2UYGdsdxfDOXnd9OlZYFCwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里妈妈发布了一个新的ID保持项目EcomID，旨在从单个ID参考图像生成定制的保ID图像，优势在于很强的语义一致性，同时受人脸关键点控制。EcomID 方法结合了 PuLID 和 InstantID</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491312&amp;idx=4&amp;sn=672eca697bc9fee6400cb0bba6658c0f&amp;chksm=fda8c56ef29718946fa577be5a5a2b17754f3de7ebec8955903909dec6e2d678888892ff3c63&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 30 Mar 2025 14:58:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FlashFace: 具有高保真身份保存的人像个性化方法，效果超越InstantID，人脸定制化更逼真了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekGB20aoopfDW9Ia72SmdXIpHxTUXCIsjaFY2ob7ymtpQcesNrLicxwJME93bc3QPGgQ9eWOpYd9VA/300?wxtype=jpeg&amp;wxfrom=0"/><p>FlashFace技术是由香港大学、阿里巴巴集团、蚂蚁集团共同研发的一项实用工具，用户可以通过提供一张或几张参考面部图像和文本提示，就可以轻松地即时个性化自己的相片。与现有的人像定制方法相比，Flas</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491312&amp;idx=5&amp;sn=e32c2a0caea54cc6cee33ab1528063e6&amp;chksm=fdf40eea9a67872261243da21d6f9dd74619e85cf1133321a0694cded7bd0c651ad925ffbd82&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 30 Mar 2025 14:58:10 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[olmOCR：重塑PDF文本处理，让语言模型更智能、更强大！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4IAQ3D7RpAMNb2namtUvCm06G4XyBQk2BvFF6sibwR50ffvQBeE8kk0ZM9vwsVG26eMLdZ9kcia7w/640?wxtype=jpeg&amp;wxfrom=0"/><p>olmOCR，这是一个高性能工具包，旨在将 PDF 和文档图像转换为干净、结构化的纯文本。 olmOCR的主要特点包括：高精度文本提取：经过大量多样化PDF内容的训练，采用独特的提示技术，显著提高文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491311&amp;idx=1&amp;sn=d2c51e4f8a0a12a274a46e2c523c79b3&amp;chksm=fd92e6db5e7e9c3dffda84f93817cbe8c440a054eacf0d387f91ffd8e18c7fedb4cc9e1f2925&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 29 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DPG-Bench榜首！智谱开源文生图模型CogView4：支持中英文输入和生成，免费商用授权！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekabsI7MyRPhcqTEHwmEMZhvC6lcJXaMUIXeLEHuiafYK4Her5iaKXhp5mbyiagGrmxyHV9FXCiccH0cQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在图像生成技术的浪潮中，智谱开源再次引领潮流，推出了全新的文生图模型——CogView4。这款模型不仅支持中英双语提示词输入，更擅长理解和遵循中文指令，让创意表达无界限。尤为值得一提的是，CogVie</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491311&amp;idx=2&amp;sn=cb9da78ababfe7de7daa0a4329b6b2ce&amp;chksm=fd32171e53a6fffb52c23c896901a4e81c95f589164b426e9155df16f0ab5d37bf170c478166&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 29 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像自回归新范式！阿里达摩院提出FAR！基于频率渐进自回归的图像生成方法！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JPYPxZ0MuUMXoVibiaerdXl1DDoy0kTu2GjoCXlazeNXCg7hSOWlH2Ro8Hoa0ic6nBbib4HK1KxZqYfg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Frequency Autoregressive Image Generation with Continuous Tokens论文链接：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491311&amp;idx=3&amp;sn=313e48e2b5a6b970c77e296db2d704cc&amp;chksm=fd13ac2190d182f1b418c61d7c508da5488125a3e12fa80c90942abd399b78b3e9ae8717a1d2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 29 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里发布新开源视频生成模型Wan-Video, 支持文生图和图生图,最低6G就能跑, ComfyUI可用!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emELibL5kVkYibicFiaR0laM2LPanMoANDKaC5QVXWXiawVrJIjXcdbschfSzanarf8EbFZpGTOSicjTZAQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Wan-Video 模型介绍：包括 Wan-Video-1.3B-T2V 和 Wan-Video-14B-T2V 两个版本，分别支持文本到视频（T2V）和图像到视频（I2V）生成。14B 版本需要更高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491311&amp;idx=4&amp;sn=83f4de5473a66bd99f48f7182537124b&amp;chksm=fd21d1c1113cec0d42ff79ada33af23ec0df35b88c6314243ae0fa222359f805911a7c0262b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 29 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[公众号10000粉丝啦！与你分享一些背后的故事。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elTZAO7nveGZkbHy0bhiclickcAadUYAHdJYejmtfmCcZepy9KMBonLvAMVMbMLnSHjut1bHbicpv0NQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天，AIGC Studio 的订阅数突破了10,000。这是一个值得纪念的时刻，写公众号这一年多以来，从0到1的艰难破冰，从1到100的惊喜积累，从100到1000的稳步前行，再到如今突破五位数的里</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491310&amp;idx=1&amp;sn=b6358af617dc430d4ac40cdece1c1485&amp;chksm=fd6b0550389109cde939aac7e03bd76b5bf0533ce2d6b4fe05e4932a0e6f3a9ed55703a7709a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Mar 2025 16:15:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Google 发布最新开源模型 Gemma 3 性能超越DeepSeek V3、o3mini为全球第二强开源模型！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1Tx7TDib2JZlYSOcIeFibGx26nJ97mYDqomS6G9eBfNYd12uHm60HC3icw/640?wxtype=jpeg&amp;wxfrom=0"/><p>Google 发布其开源模型系列最新模型 Gemma 3。Gemma 3是一个高性能、可移植的轻量级 AI 模型，适用于单 GPU 或 TPU 部署，支持多语言和复杂任务。 主要特点总结如下：支持 1</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491230&amp;idx=1&amp;sn=e8ccaaf50ede7fa24d7335bd53901fa5&amp;chksm=fd9edb25254cab81a6cec126c80833690cd59ff1550c7ae2b19799a778c6a25dcfeca1fa65fd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Manus平替来了！CAMEL-AI开源OWL，开源框架中排名第一,上线一天获得3.3K stars！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elm4qdlMbfjmuJgIxhRCCZM2MncOeQfmqwBKZQvXFoLhraCN3dyfhhWYcnRH9edJicQVVA1ZkS0Azg/300?wxtype=jpeg&amp;wxfrom=0"/><p>昨天的文章中跟大家介绍了OpenManus,感兴趣的小伙伴可以点击以下链接阅读~OpenManus：5个人三小时复刻开源版Manus，不需邀请码, GitHub已获 8k+ star！今天给大家介绍的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491230&amp;idx=2&amp;sn=32a85b1dee0d8a27e118ecd01a938c43&amp;chksm=fd203bf285ac989c8a638d0b0e76be8aea2521f562f1a4ae09b9212de3cd4c00f06e27a2149e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D虚拟人ExAvatar：由简短视频建模转化为3D数字形象。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekzqB2EbDBmquHlenf6YcicAWMXQALDcXjabJaEKqR2IKMpyViauaiaoCFPWRkVQPGibAUElFHg6rBNzw/300?wxtype=jpeg&amp;wxfrom=0"/><p>ExAvatar是由DGIST和Meta公司的Codec Avatars Lab联合研发的一项技术，能够通过捕捉视频中的动作和表情，转化为栩栩如生的3D数字形象。这项技术解决了以往技术中的难题，提高了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491230&amp;idx=3&amp;sn=40387a744cfafd679e91231963032897&amp;chksm=fd97fb8abb80f70f337d8c3b6c19b6d2b9172b84e49294830d517f8a30cea6cc3a0f78705021&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | OmniGen-ComfyUI：简化多任务图像生成和编辑操作,一键生成任意你想要的效果！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek3AzrrMoNWTaibIOp0yQxuUdhncrj6uxibR6BDtnnc5GUloGNfcX0jbZfEnkb7yqhSkm5IicnKTPlfA/300?wxtype=jpeg&amp;wxfrom=0"/><p>还记得之前的文章中给大家介绍过的OmniGen么？感兴趣的小伙伴可以点击下面链接阅读~统一图像生成模型OmniGen：可由多模态提示直接生成各种图像。今天给大家介绍OmniGen的Comfyui实现，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491230&amp;idx=4&amp;sn=cba9283d47d70ff5ec6334b06a1a79de&amp;chksm=fd40cd393213c7851f0581ef5a53d42c19421e5b7e98c449d7c6c8ecc4a5a894bb9a70e9beb7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>