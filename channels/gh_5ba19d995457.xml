<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    




























    <item>
      <title><![CDATA[北大提出定制化漫画生成新框架DiffSensei，可生成具有动态多角色控制的漫画图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcSnOoT1icicSWQibicicqfkyEgKtXcy3S4XBxj4sIBiacegBSAicARmN6YDuAjO6tUqgQ6TNNE8CbF3pFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>由北京大学、上海人工智能实验室、南洋理工大学提出了一种新框架DiffSensei可以实现定制化漫画生成，解决现有方法在多角色场景中对角色外观和互动控制不足的问题。DiffSensei结合了基于扩散的图</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489624&amp;idx=1&amp;sn=b242cd79e0d6fdde2bb684f494ff8b0a&amp;chksm=fdaa8a0bd628c63d1224ba504439f4063b0e235f7a8fcc8a38d5e52ac249747ea98e0a6d5904&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 28 Dec 2024 16:19:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[Story-Adapter：能够生成更高质量、更具细腻交互的故事图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekx1e8oxA3YKibkhot7h9UJZSKKULxCTzezvw8wSOvf1jqib40MePuLWQamEVrmH3RC3HsKvOkJ9S3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前已经给大家介绍过关于故事文本生成图像的相关内容，感兴趣的小伙伴可以点击以下链接阅读~字节&amp;南开提出StoryDiffusion：生成一致的图像和视频来讲述复杂故事，图灵奖得主Yann LeCun亲</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489624&amp;idx=2&amp;sn=0e5c05fa7cc769debfa2acf65dd3bcf3&amp;chksm=fd2b650114031db3e983bfa81f5e412080910de8e51cd3643b6a993cfa78ab2ee4201be135b3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 28 Dec 2024 16:19:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[阿里推出升级版AI翻译工具：Marco MT 性能超越Google、DeepL和ChatGPT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvICGVGwvK1ZowHkm5otQN1GWBq1oKgOpXCvFcU6T8e0WgLCSBUqvcfmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里巴巴的国际业务部门于推出了一款升级版的AI翻译工具，名为Marco MT。这款工具在翻译性能上超越了Google、DeepL和ChatGPT的同类产品。该工具的目标是帮助商户更好地在全球市场销售，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489624&amp;idx=3&amp;sn=2d4b568d6b3d35777de19d5d9a4768e3&amp;chksm=fd049aa9fbcf7990ab62709c0d42b033866822b910f678b1376468cf52e23ebcef61e0a3463e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 28 Dec 2024 16:19:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[ScribbleDiff：使用涂鸦精细引导扩散，实现无需训练的文本到图像生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4dVnOT75Vve5gBZeAMAcqnHFQnQNTu2jZ3gdtvtEhgfeuBiawdPpo4eRXb4xIj7t0TCyfMVB3Rhg/300?wxtype=jpeg&amp;wxfrom=0"/><p>ScribbleDiff可以通过简单的涂鸦帮助计算机生成图像。比如你在纸上随意画了一些线条，表示你想要的图像的轮廓。ScribbleDiff会利用这些线条来指导图像生成的过程。首先，它会分析这些涂鸦，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489624&amp;idx=4&amp;sn=4a76a1ca979610f344374ca94cb2b306&amp;chksm=fdc57379b4c76dcf849242f881eb3d3365a1d7fc30643f9a61254a1cacd48365f527801f17f4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sat, 28 Dec 2024 16:19:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[单幅图像合成 360° 3D场景的新方法：PanoDreamer，可同时生成全景图像和相应的深度信息。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el8quKicUEibqsQFrF8ttU8UZJIaZuVsUww2Z2IDLp7MYqLaIsWuo5dAG2Y1iaHf8AibCjXj4KFPbTv3A/640?wxtype=jpeg&amp;wxfrom=0"/><p>论文介绍了一种从单幅图像合成 360° 3D 场景的新方法。该方法以连贯的方式生成全景图及其相应的深度，解决了现有最先进方法（如 LucidDreamer 和 WonderJourney 的局限性。这</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489622&amp;idx=1&amp;sn=597d6e7ed97d103ec2143d22e33cdd2e&amp;chksm=fd20afec93b756bb1cb7b5e891da7c2129a289d868bf8624afe0ed08ed812becdaa2493f5953&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[超越DragDiffusion!哈工程联合南大提出FastDrag：可以几秒内完成基于拖动的图像编辑。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el1M9OhKbp7aVFqDIicZqBo4KKdolgwrn8m3yECIn5VrcqNnCuNxG4ud1KNvKlkWI1InpekwGDSGUQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中给大家介绍过许多关于通过拖拽实现图像和视频编辑的方法，感兴趣的小伙伴可以点击👇链接阅读和收藏，整理不易，欢迎大家给文章点点赞和在看！StableDrag：一种基于Diffusion模型的图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489622&amp;idx=2&amp;sn=7ac8d89777915b50aa83d078b3b850f1&amp;chksm=fd20013a5fa5a1ad363e4af3b8eff7ee73f42e920c75169872ccd305a1cac44943da0363f540&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[提出街景定位大模型AddressCLIP：一张图实现街道级精度定位！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldKGCwibmhq5RSxC5rV78dDcVpQDWZ2qUibtJW2qRF8ehlmicnuSw3n5MdOVQ0NTovfOnPib1RNDwBibQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>中科院自动化所和阿里云一起推出了街景定位大模型AddressCLIP，只要一张照片就能实现街道级精度的定位。比如给模型看一张北京南锣鼓巷的街景之后，它直接给出了具体的拍摄位置，并列举了附近的多个候选地</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489622&amp;idx=3&amp;sn=a0f6aa7fc9640f3eaa60ad0d5e203e69&amp;chksm=fd043413ce14fd55963fb599d5b9aba61a3d415acb61c6b5cf57eff4add43ef149244676222f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 27 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[马斯克X-AI发布文生图模型Aurora，已集成到聊天机器人Grok中, 将面向所有用户开放。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enEtibxlukPrYKiah0Ke78WycRneTHUqfva8MTdTmSgCvDdsSgDibeDCo0O9j7sQLFlf1NJg4xTOdYlA/640?wxtype=jpeg&amp;wxfrom=0"/><p>千呼万唤，马斯克X-AI发布了文生图模型Aurora，并将其整合进了聊天机器人Grok中。Aurora不仅支持文本输入，还可从用户提供的图像中获取灵感，或直接编辑用户上传的图像。Aurora 是一个自</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489621&amp;idx=1&amp;sn=e8f57b95b7a63b69b24c705aa62b1d25&amp;chksm=fdbeaac08638906cdc9f8ecc535f8540f69aca8e161f96b09fda5dd895921793fd068012a3bd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[马斯克开源自家大模型Grok-1：具有314B参数，由 xAI从头开始训练！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enWzcG7CYZD52ibvUMepv0Iwdt3jHibqYyWbHkPFIjN2NntK7V7gHu8xamHsvQHCYWziazNFwTMtpZJA/300?wxtype=jpeg&amp;wxfrom=0"/><p>就在刚刚，马斯克在最后一刻如约开源了Grok，模型有314B大小，这是第一个如此规模的开源模型。如此体量直接斩获目前最大开源模型的头衔。据了解，Grok-1于2023年10月完成预训练阶段，该版本针对</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489621&amp;idx=2&amp;sn=ab2cbe1da3ae5496c60fe3b196ff4d34&amp;chksm=fdedf8b7fcc9725eeacdb74c3d47f5fd0f797441ea8e780811140b00c0f480ebd760cfcd648f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Poetry2Image：专为中文古诗词图像生成，忠于原诗意境和语义。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emh13jOMSY9oYmD0NHOx8BcYfwYJj74Cog1EPA8EQnekKhKwrxDasX2PxLvN7VqWDL8nRUrassVIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>直接基于诗句中的文本进行图像生成通常会导致丢失图像中的关键元素。为了解决此问题，哈工大提出Poetry2Image，通过实施有针对性的图像校正解决这个问题，有效地捕捉这首诗所传达的语义和艺术精髓。Po</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489621&amp;idx=3&amp;sn=754ba5fc2cff8ff8631be61e8bf36d0b&amp;chksm=fd531951e5441790b6291d6199603cd4f375badd322774cd643397a695b5a6efe4dd5f6ebb70&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[「视觉AI任意门」AnyDoor，只需点两下鼠标就可以实现任意场景物体交换]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ektxTkDn4pgjVvOnwLzwyficpf10rGdcVX0iate9R5qWNUJpdHGSBNRYqI6ZaAPPyjIAwiaUiapjzicWqA/300?wxtype=jpeg&amp;wxfrom=0"/><p>        香港大学、阿里集团、蚂蚁集团联合开源了基于扩散模型的，图像生成、控制模型——AnyDoor。AnyDoor实现了零样本的图像嵌入，主要功能是“图像传送”，点两下鼠标，就能把物体无缝「传</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489621&amp;idx=4&amp;sn=f351a616ed482da184cfbd6806d6e2db&amp;chksm=fda893596db4cb16c6fdb658db3d45a34ccb04b4c4ff05a5fa9e533c095335ff47314c9aa056&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 26 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[图像超分辨新SOTA！南洋理工提出InvSR,利用大模型图像先验提高SR性能, 登上Huggingface热门项目。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emvRmmSX73ApBN83mPSIUnndGUoqrp8dTsfo3BKVIVGVNf5sWoXGauJCgAEaaCQm9Qb7QfuM34qZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>Zongsheng Yue南洋理工大学的研究者们提出了一种基于扩散反演的新型图像超分辨率 (SR) 技术，可以利用大型预训练扩散模型中蕴含的丰富图像先验来提高 SR 性能。该方法的核心是一个深度噪声预</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489619&amp;idx=1&amp;sn=f182985655b722a6b28af1786f859571&amp;chksm=fdbc675665c75a8ea94a8f7b610b9b037cad7eb123e6362921c03687fe1e7665adf82e833a11&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯提出ViewCrafter：一张图像就可以制作影视特效和游戏画面！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPOajsP01qNvmwKPWKzicOsEEbzBxMRtYWNicS7fSTCWsMB1YH3tWIYmKrNLzGfsI0qOR2rIwTbN4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>北大和港中文联合腾讯人工智能实验室提出了 ViewCrafter，这是一种利用视频扩散模型的先验从单个或稀疏图像合成一般场景的高保真新视图的新方法。可以简单理解为将复杂的图像转换成新角度的图像版本。首</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489619&amp;idx=2&amp;sn=dc67cf591a46e2150d13b00de98b73ff&amp;chksm=fdae0c285f441ba5991e81d8edbf83059683056fc5ea8043688b9b8ede786ba3d67e7ad8e943&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯 | 中科大提出Make-It-Animatable：一秒内可将任何3D人形模型变成动画角色]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgeG73PxwM4k72wVClKXaAf0yPYtOtKUjLgb02frh2Xh9vAawfNd5XlA/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯联合中科大提出了一种用于动画 3D 角色制作的新型框架Make-It-Animatable，可以在不到一秒的时间内使任何 3D 人形模型准备好进行角色动画制作，支持各种 3D 表示且生成质量和速度</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489619&amp;idx=3&amp;sn=f110c42876046cc736ed5007fbf41cf1&amp;chksm=fd93a6797762f9f6b4034cc8c563c5ac1f1708cc1b8629eb6908a8f1ff1c2e2bc797b69ab156&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489619&amp;idx=4&amp;sn=6e5b4127d53c33675b51b3f9f032089f&amp;chksm=fddd382a70616c2204bec85e723206b35c8f3361803c638b6088921c0828c765b039773d190e&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 25 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Huggingface Trending！可控人物图像生成统一框架Leffa，可精确控制虚拟试穿和姿势转换！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emvRmmSX73ApBN83mPSIUnnw4qVp8X9ONMxpUQDBiaYSIRDzOCoVkXLaTPVaE68iceCFZ392Kf5RIrA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个Huggingface上虚拟试穿的热门项目Leffa，Leffa是一个可控人物图像生成的统一框架，可以精确操纵外观（即虚拟试穿）和姿势（即姿势转换）。从效果看生成效果很不错！unse</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489618&amp;idx=1&amp;sn=5650938e5dfb4b7cae5f6332248d43a8&amp;chksm=fd56b7afacd586da1bca5e2ba6ecd149324ad285ce83a3b2f13b6f115720221ed66909414938&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 16:22:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[快手可图上线一键换衣Kolors Virtual Try-On，直冲开源项目Top 1！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enWSibOOIL5olEVr4QGiapQjV2hBCzbZIzmXNjBtLkqG3ndIHVUZLFsPYXXXTBsmL3ojSmdUZztnn5w/300?wxtype=jpeg&amp;wxfrom=0"/><p>前几天，快手可图团队在HuggingFace上面搭建了一个虚拟试衣Demo,本周该项目的火热程度已经冲到了HuggingFace的Top 1。那么Kolors Virtual Try-On 到底有什么</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489618&amp;idx=2&amp;sn=899bdd8828512e8c20fb7a8ca1be8518&amp;chksm=fd485cd11a954ad216359cf5192e06bb1a9be4127e6ed8cef9f8d1f3929131f70201ddc4c0c2&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 16:22:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[文生图像编辑来了！英伟达提出Add-it，无需训练，可根据文本提示向图像添加对象。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emmkDiagtskaHJodPFibMTUYJZY50N6JpzSdpSqpDMMdhm1JHxUv7E3vPPDa6XmXuygFoa0eiaBct3Bg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Nvidia提出了Add-it，这是一种无需训练的方法，可根据文本提示向图像添加对象。Add-it 适用于真实图像和生成的图像。该方法利用现有的文本转图像模型 (FLUX.1-dev)，无需额外训练。</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489618&amp;idx=3&amp;sn=7c9705d9e6e007ca6b69fcff90dcaad4&amp;chksm=fdae9ffee1f075d90261eb89d50d3b0a87af92faecebb0267931044a8a7810fb6c114cd26ce6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 16:22:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Haper SD Lora: 8步就可以用 Flux-dev生成图片!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eksy31uial7qPUM1bKGJAsI4BP97gdj3Ez3f9MI6ahElq7FZkQBowmnJAu1mBM0rOdWlon0wCb0tibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>2024 年 8 月 26 日,字节开源了 FLUX Dev 的 Haper SD Lora。只需要 8 步或者 16 步就可以用 FLUX 生成图片，大幅减少 FLUX 的生成时间。建议 LoRA </p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489618&amp;idx=4&amp;sn=dfd78622d906312f68c2b0ed5955a264&amp;chksm=fd27903edaf8a39334e7be2706fbedf385c1ab86eb40a7737181d9d9ddcc4bfecb9858b24067&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 24 Dec 2024 16:22:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[何恺明团队在文生图领域的最新突破性工作Fluid，刷新文生图质量纪录。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enguULNRdFY490TCSZibjWdBDtzjb1fnISWIUibYKVtZZjzibCWozIpuLNnibvGv0UaoHrF8HjA40xKIA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍何恺明团队的在文生图领域的最新突破性工作，论文中详细讨论了在视觉领域和文生图任务中自回归模型的扩展行为，并提出了使用连续token和随机顺序生成的新模型Fluid。 Fluid模型在MS</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489594&amp;idx=1&amp;sn=264a2e4aab1801d1d23d933bfa68b057&amp;chksm=fd758292fcb2aefe3058ede4a2936f4f1c9fc8a65e9dd17219245da75f3da177a04090a20d76&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[北航 | 多功能即插即用适配器MV-Adapter：实现多视图一致图像生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfSL2lH1ru1uCJuUuA21YKHU5ia5SLlWu0BztQtHU3YSeZIYv3K9nGSHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>北航提出了第一个多功能的即插即用适配器MV-Adapter。可以在不改变原有网络结构或特征空间的情况下增强T2I模型及其衍生模型。MV-Adapter 在 SDXL 上实现了高达768分辨率的多视图图</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489594&amp;idx=2&amp;sn=f32c41aa32c472ee77ef9d69e021ba22&amp;chksm=fd435f023a602392265cce46e40935ecd8b7d628d9cf444766f47c25e7ac91c624f68c82dd3f&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Face2QR:可根据人脸图像生成二维码，还可以扫描，以后个人名片就这样用了！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDXLyhv5gUBA9w7NggpzadO1jATGuCxxia6dLEgQBFVb37eWtav37qYkiabubYa9vGGTHlEWmbql9w/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是一种专为生成个性化二维码而设计的新方法Face2QR，可以将美观、人脸识别和可扫描性完美地融合在一起。下图展示为Face2QR 生成的面部图像（第一行）和二维码图像（第二行）。生成的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489594&amp;idx=3&amp;sn=dbe5de5778895cc172e896343e01a71f&amp;chksm=fd91d41eb0ac9041c3144da7e4b24647c006430b4794930430857212e22708d85eeabcfe3909&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一图看尽AI文生图未来，北大发布文生图十年综述：超440项工作回顾。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDXLyhv5gUBA9w7NggpzadRrialXnXJ0hpkUPylInNS5ibB5unS9uBgxThVxDiaMNn2QsZM4tTQg5Fw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的文章来自北大发布的文生图十年综述，文章回顾了超过440项相关工作，重点探讨了生成对抗网络（GAN）、自回归模型（AR）和扩散模型（DM）在T2I任务中的应用和演变。还涉及了T2I技术的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489594&amp;idx=4&amp;sn=b9d11eda3f0e446b5cc6c761535e21f2&amp;chksm=fdbfded8c580d4ec9f71d1372bd869855aeaa878b4f10e17cd9b37d10b6c2171882b7ba4d5fc&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 23 Dec 2024 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[单图可生成虚拟世界？约翰霍普金斯大学提出GenEx，一张图片即可创建可探索360° 3D世界！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enEtibxlukPrYKiah0Ke78WycKUONRrjNlEFSNapJEh6SJ1d66ng13nsbGzI0AOOoofHoVQwXlLWo7w/640?wxtype=jpeg&amp;wxfrom=0"/><p>约翰霍普金斯大学团队提出的GenEx是一种 AI 模型，仅通过一张图片即可创建完全可探索的 360° 3D 世界！用户可以以交互方式探索生成的世界。借助这个想象的世界，GenEx 在想象空间中推进了具</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489578&amp;idx=1&amp;sn=573fd177918ab994fda27691c4739e98&amp;chksm=fd4ec9e45b9597ba8742e1986c4b21b7f84bec1da89ea27a398b2a8b83be42045258fc4b88e3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 16:18:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[智谱AI联合清华开源视频生成模型CogVideoX-5B。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>A golden retriever, sporting sleek black sunglasses, with its lengthy fur flowing in the breeze, spr</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489578&amp;idx=2&amp;sn=7176679ee2df2432e7e5fcccc7b7166f&amp;chksm=fd9810b90b426bb593537a3315a76d33ddad549bd3e03e0763049809742553abf42382eb6926&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 16:18:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯震撼发布！MOFA-Video：表情随心换，运动由你控，视频创作由你做主！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eluznmN5hhFpzms6Qx3Wv5eLBPz0lIKurfh4NGn76ysqzAfKFb3JzIZhVtcMibPQfcYW5Yfg4jSDSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯开源了一个非常全面的视频控制方式 MOFA-Video。支持通过箭头控制视频内容的运动方向，类似运动笔刷。还支持将原有视频的面部表情迁移到新生成的人脸视频上。上面两种控制方式也可以同时在一个画面中</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489578&amp;idx=3&amp;sn=562e65ad208d27254e48aa744416df38&amp;chksm=fdae0b253b23267b3967abfb17b4d9fdd1f8853b6f4515e9cdeb72141be75d5f779911906f05&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 16:18:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[超越IP-Adapter！字节提出MoMA，一种即插即用、无需调优的快速个性化生成方法！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcDtU5TRWR4b0ttfgqrxKDOQAmDscucEyJqSeHYUm1lVuU1IS2LukibibiaoOxpibhtu00EDvRCvPshQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出一种即插即用的快速个性化生成方法-MoMA。不需调优，只需一张主体的图像(下图蓝色圈出)，就可以生成文本对齐的、保留身份的同一主体的新图像，只需要一次向前传递。我们的模型既支持重新语境化，即相</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489578&amp;idx=4&amp;sn=7a4979cf208eac34556944947479fe8e&amp;chksm=fda70c63cea7a112055f8371101cc66dd97226a0d1d1c8655ba2ffe8a2c7b9c2a0f24922145a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 22 Dec 2024 16:18:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[重磅！Grok 宣布对所有人免费开放使用！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enEtibxlukPrYKiah0Ke78WycE6iby25ZkyiabnY17CC6vsR44Rt0UCdF2KxFrFnrYfQjdpynXJwFfcicQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>AI工具又多了一个选择！ Grok 宣布对所有人免费开放使用！马斯克说Grok集成了X上的数据，因此在回答最新信息方面的问题是最厉害的！Grok 现在将𝕏实时洞察与网络搜索相结合，以获得及时、准确的答</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489577&amp;idx=1&amp;sn=cd58000f62fc0263567d57f3a2485d37&amp;chksm=fd67627f4b8d9b1b84a37942fb0514e805087c8c9bb963da237f34b214fb2af25da0d1069d07&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 16:52:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[释放你的想象！支持25种复杂编辑类型！浙大等提出AnyEdit：统一高质量图像编辑框架]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogvQmU85Kosfv2RDCta999EbyF8VGjNflEKL8rzY2kCTLkHufbCjRTU5ianGMict4uibvsA4bKvfblyA/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIGC Studio”文章链接：https://arxiv.org/pdf/2411.15738 项目链接：https://dcd-anyedit.github.io/亮点直击从</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489577&amp;idx=2&amp;sn=09802db03a0d6e8d15ee6d5c8b90a5c7&amp;chksm=fd2d348bd27ed63b646cdceccff45ed1f71437ba44dc662b7ee02f0445a40736407a4dfb97c3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 16:52:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[11.6k星星！Facebook开源的儿童手绘AI转动画项目，儿童艺术创作赛道可落地。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NYTuBbaNon2vjiaAUMWgpNkZmZ2WywhPia4Ryk9Fw4H7g4BxlLIvmicicW46SSfW3fUm1JCFZKwgCRIBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐的是Facebook开源的AnimatedDrawings。主要功能是让儿童简笔画里的主体角色动起来。这个AI项目落地场景很不错，儿童艺术创作领域。儿童对人物形象的描绘非常富有表现力且多</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489577&amp;idx=3&amp;sn=73a35feba30f7392947f829f153a1f1a&amp;chksm=fd52de476a64f7cf61d277c40c15d2ccc0a7ed1896698eeeec1a40a3e9c3193d9bdceab5d261&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 16:52:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[InstantX 重磅开源 FLUX.1-dev-IP-Adapter 模型，文中附模型和comfyui工作流下载。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eltYhV1JmK1ib9FbmIt2gIyP6xwE5MPwewm6kG9gwsXpPEaHHTOicBN3XsV2LsRvJ5qWf00gn2UwKaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>InstantX 团队的研究人员开源了 FLUX.1-dev-IP-Adapter，这是一个常规 IP-Adapter，新层被添加到 38 个单块和 19 个双块中。使用siglip-so400m-p</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247489577&amp;idx=4&amp;sn=5aa81bfb5326c9774a8bf37628d7d4fa&amp;chksm=fd8ef22c7c19c7ebab990f7cff86a0cfa05269e021c49386bdba24accb2cc69734374864b29a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 21 Dec 2024 16:52:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
