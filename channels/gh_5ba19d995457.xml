<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    





















    <item>
      <title><![CDATA[耶鲁大学和Adobe提出SynthLight：智能重塑人像照明，打造完美光影！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPyLquFq9rYTicjFkPwyh9fFVDfMwbeuJFlesWohTUXxZRSXxUpCJVwUUib0mdhjaia5sa6Ciaibic8AQg/640?wxtype=jpeg&amp;wxfrom=0"/><p>耶鲁大学和Adobe提出一种用于人像重新照明的扩散模型SynthLight，该方法将图像重新照明视为重新渲染问题，其中像素会根据环境照明条件的变化而变化。在真实肖像照片上可以产生逼真的照明效果，包括颈</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490091&amp;idx=1&amp;sn=0af9c93268a6d0844956ab9c938e7c2f&amp;chksm=fd53a4268483f78fd1fbfa8861a5ad309c5f2f69c1d82061df23fc6eabcfc845ed6f140771f0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 31 Jan 2025 16:06:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[图像超分辨新SOTA！南洋理工提出InvSR,利用大模型图像先验提高SR性能, 登上Huggingface热门项目。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emvRmmSX73ApBN83mPSIUnndGUoqrp8dTsfo3BKVIVGVNf5sWoXGauJCgAEaaCQm9Qb7QfuM34qZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>南洋理工大学的研究者们提出了一种基于扩散反演的新型图像超分辨率 (SR) 技术，可以利用大型预训练扩散模型中蕴含的丰富图像先验来提高 SR 性能。该方法的核心是一个深度噪声预测器，用于估计前向扩散过程</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490091&amp;idx=2&amp;sn=4dc0b538c54b41c3b34a4c459df58440&amp;chksm=fd49edaabcfe442e6ce5d3e134d8326ee67c4b4d930dab40c0726b961add8efcf540c4c4eaac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 31 Jan 2025 16:06:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[单幅图像合成 360° 3D场景的新方法：PanoDreamer，可同时生成全景图像和相应的深度信息。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el8quKicUEibqsQFrF8ttU8UZJIaZuVsUww2Z2IDLp7MYqLaIsWuo5dAG2Y1iaHf8AibCjXj4KFPbTv3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文介绍了一种从单幅图像合成 360° 3D 场景的新方法。该方法以连贯的方式生成全景图及其相应的深度，解决了现有最先进方法（如 LucidDreamer 和 WonderJourney 的局限性。这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490091&amp;idx=3&amp;sn=ed3ac3460df34ad5bda0b1417ee34ae2&amp;chksm=fdc5168728878e9751498a26501068f269281c161becc4ac67fb5d699390bc8253024f8704ce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 31 Jan 2025 16:06:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[腾讯 | 中科大提出Make-It-Animatable：一秒内可将任何3D人形模型变成动画角色]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgeG73PxwM4k72wVClKXaAf0yPYtOtKUjLgb02frh2Xh9vAawfNd5XlA/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯联合中科大提出了一种用于动画 3D 角色制作的新型框架Make-It-Animatable，可以在不到一秒的时间内使任何 3D 人形模型准备好进行角色动画制作，支持各种 3D 表示且生成质量和速度</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490091&amp;idx=4&amp;sn=b429704b55c313585472b82fd2b535e0&amp;chksm=fdfec11be242e860fdaf91dddd0e8c2a44d56528dfc640b0634e24efecc479604345e1d3a78f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Fri, 31 Jan 2025 16:06:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[DeepSeek开源多模态模型Janus-Pro的ComfyUI使用教程，文中附模型和工作流下载。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enb5zKF6gvurVAmOLrPRAhFLvb45xtbwKzvDHEfDoJNyqQeAWoiaN8o3QOQZeARnWnmvTZdNh0ABsQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍DeepSeek发布的Janus-Pro模型的ComfyUI实践教程，包含ComfyUI安装，模型下载，工作流下载等，欢迎大家一起交流学习，也欢迎添加公众号小助手加入读者交流群，一起探索</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490090&amp;idx=1&amp;sn=15975a24f6a497ab289dc082535605ff&amp;chksm=fd11c062b25aec5d580af3595184cc77a90f769852d2db7529e26abc088780680e424da7391a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 30 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek开源Janus-Pro-7B：多模态AI模型性能超越DALL-E 3 和 Stable Diffusion 3!]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enb5zKF6gvurVAmOLrPRAhFcaHiaiclO2A4p8xHMlrzicfJTT2YRJ96xcpxAialNYX1udoHkp8paKetdA/640?wxtype=jpeg&amp;wxfrom=0"/><p>中国人工智能公司 DeepSeek 的 R1“推理”人工智能已经引起了广泛关注，位居应用商店排行榜首位并改变了股市。随后DeepSeek又宣布开源新一代多模态模型Janus-Pro-7B，该模型在图像</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490089&amp;idx=1&amp;sn=5d6b970e167bbefefe3d5a9069994f2e&amp;chksm=fd046eaacb64ee13f8358309220e9666091b2d41f7707a4d5c8bfac669224dd975f842b1864c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 29 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek-V3 正式发布，已在网页端和 API 全面上线，性能领先，速度飞跃。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsVQ8iaD3eY0RibaYkYGTf6mgibWMibTiaiccjeVMM6rnIOdfQ4sLtwbuJJ1iaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek-V3 在推理速度上相较历史模型有了大幅提升。在目前大模型主流榜单中，DeepSeek-V3 在开源模型中位列榜首，与世界上最先进的闭源模型不分伯仲。unsetunset简介unset</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490089&amp;idx=2&amp;sn=1450aba31793a33547691c2fb3f64eff&amp;chksm=fdb35206a7a8fd4a10fed566080d52842362005e2c1f9dda4ae31838691f6426e4e343434fdb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 29 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[单张照片生成3D头部模型！Adobe提出FaceLift，从单一人脸图像重建360度头部模型。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4qXFbiaEqoEPejUQNwuqLOrpIE3WmoKJBxjrMnCoHDn3huArYyaCa7Ew/300?wxtype=jpeg&amp;wxfrom=0"/><p>FaceLift是Adobe和加州大学默塞德分校推出的单图像到3D头部模型的转换技术,能从单一的人脸图像中重建出360度的头部模型。FaceLift基于两阶段的流程实现:基于扩散的多视图生成模型从单张</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490089&amp;idx=3&amp;sn=cc228ca85a55b5726e11e4760de7ccbd&amp;chksm=fd086da1e7d52f9441ecd1408151bb33bf023955d87e9cc58168dc7a04c6d5acd19c51e7aab8&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 29 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一个LoRA同时处理内容和风格？UIUC提出UnZipLoRA，可同时训练两个LoRA，与原有LoRA兼容。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekK8oWGMLQzxWWfB4pkH8CCntib22WMYOGLwrnJpjeM7SCyxLnkZxmUEMEJADyvx3g4ZicOs12gOU1Q/300?wxtype=jpeg&amp;wxfrom=0"/><p> 一个LoRA可以同时处理内容和风格了？UIUC提出UnZipLoRA， 可将元素从单个图像中分离出来同时训练两个LoRA，与原有LoRA兼容。伊利诺伊大学厄巴纳-香槟分校的研究者们提出了一种将图像分</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490089&amp;idx=4&amp;sn=de4955462f5361ad77dd3016fc2b6956&amp;chksm=fd6b9fa7ae324a93f197b9f9b9f084f9c2a3dd9bd38485d87b8be89cd619767d8456c66803b1&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 29 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[「感谢读者一路同行，2025一起解锁AIGC的更多惊喜！」来自AIGC Studio的新年祝福～]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enb5zKF6gvurVAmOLrPRAhFtpjLqq0QJVtln8ZXSDeWic26Br1Fh6k6LHfu2sgOLxdibBRetJFSsoBg/640?wxtype=jpeg&amp;wxfrom=0"/><p>2024年已经画上句号，感谢各位读者一年来的陪伴与支持！这一年，我们共同探索了AIGC的无限可能，分享了无数有趣、前沿的内容。每一篇文章的背后，都是对技术的热爱和对未来的期待，而你们的每一次阅读、点赞</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490088&amp;idx=1&amp;sn=be4ee50cc4cece6c840cb89d6e6b59ac&amp;chksm=fda21e8d46b1b3bae575f3b3dd554103a92fc7bccafa1c82bce3bf70c3a82953dd1005fbcd72&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 28 Jan 2025 16:11:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达开源4K图像生成模型Sana，可在16G显存电脑部署，支持ComfyUI和LoRA训练。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6Zafxy9AicSRodyIcwlSHNT9mr6NOzfTpJPhveE41Xmh1RVMhhibAgXAt3qSb6eFx0HfpEYX74THA/640?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达开源了一个可以直接生成 4K 图片的模型 Sana。 Sana-0.6B 可以在 16GB 的笔记本电脑 GPU 上部署。生成 1024 × 1024 分辨率的图像只需不到 1 秒钟。官方已经支</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490058&amp;idx=1&amp;sn=f671f319d7fd3f82c07be81aa55e5d2e&amp;chksm=fd2fa9352628b4ff1d6bf2f915de5fba7754aa2146ab0844f895cf296f9e8054e23e35342a70&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 27 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[复旦&amp;字节提出layout-to-image新范式，支持基于布局的MM-DiT架构下可控图像生成！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekXX8zYF4UxzjmCibmVsNeNfHdzvia0ykHy5vQljhxHZhBKib0DHCIdedbOAMsic8KZ423vtGia19o4Wow/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇分享论文CreatiLayout: Siamese Multimodal Diffusion Transformer for Creative Layout-to-Image Generation</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490058&amp;idx=2&amp;sn=781b6dc047987911723ab4d92e23378b&amp;chksm=fd8118d00f71769b5a87ce76c4599f7c3d0195c96a246327b08ec706f264bdfc71f7019ce276&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 27 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[SHMT：通过潜在扩散模型进行自监督分层化妆转移（阿里&amp;武汉理工）]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsjQl0sGle0TkYDcmMMuGmbtLXibkDVicOAa1tpYmub1EJgQJfZ41lm6WQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>当前的妆容转移技术面临两个主要挑战：缺乏成对数据，导致模型训练依赖于低质量的伪配对数据，从而影响妆容的真实感；不同妆容风格对面部的影响各异，现有方法难以有效处理这种多样性。今天给大家介绍的方法是由阿里</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490058&amp;idx=3&amp;sn=04b9f8f32aa3b7145c1821b47d4ea26b&amp;chksm=fd8a91cc96f2a2e1f3d41311d6c21bd95ff9b7cd6d1a34f76e7e1317e3ab7127dc8ba3c8fafa&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 27 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[提出街景定位大模型AddressCLIP：一张图实现街道级精度定位！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eldKGCwibmhq5RSxC5rV78dDcVpQDWZ2qUibtJW2qRF8ehlmicnuSw3n5MdOVQ0NTovfOnPib1RNDwBibQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>中科院自动化所和阿里云一起推出了街景定位大模型AddressCLIP，只要一张照片就能实现街道级精度的定位。比如给模型看一张北京南锣鼓巷的街景之后，它直接给出了具体的拍摄位置，并列举了附近的多个候选地</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490058&amp;idx=4&amp;sn=187ced6c7d7f40ec09a755763c6b9670&amp;chksm=fdbb265fbde436ab4fc4e9a040a1e60d68e1f8fe5cb9ed097502d404f8fbc9ee9218b3981df6&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 27 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[单张照片生成3D头部模型！Adobe提出FaceLift，从单一人脸图像重建360度头部模型。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4qXFbiaEqoEPejUQNwuqLOrpIE3WmoKJBxjrMnCoHDn3huArYyaCa7Ew/640?wxtype=jpeg&amp;wxfrom=0"/><p>FaceLift是Adobe和加州大学默塞德分校推出的单图像到3D头部模型的转换技术,能从单一的人脸图像中重建出360度的头部模型。FaceLift基于两阶段的流程实现:基于扩散的多视图生成模型从单张</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490057&amp;idx=1&amp;sn=abf129eb3d79e47e5868f82fb2c27131&amp;chksm=fd9941c812f75472c02b9919c97a24ac51e9f744f06c2d95ff899d806b3168f8ee11988e2aea&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 26 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一键试衣or一键脱衣？TryOffAnyone：从人像输入中生成高质量平铺服装。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUnCMiaBjZZszIFmMq4b6eoaD7GTE6xt5Kkbz15pCGnYFBHiaXPN7qYcV79yBTU689jcMRI5dJd0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>TryOffAnyone 是一种新颖的单阶段框架，旨在从穿着衣服的人的输入图像和覆盖服装区域的相应服装掩码合成高质量的平铺布料图像。在 VITON-HD 等基准数据集上实现了最先进的性能。该方法在为全</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490057&amp;idx=2&amp;sn=bc8fef13bc2549981e44048cb0ce7664&amp;chksm=fdc3bef4062c2ca60abc1de2e59d7633505ea3632ac5e653b4afaee22b45b08a5c37c1a8f94b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 26 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Adobe发布TurboEdit：可以通过文本来编辑图像，编辑时间<0.5秒！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKcprhHqENugIHSUTwb3EOiaaqictMa8fmmNEDqsoISMhGDZH4oZmh7vtMn5sov6khPdhIypPkhDZQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍Adobe研究院新的研究TurboEdit，可以通过文本来编辑图像，通过一句话就能改变图像中的头发颜色、衣服、帽子、围巾等等。而且编辑飞快，<0.5秒。简直是图像编辑的利器。相关链接项目</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490057&amp;idx=3&amp;sn=8c33be1915dfe03902e10b066e2fc7c6&amp;chksm=fdbf1488eda57bc8c82735506307c1fbdb6ce67b2ad1e96e7c7c2ee7ce0e7550abae3df32d22&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 26 Jan 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浙大 | 腾讯 | 华为提出视频生成框架VideoMaker，可由参考图实现Zero-shot定制化视频生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekaVfDRjALdOCj5889F1MpALuqg2wbFklkt9TIVHLSyQfTQ65do3Pe4Szhc0sWs0dMVTLfiavGbvRQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>浙大联合腾讯和华为提出了一种新的定制化视频生成框架——VideoMaker，利用VDM的内在能力，实现高质量的zero-shot定制化视频生成。该方法通过直接输入参考图像到VDM中，利用其固有的特征提</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490056&amp;idx=1&amp;sn=515a850881d7ef3822914ea6560d3fe1&amp;chksm=fdca9bd4cd455e689d4221795ed3a48e51a7a8bd31df2e309570e49c5780f65d6bf29cb81bdd&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 26 Jan 2025 00:08:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一键脱衣？TryOffAnyone：从人像输入中生成高质量平铺服装。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUnCMiaBjZZszIFmMq4b6eoaD7GTE6xt5Kkbz15pCGnYFBHiaXPN7qYcV79yBTU689jcMRI5dJd0g/300?wxtype=jpeg&amp;wxfrom=0"/><p>TryOffAnyone 是一种新颖的单阶段框架，旨在从穿着衣服的人的输入图像和覆盖服装区域的相应服装掩码合成高质量的平铺布料图像。在 VITON-HD 等基准数据集上实现了最先进的性能。该方法在为全</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490056&amp;idx=2&amp;sn=c2ea44a0f6e1f07f65487d61e6412a7d&amp;chksm=fd112f0f1371c0eaf18562e06b386ac72123601926151ffbf5be041b5380504cf2629aaaf778&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 26 Jan 2025 00:08:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekB7CXUYR45xqh1P2Q9zWuxgmicJiaO6JPkkhoaibkSARt6qftWXI9ofZjt9NK9vuibg0UrfhA2kTPRaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT今天介绍的文章来自公众号粉丝投稿，腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT，给定一个人像图像和一个衣物图像，就可以生成一个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490056&amp;idx=3&amp;sn=c251f6741179b8376358db838c84bd6b&amp;chksm=fd4e02ee03cd7d095d3a8e55f9b6f2b344a8493200479a2c7d298e8bf5cab6b1c928d230c38b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 26 Jan 2025 00:08:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
