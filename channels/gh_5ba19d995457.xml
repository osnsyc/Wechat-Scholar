<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[音频生成新突破！矿大&amp;快手提出首个多模态音频生成框架AudioGen-Omni，一键搞定视频转音频/语音/歌曲。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elRibQicbES3yE84iaQribf4r53AxtApIOia6OQ4SnoHIHFxB48CDpTpqxVdWMuwIPeocp39ZEvHXiaOEQA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494797&amp;idx=1&amp;sn=2562fe693c02cf94e052ff9c36e247ef&amp;chksm=fdb1d2bf9ac959a4bb432c0bad4ae3fb5d9a3a752ec9a233015e59ab32f748e049a804e67200&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刷新SOTA！这个开源OCR凭1.7B参数AI视觉模型，实现全能文档解析。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NYaM5gOXKDOT9FZgBmNRUN6jsYYsc8oUlrH1bwgXH3zuEp6exwxFlbwycYk7svJuSoJu2XPrVxm0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>好久没推OCR开源了，今天找到一个猛的，项目很新，劲头很足，它最大的特点，是基于视觉大模型。现在的OCR已经不只是文字识别了，更重要的是一些其他格式的内容，像是公式、表格、多语言等等。这个轻量级的视觉</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494797&amp;idx=2&amp;sn=cb95542381ffbb16cf80cfd5f430a91e&amp;chksm=fd139abbdab762d742f6c50d15cbe7cd41cbe768fac2a7fbf6d43c3c0643af47a393d6d87920&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源多模态生成模型新标杆！OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494797&amp;idx=3&amp;sn=39b73870838ed74397bfcc59eac75ceb&amp;chksm=fd1b38ea13276ca4bc1a5254d90d897f2309b4d19139fa0440662540cde60c4d528260bbe0ac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别"纸片人"试衣！阿里&amp;浙大提出3DV-TON，用3D几何骨架+动态纹理场，让虚拟模特"活"出真实衣褶！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECFZTEAl6XrNJIs6kBFtCKh4H4USr1Odbdw4IOg8SSgUfrQQVgR52lmA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里联合浙大提出3DV-TON，可生成高保真度和时间一致的视频试穿结果，3DV-TON是一种基于几何和纹理 3D 引导的新型扩散框架。 可处理各种类型的服装和身体姿势，同时准确还原服装细节并保持一致的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494797&amp;idx=4&amp;sn=79c08ffad44224d192818b4732a26a87&amp;chksm=fde94e99c9873defedcf9761c7e862fb3cdfb346b3a1ca9be9267363152fe8478d2f126c8625&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[通用世界模型来了！Google重磅发布Genie 3：动态世界实时生成，24帧720p引领多样化交互式潮流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekOicvEwNdEEX8G6p02iaJaXic52OlLuL4CxeBEjguQBkKSDsz3mYaibzgZ3MUywGpmREfiagMhS3Tfribw/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494700&amp;idx=1&amp;sn=aaeeda359d67bfcfe19b63fef9944211&amp;chksm=fd48729d3be5f948c6a722ec6f754679043cd062e9dc13d8791afb11f198c4ab71c02f02321b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 05:42:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出从单一主题发展到多主题定制的通用框架UNO，通过情境生成释放更多可控性。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elo3s89icGNibsPQVXGhctg9WDrsYXyWyFSyqXzUDm6eOsD3G2Z7XbSMUPZrQw19LsCTpuzPx9KiaCWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494700&amp;idx=2&amp;sn=66bc8b33928c0446b1cac041d6ee4cac&amp;chksm=fd7dbd044c97e6064b57a231b70a46fd83a5b40cbd835fb4f04decbbc0ceac5b4ecdcb63b1ff&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 05:42:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 字节DreamFit: 多主题电商服装迁移！轻量级即插即用任意服装模特匹配]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGSxicUBwA56Pek0VwHmNacVsMhP7pROSIyva554J3rL1LBI4t5lpvM0icF2YaPAtfrN22ICPibd001Fg/300?wxtype=jpeg&amp;wxfrom=0"/><p> DreamFit:为服装增加电商模特DreamFit简介今天文章介绍一款新的虚拟试衣框架：DreamFit，这是一款结合了一种专门为以服装为中心的人类生成量身定制的轻量级任何服装编码器。DreamF</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494700&amp;idx=3&amp;sn=b0d1758ac1a9fbce33067a01de6362ff&amp;chksm=fd269b18c0621100ddcfcf754e3c1cf88f80b0f55bb4795d5981e4d89f9af674d92168f9e4a6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 05:42:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[文生图新架构！清华提出MADFormer！混合自回归与扩散的Transformer模型！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Ir9WHCQBicWXDuF5MpvmWMQh4QPfVT8nXE9Tnw27035bkagHHFhhyzApmdO2oxAbKbOs56pmZG7JQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generati</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494700&amp;idx=4&amp;sn=9113db2461c76632b19e1c7efdeb56ce&amp;chksm=fd02f366efba02b0b45af662f12c46082e97ef76cd61c57d00e23623dae6e41742b7ee3399cd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 05:42:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL2025 | 15篇多模态论文揭示未来AI走向]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekOicvEwNdEEX8G6p02iaJaXicibt3piaL92aeAvhxXRMUgDdias9VYCZpwIJV2vz8icMy5PkicJ7ACickYkuQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>多模态人工智能正以前所未有的速度重塑我们理解世界的方式，它让机器能够像人类一样，融合视觉、语言、声音等多重信息进行感知、推理与创造。作为自然语言处理与计算语言学的顶级盛会，近日召开的ACL（计算语言学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494686&amp;idx=1&amp;sn=61d889434ef73982a5d8f9c5f36261ee&amp;chksm=fd5e06741a5e37d024ff6f280ff0a0fd84956636048112e30ea420a7fd400ba2f5747c12af43&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 11:31:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节、港理工提出 Many-for-Many，支持10+任务，8B参数“逆袭”商业视频生成引擎。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXr1okRdYbDMkiaMBJd2BP7Rly0sBNFZKib2sPFdbSs7MvfFpF6hn5uyKnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节、港理工提出超强统一视觉模型 Many-for-Many，如何凭它让 8B 模型“逆袭”商业引擎？字节跳动与香港理工大学提出统一框架 Many-for-Many，它借助众多视觉生成和操作任务的训练</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494686&amp;idx=2&amp;sn=3687cbd59ce36a284cca75ce7267fe67&amp;chksm=fdec84a3d54694f4370241b9fae451b1726c2720d28e157e7174ddea725c415f69ff56c0cf11&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 11:31:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源二次元风格生成Neta Lumina，从Furry到国风，全方位赋能动漫创作新体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnnuuc8trMqQZdXicVSnCicAT0JorhOHp7RZ0picPcQW6vmQULK0icb6qeo3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>Neta Lumina是由 Neta.art 实验室开发的高质量动漫风格图像生成模型。基于上海人工智能实验室 Alpha-VLLM 团队发布的 开源Lumina-Image-2.0，利用大量高质量动漫</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494686&amp;idx=3&amp;sn=a1704781dc8bf41f55f7babd4081ae57&amp;chksm=fd1faf195a963535ba4a3ed6e71287c1514bf2803e103c59d34ccb53bf33445c9022894a3416&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 11:31:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大×字节提出ComfyMind：生成/编辑/推理三连冠，开源领域再掀狂潮。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elI7B3IZQkA99hvyeKlzPzyeqYm9eaK3j5oUNFlRDs6yaz4YvOHWYMnpeWHk5ic5s7zDkXrP7RYtBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、字节跳动提出的一款基于 ComfyUI 平台构建的协作式 AI 系统ComfyMind，旨在实现稳健且可扩展的通用生成功能。在 ComfyBench、GenEval 和 Reason-</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494686&amp;idx=4&amp;sn=23451ad9c334ee58ee77919d2e8195ad&amp;chksm=fdf413ca6c0406cb96672b4d46be19f959c02cd633d1ad335ffd33a4e89fd81356770f55c064&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 11:31:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 港科大&amp;商汤等提出3D生成框架CoPart和首个3D物体数据集，开启3D生成“从一到多”新纪元。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45IqouPaRapq8gWkGsbxM1dTO9s8LcAth8EpxCCuuF5TTMQPvpUxibvkflknA/640?wxtype=jpeg&amp;wxfrom=0"/><p>香港科技大学、香港中文大学、商汤科技研究院提出了一个全新的基于部件的 3D 生成框架CoPart ，它能够通过多个上下文部件潜在特征来表示 3D 对象，并同时生成连贯的 3D 部件。并且还发布了首个已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=1&amp;sn=91ac5035c23845d5ebbc8e7c22593048&amp;chksm=fd264d523ecfd9c20cec2808d13c910f453a8fc64f3dcab7130d1108bf821f40e213f637c502&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[自动生成ComfyUI工作流？英伟达提出ComfyGen：通过LLM来生成匹配文本的工作流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eny4Iriba5NSXkHvLxicLITJDqnLYd3byQhrC0bKwIGSOFEPvibmO8gTicw8bg8Y16oLT3TR7jWM7j2AA/300?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyGen的核心在于通过LLM来匹配给定的文本提示与合适的工作流程。该方法从500个来自用户的多样化提示生成图像，随后使用一系列美学预测模型对生成结果进行评分。这些评分与相应的工作流程形成了一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=2&amp;sn=1a210355a13a70904ac362f166b39866&amp;chksm=fdac5bf7acb4c86844eb5f91193e4ecfe12dd7d5c67211e864f845eef1516bd47d7c4556a86f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[GigaAI发布全球首个解耦式人体视频生成框架HumanDreamer，可生成由文本到姿态到人体的高质量视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7F3dWu899ia30B7OUIZdlXFicRk96bnw8CxvB7cawibZFt7o1OsHwARZWlw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由GigaAI、北大、港中文联合提出了一个解耦的人体视频生成框架HumanDreamer，可以根据文本提示生成各种姿势，然后利用这些姿势生成人体运动视频。此外论文还提出了用于人体运动姿势生成的最大数据</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=3&amp;sn=4f8a628a92f50c611e94f96f65c28926&amp;chksm=fdbdc2555ea3b86ddad48d875db1f4f0f5f57d84aad87d347f198abd4592ff729b2a7de9db66&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北大提出高效视频生成框架Magic 1-For-1！一分钟即可生成1min时长的高质量视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Im7d1myrXRAiarmcWtBLIuFK9FQGib66tAQmlDsP6icPCQpkZ9dLLmVqzlmibR6zRCHiaJSK7kuibJkGmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>计算机视觉最新论文今日论文推荐论文名：Magic 1-For-1: Generating One Minute Video Clips within One Minute论文链接：https://ar</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=4&amp;sn=4c907de5a4ab06fe66a483f3be9f66d7&amp;chksm=fd4cae3243305cedc5cf051df6a541e18011596d2ae0f7297a35b0cf65da41ee985a21c05e01&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里重磅开源Qwen-Image：200亿参数MMDiT模型，SOTA级卓越中文渲染，海报/PPT/文案设计一键搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ema74qVxKj0HCrThBTWG0dFqtnpdqkibjicsufldwWH5sSWGB3DllIqOJWFLl0EFqtUcicE2PgvEG9dA/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里通义千问发布了首个开源图像生成基础模型Qwen-Image，Qwen-Image是一个200亿参数的MMDiT模型，是通义千问系列中首个图像生成基础模型。主要特性包括：卓越的文本渲染能力: Qwe</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494559&amp;idx=1&amp;sn=5379ef61226c4204729706aa68b00fce&amp;chksm=fd103ec8eebbe90f43f5fe25651aa9e001145de2bedcea379883ba19c937324c09f89efa23a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[重构图像编辑！ComfyUI 原生支持 HiDream E1.1，真正开启「自然语言改图」新时代。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE5NTaVjpZ3bk5vDpSbE1hBc7keDkNib2UkUne9RfxEoRwQWTr6U6ZNLicQmWoBibs9fclxMl6m3no0og/300?wxtype=jpeg&amp;wxfrom=0"/><p>你有没有想过，未来的图像编辑，不再是鼠标点点涂抹，而是像跟设计师对话一样——你说一声“把这只猫变成火箭侠”，AI立马给你实现？现在，不是“未来”了，这已经被 HiDream E1.1 搬到了 Comf</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494559&amp;idx=2&amp;sn=b3226e80438760f76e24c48185df8c6c&amp;chksm=fd638f865523b6f8a765fe89879789eb4ba0e6fd9b90934e08e153c93a3a4999d01220b03abe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI时代职场生存指南！微软公布“最容易被AI替代”和“最不容易被AI替代”职业报告，避开高危职业，拥抱新机遇！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45Iqouv4a8VOjh7iabrSiajsu7cpvdNxVzKonXeCaXxrhL17yricSm2vtJV63DA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在科技日新月异的今天，生成式人工智能（AI）正以前所未有的速度渗透进我们的工作与生活。近日，微软研究院联合微软团队发布了一项重要研究——《Working with AI: Measuring the </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494559&amp;idx=3&amp;sn=5a53820c0d966ae0455b3295c2f5eb22&amp;chksm=fd600f0ec1300cd27361f0508a135ef24153106ab488ac95c95a9595fa43edf2b432321a850a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大&amp;美团提出PosterCraft，文字渲染与艺术融合，从创意到成品只需一步！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elRPnxm15EcjBGoXOC5AYqzmibC3IibyVqwj02b3JZwTrRYibZ5X4eYgJcibSRkrEYHSF6tueI2pO8OFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一款由香港科技大学和美团联合开发的创新性海报生成模型框架：PosterCraft，其擅长精确的文本渲染、抽象艺术的无缝集成、醒目的布局和风格的和谐。PosterCraft 的设计理念是统</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494559&amp;idx=4&amp;sn=e84ac6500741e5b1aac414790575ccd8&amp;chksm=fdcf8814250c5ab91c18158bbda54d99122df5e2d85131a7e5dfede967fbf4f6f82a877e7ece&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[实时魔法降临！Decart推出全球首个直播AI视频生成模型MirageLSD，24FPS实时生成零延迟、无时长限制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45Iqoua2PibNicnuedMFXuGp46gKjZiaIZiceXrtPryTsX8D3WXw9HJg4ibFULg8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>Decart推出首个直播扩散AI视频模型—MirageLSD。不同于Veo等市面上时长有限、存在延时的视频生成模型，Mirage可以实时转换无限长的视频流，1080P处理响应时间小于40毫秒，彻底消除</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494526&amp;idx=1&amp;sn=51333d0373a4ce6e92fa0871bad2f7de&amp;chksm=fd847afefe086432da9afaf4be4d8090413ce2005f5fdcf90d8d87b2484f348b912dca6bd2af&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大提出RealCam-I2V！精确相机控制的新型视频生成I2V框架！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXW2QTHDiatN7k4pGOJfic1lBfxyVelPRsL0aibr9cCI1YRoX6z1QXcP1lKA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control论</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494526&amp;idx=2&amp;sn=be1d4217b3d1b254682bbd54787e20c5&amp;chksm=fdcafe944980187dc0aa9329fee24a237b48551ec1db87959fa67210f922c5c33ac8e42260cc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多领域SOTA诞生！Vid2World：打通视频扩散到世界模型的“任督二脉”｜清华、重大]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaeFVcHGjGc24PwYRxSa3SRzxraaxquD1Y4eiapCrHo7GN2pjc3L4XfolskYUicsqxRONc0Q9o3iaR8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文链接：https://arxiv.org/pdf/2505.14357 项目链接：https://knightnemo.github.io/vid2world/ 生成效果速览亮点直击首个系统性探索</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494526&amp;idx=3&amp;sn=92af001d8054c9fbc79259e8592e2fde&amp;chksm=fd03f4eecbfb3fd4b9d1a3c7d5adb9209bb6e3bb38442b41521c22ce960ebb647e56f7f3eb7b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq5BIttmnJoy6onMGT6hEJiblmfujJkZFpZjpO6usAYRtw7aj1tZbJZYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元团队提出的 HunyuanVideo-Avatar 是一个基于多模态扩散变换器（MM-DiT）的模型，能够生成动态、情绪可控和多角色对话视频。支持仅 10GB VRAM 的单 GPU运行，支持</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494526&amp;idx=4&amp;sn=485c91a9b0694eec487932f0bae09411&amp;chksm=fdcf04cca76b287738f7ad0828dfe9e704d581a6841f305a9788cd3f8e46c9efefcff5147b32&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI时代职场生存指南！微软公布“最容易被AI替代”和“最不容易被AI替代”职业报告，避开高危职业，拥抱新机遇！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45Iqouv4a8VOjh7iabrSiajsu7cpvdNxVzKonXeCaXxrhL17yricSm2vtJV63DA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在科技日新月异的今天，生成式人工智能（AI）正以前所未有的速度渗透进我们的工作与生活。近日，微软研究院联合微软团队发布了一项重要研究——《Working with AI: Measuring the </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=1&amp;sn=6821a4cd9b855a8cee6766d9c8a55b25&amp;chksm=fd3e575a49958b01a2817db80a2011c7ab131c243efff247ef2e33b5893ebddcc9942809bca9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出新框架ImageRAG！RAG+AIGC提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JK3j8AP855QOPLGKEpd37E3bPLWmIOj4bSM2oUxbcSEQ3NFVFyqRhEKjhBGvFkPMAwAaMsbszianQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation论文链接：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=2&amp;sn=2e4ee84eb60755441043a6e20c33ded0&amp;chksm=fd0cddbe3403eed7be30fb2c5ada2c9604fa4f5fa9313e6045a0a8888cd8f3fefa3b3ad0bf2a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文了解 DeepResearch：AI 如何重塑深度研究与知识整合]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIo0ia75NSGFsObsIAKtZ35qIl2VrDtpaxMVkxU4QsGhZJdF0ZqOibRyJfONRdRTChR9oaFpPcAt00ug/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，AI 工具逐渐从“快速问答”向“深度研究”跃迁。DeepResearch（深度研究）正是这一浪潮中的代表性技术，它通过多步骤推理、海量信息整合与结构化报告生成，将原本需要数天的人工研究任务压缩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=3&amp;sn=1dfd0fbea8dbdfb036e7a6b7a3dc7e91&amp;chksm=fd1f668fe4fe0777e78f07eb25b66028aa551866ea6ac8d1e453e42ac35d70c4185ca562d50f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南开提出1Prompt1Story，无需训练，可通过单个连接提示实现一致的文本到图像生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzPNo4OCBUcdtmaQJs6N0wWib04FeoPN0dUqhYsAJa4gIVOeKpt04Ox35gLkECLB9LEJGNnrDPu9g/300?wxtype=jpeg&amp;wxfrom=0"/><p>（1Prompt1Story）是一种无训练的文本到图像生成方法，通过整合多个提示为一个长句子，并结合奇异值重加权（SVR）和身份保持交叉注意力（IPCA）技术，解决了生成图像中身份不一致的问题，同时保</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=4&amp;sn=df996bacb4a74e8df8fddf3c87c6063a&amp;chksm=fd52a93cb741df3e31740765f03a031bfac37323943192291aff3f3085ad33a550226f9969e8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>