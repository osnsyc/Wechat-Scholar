<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    




























    <item>
      <title><![CDATA[香港科技大学提出YuE：Suno级别开源音乐生成模型，支持中文！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZsukicic1pwKicvO5kl9ea5rGcBfEiaHiaQP2qUjqPV3wDPziblkH7xOuXdRw/640?wxtype=jpeg&amp;wxfrom=0"/><p>YuE是港科大提出的一个开源的音乐生成基础模型，专为音乐生成而设计，专门用于将歌词转换成完整的歌曲（lyrics2song）。它可以生成一首完整的歌曲，时长几分钟，包括朗朗上口的声乐曲目和伴奏曲目。Y</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490515&amp;idx=1&amp;sn=f021bcbbbb5608142e8a4cd9104b9e94&amp;chksm=fdf994841a673d36f40b4ce99ac89d3625ad2c3763a34ea3c9af2ba572c5cf8c80ff4aea1489&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 25 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[马斯克疯了？Grok3 突然免费！还说让大家“用到服务器崩溃为止”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/QFmOy9B4XPW93brzPiaQQlVAqCHrRsnnJGIBGkAOnKSFHtHzBJjfZ1vzicEpnmNNa0haIM0RlY8Mx7mNfJaoApmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>就在 2 月 18 日，马斯克旗下 xAI 公司宣布推出其最新 AI 模型 Grok 3。2 月 20 日，xAI 宣布 Grok 3 即日起向全球用户免费开放使用，直至服务器达到崩溃为止。（也可以理</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490515&amp;idx=2&amp;sn=97c2c95f08e7e6086eeebc627e4e1d1e&amp;chksm=fd399f822bbc1511c77bdfc5c799dc64f82c0259600194e2a730ec1826f7efd163f6b3b74237&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 25 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[解决文生图质量和美学问题，字节跳动提出VMix：多维度美学控制方法，一键提升图像美学。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcic6UBBbFKhnQGPNFnt0uNP0icQj44gWuVMkaK2nsqNia2kicW5icETqKKVMA/300?wxtype=jpeg&amp;wxfrom=0"/><p>为了解决扩散模型在文生图的质量和美学问题，字节跳动&amp;中科大研究团队提出VMix美学条件注入方法，通过将抽象的图像美感拆分成不同维度的美学向量引入扩散模型，从而实现细粒度美学图像生成。论文基于提出的方法</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490515&amp;idx=3&amp;sn=9fc95478aa6836ff42fe8756bc3c7daf&amp;chksm=fd9b6503871087dbd5ac836db098d63223877f0170297e62420f85416e897f6fab3e5aa41c02&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 25 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[国科大提出SayAnything！高保真语音驱动说话人视频生成神器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5K5KErGYAcboNZ5g1ickzvcVkQLCcDMsCQcyM5NbvALsSFic6AIQm1WH4bTtNZ1icfTrh6g2j7b1kRhQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：SayAnything: Audio-Driven Lip Synchronization with Conditional Video Diffusion论文链接：https://arxiv</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490515&amp;idx=4&amp;sn=c488ccbd4604631c9afe07161e4ad7bf&amp;chksm=fd78a3f46b6634445e111c13d7be1830c26517f23e8bfb5f2c6491875ac3f1f97ac993849d5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Tue, 25 Feb 2025 16:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[LuminaBrush 在图像上绘制照明效果的构建交互式工具。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emstfptCQxwPFVbYI1WNOA3hBPXy2a1MjMxRyibAmc4FtFqLVcy56JI8l8XdNxdSFPyAw6H06p4Xuw/640?wxtype=jpeg&amp;wxfrom=0"/><p> LuminaBrushLuminaBrush 是一个构建交互式工具以在图像上绘制照明效果的项目。该框架采用两阶段方法：第一阶段将图像转换为“均匀照明”的外观，第二阶段利用用户涂鸦生成照明效果。相关链</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490513&amp;idx=1&amp;sn=9061a763dc13527ddafa414a73823c9b&amp;chksm=fd0ecc5c519367b5bd47350e1ea243c3a8230b624cdaefa19daa6d841785a043dbda49aa93ff&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 24 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[ComfyUI 迎来重大更新：原生支持 Lumina Image 2.0，解锁极致图像生成体验！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE4wDn16WHKLZgNuLEibJtk3l1Z7eg0ERD9iafAP0MSxU9wTK5wLficV8WFuWqq0KZ2jYcpooQ5gwdZOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在 AI 视觉创作的浪潮中，ComfyUI 再次迎来重要升级——原生支持 Lumina Image 2.0！这意味着，你现在可以在 ComfyUI 中无缝体验 Lumina-Image-2.0 强大的</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490513&amp;idx=2&amp;sn=2f883bf224d210e191df2ceb22c5a5f4&amp;chksm=fd9b85e56931c56d571b9cefc0477da891c1c62bcefa261815fab85e81ddd22a218423893738&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 24 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[国科大提出SayAnything！高保真语音驱动说话人视频生成神器！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5K5KErGYAcboNZ5g1ickzvcVkQLCcDMsCQcyM5NbvALsSFic6AIQm1WH4bTtNZ1icfTrh6g2j7b1kRhQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：SayAnything: Audio-Driven Lip Synchronization with Conditional Video Diffusion论文链接：https://arxiv</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490513&amp;idx=3&amp;sn=ec8fbdbb5d06916b50f5e06363704689&amp;chksm=fd4b2211282a456b682c4c3007266861586e5be4bd9b1f91dbbc7fd9e34696ea0a9135865806&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 24 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[YuE：用于完整歌曲生成的开放音乐基础模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p></p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490513&amp;idx=4&amp;sn=0b849dd72b983ad39ed1af004ca8d40c&amp;chksm=fde1b23f4b54b7ae5dc7bd769a1ca3d22e784bc5b5fb018e598686ce99bd37b911c54ed5e3d9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 24 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[魔发奇缘，3D发型生成新突破！TANGLED：可用任意样式和视点的图像生成 3D 发束]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekpCyj06iactRk96xGc32gLwfpjZlTjjCSbXm0Lib95G5D5yo7ElFr9uxtoh3BdCt4nr4ht1wrCGWWw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在数字时代，发型不仅是时尚的标志，更是个人文化身份的彰显。但传统3D发型生成技术往往难以捕捉复杂发型的细腻之美。为此，上海科技大学和华中科技大学推出了ANGLED技术，能从任意风格、视角的图像中，轻松</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=1&amp;sn=08ea1babf6f4a250fc1a070192d94a58&amp;chksm=fd18769d857fb9c659af26deb5e1e6cf9712edb5c11525b839cabbf45aedad95c9ac5643f482&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 23 Feb 2025 22:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[澳门大学提出DC-ControlNet！解耦控制条件！灵活性和精度超过ControlNet！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IJObOoyvhRkCaPGyos7d8xL9KBFJiaWYgoicVEkmuuB7slvPLj3SIW9jx5pace0iagDibDDTLU1P3Lwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：DC-ControlNet: Decoupling Inter- and Intra-Element Conditions in Image Generation with Diffusion</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=2&amp;sn=de121316a3123aa0581f09725abe2bd6&amp;chksm=fd0068d3835af5ba38f14f910e10993f3a78f8da58fc4d63e8db4101161d28881299658a7a8b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 23 Feb 2025 22:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[开源版Deep Research，一句话创建Agent工作流帮你完成电脑上的复杂操作，股票分析也轻松实现。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NZM99XBibic0ksT7p0zTFpQHQT2lY40u4GloUhxMpWMlQLDWe9ic4uibxzibicD0eiauVkGszvokib9MfuhLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI刚出来的时候就不断在说，后面非常多的工作就不需要人去做了，都是AI在做。之前很多人不相信，现在已经有很多公司在裁员了，而且裁员后业绩反而更好了。当然，我们平时也不愿意做一些繁琐重复的工作，让AI去</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=3&amp;sn=ebb27cdf7263a50217dd05d142035047&amp;chksm=fd3d55f1d3f84c431f8200a0e71d5b1cd624efc7849f4dd65cec876ccc1dedb7d71aceea768b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 23 Feb 2025 22:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[小红书提出新面部视频交换方法DynamicFace，可生成高质量且一致的视频面部图像。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4wY9icyCBJHtpRNSEtIVu23ib2dMfGUzdVZH7hKlE7v6ZRLfdk46k3hHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>DynamicFace是一种新颖的面部视频交换方法，旨在生成高质量且一致的视频面部图像。该方法结合了扩散模型的强大能力和可插拔的时间层，以解决传统面部交换技术面临的两个主要挑战：在保持源面部身份的同时</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=4&amp;sn=cf008a19b978ab7f5ca27c2f67b893ea&amp;chksm=fd0052e96469409dee07028c56d34eb9f9ca3e3ce152f5eed389aaa7f0af9935412864f20402&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sun, 23 Feb 2025 22:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[免费才是王者？Grok 已冲到美区榜一！XAI 发布Grok3的详细介绍文章。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekY4qnP4C45mhDVMQH4yySsQTsdH9I7ZO4YVrBXiavb43OdiauyElcLrRLQ7u9GdAhXEoPjx4fhPicLw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在 200 多万人的见证下，马斯克的 AI 公司 xAI 正式推出 Grok 3！ 果然，谁能让用户免费用好模型，谁就能起量。 目前，Grok 应用现在已经是美区榜一了。之前的文章中已经和大家介绍过相</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490500&amp;idx=1&amp;sn=5f22f6906758b94668bb934572218eae&amp;chksm=fd7a66827e9f4c9e52f116944324f02c7ec6350322e4ff5513066a90866aa16839738ac1c0bb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 22 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Animate Anyone 2来了！角色动画与环境之间更具互动性，动画真实感和一致性更高。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXWFznUMicvLicvkDmEwFhC2ibGGPzYD6cjmOwxrY9X4Vbv4qexWHZ3R7hibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的角色图像动画方法Animate Anyone，感兴趣的小伙伴可以点击下面链接阅读~阿里Animate Anyone：让任何静态图像动起来，让C罗、梅西、内马尔一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490500&amp;idx=2&amp;sn=f743c90e4bdaf7621f4f04d51a854ccf&amp;chksm=fd9b96d6f3cbfee3eff3c4366daa7a6db46ef0f140a449a9be63265e588bb1c32bbfac2d670b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 22 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌推出PaliGemma 2 mix：用于多任务的视觉语言模型，开箱即用。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZG3A9ureoTeOkRX7vpoweMqWfIXVPrnftNxPZXeKdfJFf3WSY8K2fGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>去年 12 月，谷歌推出了 PaliGemma 2 ，这是Gemma系列中的升级版视觉语言模型。该版本包含不同大小（3B、10B 和 28B 参数）的预训练检查点，可轻松针对各种视觉语言任务和领域进行</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490500&amp;idx=3&amp;sn=fff10e89e53cbc49d98ecd2a158352a0&amp;chksm=fd4af009eb86df9e052a7c7489667ae610f3d67d887014330dc832a9c728adc33b4e13b32f90&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 22 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一起来学吴恩达新课《Transformer中的注意力机制：PyTorch的概念和代码实现》！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekAuUNNvuhqhCqoRTbKeLmgw71mhsu9IWMRXCr0oO4oVk3w2IO8gPj33kicbvU4Z2uBRJFnQJXic8JA/300?wxtype=jpeg&amp;wxfrom=0"/><p>吴恩达新课《Transformer 中的注意力机制：PyTorch 中的概念和代码》来了！主要内容是深入浅出的理解Transformer架构的核心技术——注意力机制。该课程适合于有一定的 Python</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490500&amp;idx=4&amp;sn=0072125a0cbb3a44f9bed050fd3e970a&amp;chksm=fd83374661db4544c0ba398aa6416213141db8c51ff5864fd1fca51bf1992019b5b07fd6eb72&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 22 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一起来学吴恩达新课《Transformer中的注意力机制：PyTorch的概念和代码实现》！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekAuUNNvuhqhCqoRTbKeLmgw71mhsu9IWMRXCr0oO4oVk3w2IO8gPj33kicbvU4Z2uBRJFnQJXic8JA/640?wxtype=jpeg&amp;wxfrom=0"/><p>吴恩达新课《Transformer 中的注意力机制：PyTorch 中的概念和代码》来了！主要内容是深入浅出的理解Transformer架构的核心技术——注意力机制。该课程适合于有一定的 Python</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490475&amp;idx=1&amp;sn=11ec2e773b4d543e32e35584a12e3391&amp;chksm=fdca0eb586bcafe6ebca6157a954bd5af06121ce52e716d48823d1a2907aea0e240fa68cd788&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[首个文字生成手语模型来了！SignLLM通过文字描述来生成手语视频，目前已经支持八国手语！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emjicP7If65XYX4tPQXyr9lHCqPXiapc8ulVDfA37EA56NmoCwMkfhAebQyzWagLJMia7wl1t0O59HLQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>SignLLM 是目前第一个通过文字描述生成手语视频的多语言手语模型。该项目引入了首个多语言手语数据集 Prompt2Sign，它使用工具自动采集和处理网络上的手语视频，能够不断更新，且具有轻量化特点</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490475&amp;idx=2&amp;sn=d6d2e9f7af98df828572569875331053&amp;chksm=fde9616cdcd951b8221809a6e9ad0a7e126a52fac9b81ec2c208ed00e84d9deab832b7cb2c8a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华联合腾讯提出全模态模型Ola！图像、视频和音频等多模态理解一网打尽！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5ILy9I4g9e9dFh1achfYgv3N1UvxyxaO5FN5kwaEYDvzicXohJyGkQPum02iaiaiaoIyUCYuw4f7VG7cQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment论文链接：</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490475&amp;idx=3&amp;sn=1d3082902d2bc61721812a885a587d11&amp;chksm=fdd5cb799e5a09dfe4aab2e7061aba4e8159d5105cbd9c2f635d6243fc1595090f319d992f4c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Github热门机器学习笔记:「从零构建大型语言模型」]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emtHS7t5ic0uQWb1AOhKNDRVQe1ibV5hcbvDj7icpDN1BtRicibpaHbuszyA75wydLlzCvmBKSLia5XJSLQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐一份GitHub上很火的机器学习学习笔记《从零构建大型语言模型》，目前已经收获1.4K stars，，这份笔记完美展示了从零构建LLM的技术路线图，既有理论深度，又包含实践要点。每个核心</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490475&amp;idx=4&amp;sn=76bfc07e0f82953341107f3bd052b03f&amp;chksm=fd7fb984967a8950dff886d00042441bc12ac73523109553716a81804f91e2cab0fd6221fe4a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌推出PaliGemma 2 mix：用于多任务的视觉语言模型，开箱即用。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZG3A9ureoTeOkRX7vpoweMqWfIXVPrnftNxPZXeKdfJFf3WSY8K2fGQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>去年 12 月，谷歌推出了 PaliGemma 2 ，这是Gemma系列中的升级版视觉语言模型。该版本包含不同大小（3B、10B 和 28B 参数）的预训练检查点，可轻松针对各种视觉语言任务和领域进行</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490439&amp;idx=1&amp;sn=e1ed5f5383dbd15a2b1868855ddebb2e&amp;chksm=fda2e81145b6732b62e028318fd1e653fd657372addb59c6b9b8f5915aefe3f7ff73bc2fead5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek们的成本，是怎么计算的？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jEa2NN5eMic76LNKtDbp6JciaVMNpJ0DfXv52YEQqq4xTf9WUrtSejmqicfnUDqnZjib7GrNrJnMw22eSMwgbg8odw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型混战，一边卷能力，一边卷“成本”。定焦One（dingjiaoone）原创作者 | 王璐编辑 | 魏佳DeepSeek彻底让全球都坐不住了。昨天，马斯克携“地球上最聪明的AI”——Gork 3在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490439&amp;idx=2&amp;sn=cfa845064014dd1e045e72acec82074a&amp;chksm=fdb1e75e0d2e6ceb23beb3d9f6b256bfb50b07e94580af413ef5b66e492f14aa141ead46d74a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[马斯克全新发布Grok3模型，坐拥20万张卡的新王！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsH9cZmp9X46ouoOXg3cwrPEkXVwv6oRupo8tbuYLibC6vwAv1LMw1M0JbUwyTMWlNibd2Obo6xhujiag/300?wxtype=jpeg&amp;wxfrom=0"/><p> Datawhale分享 最新发布：xAI，Grok 3刚刚，马斯克所说的“地表最强的 AI”终于来了。在 200 多万人的见证下，马斯克的 AI 公司 xAI 正式推出 Grok 3！“我们非常高兴</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490439&amp;idx=3&amp;sn=ba8e5136a610b5c1a8e8c705efa41a0b&amp;chksm=fd14e9ce05b7e0e09b18f35c67a9face2e3fa242e6048a61c293fb8579d35add9383f93930a9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[4w Star！一个低成本微调DeepSeek的开源方案，悄悄火了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em1HmyUKxNSkwicvdQ8NMBGYFcBaleAYz933cxSgezict1pspKaC1IcNtgBUtibWM48Zg6sczMR1bjlg/640?wxtype=jpeg&amp;wxfrom=0"/><p>文章来源：夕小瑶科技说 DeepSeek V3/ R1火爆全网，基于原始模型的解决方案和API服务已随处可见，陷入低价和免费内卷。如何站在巨人肩膀上，通过后训练（post-training）结合专业领</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=1&amp;sn=fa18deca3b2bcf128a387a31c301f781&amp;chksm=fd6ba6ac454e2dcf430747a6086c3bfe97b08d2e9d865e112e45e2d4bfa3165de0583adbcfeb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文搞懂DeepSeek的技术演进之路：大语言模型、视觉语言理解、多模态统一模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic6bZ8AZw730k5S06S2AKhSycdsVgq61HibHXoXHUxwbibkSa74Uib0srhbxdiaibHxADIxvDeRt0SNaoAw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文撰写路径比较清晰，意在初步梳理DeepSeek技术的演进及进化之路，主要包括三大方向：大语言模型、视觉语言理解模型、多模态统一模型！大语言模型系列论文：DeepSeek-LLM -> DeepSe</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=2&amp;sn=a24a6403f726263ce60a8f93588ba90e&amp;chksm=fd1b6428801aef67712a9607f6e748b0b12c894f77d95d649961afc416c53e937e257d82086a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[StepFun提出Step-Video-T2V！300亿参数视频生成大模型！可生成204帧视频！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcJicm2I75ZP1rkl1ZMqicoKfreYnRFLqFBbibqBpPJl9LzNL6OUXy1tmllZuicN8KGIYIbPRjfSZnnOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model论</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=3&amp;sn=c6f8a757ae9834ad9ad2df1d9a837a19&amp;chksm=fd9a0ac665a3826364f86b7a1a397f8103243bc2551b4cc0f96ce1c239d208e220ec1da784f3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekB7CXUYR45xqh1P2Q9zWuxgmicJiaO6JPkkhoaibkSARt6qftWXI9ofZjt9NK9vuibg0UrfhA2kTPRaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT今天介绍的文章来自公众号粉丝投稿，腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT，给定一个人像图像和一个衣物图像，就可以生成一个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=4&amp;sn=8aee6a1069da7fa31e1524099e7692d9&amp;chksm=fdfb049a20f36a4aae141e866751086f84cec821866f37a227a0037c0625275577a6a687e251&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
