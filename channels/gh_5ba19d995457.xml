<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[Google DeepMind 发布最强视频生成工具 Veo 3, 可为作品添加音效、环境噪音、对话，文中附体验链接。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcnWs2mR9uePicbSxmgsNGYEOvC44lWnQUfBAMbv2Kgy7vDib4ee4tlF1R091cfagJqdQWc10PdkUA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天跟大家介绍谷歌的视频生成模型 Veo 3，可为作品添加音效、环境噪音甚至对话，所有音频均可原生生成。它还能提供一流的音质，在物理效果、真实感和快速响应方面均表现卓越。相比 Veo2 的改变Veo </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493036&amp;idx=1&amp;sn=57cb7b8bc73e9758a0ef273f5dc83dd7&amp;chksm=fddc0ee3ddac788bf7b869da6f3b29728f49442c76d64f2e67f142e3447b82b25bee8abe04f1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多领域SOTA诞生！Vid2World：打通视频扩散到世界模型的“任督二脉”｜清华、重大]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaeFVcHGjGc24PwYRxSa3SRzxraaxquD1Y4eiapCrHo7GN2pjc3L4XfolskYUicsqxRONc0Q9o3iaR8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文链接：https://arxiv.org/pdf/2505.14357 项目链接：https://knightnemo.github.io/vid2world/ 生成效果速览亮点直击首个系统性探索</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493036&amp;idx=2&amp;sn=287c97d19d8a083465ef5f5c482b6f77&amp;chksm=fd0ca0368b4022a12552fc5bd125ff1a3b7dfa58a6299f344dde7e9b0f1b3c87b7fe0414e2d1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[7k星星爆火！用微信聊天记录训练一个自己的数字分身回信息，还能克隆声音回复语音消息。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NarO1FqtJTNnAkBYibHt0foxa0Fe75VZQRCPicXrJ4JdcyBcfXfytFdyEnQK4gfA5aQ6UicqjUDAHFrA/300?wxtype=jpeg&amp;wxfrom=0"/><p>早就想拥有一个AI来帮我回消息，最好是能跟我说话风格极其相似的。今天发现一个好玩的开源项目，能根据微信的聊天记录，给自己做一个“数字分身”。而且，它不只是能回消息，还能学习你的音色回复语音消息。这难道</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493036&amp;idx=3&amp;sn=dd38245bd72befb0254b2eb5a240ad3f&amp;chksm=fdeebed71f41c4fed5fa734fa797ac9859db111975f3c0d1f71fac28909a2df9cb541a57f45e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布视频基础大模型Seaweed，70亿参数超越同类140亿参数视频模型效果，单GPU就可生成1080P！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrSjMIibqt135GUNpF74oSRXfm9iakLUsJ4cuaJkMv3pwe9GUibyujB4o5rb4L0I9e4f2iacOibCyryMg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Seaweed 是“Seed-Video”的缩写，是一项旨在构建视频生成基础模型的研究成果。该网页展示了拥有约 70 亿 (7B) 个参数的扩散变换器 (Diffusion Transformer)，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493036&amp;idx=4&amp;sn=0c835a82f6987e42d252fa2508a995ec&amp;chksm=fd07035ce65c05033233109b7f0697a3dc88f672dea40200cad78f73d4dee62870126e66b0ac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 单目人头重建最新SOTA方法！清华与IDEA发布HRAvatar：高质量可重光照头像化身。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcnWs2mR9uePicbSxmgsNGYiaIpAYOKGXsNFuVukEA1d7LtHtMTZOchC13qPYAk2xR4icpicKxYmnicbQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍创建3D头像化身对于电影、游戏、沉浸式会议、AR/VR等领域至关重要。在这些应用中，头像化身必须满足几个要求：可动画化、实时、高质量和视觉上逼真。然而，从易获取的单目视频中创建高度逼真且可动画化的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493035&amp;idx=1&amp;sn=ff7ae51aa4c603db8d0b53e7224bf718&amp;chksm=fd7938f6f473f1e9f8b1b2174938dac6b76ebbf4b540b6d3c5fe0572d41c05c1b060bec4551e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谢赛宁团队提出BLIP3-o：融合自回归与扩散模型的统一多模态架构，开创CLIP特征驱动的图像理解与生成新范式!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek5oLyjfCjICEWyMhWNvFXDN37WVtXa4JeBibibTSdNGmBP0wSFhuUAJkiaz9qNwiccNW4SuNJ7FvduuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>BLIP3-o 是一个统一的多模态模型，它将自回归模型的推理和指令遵循优势与扩散模型的生成能力相结合。与之前扩散 VAE 特征或原始像素的研究不同，BLIP3-o 扩散了语义丰富的CLIP 图像特征，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493035&amp;idx=2&amp;sn=11168beeef80eae57c12473178439355&amp;chksm=fd948dbb03d7e6b315b9604ff14fb1b1d7696f850f18f374b03a8c9eda63512dda18d13487c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图生3D新SOTA！港中文&amp;字节&amp;清华联合提出Hi3DGen:通过法线桥接从图像生成高保真 3D 几何图形。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elT6Ok13J4tBFt6yibibVpmCofpeSCJb5Do6ZzCr2Yv2wPial5QS5sdppZe8K6ubyDPzv4yf6QNaOicHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学联合字节跳动和清华大学提出Hi3DGen，这是一个通过法线桥接从图像生成高保真三维几何体的全新框架。Hi3DGen 由图像到法线估计器、法线到几何学习方法以及三维数据合成流程三个关键组件组</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493035&amp;idx=3&amp;sn=c6ffc6dacc38ae2ec524aae87da3b0e9&amp;chksm=fdccd14be70f7eba72d608d889b522f9aae0203735ca318fea6cdcffa6979a6d5b725c1292d2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493034&amp;idx=1&amp;sn=9f5924afb753e1095889765b225b0b18&amp;chksm=fd19b0b060dd3755756fbaed7c0b7a77052e1afb720d26c1a7431eb66618698a632c3ecc44b7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 28 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[音视频同步生成的终极突破！浙江大学提出JavisDiT！HiST-Sypo技术实现帧级对齐！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IllwjzyahfYe3lVzotU3V1MZ9EYSziaPYoRvako9SY8kibHfdibhUKeiaP1lK2fWiafUwY7AOZZqvfibLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：JavisDiT: Joint Audio-Video Diffusion Transformer with Hierarchical Spatio-Temporal Prior Synchr</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493034&amp;idx=2&amp;sn=dd7bf26e489a129405f608099b6543fa&amp;chksm=fd1f2aca7f1cd02f6502e30201ba29c1c19b63490c051ec9d76f8615c2d666957c6aa5a64793&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 28 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港大&amp;Adobe联合提出图像生成模型PixelFlow，可直接在原始像素空间中运行，无需VAE即可进行端到端训练。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em57kq23EbSGQ52kUcSia6n8oTIJOicficBicZpibaJQgm7tEpQJ6psVkrLse6pjDUwqiaktvnGSEiaL6xPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港大学和Adobe联合提出了一种直接在原始像素空间中运行的图像生成模型PixelFlow，这种方法简化了图像生成过程，无需预先训练的变分自编码器 (VAE)，并使整个模型能够端到端训练。通过高效的级</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493034&amp;idx=3&amp;sn=b5146708b1a48b6b460e759e1bd6c823&amp;chksm=fdca895f7ade8cda1b6efd6628e97b9f145efca6dae57414fc821ecfacdd39179e227dfb17d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 28 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源数字人克隆神器HeyGem：1秒视频生成4K超高清AI形象，用AI重塑数字人创作生态！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRrgxstWFTNfP8vOAkR5RI8GOy83ObgNDrZJL0p3TTnAIBViacS7PlySow/640?wxtype=jpeg&amp;wxfrom=0"/><p>在虚拟形象与数字内容需求激增的当下，传统3D数字人制作的高昂成本（动辄数十万美元）与复杂流程，让许多行业望而却步。而今天，一款由Duix.com团队打造的开源AI项目HeyGem，正以颠覆性技术打破这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493033&amp;idx=1&amp;sn=9226c2e340cbca59548eeff87a8f23eb&amp;chksm=fd465a092a1383186ffc5d22b6a0afe78c54af3da6a888493cec8361036eb85a0f979c380761&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 27 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[利用多模态模型赋能，SONY团队完成音乐到音乐视频描述生成大突破！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Jn7gNOibialUb7ePwaNgQPKeSIN3Kfa1hwX15JM3vgCh8jl1Fm3ZyyqibhJ0YwwiaTxARyLn4ucxtkUw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Cross-Modal Learning for Music-to-Music-Video Description Generation论文链接：https://arxiv.o</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493033&amp;idx=2&amp;sn=c8e23e47fa7deb61053b222619a23510&amp;chksm=fdddfb5fccdb16ac37b7c290f74625402e8fb48fc773a71f7c8fa5b19b49270ef7b8d5773d88&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 27 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[太强了！浙大联合上海AI Lab提出视觉统一Diffusion架构DICEPTION！各种视觉任务一网打尽！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcb6XeOfGM7ic3jww1VGas5hyQ5UbdLhbhjcqHwrckdlwdXIvppjK9PlGZVkxMpOMiaT6tDJ32KOqiaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>数源AI 最新论文解读系列论文名：DICEPTION: A Generalist Diffusion Model for Visual Perceptual Tasks论文链接：https://arx</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493033&amp;idx=3&amp;sn=ee5fb1ef949c7833cd1d17bd1ca23821&amp;chksm=fdc51797ee2ef42656eabe900a70b6c3ef3038a6600223516ea2d9baf712ebffd34135903fc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 27 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[炸裂！ComfyUI 原生支持 HiDream-I1，全新文本转图神器来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2ibyrQzlh4BO0Xa83u0NI5WzuIBs5KCqMafPkjLwMiapJ0TVwXCaj6ibIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyUI 原生支持 HiDream-I1，全新文本转图神器来了！大家好，这不是演习！ComfyUI 终于官宣——原生支持 HiDream-I1 模型啦！对于熟悉图像生成的小伙伴来说，这可是一件值</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493033&amp;idx=4&amp;sn=0a8652929beb0fc72eb6a50a20328cac&amp;chksm=fdc952285125628019fec4114bef0cc112aeacd5d2f3da79e1afcd5d6bca2dd88a6c54f573d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 27 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节推出统一多模态模型 BAGEL，GPT-4o 级的图像生成能力直接开源了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRre72SQ3NTx8amQXBMt77z295uWjzKl5kweQFLEMa31vXicZ35AvS4Lfw/640?wxtype=jpeg&amp;wxfrom=0"/><p>字节推出的 BAGEL 是一个开源的统一多模态模型，他们直接开源了GPT-4o级别的图像生成能力。（轻松拿捏“万物皆可吉卜力”玩法~）。可以在任何地方对其进行微调、提炼和部署，它以开放的形式提供与 G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493007&amp;idx=1&amp;sn=2450124ac892965707e662a3dc99bc9c&amp;chksm=fd7dc800f40b88b86aacdf8601e0ca9c3f439daaa452f60ea93ada0fffeebebee7c885927c98&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 26 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑革命，万物皆可插入！浙大/哈佛/南洋理工提出Insert Anything，告别PS抠图，AI让世界无缝生长。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7Ficnb2ehPShfDudYtibS1fkY0Su3IFmdP3MkS9KDH1gsquQnXh8Ku6TPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学、哈佛大学、南洋理工大学联合提出了统一的图像插入框架Insert Anything，支持多种实际场景，包括艺术创作、逼真的脸部交换、电影场景构图、虚拟服装试穿、配饰定制和数字道具更换，下图展示</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493007&amp;idx=2&amp;sn=a993359dfcd1ddbe8fb2d41a16338b03&amp;chksm=fddb59fee978f4956ebe2d33aedb21e6b9844ecb3a8f0d51768ea60d29d709637e0d620b9992&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 26 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[6秒音频即可克隆AI语音！FLOAT数字人生成语音/口型/表情，情感同步超惊艳，文中附工作流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJcmBGicWjwiauMpFknBOofINibzHjBSIibjwDHKYvhnzulS1E2KIPicobCywA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的 FLOAT 是一种基于流匹配的音频驱动的说话肖像视频生成方法，可以增强语音驱动的情感运动。该方法唇形同步质量高，生成速度还很快。6秒音频完美生成语音/口型/表情。情绪转移由于 FLO</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493007&amp;idx=3&amp;sn=d2d8f0a69bd8915725228c6d49ceed96&amp;chksm=fd52c14d6ed8d1a95ec30520f43231c925fa8d2faf080b5bc3c5b92d662f12dad398ac18a8e8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 26 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦&amp;腾讯优图提出基于扩散的情感说话头像生成方法DICE-Talk，可为说话的肖像生成生动多样的情感。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekBUypVTojw9NicChAveibQcTccRrbh6qA2W0fWIHSYHibiaqHEFxVLBnicZtkEricIgpsqDf5wqctkvqRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>复旦大学和腾讯优图联合提出DICE-Talk，这是一个用于生成具有生动、身份保留的情感表达的谈话头部视频的新框架。可以为会说话的肖像创作出生动多样的情感表达。相关链接论文：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493007&amp;idx=4&amp;sn=3c06934c2b776520241c62a87bb0dc89&amp;chksm=fd1f7254e73a0c323fdb694250b84023bd68bf21e1735681fe97dc797df6b7ed20cccb88544a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 26 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AIGC Studio 联合机械工业出版社给读者免费送新书啦，开启 AIGC 智能教学新时代！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRrRLGsBHPcPFYjEQGy2R1696AH45yrdicaI7TibaZZoxAiauDh2ic1IMLl1w/640?wxtype=jpeg&amp;wxfrom=0"/><p>亲爱的读者们，我们正身处人工智能（AI）技术飞速发展的浪潮中，AI正以前所未有的速度重塑教育领域。你是否渴望了解AI如何赋能教学，提升学习效率？是否想掌握最新的AI教育工具，成为未来教育的引领者？现在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493006&amp;idx=1&amp;sn=ef99a6d477ab0bfb69aaa25eed245895&amp;chksm=fd6ff6adb9bc8e77c3664fa305ee40e9abcb379a943670e2ab16dfe33ed3c136e6427333ac34&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 25 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[视觉生成领域新突破！无需引入任何外部表征组件：SRA助力Diffusion Transformer实现自我表征指导。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcnWs2mR9uePicbSxmgsNGY5eoKECJw2VJZHk986ZktQp6KeSnEV1SrSa2JVMKibe6QbJ5dpasib3Kw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章来自公众号粉丝投稿，对于Diffusion transformer在视觉生成领域获取高质量表征不容易的问题，文章提出了一种SRA(Self-Representation Alignment)方</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492810&amp;idx=1&amp;sn=f9e0c5c2aad85a2d7583a90415a29409&amp;chksm=fd0ef80dadbe86088af659924fa73e14ef4cd85a9a05517fdcb28cdaacaac9000390d1697871&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 24 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Apple提出UniGen！多模态理解生成统一xii新架构！CoT - V提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KqpbKjwyf8GDnoGZ1ANRZVHSofem5JIanFIxSibozXUibNxHviaUIPE6FTh1nw9lCf16QMqWDaqf7cg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniGen: Enhanced Training&amp;Test-Time Strategies for Unified Multimodal Understanding and </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492810&amp;idx=2&amp;sn=78a042467cb774887c54251d98689a96&amp;chksm=fd946423c2521902cc57950d1287e8d034ef55b11a3e2f1e0f9d8b7eeee9b548cbf4f4a32cc3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 24 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI视频生成新突破！字节提出一致性视频生成方法Phantom：通过跨模态对齐生成主题一致的视频，超多应用场景。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7FjUDMtLDDzOxeRDTsjoBO7nWymp4ibfUg4ngicJhNSbFdrgXOp81mHMKg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Phantom 是一个统一的视频生成框架，适用于单主题和多主题参考，基于现有的文本转视频和图像转视频架构构建。它通过重新设计联合文本-图像注入模型，利用文本-图像-视频三元组数据实现跨模态对齐。此外，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492810&amp;idx=3&amp;sn=8631834744a0367b70cbbaa3318d8d31&amp;chksm=fdc8db091d82c60cec2d7eea45943088786edb2aae642d9bd11d9212aec08b217189201e53f0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 24 May 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>