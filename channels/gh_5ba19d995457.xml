<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[ICLR 2025 | 解锁虚拟试衣新姿势！智象未来提出SPM-Diff，大幅提升真实性、可控性，让衣服“贴身”又自然！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrh9ic75wTHs9dqezVrp8tteQeOdKicBiciaVprFFxw2NDD0xvwlGbvdtfzxm3Z3f8AmbzvLDk7lMYeg/640?wxtype=jpeg&amp;wxfrom=0"/><p>网购衣服总担心“买家秀”和“卖家秀”天差地别？虚拟试衣不自然、细节难还原的问题一直困扰着消费者。智象未来团队提出SPM-Diff算法，成功攻克虚拟试衣两大难题，论文《Incorporating vis</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493078&amp;idx=1&amp;sn=d1e2a4ddcd0c6b2036760388a33f154a&amp;chksm=fd50f3d2938e33cc70752423720b16946756d33fb95c3e3a9061cc49d6c87e7539962663eb74&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 16:44:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图生3D新SOTA！港中文&amp;字节&amp;清华联合提出Hi3DGen:通过法线桥接从图像生成高保真 3D 几何图形。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elT6Ok13J4tBFt6yibibVpmCofpeSCJb5Do6ZzCr2Yv2wPial5QS5sdppZe8K6ubyDPzv4yf6QNaOicHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学联合字节跳动和清华大学提出Hi3DGen，这是一个通过法线桥接从图像生成高保真三维几何体的全新框架。Hi3DGen 由图像到法线估计器、法线到几何学习方法以及三维数据合成流程三个关键组件组</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493078&amp;idx=2&amp;sn=886c9fbb9fa656d769f434570342f595&amp;chksm=fd02c648800d96235e50487969f27fb8d0305ab1976b259cc1bb55a0eefadf3f4b1a981d376c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 16:44:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源换脸写真模型InfiniteYou，可实现零样本身份ID一致保持，无缝集成FLUX、ControlNets、LoRAs！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFB9QEic6a0icic21hdjU7tWMfgnZWZ32D1adHqJcD4Z8fvzhEvH6KNghsZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个字节刚开源的换脸写真新模型InfiniteYou，这是一种先进的零样本身份ID一致性保持模型，由字节跳动基于文生图领域最强开源模型FLUX模型研发的。InfiniteYou专注于利用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493078&amp;idx=3&amp;sn=693e2c223beef8e7c97e61fa077653ae&amp;chksm=fd584cffe95e22ca4b6dfc0db42d32997193bddd18d734b4ac9c8922ce678d33c3fb2047362a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 16:44:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 机器人双臂操控新突破！KStar Diffuser如何解决自碰撞与运动约束世纪难题？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojvz9clmicqUEHWru0TSQwicibDxwd6pXeiac1QbZwUoibnWeMnE5ib2jBibpdEXVK5T4bFCwMWWK9BcS4dg/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2503.10743亮点直击与现有方法仅在笛卡尔空间中优化末端执行器姿态不同，提出了一种新颖的时空机器人图，显式地建模机器人物理配置，以指导生成动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493078&amp;idx=4&amp;sn=86046125e032420f90b9c32ddec2691d&amp;chksm=fd1e90ed12f42d11e23897b34c2d8c5517abd5f0c5a54fbb47c8a99b912ef6d0598fb733da0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 16:44:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像定制大一统？字节提出DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等任务，有效解决多泛化性冲突。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1Zrf8JKiaMovMsw9t4ZW4pibcVZlWM8AF7GsajlXAPWl5IJgnfQRpnvoA/640?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出了一个统一的图像定制框架DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等多项任务，不仅在广泛的图像定制场景中取得了高质量的结果，而且在适应多条件场景方面也表现出很强的灵活性。现在已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493040&amp;idx=1&amp;sn=408b9d6c8ab2246c5566771acbdc9b52&amp;chksm=fde077af982773950d58317b50384f58162e9659e4226a3106d34e31034fafbd18720e695cb2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 22:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[[ComfyUI]阿里WanX2.1：最强开源视频模型易主！静待社区生态开源直逼闭源，Vbench榜首第一]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGR4iczdl1w1JCwWwhHibiaD9umzM0GtLxG8EhR3dUBt02neC4QvYYvoFicjM1FhMAten8AeAnfhcCtHYA/300?wxtype=jpeg&amp;wxfrom=0"/><p> 阿里WanX2.1：文生和图生视频模型ComfyUI体验WanX 2.1简介在昨天的文章（阿里Wan2.1：最强开源视频，本地部署优先体验！Vbench榜首第一，超越Sora&amp;混元&amp;Gen3&amp;Pik</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493040&amp;idx=2&amp;sn=3e6c6208ee386883cc3ed29d93c569ff&amp;chksm=fd0944dd986d69d017e2f1dbb567d7471c8d717ed7b9e1faf8f94baa809e23bea347fe316db1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 22:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[StepFun提出Step-Video-T2V！300亿参数视频生成大模型！可生成204帧视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcJicm2I75ZP1rkl1ZMqicoKfreYnRFLqFBbibqBpPJl9LzNL6OUXy1tmllZuicN8KGIYIbPRjfSZnnOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model论</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493040&amp;idx=3&amp;sn=b0f39a563ae7e17b91d7a394d0dfffc9&amp;chksm=fdeb65a37cb2deac484b915babdd7111555c28a29a1100390fcc1f3ab26271507b1a36b65fcc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 22:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[英伟达开源4K图像生成模型Sana，可在16G显存电脑部署，支持ComfyUI和LoRA训练。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6Zafxy9AicSRodyIcwlSHNT9mr6NOzfTpJPhveE41Xmh1RVMhhibAgXAt3qSb6eFx0HfpEYX74THA/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达开源了一个可以直接生成 4K 图片的模型 Sana。 Sana-0.6B 可以在 16GB 的笔记本电脑 GPU 上部署。生成 1024 × 1024 分辨率的图像只需不到 1 秒钟。官方已经支</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493040&amp;idx=4&amp;sn=a5e0f809d5486b41db803833bd720017&amp;chksm=fda56049095d6bf06c967a684a43330d8637ffd0793ae1923e94c57b4ac190a18b953724b918&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 22:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[中科院提出图像定制方法MCA-Ctrl，无需调优的即可使用文本和复杂的视觉条件实现高质量的图像定制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1KFwReqeCxk2s3eVTGWZJ0ibicT6EGpGzrsJ4W6jtTm4fLh17icB9CJNyg/640?wxtype=jpeg&amp;wxfrom=0"/><p>中国科学院计算技术研究所研究团队提出了多方协作注意力控制方法( MCA - Ctrl )，这是一种无需调优的方法，能够使用文本和复杂的视觉条件实现高质量的图像定制。MCA-Ctrl 可用于文本驱动的主</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493039&amp;idx=1&amp;sn=1a0d8cd77139520d977de081b64e1d05&amp;chksm=fd7a0e8743f44c5ddb35650a19036a31ddea66dafc80ed76aa3e4d751c9ae9351fe224ea0d14&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 01 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[加利福尼亚大学提出TULIP！视觉-语言模型的新王者！AI性能全面碾压CLIP！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KsLicuyg3oA0dGOnwBictNTE782KtlqwlaVEmKrVyKAO0YzauujiaGWFqaYjHzZqKD5rLk8dQLKZtEg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：TULIP: Towards Unified Language-Image Pretraining论文链接：https://arxiv.org/pdf/2503.15485开源</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493039&amp;idx=2&amp;sn=58b3cfdb679889822a8f836395a540bb&amp;chksm=fdd2ade7ef0cc50907d5ef09aee348525f9f91c08e598e934e1cec10e5e8acfda57e1cbb024c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 01 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493039&amp;idx=3&amp;sn=bcb97491e538dc22a7109f16d002a44a&amp;chksm=fd3dc7d4ba091933aa419141d11377612766233605f58b52cc32c35ea4db163bd8cf7fab404f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 01 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LBM：用于图像到图像直接快速转换，支持可控照明、图像恢复、物体移除等功能！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eniaAibjBDYoftj8VvjntaLlazzrjyAuCaxtUgTmwTpbpXdlUbj1mP1pmA9QicicVlSzvQAT83J2fYzAA/300?wxtype=jpeg&amp;wxfrom=0"/><p>LBM是一种新型、多功能且可扩展的方法，它依赖于潜在空间中的桥匹配来实现快速的图像到图像转换。该方法仅使用一个推理步骤即可在各种图像到图像任务中达到最佳效果。除了效率之外，该方法在不同图像转换任务（例</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493039&amp;idx=4&amp;sn=4fbfb2da3225560352f22b382def7675&amp;chksm=fdc660b3a5d3d07d62cff7de7f39272b7d70164aed203f2ebe5caa841509a21376310098d1f4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 01 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 香港中文大学 MMLab 提出文生图模型 T2I - R1，文生图进入 R1 时刻！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1XALE57UTLoPLT6xjsxJW5tiaoo8VJdc0HMQQUAGdaNID9L9wkBMspWA/640?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学 MMLab 提出了一种基于双层次 CoT 推理框架与强化学习的新型文本生成图像模型 T2I-R1，该模型结合了语义级和 token 级的链式思维（CoT）推理过程，并通过强化学习进行增强</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493037&amp;idx=1&amp;sn=77d5a5fccce640268929f28476e514fa&amp;chksm=fda822bf2f998f806ab42fb3aaf17ccf4bd4ed916111984436497aac16d0fabe86fe656d9d15&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 31 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 机器人双臂操控新突破！KStar Diffuser如何解决自碰撞与运动约束世纪难题？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojvz9clmicqUEHWru0TSQwicibDxwd6pXeiac1QbZwUoibnWeMnE5ib2jBibpdEXVK5T4bFCwMWWK9BcS4dg/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2503.10743亮点直击与现有方法仅在笛卡尔空间中优化末端执行器姿态不同，提出了一种新颖的时空机器人图，显式地建模机器人物理配置，以指导生成动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493037&amp;idx=2&amp;sn=7ac23118081bbd001d3f15c359875fb3&amp;chksm=fde1b50caa97ed597f0625b57db85ddf63e05006af60553a794a0d8a271a7d203ec7e9ff842e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 31 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 多实例扩散模型MIDI：可从单个图像创建高保真 3D 场景，模型&amp;代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emQH9S7pGDiaODq1bPiaoKg0UwQg0Pd1kyLMVicNPaNIDRbCcjvvBMqMbicEWI8LS5IVX4LjXG1tHR3Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>MIDI 是一种 3D 生成模型，用于从单幅图像生成合成 3D 场景。与依赖重建或检索技术的现有方法或采用多阶段逐个对象生成的最新方法不同，MIDI 将预训练的图像到 3D 对象生成模型扩展为多实例扩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493037&amp;idx=3&amp;sn=20eef87bf4c8acb10d1969295086746c&amp;chksm=fda1aa9c91f6b19fe8663c9be7ff3e43e59989d0a73605b427e283c4a9f823b998a3e9e07683&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 31 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 清华提出一键式视频扩散模型VideoScene，从视频到 3D 的桥梁，一步到位！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en6YOGtn3XXJMye1oxLXOtQDu8lVia8rZmBpsouclpUQ8eY6ebkIhqsCQhQiabYLqW83mluezLMicI1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华大学的研究团队首次提出了一种一步式视频扩散技术 VideoScene，专注于 3D 场景视频生成。它利用了 3D-aware leap flow distillation 策略，通过跳跃式跨越冗余</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493037&amp;idx=4&amp;sn=f8cdf8355337687f3ca4ddf652c6e51c&amp;chksm=fd8bebafe7b71575f61568d5ef0e38d7b4e675c0d69bbeea8c9442bfbf76b47f8814b838d6d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 31 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Google DeepMind 发布最强视频生成工具 Veo 3, 可为作品添加音效、环境噪音、对话，文中附体验链接。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcnWs2mR9uePicbSxmgsNGYEOvC44lWnQUfBAMbv2Kgy7vDib4ee4tlF1R091cfagJqdQWc10PdkUA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天跟大家介绍谷歌的视频生成模型 Veo 3，可为作品添加音效、环境噪音甚至对话，所有音频均可原生生成。它还能提供一流的音质，在物理效果、真实感和快速响应方面均表现卓越。相比 Veo2 的改变Veo </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493036&amp;idx=1&amp;sn=57cb7b8bc73e9758a0ef273f5dc83dd7&amp;chksm=fddc0ee3ddac788bf7b869da6f3b29728f49442c76d64f2e67f142e3447b82b25bee8abe04f1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多领域SOTA诞生！Vid2World：打通视频扩散到世界模型的“任督二脉”｜清华、重大]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaeFVcHGjGc24PwYRxSa3SRzxraaxquD1Y4eiapCrHo7GN2pjc3L4XfolskYUicsqxRONc0Q9o3iaR8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文链接：https://arxiv.org/pdf/2505.14357 项目链接：https://knightnemo.github.io/vid2world/ 生成效果速览亮点直击首个系统性探索</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493036&amp;idx=2&amp;sn=287c97d19d8a083465ef5f5c482b6f77&amp;chksm=fd0ca0368b4022a12552fc5bd125ff1a3b7dfa58a6299f344dde7e9b0f1b3c87b7fe0414e2d1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[7k星星爆火！用微信聊天记录训练一个自己的数字分身回信息，还能克隆声音回复语音消息。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NarO1FqtJTNnAkBYibHt0foxa0Fe75VZQRCPicXrJ4JdcyBcfXfytFdyEnQK4gfA5aQ6UicqjUDAHFrA/300?wxtype=jpeg&amp;wxfrom=0"/><p>早就想拥有一个AI来帮我回消息，最好是能跟我说话风格极其相似的。今天发现一个好玩的开源项目，能根据微信的聊天记录，给自己做一个“数字分身”。而且，它不只是能回消息，还能学习你的音色回复语音消息。这难道</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493036&amp;idx=3&amp;sn=dd38245bd72befb0254b2eb5a240ad3f&amp;chksm=fdeebed71f41c4fed5fa734fa797ac9859db111975f3c0d1f71fac28909a2df9cb541a57f45e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布视频基础大模型Seaweed，70亿参数超越同类140亿参数视频模型效果，单GPU就可生成1080P！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrSjMIibqt135GUNpF74oSRXfm9iakLUsJ4cuaJkMv3pwe9GUibyujB4o5rb4L0I9e4f2iacOibCyryMg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Seaweed 是“Seed-Video”的缩写，是一项旨在构建视频生成基础模型的研究成果。该网页展示了拥有约 70 亿 (7B) 个参数的扩散变换器 (Diffusion Transformer)，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493036&amp;idx=4&amp;sn=0c835a82f6987e42d252fa2508a995ec&amp;chksm=fd07035ce65c05033233109b7f0697a3dc88f672dea40200cad78f73d4dee62870126e66b0ac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 30 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 单目人头重建最新SOTA方法！清华与IDEA发布HRAvatar：高质量可重光照头像化身。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcnWs2mR9uePicbSxmgsNGYiaIpAYOKGXsNFuVukEA1d7LtHtMTZOchC13qPYAk2xR4icpicKxYmnicbQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>介绍创建3D头像化身对于电影、游戏、沉浸式会议、AR/VR等领域至关重要。在这些应用中，头像化身必须满足几个要求：可动画化、实时、高质量和视觉上逼真。然而，从易获取的单目视频中创建高度逼真且可动画化的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493035&amp;idx=1&amp;sn=ff7ae51aa4c603db8d0b53e7224bf718&amp;chksm=fd7938f6f473f1e9f8b1b2174938dac6b76ebbf4b540b6d3c5fe0572d41c05c1b060bec4551e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谢赛宁团队提出BLIP3-o：融合自回归与扩散模型的统一多模态架构，开创CLIP特征驱动的图像理解与生成新范式!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek5oLyjfCjICEWyMhWNvFXDN37WVtXa4JeBibibTSdNGmBP0wSFhuUAJkiaz9qNwiccNW4SuNJ7FvduuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>BLIP3-o 是一个统一的多模态模型，它将自回归模型的推理和指令遵循优势与扩散模型的生成能力相结合。与之前扩散 VAE 特征或原始像素的研究不同，BLIP3-o 扩散了语义丰富的CLIP 图像特征，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493035&amp;idx=2&amp;sn=11168beeef80eae57c12473178439355&amp;chksm=fd948dbb03d7e6b315b9604ff14fb1b1d7696f850f18f374b03a8c9eda63512dda18d13487c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图生3D新SOTA！港中文&amp;字节&amp;清华联合提出Hi3DGen:通过法线桥接从图像生成高保真 3D 几何图形。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elT6Ok13J4tBFt6yibibVpmCofpeSCJb5Do6ZzCr2Yv2wPial5QS5sdppZe8K6ubyDPzv4yf6QNaOicHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学联合字节跳动和清华大学提出Hi3DGen，这是一个通过法线桥接从图像生成高保真三维几何体的全新框架。Hi3DGen 由图像到法线估计器、法线到几何学习方法以及三维数据合成流程三个关键组件组</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493035&amp;idx=3&amp;sn=c6ffc6dacc38ae2ec524aae87da3b0e9&amp;chksm=fdccd14be70f7eba72d608d889b522f9aae0203735ca318fea6cdcffa6979a6d5b725c1292d2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 29 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493034&amp;idx=1&amp;sn=9f5924afb753e1095889765b225b0b18&amp;chksm=fd19b0b060dd3755756fbaed7c0b7a77052e1afb720d26c1a7431eb66618698a632c3ecc44b7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 28 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[音视频同步生成的终极突破！浙江大学提出JavisDiT！HiST-Sypo技术实现帧级对齐！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IllwjzyahfYe3lVzotU3V1MZ9EYSziaPYoRvako9SY8kibHfdibhUKeiaP1lK2fWiafUwY7AOZZqvfibLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：JavisDiT: Joint Audio-Video Diffusion Transformer with Hierarchical Spatio-Temporal Prior Synchr</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493034&amp;idx=2&amp;sn=dd7bf26e489a129405f608099b6543fa&amp;chksm=fd1f2aca7f1cd02f6502e30201ba29c1c19b63490c051ec9d76f8615c2d666957c6aa5a64793&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 28 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港大&amp;Adobe联合提出图像生成模型PixelFlow，可直接在原始像素空间中运行，无需VAE即可进行端到端训练。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em57kq23EbSGQ52kUcSia6n8oTIJOicficBicZpibaJQgm7tEpQJ6psVkrLse6pjDUwqiaktvnGSEiaL6xPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港大学和Adobe联合提出了一种直接在原始像素空间中运行的图像生成模型PixelFlow，这种方法简化了图像生成过程，无需预先训练的变分自编码器 (VAE)，并使整个模型能够端到端训练。通过高效的级</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493034&amp;idx=3&amp;sn=b5146708b1a48b6b460e759e1bd6c823&amp;chksm=fdca895f7ade8cda1b6efd6628e97b9f145efca6dae57414fc821ecfacdd39179e227dfb17d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 28 May 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>