<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[OpenManus：5个人三小时复刻开源版Manus，不需邀请码, GitHub已获 8k+ star！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emMD5hHjQCsGyZibkezY8B2QF5NBwYrUdvsNHsYIucmvguy5CPoDhibY2oQo4DGuhVvjgddCicOTwXcg/640?wxtype=jpeg&amp;wxfrom=0"/><p>当全网还在求 Manus 邀请码的时候，结果有一个小团队用了 3 小时就做出了 Manus 的开源实现OpenManus ，而且不需要邀请码。OpenManus团队来自MetaGPT，团队成员只用了1</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490644&amp;idx=1&amp;sn=237d4af9fc0c552d95c1fd84daf220b5&amp;chksm=fdfbe1b6f2e3e4601d5a1e2a829b6857a9a82225030875e537066ef41e7271c8eb7c5d17a299&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Manus震惊全球AI界。全球首款通用AI Agent：三个问题带你了解！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKCVeQ9eGicyAnj6ic6U5bkS8oOqYUt1IHZEbXBB7HYVADBhUaXmWDRA7vS6QIGhJpKaXpDiaBJe0jA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在科技日新月异的今天，每一个重大的技术突破都可能成为推动社会进步的强大动力。2025年，似乎正成为这样一个充满无限可能的年份。继DeepSeek之后，又一款带有中国印记的AI产品——Manus，以其独</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490644&amp;idx=2&amp;sn=7ff8e2da138f1ef149f0294256810ffc&amp;chksm=fd084718229ebfa5bcfb5cac548ff703559bd0382766f24ed5791a27d248e8a4ba53981e67ce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LuminaBrush 在图像上绘制照明效果的构建交互式工具。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emstfptCQxwPFVbYI1WNOA3hBPXy2a1MjMxRyibAmc4FtFqLVcy56JI8l8XdNxdSFPyAw6H06p4Xuw/300?wxtype=jpeg&amp;wxfrom=0"/><p> LuminaBrushLuminaBrush 是一个构建交互式工具以在图像上绘制照明效果的项目。该框架采用两阶段方法：第一阶段将图像转换为“均匀照明”的外观，第二阶段利用用户涂鸦生成照明效果。相关链</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490644&amp;idx=3&amp;sn=1311d7bcecddfa9b045945da8884cdc2&amp;chksm=fd0319ec3d5662f31aa8bc19e7ef832a4db5dd020fc6333e5f5b8a31a340545c0b1468811dcd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Google发布新AI工具Whisk：使用图像提示代替文本，快速完成视觉构思。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2end3mWUdomxapVIqKPBfrWChHLuwfMCvRvq1l8Kl6qfOOlq9YUxzPEdzMibDSUo0R5owCSicTJLumBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Google发布了新的AI工具Whisk，Whisk 是 Google Labs 的一项新实验，可使用图像进行快速而有趣的创作过程。Whisk不会生成带有长篇详细文本提示的图像，而是使用图像进行提示。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490644&amp;idx=4&amp;sn=35d20bf95d5f3756dc65b8b9fc75050c&amp;chksm=fd020b643a9198ffa67b13376cf3b790af14e846172c31044efab85685bdfee92d44e5f51786&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OpenMauns：5个人三小时复刻Manus，不需邀请码！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>Manus 令人难以置信，但 OpenManus 可以在没有邀请码的情况下实现任何想法！OpenManus团队来自MetaGPT，团队成员只用了1个小时就完成了核心系统，整体也只用了3个小时。每个人都</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490638&amp;idx=1&amp;sn=b4087d6b8da9f059d0f65577fb4105c0&amp;chksm=fd57578c5f0d7247110c8ea1e33b1e01e7f53b9fc28daad63ca97fea5bdbb739a04e124d258c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 07 Mar 2025 13:03:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek之后，Manus再度震惊全球AI界。全球首款通用AI Agent：三个问题带你了解。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKCVeQ9eGicyAnj6ic6U5bkS8oOqYUt1IHZEbXBB7HYVADBhUaXmWDRA7vS6QIGhJpKaXpDiaBJe0jA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在科技日新月异的今天，每一个重大的技术突破都可能成为推动社会进步的强大动力。2025年，似乎正成为这样一个充满无限可能的年份。继DeepSeek之后，又一款带有中国印记的AI产品——Manus，以其独</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490614&amp;idx=1&amp;sn=949a2f1720b1445f4da540898efae6e1&amp;chksm=fd8789d79bfbadb73860caf4e7b0e8d74b9999a119866d13478987d59b1c8f271e167c52d846&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北大提出高效视频生成框架Magic 1-For-1！一分钟即可生成1min时长的高质量视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Im7d1myrXRAiarmcWtBLIuFK9FQGib66tAQmlDsP6icPCQpkZ9dLLmVqzlmibR6zRCHiaJSK7kuibJkGmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>计算机视觉最新论文今日论文推荐论文名：Magic 1-For-1: Generating One Minute Video Clips within One Minute论文链接：https://ar</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490614&amp;idx=2&amp;sn=0a57a17fa7c954f0be9d5a366e54e3dc&amp;chksm=fd58e4b7fdef6afad516396c254055798095adfcdb8c7a4bcb185529bab2077a3b67354022e7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北航 | 第一个多功能即插即用适配器MV-Adapter：轻松实现多视图一致图像生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfSL2lH1ru1uCJuUuA21YKHU5ia5SLlWu0BztQtHU3YSeZIYv3K9nGSHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>北航提出了第一个多功能的即插即用适配器MV-Adapter。可以在不改变原有网络结构或特征空间的情况下增强T2I模型及其衍生模型。MV-Adapter 在 SDXL 上实现了高达768分辨率的多视图图</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490614&amp;idx=3&amp;sn=84c4f38de1b830a8bba71b1cdb677ddb&amp;chksm=fd6c5e775728ff22d0fa4687f3945fcab70e307048238e6a5febd239c478401835c2edbc2bb3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌推出PaliGemma 2 mix：用于多任务的视觉语言模型，开箱即用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZG3A9ureoTeOkRX7vpoweMqWfIXVPrnftNxPZXeKdfJFf3WSY8K2fGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>去年 12 月，谷歌推出了 PaliGemma 2 ，这是Gemma系列中的升级版视觉语言模型。该版本包含不同大小（3B、10B 和 28B 参数）的预训练检查点，可轻松针对各种视觉语言任务和领域进行</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490614&amp;idx=4&amp;sn=dfb39fb9085e0ce7ce8d69d5616c89fc&amp;chksm=fd16ad60a318a32e038b258d4416d8cc5a089d88702e78f6c6d3d449b3bc3493aeecafdff515&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 06 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里发布新开源视频生成模型Wan-Video, 支持文生图和图生图,最低6G就能跑, ComfyUI可用!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emELibL5kVkYibicFiaR0laM2LPanMoANDKaC5QVXWXiawVrJIjXcdbschfSzanarf8EbFZpGTOSicjTZAQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>Wan-Video 模型介绍：包括 Wan-Video-1.3B-T2V 和 Wan-Video-14B-T2V 两个版本，分别支持文本到视频（T2V）和图像到视频（I2V）生成。14B 版本需要更高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490584&amp;idx=1&amp;sn=fe694eb011d3353ffb9d928dbf0a53be&amp;chksm=fd0246e0ed834cd8ed25b326c914a22c27d26419b3e1c5afe597548661aebcc2404db6482a7d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[电商领域利器来了！港大&amp;阿里提出MimicBrush，可模仿参考图进行零样本图像编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enu15BEdxn8DpEdshmGPMicepiaSYu1INiahHv6ZdWxcTRjT1UexEYITfITVC8uhS6hWlib4Wodyfrr3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里和港大提出的MimicBrush可以通过对参考图模仿进行零样本图像编辑。将一张图片的某一部分融合到领一张图片上去。用在电商商品展示上或者单纯的图片编辑和内容迁移很有用。从官方演示来看效果也很好。M</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490584&amp;idx=2&amp;sn=c93414ea4529a07a782a7c6ceb1fa9d3&amp;chksm=fd61c34ae8594dfa5892c10f52deee502175222b53c497cf671f77ec6a7a90952aa7da2342af&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[澳门大学提出DC-ControlNet！解耦控制条件！灵活性和精度超过ControlNet！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IJObOoyvhRkCaPGyos7d8xL9KBFJiaWYgoicVEkmuuB7slvPLj3SIW9jx5pace0iagDibDDTLU1P3Lwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：DC-ControlNet: Decoupling Inter- and Intra-Element Conditions in Image Generation with Diffusion</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490584&amp;idx=3&amp;sn=ac5e2ddabb690e93ebeda1861f99f902&amp;chksm=fda3e3054ad4d470503d95e966f1fbc17c31a99236066de6ece904408b7f30b82aa4b0a08b72&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICIR2025 | CubeDiff：无需考虑失真，重新利用基于扩散的图像模型来生成360°全景图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6qavvqaKicyhfbe1wrRfKuEmZbfJ8LvrOgQJMgZYG5CztqNUPPASQbtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给大家介绍过许多关于3D生成的文章，感兴趣的同学可以点击公众号菜单栏查看3D生成专栏，创作不易，欢迎大家点点赞和在看~CubeDiff是一种使用基于扩散的图像模型生成 360° 全景</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490584&amp;idx=4&amp;sn=5eaf557b0b77ce14365259b921883d5f&amp;chksm=fd163121ab3ab307f4b1af978e490b0d9dbb2c1c9efc6401b1479c8312233ad38589e210823f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICIR2025 | CubeDiff：无需考虑失真，重新利用基于扩散的图像模型来生成360°全景图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6qavvqaKicyhfbe1wrRfKuEmZbfJ8LvrOgQJMgZYG5CztqNUPPASQbtg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给大家介绍过许多关于3D生成的文章，感兴趣的同学可以点击公众号菜单栏查看3D生成专栏，创作不易，欢迎大家点点赞和在看~CubeDiff是一种使用基于扩散的图像模型生成 360° 全景</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490543&amp;idx=1&amp;sn=5612888e956f0106578eaa019f577656&amp;chksm=fd0f27c47f012bf005fca5132a31a6f4bdb2bdf08c9532581d8e2caecc5e65a7d0536a9e8a1e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 16:12:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[StochSync：可在任意空间中生成高质量360°全景图和3D网格纹理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enXFFuKUPQcYLlG3aibBhJtN7xgJCpXZE7HoaWiahrDNLktV0doUSl1wRalx4MZej02YkgNsTVfSbpg/300?wxtype=jpeg&amp;wxfrom=0"/><p>StochSync方法可以用于在任意空间中生成图像，尤其是360°全景图和3D网格纹理。该方法利用了预训练的图像扩散模型，以实现zero-shot生成，消除了对新数据收集和单独训练生成模型的需求。St</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490543&amp;idx=2&amp;sn=4bcb6a9ceb33d74506d10c9192481efa&amp;chksm=fd5c46beedb75bf24522af9c98149de73eddff0c393a8e2fc377b363c26fc67f9fb470f05c98&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 16:12:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单幅图像合成 360° 3D场景的新方法：PanoDreamer，可同时生成全景图像和相应的深度信息。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el8quKicUEibqsQFrF8ttU8UZJIaZuVsUww2Z2IDLp7MYqLaIsWuo5dAG2Y1iaHf8AibCjXj4KFPbTv3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文介绍了一种从单幅图像合成 360° 3D 场景的新方法。该方法以连贯的方式生成全景图及其相应的深度，解决了现有最先进方法（如 LucidDreamer 和 WonderJourney 的局限性。这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490543&amp;idx=3&amp;sn=c6643842afa2c65148191fa5b03e636c&amp;chksm=fd8c0d2e25438e364d8a0ca539bdd0b1ce2b1421a1834815485a82078508ddfba2251035e97f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 16:12:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TRELLIS：用于创建多功能、高质量的360°全景图生成方法，实现可扩展多功能3D生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emeYg29ZW9ZRFeXmWsX2FIsrcRtOibx92ZhEt1Z0UdQ7JsQibr17Y0WaD8O08DMM3XIor43XOZVMvXg/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华大学、中国科学技术大学、微软研究院联合提出T RELLIS，这是一个大型 3D 资产生成模型，可根据文本或图像提示（使用 GPT-4o 和 DALL-E3）以各种格式生成高质量的 3D 资产，可在</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490543&amp;idx=4&amp;sn=2cbb023aa7f1bd83b5de17d2b9cc6526&amp;chksm=fd1e2aa8a4311c9ff6b1fd788f0da9698d8cce11c373dffdadee68df671f607c2aa9cb27b584&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Mar 2025 16:12:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南开提出1Prompt1Story，无需训练，可通过单个连接提示实现一致的文本到图像生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzPNo4OCBUcdtmaQJs6N0wWib04FeoPN0dUqhYsAJa4gIVOeKpt04Ox35gLkECLB9LEJGNnrDPu9g/640?wxtype=jpeg&amp;wxfrom=0"/><p>（1Prompt1Story）是一种无训练的文本到图像生成方法，通过整合多个提示为一个长句子，并结合奇异值重加权（SVR）和身份保持交叉注意力（IPCA）技术，解决了生成图像中身份不一致的问题，同时保</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490542&amp;idx=1&amp;sn=9b01d1603a7aaab7939445b11ab9f806&amp;chksm=fd066915a0549dba0c9c7d5746bbc6edef622c274fb22ef8633ee6ff8d34a71ef17349e6a028&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CineMaster: 用于电影文本到视频生成的 3D 感知且可控的框架。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMLBRnvtbr9hh7W1ccXtbHEFc26iarR5N2r9CO0FlrI8VbA3yicts8jmfYqQu9BHcgSCETWsJ0PawQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>CineMaster是一种 3D 感知且可控的文本到视频生成方法允许用户在 3D 空间中联合操纵物体和相机，以创作高质量的电影视频。相关链接主页：cinemaster-dev.github.io论文介</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490542&amp;idx=2&amp;sn=e2a44ffbea977468ca18383d19f3541a&amp;chksm=fde5816f23c1435055648f7dbc3b30f0aef226dab2924544c45ec5570c9151dc4417eabe8b10&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[震惊！东京大学提出ARTalk！语音驱动3D面部动画大突破！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JgxI2td6MuHkKtXCMBGlVyNoBucDYsH1Jct1PGOib0q03Jn6GdpLz4QjrI8emN5ohoxj6WzEHv54w/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model论文链接：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490542&amp;idx=3&amp;sn=0c74f66577b3a85fdb1b1d79a6156a01&amp;chksm=fd33a5202de54545ce92731a21000648f8a910655c727cacd2df47288dc38a82cf2fa56b52d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490521&amp;idx=1&amp;sn=9338c7246b5b4cc587818d0c2258e9a9&amp;chksm=fd14567aabbed1399ced8b0d2fe2de3d132991286ea51a5c471f3bffc0879b728b211d329c8d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超级智能“试衣镜”！GarDiff：高保真保持目标人物特征和服装细节，虚拟试穿技术新SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUN5oqyRgSButjKACUwRIef94PhQmUMcfJSkj4W9NicELKlw377icJuhpfjx2VUNPWKHMM0Gqib5Eg/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前已经给大家介绍了很多关于虚拟试穿的文章，本公众号也总结了虚拟试衣专题在公众号菜单栏，感兴趣的小伙伴可以在公众号内搜索“虚拟试衣”阅读～今天给大家介绍一个最新的虚拟试穿技术GarDiff，它可以分析</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490521&amp;idx=2&amp;sn=2f6ae2eff14abfd89788ed4e5be1c032&amp;chksm=fd5fdde867001d56db3b13bbaac5154ff39d93f0619a4781d1da9eef14a1c45c4b1e9bc8f381&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港大&amp;Adobe提出通用生成框架UniReal：通过学习真实世界动态实现通用图像生成和编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfcOvKg4alghJicfViaQXPN3cGVy3SYtSRiaWE0jyTlhQNs1mRy2lUoe0Pw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的文章来自公众号粉丝投稿，由香港大学，Adobe提出的统一图像生产与编辑方法UniReal，将多种图像任务统一成视频生成的范式，并且在大规模视频中学习真实的动态与变化，在指令编辑、图像定</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490521&amp;idx=3&amp;sn=2ea722547f91ac965281f729fa88b406&amp;chksm=fde03d60420daace88c2d1035962c36da3e5834b246add52daa116ffc3b1514817f4b5163273&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态图像生成模型Qwen2vl-Flux，利用Qwen2VL视觉语言能力增强FLUX，可集成ControlNet]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYHx9RLCm1u1zJr61WGBPZZicviaGPyXN8y5ZTaZE9jpPcdNSX1nmUlib5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2vl-Flux 是一种先进的多模态图像生成模型，它利用 Qwen2VL 的视觉语言理解能力增强了 FLUX。该模型擅长根据文本提示和视觉参考生成高质量图像，提供卓越的多模态理解和控制。让 F</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490521&amp;idx=4&amp;sn=94f253805cdbd408e79c2addde107210&amp;chksm=fdc959a905b64dacf7d3942a97a5149e6860ed5605a6bd869672eb07c874c326c24e33bf3650&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 02 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CineMaster: 用于电影文本到视频生成的 3D 感知且可控的框架。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMLBRnvtbr9hh7W1ccXtbHEFc26iarR5N2r9CO0FlrI8VbA3yicts8jmfYqQu9BHcgSCETWsJ0PawQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>CineMaster是一种 3D 感知且可控的文本到视频生成方法允许用户在 3D 空间中联合操纵物体和相机，以创作高质量的电影视频。相关链接主页：cinemaster-dev.github.io论文介</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490520&amp;idx=1&amp;sn=b217a6ebc742080bf81796c7b1d162f3&amp;chksm=fd91b7e8d4d682b2260cb1e4b5840f5c283885f577ac646ff12dc8073a9b37d7e095ed7e33f2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 16:14:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态图像生成模型Qwen2vl-Flux，利用Qwen2VL视觉语言能力增强FLUX，可集成ControlNet]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYHx9RLCm1u1zJr61WGBPZZicviaGPyXN8y5ZTaZE9jpPcdNSX1nmUlib5g/300?wxtype=jpeg&amp;wxfrom=0"/><p>Qwen2vl-Flux 是一种先进的多模态图像生成模型，它利用 Qwen2VL 的视觉语言理解能力增强了 FLUX。该模型擅长根据文本提示和视觉参考生成高质量图像，提供卓越的多模态理解和控制。让 F</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490520&amp;idx=2&amp;sn=6bf63f8435ec46ef939e7efe6be4eab5&amp;chksm=fdf7179b55ec937165122670235b77f765b563fca797aebb071e5e5da28a1b6f5cc8c1430ecd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 16:14:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北航 | 第一个多功能即插即用适配器MV-Adapter：轻松实现多视图一致图像生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en3n1j1LLVnKmKxjJUkVMkfSL2lH1ru1uCJuUuA21YKHU5ia5SLlWu0BztQtHU3YSeZIYv3K9nGSHQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>北航提出了第一个多功能的即插即用适配器MV-Adapter。可以在不改变原有网络结构或特征空间的情况下增强T2I模型及其衍生模型。MV-Adapter 在 SDXL 上实现了高达768分辨率的多视图图</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490520&amp;idx=3&amp;sn=f9665d89e6f81c9dde852d80d8f13cb4&amp;chksm=fd6fe66eaec98737528c0dabbb57943ea004b1a494a053c058eed9885c6c4c74553d59150972&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 16:14:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大 | 腾讯 | 华为提出视频生成框架VideoMaker，可由参考图实现Zero-shot定制化视频生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekaVfDRjALdOCj5889F1MpALuqg2wbFklkt9TIVHLSyQfTQ65do3Pe4Szhc0sWs0dMVTLfiavGbvRQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙大联合腾讯和华为提出了一种新的定制化视频生成框架——VideoMaker，利用VDM的内在能力，实现高质量的zero-shot定制化视频生成。该方法通过直接输入参考图像到VDM中，利用其固有的特征提</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490520&amp;idx=4&amp;sn=199e3c48ba0303fb009601951f9095dc&amp;chksm=fd6b19616f89fcb8f99d323d5487af5c993ef74ef8dc5ab141118c2e84983ac3c4aff5ca958f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Mar 2025 16:14:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大提出视频生成方法VidSketch：可从手绘草图和简单的文本描述生成高质量视频动画。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMLBRnvtbr9hh7W1ccXtbHgw4aIUWZuDmaia40dSE9oXFEapMjdUy4355HjGBNbH33XBwB6vDxFhg/640?wxtype=jpeg&amp;wxfrom=0"/><p>浙大提出的VidSketch是第一个能够仅通过任意数量的手绘草图和简单的文本提示来生成高质量视频动画的应用程序。该方法训练是在单个 RTX4090 GPU 上进行的，针对每个动作类别使用一个小型、高质</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490519&amp;idx=1&amp;sn=79506d6c5873f4175f9df966ed1a80b0&amp;chksm=fda06817e332ac2250802f0818d3a4e66a6ff27eb46e41c260e83e1d4701d4c19184c7021053&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出新框架ImageRAG！RAG+AIGC提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JK3j8AP855QOPLGKEpd37E3bPLWmIOj4bSM2oUxbcSEQ3NFVFyqRhEKjhBGvFkPMAwAaMsbszianQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation论文链接：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490519&amp;idx=2&amp;sn=ce3026b5dc7d195a19f51fe317ba1385&amp;chksm=fd147c133a8857326f4b8c8e6df4d5078903fc221cd5359c784e4fc58a5f118b817c03fd35a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[电商领域利器来了！港大&amp;阿里提出MimicBrush，可模仿参考图进行零样本图像编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enu15BEdxn8DpEdshmGPMicepiaSYu1INiahHv6ZdWxcTRjT1UexEYITfITVC8uhS6hWlib4Wodyfrr3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里和港大提出的MimicBrush可以通过对参考图模仿进行零样本图像编辑。将一张图片的某一部分融合到领一张图片上去。用在电商商品展示上或者单纯的图片编辑和内容迁移很有用。从官方演示来看效果也很好。M</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490519&amp;idx=3&amp;sn=554d23556191e02c38f336b2e29245b2&amp;chksm=fd99c66c9c358101f2bdb8d4e9d28aab08764a11e762a9e442bd5e1d1680274c2ade741e9264&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 16:06:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Meta提出Fast3R！多视角快速3D重建新SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAdQicl6tFbm7xyZxj3Q91AjRBzA4Vrr5253RCiabI6uiaibZMIdTyoq6TZdXe8AotLRlkE2pkJyqGQLfQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass论文链接：https://arxiv.org/pdf/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490519&amp;idx=4&amp;sn=a905ede7d9d76c9eb1adde9699ad71ef&amp;chksm=fdb0c30ddfa289234019713b54d6e1b9b4fe9f44d346186c9fe1e1512781ae161dd27d7a2d2c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Feb 2025 16:06:00 +0000</pubDate>
    </item>
  </channel>
</rss>