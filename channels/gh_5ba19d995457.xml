<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[谷歌黑科技炸场！LightLab：只需一张图+AI，光影编辑像呼吸一样简单，废片秒变电影级大片！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek5oLyjfCjICEWyMhWNvFXD4gjUliaiaZ2wibPXVQsv1Vm81gqpJibC7scwg1DqQJbMMmvr7P8D5cPMCA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中以及和大家介绍过需要关于图像&amp;视频重打光的方法，在今天的推送文章中，已经帮大家重新整理好了，欢迎大家点击阅读~今天给大家介绍谷歌提出的一种基于扩散模型的方法LightLab，可以实现对单</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492719&amp;idx=1&amp;sn=99354cc4985dc55c109838046f75fbb4&amp;chksm=fdacbfb75e0042cba268425f308b31bcb71945fd3ae2c0f3f770d26fc237ebabe2f3c9f892fa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IC-Light升级，支持视频重打光! RelightVid可在多视频场景中重照明，支持文本提示、背景视频和HDR输入！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6QSiaic7OicOck7L6SeBvmG8KxGGhaK7IiaIoGtBJsFyM7LffJExAYwxgr09hKHicONPnN40NOq3Cib7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经和大家介绍过ControlNet作者关于图像重打光的工作IC-light，这篇论文也是获得了ICLR2025的满分评分，感兴趣的小伙伴可以点击下面链接阅读！ICLR 2025满分论文，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492719&amp;idx=2&amp;sn=2950a56f26e8587c95186e0c9117dcdb&amp;chksm=fdff6c2ef47e1f54bb031474e3e4498163df8529daca24886b2d05817c3423e03251dc4a09e8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[耶鲁大学联合Adobe提出SynthLight：智能重塑人像照明，打造完美光影！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPyLquFq9rYTicjFkPwyh9fFVDfMwbeuJFlesWohTUXxZRSXxUpCJVwUUib0mdhjaia5sa6Ciaibic8AQg/300?wxtype=jpeg&amp;wxfrom=0"/><p>耶鲁大学和Adobe提出一种用于人像重新照明的扩散模型SynthLight，该方法将图像重新照明视为重新渲染问题，其中像素会根据环境照明条件的变化而变化。在真实肖像照片上可以产生逼真的照明效果，包括颈</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492719&amp;idx=3&amp;sn=5e06c57c62bdf8160727f2911a8a7b18&amp;chksm=fd9f9180528417d6eb5a90537c53aa755d2edbc52acb91625e764569e4287f78b99d00f03150&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025满分论文，ControlNet作者新作IC-light，控制生成图像照明，代码模型已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enrJ6ibDPoiaQXzhMdZU8spAicfF8vgRl2qenVGz9ZkJkJgBYXd26ys3WTPnNDJtK81bRSE1Xia412nbQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>罕见！ICLR 2025 惊现了一篇满分论文，4个审稿人同时打出了[10,10,10, 10]，这是什么炸裂的存在？！这就是ControlNet的作者张吕敏，继ControlNet 后提出的IC-li</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492719&amp;idx=4&amp;sn=9b617f922e3e7a1681a2343d5385cc9a&amp;chksm=fda03aa51aca322b363f9343404c40c107837a266926ac84f76fc3ec2849b48616e1e8bdbe2b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[​IC-light V2：基于FLUX训练，支持风格化图像，细节远高于SD1.5。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXSHQPic5rJ8IBKiaNosJKl4zjuJBWaX5OT2Lf7ZUfribJIKIVPQd63HVFcGOR4owDUYVuia3JgZoueg/300?wxtype=jpeg&amp;wxfrom=0"/><p>IC-light V2：支持处理风格化图像“IC-Light”全称是“Imposing Consistent Light”，IC-Light 是一个操纵图像照明的项目。目前已经发布了两种类型的模型，两</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492719&amp;idx=5&amp;sn=ef2c28606afe86bf50fd73c138202ff6&amp;chksm=fd68bd28182b21beb89ddf7f52ae25c260dc958743a1b826470b8b1ecb395c9954533849f572&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 22 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[哔哩哔哩再放大招！开源最强文本转语音模型Index-TTS，超真实语音克隆，可纠正发音、控制停顿。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekBSQolZZOuH0N3j03LsQJ4iaV41U2U7rc7sOzwoFzlxLhwic4zicGU7C9cnmslZt0afXNjyErakLib2Q/640?wxtype=jpeg&amp;wxfrom=0"/><p>哔哩哔哩最新开源的 Index-TTS  是一个 GPT 风格的文本转语音 (TTS) 模型。它能够使用拼音纠正汉字发音，并通过标点符号控制任意位置的停顿。经过数万小时的数据训练，该方法达到了最佳性能</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492718&amp;idx=1&amp;sn=00c7ca18ac08958d965bbcd3710a12b9&amp;chksm=fde412718fec897012e790e372142c946f89f22af26088cea3ef285ffd0a9c2ed66ada2cfc30&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[哔哩哔哩开源目前最强大的动漫视频生成模型Index‑AniSora，给二次元世界的献礼！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enSiccUGiblNd9QEDRcSD96fBURrzeY4wTV8PKUrO1z3OVvvWGu3cqBYg8yJTxdEbtefDDE4WXaYsLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是哔哩哔哩献给二次元世界的礼物——Index‑AniSora，目前最强大的开源动漫视频生成模型。它支持一键生成多种动漫风格的视频镜头，包括番剧片段、国创动画、漫画改编、VTuber 内</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492718&amp;idx=2&amp;sn=dd2451579f3a4d06f3c2f267cdb7f0fe&amp;chksm=fd74914dbcbccfc25938c9500780811abf1fdc4419d32f571103ac8c7693367367a76ca73551&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492718&amp;idx=3&amp;sn=68581704414edfc6e54f258fe6b8d9bb&amp;chksm=fd1086ac22cf95442d58ca39ae94c81e106809c6206ad0a4d0b09ee1ab64bc336610a674686a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492718&amp;idx=4&amp;sn=94f33d4bcd95ff84571c62fdc2a21909&amp;chksm=fdc8e99f181a2016d4e6daa373a48c9d088af9ac5f4c749e048444db6cc095435a4ff5e3e2b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 21 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[给二次元世界的献礼！哔哩哔哩开源目前最强大的动漫视频生成模型Index‑AniSora！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enSiccUGiblNd9QEDRcSD96fBURrzeY4wTV8PKUrO1z3OVvvWGu3cqBYg8yJTxdEbtefDDE4WXaYsLA/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的是哔哩哔哩献给二次元世界的礼物——Index‑AniSora，目前最强大的开源动漫视频生成模型。它支持一键生成多种动漫风格的视频镜头，包括番剧片段、国创动画、漫画改编、VTuber 内</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492684&amp;idx=1&amp;sn=11915e42a737f6e39e8f2c198f1e09c9&amp;chksm=fd7a0ff4ea5d1b64ed619b8a816a6d4e5c270b3c63208be5b3f730ae1a5dae347b3a74336407&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型再现黑马！英伟达开源Llama-Nemotron系列模型，效果优于DeepSeek-R1。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafoC1ibJ7eE1fvbrtrICXG1kaXfiaqibBmibzznCUHyiaB4NGTibwK6pmBM0hA/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，英伟达推出了 Llama-Nemotron 系列模型（基于 Meta AI 的 Llama 模型构建）—— 一个面向高效推理的大模型开放家族，具备卓越的推理能力、推理效率，并采用对企业友好的开放</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492684&amp;idx=2&amp;sn=53439f12162dc38eaa0a30abfc172de5&amp;chksm=fd60209f088ba27da940c7793d562cdbb5d59ff8b667d3fffa235517abd3b6af4986c07650ae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D 生成新 SOTA！SECERN AI 提出 方法 SVAD，单张图像合成超逼真3D Avatar！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJczQ6xAAgVU8NYrMphwhLiaiajhcsCMja0TDYcr6RulFp9C6Yt1mtcbiamA/300?wxtype=jpeg&amp;wxfrom=0"/><p>SECERN AI提出的3D生成方法SVAD通过视频扩散生成合成训练数据，利用身份保留和图像恢复模块对其进行增强，并利用这些经过优化的数据来训练3DGS虚拟形象。SVAD在新的姿态和视角下保持身份一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492684&amp;idx=3&amp;sn=138e8a677e24ed57e53a688c5d73ce14&amp;chksm=fd5949abc21cb8519a499fe29b8595a728100de796632607638319a4878f7d07362b3119fb17&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[炸裂！ComfyUI 原生支持 HiDream-I1，全新文本转图神器来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2ibyrQzlh4BO0Xa83u0NI5WzuIBs5KCqMafPkjLwMiapJ0TVwXCaj6ibIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyUI 原生支持 HiDream-I1，全新文本转图神器来了！大家好，这不是演习！ComfyUI 终于官宣——原生支持 HiDream-I1 模型啦！对于熟悉图像生成的小伙伴来说，这可是一件值</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492684&amp;idx=4&amp;sn=af6ae14a7dc045db56ab03f34130ec73&amp;chksm=fd7c7c55b693485bf5cee443a91e8c84077dfe8006c93711954c4076f1dc09020c5aff106ce7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 20 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谢赛宁团队提出BLIP3-o：融合自回归与扩散模型的统一多模态架构，开创CLIP特征驱动的图像理解与生成新范式!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek5oLyjfCjICEWyMhWNvFXDN37WVtXa4JeBibibTSdNGmBP0wSFhuUAJkiaz9qNwiccNW4SuNJ7FvduuQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>BLIP3-o 是一个统一的多模态模型，它将自回归模型的推理和指令遵循优势与扩散模型的生成能力相结合。与之前扩散 VAE 特征或原始像素的研究不同，BLIP3-o 扩散了语义丰富的CLIP 图像特征，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492683&amp;idx=1&amp;sn=c6f9575a6347b0fd4f905f7ec64b54a8&amp;chksm=fd600ee6b8313e076506c578485f83d8dbd2740bd8b48a901f5bbd2e1cdad50b87393ed53add&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出从单一主题发展到多主题定制的通用框架UNO，通过情境生成释放更多可控性。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elo3s89icGNibsPQVXGhctg9WDrsYXyWyFSyqXzUDm6eOsD3G2Z7XbSMUPZrQw19LsCTpuzPx9KiaCWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节跳动的智能创作团队提出了一个从单一主题发展到多主题定制的通用框架UNO，从少到多的泛化：通过情境生成释放更多可控性。能够将不同的任务统一在一个模型下。在单主题和多主题驱动的生成中都能实现高度一致性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492683&amp;idx=2&amp;sn=81496eb2cd96b6ff6e0fa8df5de1039d&amp;chksm=fdc359d002107ded0b9eb0d26dafd4996bb6ab8b6de68d9e2245f5f1e088aad1d08f3d00bc2a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[太强了！浙大联合上海AI Lab提出视觉统一Diffusion架构DICEPTION！各种视觉任务一网打尽！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcb6XeOfGM7ic3jww1VGas5hyQ5UbdLhbhjcqHwrckdlwdXIvppjK9PlGZVkxMpOMiaT6tDJ32KOqiaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>数源AI 最新论文解读系列论文名：DICEPTION: A Generalist Diffusion Model for Visual Perceptual Tasks论文链接：https://arx</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492683&amp;idx=3&amp;sn=fe89aee75d03d8a8c22dd34f825f3347&amp;chksm=fd6a9663871f0b1d4837d084092f26a9cefa277e1abfe0013b771ff7f1d53142fe7659a98c06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI插件安装失败率90%？教你4种方法0踩坑]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE4krxeSSRPxaSdK57W0WTcKsAosmf2OLF7QQMa3t5LdSSntjJPTIZQgLlJTibnRCJGn820Ex6Odf4g/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击蓝字关注我吧！ComfyUI 作为一款高度模块化、节点式的 AI 图像生成工具，近年来在国内外社区圈粉无数。但要说它最常见的“劝退点”，那一定非插件安装莫属。很多新手兴冲冲地下载完工具，还没来得及</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492683&amp;idx=4&amp;sn=989d17002404a904cfe61c5f8937f2eb&amp;chksm=fdb16e7819c41c7376d16cd0c578ed36308137b733fae9c185c6fded42c06266a538d74f218b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 19 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布 Seed1.5-VL 视觉-语言多模态大模型，20B 参数狂揽 60 项公开评测基准中 38 项 SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1LeKLydiaFjmibN24FdeB4micypmdwFpFW83KWkU4txxbiaLmiannOs7mDHw/640?wxtype=jpeg&amp;wxfrom=0"/><p>5 月 13 日，火山引擎在上海搞了场 FORCE LINK AI 创新巡展，一股脑发布了 5 款模型和产品，包括豆包・视频生成模型 Seedance 1.0 lite、升级后的豆包 1.5・视觉深度</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492644&amp;idx=1&amp;sn=20ef8da40f03d8c1eb89596943cbf227&amp;chksm=fde476152116b27784b0e0190d70744efdc2d116fae42c1cdcf127fdc8164f1e83192ed58365&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布视频基础大模型Seaweed，70亿参数超越同类140亿参数视频模型效果，单GPU就可生成1080P！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrSjMIibqt135GUNpF74oSRXfm9iakLUsJ4cuaJkMv3pwe9GUibyujB4o5rb4L0I9e4f2iacOibCyryMg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Seaweed 是“Seed-Video”的缩写，是一项旨在构建视频生成基础模型的研究成果。该网页展示了拥有约 70 亿 (7B) 个参数的扩散变换器 (Diffusion Transformer)，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492644&amp;idx=2&amp;sn=befad8fec1e3bf3cec87e2005c14c182&amp;chksm=fd0bb9a5ea8d326b94c0d2396f985d522423bf268e71966c629cc19c63cbb616424fa0fa06ec&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[142页深度解析：DeepSeek-R1的推理技术综述，AI的“思考”秘密大公开]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic74EgPzUnjibrG5SK0JmT8ksETRvVrR1XcCZjqetgGsxyQHiaa0hCYjVTIMhicnh9kAXbQjIYxYwDkxQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek-R1 就像是AI界的“思考者”，能够像人类一样进行复杂的推理和思考。在数学、编程、科学推理这些超难的任务上，它的表现简直逆天，直接对标OpenAI的o1正式版，妥妥的推理界“学霸”！</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492644&amp;idx=3&amp;sn=e3093e335f8ab5d1103acd6cb7a881df&amp;chksm=fd967052e71265de1e1d424cd5ce28af2a7fe97813c3d4a0fb70cd250dc1697ebb3bd8388fca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492644&amp;idx=4&amp;sn=ad5c0aaddedcf6fa986d7c0e324fb96a&amp;chksm=fdb7f21cca0cdaad635c885ae1aaf15e9a1757ef87f361aade9ac5255843f8b627b4299dc91e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 18 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型再现黑马！英伟达开源Llama-Nemotron系列模型，效果优于DeepSeek-R1。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafoC1ibJ7eE1fvbrtrICXG1kaXfiaqibBmibzznCUHyiaB4NGTibwK6pmBM0hA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，英伟达推出了 Llama-Nemotron 系列模型（基于 Meta AI 的 Llama 模型构建）—— 一个面向高效推理的大模型开放家族，具备卓越的推理能力、推理效率，并采用对企业友好的开放</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492601&amp;idx=1&amp;sn=ecb9383177f7d466d07a987282c7285e&amp;chksm=fdf80a63cdcfa8d53ccf7754345e908c0544610e4e7bc5e77f8afe186f1b91ae7e3dba504a1d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492601&amp;idx=2&amp;sn=af46e60dcf607f1435a016a12da2d1e4&amp;chksm=fd9549acf167fb4e195f3fddebb93a144e3a6910a3d2449a3070d44419c739cf923be4cdc500&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 最强吉卜力风格工作流EasyCN来袭，风格统一+操作简便+输出稳定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE6xg4dG7Ndtia8iag86UJ7LAcFTmCaJMwrHhZMoY5Fjia4QeyYvmmygPtEbYjX3d9emmuUYf6flou1YA/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近的ComfyUI圈子，可谓是“神仙打架”级别的热闹。就在你还在研究ControlNet怎么接线、LoRA怎么调风格时，一套堪称“傻瓜级”的全自动吉卜力风格生成流程，已经在社区悄悄流行开来。Easy</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492601&amp;idx=3&amp;sn=72620a76e822279bf770c99f73ce6f48&amp;chksm=fd61e4b6a97087a395062d9be36991f0c516119946fb1bf12e39756438b41e737b7362c7ba5d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 17 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D 生成新 SOTA！SECERN AI 提出 方法 SVAD，单张图像合成超逼真3D Avatar！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJczQ6xAAgVU8NYrMphwhLiaiajhcsCMja0TDYcr6RulFp9C6Yt1mtcbiamA/640?wxtype=jpeg&amp;wxfrom=0"/><p>SECERN AI提出的3D生成方法SVAD通过视频扩散生成合成训练数据，利用身份保留和图像恢复模块对其进行增强，并利用这些经过优化的数据来训练3DGS虚拟形象。SVAD在新的姿态和视角下保持身份一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492475&amp;idx=1&amp;sn=684077a1fb1dad9e64d6fdcd3e8c82fc&amp;chksm=fddbf47c62a1ecae66a5eb7c05349793899cbd2ddacf707b79b81616c2a5622004b0f3117296&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | VACE-14B：效果炸裂，开源AI视频里程碑！稳定高质量wan2.1视频一体化编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGTEc51fic65mC5EsS2ljQDXDgX9HPib083UyrrTPSbd3PsgEQsKNckx6trWVq4oKNwScsBKH5zQt5Yg/300?wxtype=jpeg&amp;wxfrom=0"/><p> VACE：一体化视频创建和编辑VACE简介今天文章将介绍一款最新的最新视频编辑框架：VACE。这是一种一体化模型，能够在视频创建和编辑中使用。涵盖了多种视频编辑任务，包括参考到视频生成（R2V）、视</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492475&amp;idx=2&amp;sn=60197534d5087c421627a8375f184ea8&amp;chksm=fd820329f474e058b2a1d77cdad4210241096535a48abc0bada994f55e6bf608c25918ac5a06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492475&amp;idx=3&amp;sn=2b170059f628151b0930adb940bf4f34&amp;chksm=fd5367e3b876b0ddc19924e7bbd50eb8fe279c1233fa2ef0f0ab1e77c915f1323e229c922e5b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科&amp;腾讯&amp;清华提出全球首个多模态Mamba生成框架ACTalker，支持多信号输入，数字人嘴型同步再升级！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enM1R1hvr6fIvNPnJ8HAkjER32Qr4uJljRDnNXhyE9UPgfaB2EKia2QjfDCSEHzibXgefW4NfoP8eNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由港科大、腾讯、清华联合发布的全球首个多模态Mamba驱动框架ACTalker，它是一个端到端的视频扩散框架，支持多信号控制和单信号控制，用于生成说话头部视频可以实现单/多信号随心切换，虚拟人嘴型同步</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492475&amp;idx=4&amp;sn=f4d2bb5450498be100d1310f874db258&amp;chksm=fd94e945934d5fda91c0fbe7c4ecf3c2f49fae802dde3582a623a400bc5cf574962e69d36d6a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 16 May 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>