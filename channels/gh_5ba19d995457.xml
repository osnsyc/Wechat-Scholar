<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[月之暗面开源音频模型Kimi-Audio，从「语音转文字」到「读心对话」，让AI听懂人类 “弦外之音”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNEC7g7nZPhc47aJoHlH9ymyhbNzAvibM4Zam09k4hqrh7JZEIVIibOtic48A/640?wxtype=jpeg&amp;wxfrom=0"/><p>近期，Kimi在语音交互领域发布了Kimi-Audio模型，这是一个开源音频基础模型，在音频理解、生成和对话方面表现出色。AI让机器不仅 “听到” 声音，更能 “听懂” 语言背后的情感、意图和语境。K</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492287&amp;idx=1&amp;sn=92def84f0ac1d364a13d26c853b9a39a&amp;chksm=fde6d6362b85c6e1325bd0fefa0084043da9dbaee17b52ae355f2b42c087b11fbcf99f06c86e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑革命，万物皆可插入！浙大/哈佛/南洋理工提出Insert Anything，告别PS抠图，AI让世界无缝生长。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7Ficnb2ehPShfDudYtibS1fkY0Su3IFmdP3MkS9KDH1gsquQnXh8Ku6TPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学、哈佛大学、南洋理工大学联合提出了统一的图像插入框架Insert Anything，支持多种实际场景，包括艺术创作、逼真的脸部交换、电影场景构图、虚拟服装试穿、配饰定制和数字道具更换，下图展示</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492287&amp;idx=2&amp;sn=2066bf4a0c95d1c2ea4fa6ce5d95d39d&amp;chksm=fd29478572360d392afff4550e2784fe0447f9ea2630546e69b12341d44ab46fb10e70d2da0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI编程神器Cursor，保姆级教程来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2hb9jqgpc7UzDRY9moSN30Gu953gF5tc8bQ8g3TMX1lth40K1FeMuKw/300?wxtype=jpeg&amp;wxfrom=0"/><p>一、下载与安装（很丝滑~）Cursor 是什么？想象一下，你有一个能把你的创意变成现实的造梦 AI 助手。不管你是想利用 AI 提高办公效率、开启科研提效模式，还是做一个小游戏、开发一个网站，甚至自己</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492287&amp;idx=3&amp;sn=9e95273e2e2b4defd0ac7e661a883cb7&amp;chksm=fd98f335a66322a2c14e466dce4a6492c019aa59132e5a60afb57888e407e9fe9a101f9cbe90&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字体控狂喜！Liblib AI 黑科技 RepText：无需理解文字，AI就能 1:1 复刻多国语言视觉效果。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elFfbYTqwA595BOINVFyGzKJTeUTfexNWrNdN8IAiaUICEpfK2hvFm6G9wMRKkN6XcT63ldibkLQRdg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Liblib AI提出了 RepText，可以使预训练的单语文本转图像生成模型能够以用户指定的字体准确渲染，或者更准确地说，复制多语种视觉文本，而无需真正理解这些字体。这样不管是中文、日文、韩文还是其</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=1&amp;sn=c8dde389ff8a0f42b34061cab88073b6&amp;chksm=fdf0f9eb452a4892b7f82eb19acd65b1e14c37788d677c80c74ef52200b5b244326f795075eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[142页深度解析：DeepSeek-R1的推理技术综述，AI的“思考”秘密大公开]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic74EgPzUnjibrG5SK0JmT8ksETRvVrR1XcCZjqetgGsxyQHiaa0hCYjVTIMhicnh9kAXbQjIYxYwDkxQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek-R1 就像是AI界的“思考者”，能够像人类一样进行复杂的推理和思考。在数学、编程、科学推理这些超难的任务上，它的表现简直逆天，直接对标OpenAI的o1正式版，妥妥的推理界“学霸”！</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=2&amp;sn=079a63c4faae9de36a250d6ab0172ab5&amp;chksm=fdbe448b6fa60dbe059c47e784aa4264a1e74e7ad1e11a13ef38aca213bf9d42b93cff16ca52&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港大&amp;Adobe联合提出图像生成模型PixelFlow，可直接在原始像素空间中运行，无需VAE即可进行端到端训练。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em57kq23EbSGQ52kUcSia6n8oTIJOicficBicZpibaJQgm7tEpQJ6psVkrLse6pjDUwqiaktvnGSEiaL6xPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港大学和Adobe联合提出了一种直接在原始像素空间中运行的图像生成模型PixelFlow，这种方法简化了图像生成过程，无需预先训练的变分自编码器 (VAE)，并使整个模型能够端到端训练。通过高效的级</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=3&amp;sn=03fb4e2b61fadb948acca9a182753435&amp;chksm=fd2f4f32850f34ec24a30633e9d9a6b5dc40c34fe93c497fee4fda605c32e158e15136caa975&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[英伟达提出最强「描述一切」模型 (DAM)，可生成图像或视频特定区域的详细描述，拿下7个基准SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECib2BYEbUlY3dMInZdicOKQibQAMwDLHA4kgviaROXJC16pncBthoyHBQJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达提出「描述一切」模型 (DAM)，这是一个强大的多模态大型语言模型，可以生成图像或视频中特定区域的详细描述。用户可以使用点、框、涂鸦或蒙版来指定区域，DAM 将提供这些区域的丰富且符合上下文的描</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=4&amp;sn=f87c6e35673a2de357f72417d46f40f5&amp;chksm=fdfe4ee608f84dfdbcaa172b57b0a824299ec9506d3453fbedd94f7f78e5c142221d1f694654&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别"纸片人"试衣！阿里&amp;浙大提出3DV-TON，用3D几何骨架+动态纹理场，让虚拟模特"活"出真实衣褶！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECFZTEAl6XrNJIs6kBFtCKh4H4USr1Odbdw4IOg8SSgUfrQQVgR52lmA/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里联合浙大提出3DV-TON，可生成高保真度和时间一致的视频试穿结果，3DV-TON是一种基于几何和纹理 3D 引导的新型扩散框架。 可处理各种类型的服装和身体姿势，同时准确还原服装细节并保持一致的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492245&amp;idx=1&amp;sn=160b95e244bf15f744324d221dc1dd79&amp;chksm=fdab9b8eeb0c58bd47cbac63040faf64c489e4abf3f0c42c0b6e22004deca12ce38d5d437ee7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌研究院联手牛津大学推出Bolt3D！7秒内单GPU生成高保真3D，推理成本直降300倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LR8w1T4XSJwAUg3UkzLpMRYxbTOuSXUEpxZVs5u18QTNFMFHe41E6SY6vfhMbJicRDetQWdibB3Nicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Bolt3D: Generating 3D Scenes in Seconds论文链接：https://arxiv.org/pdf/2503.14445开源代码：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492245&amp;idx=2&amp;sn=44b4076684d67ccb8491aae4497914ab&amp;chksm=fd7833f99e5a68599ff7aa5385ccc22036a213863ca81ce63f08c58154bc30754eef5b1f7e09&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[如何使用DeepSeek进行科研图表绘制？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsFkhhJibgYhskdb4vjUEaTlFuY2pp216d97E3UsjQZuBJkB8oBHK2OrmMP1t3zaSDLBxT6GhVGv5rQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>有时候我们写论文或者看 blog，看到别人画的很好看的结构图，觉得自己肯定画不了这么好。但是现在可以让大模型来帮我们结构图。一共需要用到两个工具：大模型、Draw.io。下面的示例会使用 Claude</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492245&amp;idx=3&amp;sn=5be82eee7d99fa053a202314f30e008e&amp;chksm=fd56add71bd4b4380107f11e0c1ff35383155d3ea37144bd199060773f3ae69066116af486a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[英伟达提出最强「描述一切」模型 (DAM)，可生成图像或视频特定区域的详细描述，拿下7个基准SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECib2BYEbUlY3dMInZdicOKQibQAMwDLHA4kgviaROXJC16pncBthoyHBQJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达提出「描述一切」模型 (DAM)，这是一个强大的多模态大型语言模型，可以生成图像或视频中特定区域的详细描述。用户可以使用点、框、涂鸦或蒙版来指定区域，DAM 将提供这些区域的丰富且符合上下文的描</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492244&amp;idx=1&amp;sn=b29d92197b4fb4155641dc59dc163c18&amp;chksm=fd16304a81081ad78b64487745ecbf79bd08d89cc4f25f2195e2805f9b946adeaad94b48399a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FramePack-F1：敏神全新算法重大更新！低显存ComfyUI可体验长视频生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGQdbH5tvxzar5TAtTxFX4G9Q9nTTmDOUmW2D7RDQfQTgEAkgeSRpgiaLL0F0qMLAoUcd96ndJ2Esmw/300?wxtype=jpeg&amp;wxfrom=0"/><p> FramePack-F1：全新算法和模型更新FramePack-F1简介在昨天的文章已经介绍过敏神最新基于混元视频的力作FramePack-F1模型，这是仅从前向帧预测未来帧的 FramePack </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492244&amp;idx=2&amp;sn=1832a2f7e1cc7f2a165d33af13b2533e&amp;chksm=fde265d7ccf7f1a05ed0e7220443693ca35085d784f94f5791c692253a729b499f917214a9ef&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492244&amp;idx=3&amp;sn=72f4f1941e206d1c9e970d1158ae4853&amp;chksm=fd58037ce5f18449fe170da1f968009f9173051ecebc102c1953b962a338611ff90ff89ba112&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源项目FastAPI-MCP，一键将FastAPI转换成MCP服务器，以后API=MCP。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5Nb69coNJjYwLrdDicA1kP6DUhlXhePTVYrhoZAuibXQhPthJOnFxIiaZvibmjL3GjGytM1LVUhBq7tJDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是我这个月看过的最有价值的开源项目了。MCP发布之后，很多粉丝朋友都有疑问，MCP跟API有什么区别呢？简单来说，MCP就是规定格式的API，这样才可以被AI模型来调用。现在有海量的API，但都没有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492244&amp;idx=4&amp;sn=c70bd2059be5dfbe50a13c4c97fe579d&amp;chksm=fda87d247f2afc2225aee2db0f6556669b81b280b43abbbae38f512e46c714f120e66852d512&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 06 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI界新王炸，输入提示词秒变PS大神？阶跃星辰开源图像编辑模型Step1X-Edit：19B参数对标GPT-4o。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el0tf0f2Ybm2uFN97TrfHYoqefkVHtmLwhySToicQuQpmNJTBkEoLFpYZ12wzayha9Qna8FEyr9LfQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>阶跃星辰公司近期宣布开源自家图像编辑领域模型Step1X-Edit，它使用多模态大语言模型处理参考图像和用户的编辑指令，提取潜在嵌入并与扩散图像解码器集成以获得目标图像。Step1X-Edit凭借其强</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492032&amp;idx=1&amp;sn=5c754023d6997a893f7fa731883665c6&amp;chksm=fd74a45ff856c873493409a686d49648c7965c05a638b6759328d53f219606b2c9fe1ceb8a83&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI视频生成新突破！字节提出一致性视频生成方法Phantom：通过跨模态对齐生成主题一致的视频，超多应用场景。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7FjUDMtLDDzOxeRDTsjoBO7nWymp4ibfUg4ngicJhNSbFdrgXOp81mHMKg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Phantom 是一个统一的视频生成框架，适用于单主题和多主题参考，基于现有的文本转视频和图像转视频架构构建。它通过重新设计联合文本-图像注入模型，利用文本-图像-视频三元组数据实现跨模态对齐。此外，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492032&amp;idx=2&amp;sn=dc9669111d07b5f21250912084085296&amp;chksm=fd9fa1d1bdeb829ba531bac91c217255a2739c078beb6a2dfd9862e786ff93bd1a2fb53f4299&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[GitHub高星精选！十大MCP开源项目，让AI开发效率翻倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIo9DPdialhPibJ7DTfOC3LKTAsac5ElxFbtZZzIbVJBNAichgiaXldG96fwibUCoTkVHmExKYq6n85wvibA/300?wxtype=jpeg&amp;wxfrom=0"/><p>导语2025年，MCP（Model Context Protocol）作为连接AI模型与现实世界的核心协议，正在重塑智能应用的开发范式！今天为大家盘点GitHub上10个高星MCP开源项目，覆盖聊天助</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492032&amp;idx=3&amp;sn=e4c9145106694d220902686a1d033a24&amp;chksm=fd1a5cbca6e992cfb95bbab1b07af724e7b62844043b9990774b77e53a0b67c173aa8a54dc4e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦大学提出GenPTW！AIGC水印技术新标杆！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IkWicmfRJFB8Rhcm9pq12BDzLM21lBkN6dAG83v6ib9Ea7Q7zka1iagUuP1kNYXWCiaOkzficiabqzOZVw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：GenPTW:In-Generation Image Watermarking for Provenance Tracing and Tamper Localization论文</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492032&amp;idx=4&amp;sn=220abde172d331505b4e9319f3f1c9a7&amp;chksm=fd7890cd8382820bec2c3358e788f545b8a6c773353eff3b7beeec2fce018cbe5580149e4170&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 05 May 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>