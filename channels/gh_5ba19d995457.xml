<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[IBM提出多模式图像文本到文本模型SmolDocling，可实现代码 | 公示 | 图表 | 表格 | 标题 高效转换！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eniaAibjBDYoftj8VvjntaLlaylgswEom4XlMibkcGxuU4WPZLbljDmFWMIMhdEh2dicYGoicXToiaibicmeQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>Docling团队联合IBM提出了一种多模式图像文本到文本模型SmolDocling，旨在实现高效的文档转换。它保留了 Docling 最受欢迎的功能，同时通过无缝支持DoclingDocuments</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=1&amp;sn=010ea784d33ceb329b4a04e147ca3153&amp;chksm=fdd8ae754e681e26bb8c60d581ec8e75ca5706d781fc2ab16e8e282f71e96204b7864abb448e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Seed-Music：字节跳动开发的音乐生成模型 支持多种数据输入生成和编辑音乐！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elIm6icxMVSQ1CxgxFiaRZRxgIpSB6lVKMSWd1DpYwO7bNGaOdrtXY1KXTzkCV8N36E83o4z8JLtxBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Seed-Music是一个由字节跳动研发的音乐生成模型，用户可以通过输入多模态数据（如文本描述、音频参考、乐谱、声音提示等）来生成音乐，并且提供了方便的后期编辑功能，比如修改歌词或旋律。Seed-Mu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=2&amp;sn=80c2ec88726a7f84465884cb48669d1e&amp;chksm=fda8dd3f13ed2c87d83ad45468cbcdd173027579147d66e67bf2d4f75b2d4dbca213339829c7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[震惊！东京大学提出ARTalk！语音驱动3D面部动画大突破！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JgxI2td6MuHkKtXCMBGlVyNoBucDYsH1Jct1PGOib0q03Jn6GdpLz4QjrI8emN5ohoxj6WzEHv54w/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model论文链接：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=3&amp;sn=1bb8126cf37e8a7b73a9348de9b19635&amp;chksm=fdc4d8e988c30a3bac9b8427a0da16eddf0a9cb6dd806279c085c24b69bf993f2f4303546b61&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekB7CXUYR45xqh1P2Q9zWuxgmicJiaO6JPkkhoaibkSARt6qftWXI9ofZjt9NK9vuibg0UrfhA2kTPRaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT今天介绍的文章来自公众号粉丝投稿，腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT，给定一个人像图像和一个衣物图像，就可以生成一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=4&amp;sn=601ed5357aa17567be89bfab06be7be7&amp;chksm=fd055b9e798e780cf50e543c44d5812d75a43ca52040a10453de614a26df5686bde92174bcb7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Window上6G显存就能跑文/图生3D？腾讯开源Hunyuan3D-2 Windows 便携版，轻松运行腾讯混元3D 2.0!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq6yAm26wF7SoU3RDfeYGDhleng8ndFk1MlsjEAbEoPWPzsibkOCMS4tkQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>混元 3D 2.0 Windows 整合包提供了 Hunyuan3D-2 的 Windows 便携版，简化安装流程，支持本地运行几何生成、纹理合成及文本转 3D 功能，适用于 NVIDIA GPU 用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491190&amp;idx=1&amp;sn=bc58d7fc1960c661be4d5a30379ab67d&amp;chksm=fd5b80db9573b90e52d69671fde6e3c4cc248b843a92a64573f2e0f759260866254dcf60eb13&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Mar 2025 23:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯发布混元-3D 2.0: 首个开源高质3D-DiT生成大模型，几何结构更加精致，纹理色彩更加丰富。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enScf5fx9rxa1dXnvYHW4G815SyibP84GYLJGItGoKdb7k8ibSoFf2UCRYRf4VJVbpVm4IevhxibbLDw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过腾讯HunYuan-3D 1.0，感兴趣的小伙伴可以点击下面链接阅读~腾讯发布HunYuan-3D，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。HunY</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491190&amp;idx=2&amp;sn=a04d0253994d6d588be8fc91e083b79a&amp;chksm=fdde11091b5bf784e6fa93653f648cb775e2630f6060111837af6052e4536e475666140c5909&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Mar 2025 23:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯HunYuan-3D 1.0，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elMhPFZCKibTiaBKrjL4Yql4lFH5tVlYMlAnW2RYL3JiaF4vHrEFr3z5TWpyzCAENlicH9DuH5PnpYic3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>HunYuan-3D支持文本到3D和图像到3D功能，包括网格和纹理提取在内，整个过程在 10 秒内完成。文本到 3D：用户可以通过简单的文本描述生成 3D 对象。例如，描述一片绿叶或一把棕色吉他，模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491190&amp;idx=3&amp;sn=b3c35203f25ea9310f8d632cd07ffdd6&amp;chksm=fd5ef028217832b26187a9e766a72fb582d47fa0ea7ec57550dec78a90b81dcfbae827d2bb58&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Mar 2025 23:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI听觉革命！港科大×月之暗面发布AudioX，文字/视频/图片秒变天籁神曲！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enAqmicvH5JOXsTyWrTA6QL4Qw0324EibX2dlA4ibkqCvfZTBSib6iaz47XXY5VgjdgsGwwMQ3jVeATNhA/640?wxtype=jpeg&amp;wxfrom=0"/><p>香港科技大学和月之暗面联合提出的专门用于从任意内容生成音频和音 乐模型AudioX。该模型能处理多种输入模态,包括文本、视频、图像、音乐和音频,生成高质量的音频输出。核心创新在于多模态掩码训练策略,通</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491146&amp;idx=1&amp;sn=6c7e44da48e935f95db6ca3730bba1f0&amp;chksm=fd4d73036dc39f75a159da28c3bffb453f1e290245b8de62476d22f13a97502059a66d4c4709&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Mar 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多身份定制化视频创作新突破！Ingredients：可将多个身份照片整合进视频创作实现个性化视频生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcicdv0XZf04MKlYliaBmemOkIOtBU0wKu89VAd3lkLkDU9GOLfc5OIqIjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在当今这个数字内容爆炸的时代，视频创作已成为连接人与人、传递信息与情感的重要桥梁。然而，如何高效、高质量地实现多身份定制化视频创作，一直是视频制作领域的一大挑战。近日，北京昆仑研究院的研究团队提出了一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491146&amp;idx=2&amp;sn=b3c6c4f24c56449c6f1ec94cb4604bb2&amp;chksm=fde2d699a238cb317e28b503cb77d9bc514d82529457cadd8a5da0efa43bf6fad0ce7f7a614c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Mar 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单张照片生成3D头部模型！Adobe提出FaceLift，从单一人脸图像重建360度头部模型。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4qXFbiaEqoEPejUQNwuqLOrpIE3WmoKJBxjrMnCoHDn3huArYyaCa7Ew/300?wxtype=jpeg&amp;wxfrom=0"/><p>FaceLift是Adobe和加州大学默塞德分校推出的单图像到3D头部模型的转换技术,能从单一的人脸图像中重建出360度的头部模型。FaceLift基于两阶段的流程实现:基于扩散的多视图生成模型从单张</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491146&amp;idx=3&amp;sn=43312724357bb1f07a3ea397ac79bbf9&amp;chksm=fdf6c7c4688fb74ea96b2e3e35696fdaeb18201a59cd7ed05909f4530ae087daaeb6ac596603&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Mar 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LBM：用于图像到图像直接快速转换，支持可控照明、图像恢复、物体移除等功能！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eniaAibjBDYoftj8VvjntaLlazzrjyAuCaxtUgTmwTpbpXdlUbj1mP1pmA9QicicVlSzvQAT83J2fYzAA/640?wxtype=jpeg&amp;wxfrom=0"/><p>LBM是一种新型、多功能且可扩展的方法，它依赖于潜在空间中的桥匹配来实现快速的图像到图像转换。该方法仅使用一个推理步骤即可在各种图像到图像任务中达到最佳效果。除了效率之外，该方法在不同图像转换任务（例</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491145&amp;idx=1&amp;sn=634fac8d9ea595075a47b53234a9bb6e&amp;chksm=fdd5ea90c709df77094ec95009f3bfc05b1c63bc308c459db6bc8df21dc5515d1d27c68bde06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 多实例扩散模型MIDI：可从单个图像创建高保真 3D 场景，模型&amp;代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emQH9S7pGDiaODq1bPiaoKg0UwQg0Pd1kyLMVicNPaNIDRbCcjvvBMqMbicEWI8LS5IVX4LjXG1tHR3Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>MIDI 是一种 3D 生成模型，用于从单幅图像生成合成 3D 场景。与依赖重建或检索技术的现有方法或采用多阶段逐个对象生成的最新方法不同，MIDI 将预训练的图像到 3D 对象生成模型扩展为多实例扩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491145&amp;idx=2&amp;sn=1fc54bdf95dfe0744559c199843bde39&amp;chksm=fd927151fd8eb3bbe9cbf32391801357cc9151e0ff890b22082dfee41432d0d7aaa8df0d2dc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491145&amp;idx=3&amp;sn=2ba230053e3532c4eaa82000472e9f44&amp;chksm=fdc6b343b7a3f3c4dbeee794937659987f7cdc636ec953cda7ae7a38e5415b491e1606e0b376&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从故事直接生成视频？一起来看DreamRunner如何重塑内容创作。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em0iaj7vmt3M8WRLr6mq22stzrb2ORCEYsI27cibQt41Hzt6FKUSn3V7ianSHVRapnj3w9FKpNt3jwDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天为大家介绍一种新的故事到视频生成方法-DreamRunner，它能够将文本脚本转化为长篇、多动作、多场景的视频，让故事跃然屏上。通过大型语言模型、检索增强技术和新颖的3D注意力模块，实现了对象精细</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491144&amp;idx=1&amp;sn=527085cf04e65dcc40786ac83f999b49&amp;chksm=fd0b62998addb3b9b1e4ac7a1a2c0e212795810c43f31a84ef65955f4af322d034cdcb888af3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[人类运动生成新方法MoMask：可将文本描述作为输入并生成相应的高质量人体运动动作]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enScf5fx9rxa1dXnvYHW4G8O9hft4BsqOTmwYEXsfgumPYvUYjCh2XTNsWpfHC7OEh6xL16D8nmMA/300?wxtype=jpeg&amp;wxfrom=0"/><p>该图展示了 MoMask （一种最先进的人体运动生成模型）生成的运动示例。MoMask 使用文本到运动范式进行操作，其中它将文本描述作为输入并生成相应的高质量人体运动。这种方法确保生成的动作准确反映给</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491144&amp;idx=2&amp;sn=b6c2ad0daa4abe41f377e4defea21fd3&amp;chksm=fd4391fd66eb48093f740f30f326c15465961868d925ea0432ffa11dbc53a7cb5e176e064051&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像超分辨新SOTA！南洋理工提出InvSR,利用大模型图像先验提高SR性能, 登上Huggingface热门项目。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emvRmmSX73ApBN83mPSIUnndGUoqrp8dTsfo3BKVIVGVNf5sWoXGauJCgAEaaCQm9Qb7QfuM34qZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>南洋理工大学的研究者们提出了一种基于扩散反演的新型图像超分辨率 (SR) 技术，可以利用大型预训练扩散模型中蕴含的丰富图像先验来提高 SR 性能。该方法的核心是一个深度噪声预测器，用于估计前向扩散过程</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491144&amp;idx=3&amp;sn=d449b3cd829b0149c870eee4453c8b52&amp;chksm=fdf6282d9b01e5e52e10a03f6ad5ee6937818f0b6f515f6122b8fa783f0255f0fde2c9d684af&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 多实例扩散模型MIDI：可从单个图像创建高保真 3D 场景，模型&amp;代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emQH9S7pGDiaODq1bPiaoKg0UwQg0Pd1kyLMVicNPaNIDRbCcjvvBMqMbicEWI8LS5IVX4LjXG1tHR3Ww/640?wxtype=jpeg&amp;wxfrom=0"/><p>MIDI 是一种 3D 生成模型，用于从单幅图像生成合成 3D 场景。与依赖重建或检索技术的现有方法或采用多阶段逐个对象生成的最新方法不同，MIDI 将预训练的图像到 3D 对象生成模型扩展为多实例扩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491095&amp;idx=1&amp;sn=85d958a51022cf7e925ab3491e2e5f45&amp;chksm=fd8b32da5366595615b3b53cde0812909af362b3d5b4e111c7e7db4451c470b5178731701cb9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 机器人双臂操控新突破！KStar Diffuser如何解决自碰撞与运动约束世纪难题？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojvz9clmicqUEHWru0TSQwicibDxwd6pXeiac1QbZwUoibnWeMnE5ib2jBibpdEXVK5T4bFCwMWWK9BcS4dg/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2503.10743亮点直击与现有方法仅在笛卡尔空间中优化末端执行器姿态不同，提出了一种新颖的时空机器人图，显式地建模机器人物理配置，以指导生成动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491095&amp;idx=2&amp;sn=a43ce9bacb8fc5cd2f97f6e717ed4f7a&amp;chksm=fd0102af1774207828e3b6cb374952fb09b1e8b687c2d11f2fe986c792e02429768661b93a8e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[利用多模态模型赋能，SONY团队完成音乐到音乐视频描述生成大突破！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Jn7gNOibialUb7ePwaNgQPKeSIN3Kfa1hwX15JM3vgCh8jl1Fm3ZyyqibhJ0YwwiaTxARyLn4ucxtkUw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Cross-Modal Learning for Music-to-Music-Video Description Generation论文链接：https://arxiv.o</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491095&amp;idx=3&amp;sn=f8a3a85cc2c4eeb581aeaf949bc70993&amp;chksm=fd79f8b1adb1359fe84e9e6f83543a09949da62d8477714ceed47192aadfd7b0965453f9e552&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大×月之暗面发布AudioX，文字/视频/图片秒变天籁！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>香港科技大学和月之暗面联合提出的专门用于从任意内容生成音频和音乐模型AudioX。该模型能处理多种输入模态,包括文本、视频、图像、音乐和音频,生成高质量的音频输出。核心创新在于多模态掩码训练策略,通过</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491095&amp;idx=4&amp;sn=25831a6d8744c0b9765b0d7d5e9f6ced&amp;chksm=fd3c592325e214ebf96d49d067b539b9c6417e29b03b34bbe3bf33f9f55c1aae6beac80e21e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 19 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 革新Transformer！何恺明联手LeCun提出DyT：归一化不再是必需？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1ooajMkbIFOmToYOkf8bGybVBib7s52Qh37f3FnLf24sWvTNFVjtzAMA/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，何恺明与LeCun两大巨头联手，对传统Transformer模型提出了颠覆性的改进——他们发现，长期以来被视为必不可少的归一化技术，或许可以被一种更为简单的方法所替代。这一发现不仅挑战了现有的神</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491077&amp;idx=1&amp;sn=5b9cc94084c1f2c59d5ce0162c993798&amp;chksm=fdb3a784a1605c54ce89ee4eefb494c1a84c4b9207b5590fae69b7efb1bb9d624c576544fa6c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491077&amp;idx=2&amp;sn=c402cd18055206edd349bf70a3a01a99&amp;chksm=fd002a6475afbbed4992d83974755b8bd7d4828e1830b3b60d91603b1b590f666e9de03e3a32&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里推出升级版AI翻译工具：Marco MT 性能超越Google、DeepL和ChatGPT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekDYMeOJw6PMrPrgUmBfVvICGVGwvK1ZowHkm5otQN1GWBq1oKgOpXCvFcU6T8e0WgLCSBUqvcfmg/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里巴巴的国际业务部门于推出了一款升级版的AI翻译工具，名为Marco MT。这款工具在翻译性能上超越了Google、DeepL和ChatGPT的同类产品。该工具的目标是帮助商户更好地在全球市场销售，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491077&amp;idx=3&amp;sn=8ca6fdbcee6dcc29da4038d1497cfc5a&amp;chksm=fd3e2e82e9fa19254f2be3ec7d7c30b0e510cf264fb59c95bddc26bf4b030727f46105e4c3c5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出虚拟试衣新方法EARSB，让时尚与科技完美融合！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2empB05GMsROweibZLQdTRdryhxs0ChYaSb8Q7MXgpODuC675ClEZrLFicPt5eWjzKjxOHWcsP2ic7rBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在数字化浪潮席卷全球的今天，科技正以前所未有的方式融入我们的生活，包括我们追求时尚的方式。想象一下，无需亲临实体店，只需轻点屏幕，就能轻松试穿心仪的衣物，这不再是遥不可及的梦想。NVIDIA联合波士顿</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491077&amp;idx=4&amp;sn=eea9f97b23811a912c998e9adf84b343&amp;chksm=fd153d0336e0da365ecdaf5a939f9ec9e80e48c73ba68a2db9c0bcc75bcdff2d36315e194156&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 18 Mar 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>