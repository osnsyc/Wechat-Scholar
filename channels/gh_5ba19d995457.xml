<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[ICCV 2025 | 港科大&amp;商汤等提出3D生成框架CoPart和首个3D物体数据集，开启3D生成“从一到多”新纪元。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45IqouPaRapq8gWkGsbxM1dTO9s8LcAth8EpxCCuuF5TTMQPvpUxibvkflknA/640?wxtype=jpeg&amp;wxfrom=0"/><p>香港科技大学、香港中文大学、商汤科技研究院提出了一个全新的基于部件的 3D 生成框架CoPart ，它能够通过多个上下文部件潜在特征来表示 3D 对象，并同时生成连贯的 3D 部件。并且还发布了首个已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=1&amp;sn=91ac5035c23845d5ebbc8e7c22593048&amp;chksm=fd264d523ecfd9c20cec2808d13c910f453a8fc64f3dcab7130d1108bf821f40e213f637c502&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[自动生成ComfyUI工作流？英伟达提出ComfyGen：通过LLM来生成匹配文本的工作流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eny4Iriba5NSXkHvLxicLITJDqnLYd3byQhrC0bKwIGSOFEPvibmO8gTicw8bg8Y16oLT3TR7jWM7j2AA/300?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyGen的核心在于通过LLM来匹配给定的文本提示与合适的工作流程。该方法从500个来自用户的多样化提示生成图像，随后使用一系列美学预测模型对生成结果进行评分。这些评分与相应的工作流程形成了一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=2&amp;sn=1a210355a13a70904ac362f166b39866&amp;chksm=fdac5bf7acb4c86844eb5f91193e4ecfe12dd7d5c67211e864f845eef1516bd47d7c4556a86f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[GigaAI发布全球首个解耦式人体视频生成框架HumanDreamer，可生成由文本到姿态到人体的高质量视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7F3dWu899ia30B7OUIZdlXFicRk96bnw8CxvB7cawibZFt7o1OsHwARZWlw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由GigaAI、北大、港中文联合提出了一个解耦的人体视频生成框架HumanDreamer，可以根据文本提示生成各种姿势，然后利用这些姿势生成人体运动视频。此外论文还提出了用于人体运动姿势生成的最大数据</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=3&amp;sn=4f8a628a92f50c611e94f96f65c28926&amp;chksm=fdbdc2555ea3b86ddad48d875db1f4f0f5f57d84aad87d347f198abd4592ff729b2a7de9db66&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北大提出高效视频生成框架Magic 1-For-1！一分钟即可生成1min时长的高质量视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Im7d1myrXRAiarmcWtBLIuFK9FQGib66tAQmlDsP6icPCQpkZ9dLLmVqzlmibR6zRCHiaJSK7kuibJkGmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>计算机视觉最新论文今日论文推荐论文名：Magic 1-For-1: Generating One Minute Video Clips within One Minute论文链接：https://ar</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=4&amp;sn=4c907de5a4ab06fe66a483f3be9f66d7&amp;chksm=fd4cae3243305cedc5cf051df6a541e18011596d2ae0f7297a35b0cf65da41ee985a21c05e01&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里重磅开源Qwen-Image：200亿参数MMDiT模型，SOTA级卓越中文渲染，海报/PPT/文案设计一键搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ema74qVxKj0HCrThBTWG0dFqtnpdqkibjicsufldwWH5sSWGB3DllIqOJWFLl0EFqtUcicE2PgvEG9dA/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里通义千问发布了首个开源图像生成基础模型Qwen-Image，Qwen-Image是一个200亿参数的MMDiT模型，是通义千问系列中首个图像生成基础模型。主要特性包括：卓越的文本渲染能力: Qwe</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494559&amp;idx=1&amp;sn=5379ef61226c4204729706aa68b00fce&amp;chksm=fd103ec8eebbe90f43f5fe25651aa9e001145de2bedcea379883ba19c937324c09f89efa23a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[重构图像编辑！ComfyUI 原生支持 HiDream E1.1，真正开启「自然语言改图」新时代。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE5NTaVjpZ3bk5vDpSbE1hBc7keDkNib2UkUne9RfxEoRwQWTr6U6ZNLicQmWoBibs9fclxMl6m3no0og/300?wxtype=jpeg&amp;wxfrom=0"/><p>你有没有想过，未来的图像编辑，不再是鼠标点点涂抹，而是像跟设计师对话一样——你说一声“把这只猫变成火箭侠”，AI立马给你实现？现在，不是“未来”了，这已经被 HiDream E1.1 搬到了 Comf</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494559&amp;idx=2&amp;sn=b3226e80438760f76e24c48185df8c6c&amp;chksm=fd638f865523b6f8a765fe89879789eb4ba0e6fd9b90934e08e153c93a3a4999d01220b03abe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI时代职场生存指南！微软公布“最容易被AI替代”和“最不容易被AI替代”职业报告，避开高危职业，拥抱新机遇！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45Iqouv4a8VOjh7iabrSiajsu7cpvdNxVzKonXeCaXxrhL17yricSm2vtJV63DA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在科技日新月异的今天，生成式人工智能（AI）正以前所未有的速度渗透进我们的工作与生活。近日，微软研究院联合微软团队发布了一项重要研究——《Working with AI: Measuring the </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494559&amp;idx=3&amp;sn=5a53820c0d966ae0455b3295c2f5eb22&amp;chksm=fd600f0ec1300cd27361f0508a135ef24153106ab488ac95c95a9595fa43edf2b432321a850a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大&amp;美团提出PosterCraft，文字渲染与艺术融合，从创意到成品只需一步！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elRPnxm15EcjBGoXOC5AYqzmibC3IibyVqwj02b3JZwTrRYibZ5X4eYgJcibSRkrEYHSF6tueI2pO8OFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一款由香港科技大学和美团联合开发的创新性海报生成模型框架：PosterCraft，其擅长精确的文本渲染、抽象艺术的无缝集成、醒目的布局和风格的和谐。PosterCraft 的设计理念是统</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494559&amp;idx=4&amp;sn=e84ac6500741e5b1aac414790575ccd8&amp;chksm=fdcf8814250c5ab91c18158bbda54d99122df5e2d85131a7e5dfede967fbf4f6f82a877e7ece&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[实时魔法降临！Decart推出全球首个直播AI视频生成模型MirageLSD，24FPS实时生成零延迟、无时长限制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45Iqoua2PibNicnuedMFXuGp46gKjZiaIZiceXrtPryTsX8D3WXw9HJg4ibFULg8A/640?wxtype=jpeg&amp;wxfrom=0"/><p>Decart推出首个直播扩散AI视频模型—MirageLSD。不同于Veo等市面上时长有限、存在延时的视频生成模型，Mirage可以实时转换无限长的视频流，1080P处理响应时间小于40毫秒，彻底消除</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494526&amp;idx=1&amp;sn=51333d0373a4ce6e92fa0871bad2f7de&amp;chksm=fd847afefe086432da9afaf4be4d8090413ce2005f5fdcf90d8d87b2484f348b912dca6bd2af&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[浙大提出RealCam-I2V！精确相机控制的新型视频生成I2V框架！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXW2QTHDiatN7k4pGOJfic1lBfxyVelPRsL0aibr9cCI1YRoX6z1QXcP1lKA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control论</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494526&amp;idx=2&amp;sn=be1d4217b3d1b254682bbd54787e20c5&amp;chksm=fdcafe944980187dc0aa9329fee24a237b48551ec1db87959fa67210f922c5c33ac8e42260cc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多领域SOTA诞生！Vid2World：打通视频扩散到世界模型的“任督二脉”｜清华、重大]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaeFVcHGjGc24PwYRxSa3SRzxraaxquD1Y4eiapCrHo7GN2pjc3L4XfolskYUicsqxRONc0Q9o3iaR8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文链接：https://arxiv.org/pdf/2505.14357 项目链接：https://knightnemo.github.io/vid2world/ 生成效果速览亮点直击首个系统性探索</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494526&amp;idx=3&amp;sn=92af001d8054c9fbc79259e8592e2fde&amp;chksm=fd03f4eecbfb3fd4b9d1a3c7d5adb9209bb6e3bb38442b41521c22ce960ebb647e56f7f3eb7b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq5BIttmnJoy6onMGT6hEJiblmfujJkZFpZjpO6usAYRtw7aj1tZbJZYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元团队提出的 HunyuanVideo-Avatar 是一个基于多模态扩散变换器（MM-DiT）的模型，能够生成动态、情绪可控和多角色对话视频。支持仅 10GB VRAM 的单 GPU运行，支持</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494526&amp;idx=4&amp;sn=485c91a9b0694eec487932f0bae09411&amp;chksm=fdcf04cca76b287738f7ad0828dfe9e704d581a6841f305a9788cd3f8e46c9efefcff5147b32&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 04 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI时代职场生存指南！微软公布“最容易被AI替代”和“最不容易被AI替代”职业报告，避开高危职业，拥抱新机遇！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45Iqouv4a8VOjh7iabrSiajsu7cpvdNxVzKonXeCaXxrhL17yricSm2vtJV63DA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在科技日新月异的今天，生成式人工智能（AI）正以前所未有的速度渗透进我们的工作与生活。近日，微软研究院联合微软团队发布了一项重要研究——《Working with AI: Measuring the </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=1&amp;sn=6821a4cd9b855a8cee6766d9c8a55b25&amp;chksm=fd3e575a49958b01a2817db80a2011c7ab131c243efff247ef2e33b5893ebddcc9942809bca9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出新框架ImageRAG！RAG+AIGC提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JK3j8AP855QOPLGKEpd37E3bPLWmIOj4bSM2oUxbcSEQ3NFVFyqRhEKjhBGvFkPMAwAaMsbszianQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation论文链接：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=2&amp;sn=2e4ee84eb60755441043a6e20c33ded0&amp;chksm=fd0cddbe3403eed7be30fb2c5ada2c9604fa4f5fa9313e6045a0a8888cd8f3fefa3b3ad0bf2a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文了解 DeepResearch：AI 如何重塑深度研究与知识整合]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIo0ia75NSGFsObsIAKtZ35qIl2VrDtpaxMVkxU4QsGhZJdF0ZqOibRyJfONRdRTChR9oaFpPcAt00ug/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，AI 工具逐渐从“快速问答”向“深度研究”跃迁。DeepResearch（深度研究）正是这一浪潮中的代表性技术，它通过多步骤推理、海量信息整合与结构化报告生成，将原本需要数天的人工研究任务压缩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=3&amp;sn=1dfd0fbea8dbdfb036e7a6b7a3dc7e91&amp;chksm=fd1f668fe4fe0777e78f07eb25b66028aa551866ea6ac8d1e453e42ac35d70c4185ca562d50f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南开提出1Prompt1Story，无需训练，可通过单个连接提示实现一致的文本到图像生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzPNo4OCBUcdtmaQJs6N0wWib04FeoPN0dUqhYsAJa4gIVOeKpt04Ox35gLkECLB9LEJGNnrDPu9g/300?wxtype=jpeg&amp;wxfrom=0"/><p>（1Prompt1Story）是一种无训练的文本到图像生成方法，通过整合多个提示为一个长句子，并结合奇异值重加权（SVR）和身份保持交叉注意力（IPCA）技术，解决了生成图像中身份不一致的问题，同时保</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=4&amp;sn=df996bacb4a74e8df8fddf3c87c6063a&amp;chksm=fd52a93cb741df3e31740765f03a031bfac37323943192291aff3f3085ad33a550226f9969e8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI生成彻底告别AI味！FLUX.1-Krea-dev开源：美学控制与真实感双突破，兼容FLUX生态，3行代码即可调用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45IqouLvtSzXKAXQbVT0N76xGCRBHD3zZvWY3h5UC1xpD2KLKfw2b1iaZoR4A/640?wxtype=jpeg&amp;wxfrom=0"/><p>Black Forest Labs 和 Krea 一起开源了一个新的图像模型 FLUX.1-Krea-dev,旨在提供卓越的美学控制和图像质量。该检查点是一个引导式蒸馏模型，与FLUX.1-dev 完</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494502&amp;idx=1&amp;sn=42b064fd9195ced0fdeaf22e3a1899ef&amp;chksm=fd552e4dfc6f9840962061897581947172e262063bed08d4a1bdded4078c3589fc33c2842fba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekB7CXUYR45xqh1P2Q9zWuxgmicJiaO6JPkkhoaibkSARt6qftWXI9ofZjt9NK9vuibg0UrfhA2kTPRaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT今天介绍的文章来自公众号粉丝投稿，腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT，给定一个人像图像和一个衣物图像，就可以生成一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494502&amp;idx=2&amp;sn=09c0bd46a21900d950a75cbc149d8b86&amp;chksm=fda1f990c324c355b573527994ed24e1e4fb6155f154af9f0c37c95311417ad4f78097d369ea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494502&amp;idx=3&amp;sn=3c39f468b26adba4939b5dd7539f4744&amp;chksm=fd46bd05c5a8ce34ee32e9c0509074d545cdfdd53d0d40f00c2d10f0fdbe53919e0d4df39515&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 北大提出FreeCloth：面向复杂人体衣物建模的自由生成方法，宽松服装实现高保真细节保留。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekZpjibRlqzZJvpnCtIusibumvetVwHLtQfibNRV5NCjOk9fMZ0qoTnYiblqn55YqgfyU1srg7kyibibCXA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京大学王亦洲课题组提出的名为 FreeCloth 的基于点云的混合式人体衣物建模方案，突破了现有方法在宽松衣物建模中的技术瓶颈。针对宽松衣物与骨骼运动关联性较弱的特点，该方法采用无约束自由生成网络</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494502&amp;idx=4&amp;sn=8671e6515c9ac2c100def1db6bc6433e&amp;chksm=fd9f574acf5c713f482c23f2d87d8f1fd712cb3151065cad10240692cc3f805455c073858803&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[智谱开源最强旗舰GLM‑4.5：挑战全球前列的开源旗舰大模型，专为智能体应用打造。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwVVjR2OrKwpn9VSkHhJHiavcjHQXgWGNzfttuXB3k7dzM4wc625Lbzr79ic8QdqP434KGiaQURcQTg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在 2025 年 7 月28日，智谱正式推出 GLM‑4.5 系列大模型，这是继 GLM‑4 系列之后的又一次全面升级，也是智谱首次面向智能 Agent 应用场景定制的旗舰级基础模型。GLM‑4.5 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494411&amp;idx=1&amp;sn=bf03f057f85c2584c882ad1d25893c0e&amp;chksm=fd8153ef19c6469610015ead3fcc18fced56226835b9e772b15fe3a19da0e5aed554bf70c0a2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MeshAnything V2来了！30秒生成建模师级Mesh，最大可生成面数提升至1600。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKcprhHqENugIHSUTwb3EOjn5XkV1zK43LvhbUTOvgJ8MMYraTDSoeD7ibTHT3bGcxX9ic5uAQfLGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>GitHub已揽星1.9k的MeshAnything项目上新了V2版本，由来自南洋理工大学、清华大学、帝国理工学院、西湖大学等研究人员完成。MeshAnything V2相比V1，使用了最新提出的Ad</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494411&amp;idx=2&amp;sn=a413c7b5d67f8256a1cddc9dfbf4c2dc&amp;chksm=fd31b7d707ad0fea71296c50bb0e142523946287776b1285cb24b3ca4098ceed3b530291f69e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[突破GPU内存限制！VGGT-Long开源：首次将单目重建推至千米级、无边界室外环境]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/rFGeIHcFicWekTZib9BbIiaTmjnAkRWiaU6oZOyDb1XYo2PaGL8LwFicFIe8v6aTqzZb3Yia0FKibVHttq7YHJ5gL6DbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>挖掘基础模型的潜力从单目RGB视频流中感知三维环境是自动驾驶的关键能力，然而现有方法在处理千米级长度且未标定的序列时仍面临困难。与小尺度的室内三维视觉任务不同，自动驾驶场景涉及长轨迹、稀疏的帧间关联、</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494411&amp;idx=3&amp;sn=cfe14310317924d22d48204a111fcf51&amp;chksm=fd5d38279d657f0a5978a3444b14246a5b7f780cecab3d3f35a8199801bddb684bc33b625cd2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从单口相声到群口辩论：中山大学&amp;美团开源MultiTalk：多角色对话生成SOTA模型，语音-视觉对齐精度达98.7%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enfUCFX9WW23BajIFJBpRq3lz9nCs5icOy90Hv0zVbmIjdyTsfJWWDS7Fo3ugfyXkMKIEyJEtsAoHg/300?wxtype=jpeg&amp;wxfrom=0"/><p>由中山大学、美团、港科大开源的 MultiTalk 可实现多虚拟人对话视频生成。在语音与嘴形同步方面达到了SOTA性能，并支持通过prompt实现人物、物体与场景的交互。相关链接主页：https://</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494411&amp;idx=4&amp;sn=1368947368c0905b8dbb87f3fcf142d9&amp;chksm=fd625ea8204b5c5770529ec2a2ed262dd308411839f33fffc8018cea9628d5ab4b2f5705f8a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一沙一世界，一花一天堂！腾讯发布首个开源、可仿真、沉浸式3D世界生成模型 HunyuanWorld-1.0!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPCjTfhE2exCxyco6laPao2lnHZq3ogpmmib5iasCmJnXmWuMH87RJ0LxT6CnuVbvj0gdyn5g39w6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>计算机视觉与图形学中，从文本或图像创建可沉浸交互的 3D 世界挑战重重。现有基于视频的方法多样却缺 3D 一致性与渲染效率，基于 3D 的方法有几何一致性，但受训练数据和内存效率限制。腾讯开源的 Hu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494385&amp;idx=1&amp;sn=e0adc354dad8f32f1aa8625e918a7a6b&amp;chksm=fdba33584d8f35ede3c538b7bbe57671aa61817a86cb7ac00d2b02fb29c7ccdd772a1811407f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[让SDXL实现50倍加速！中山&amp;字节最新对抗训练+双空间判别，单步生成新标杆！性能狂飙]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoia1S5Ym7bibDIvuNABiayExIP2s1GG5jBXCzgctBupACNEyZWybv3icTdFsEZwl5CqqkmoQ0LiciazJ76Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章地址：https://arxiv.org/pdf/2507.18569 亮点直击对抗分布匹配（ADM）：提出一种新的对抗学习框架，利用扩散判别器在隐空间对齐真实和伪造分数估计器的预测，替代传统显式</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494385&amp;idx=2&amp;sn=880010a11bda7a1cf1f7ad4f6ffe35d1&amp;chksm=fdf917e4d34d7ef939f2504bae652668a1ccfce0b49f37667fc1697cb2ceccb17491c77b5ee6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑革命，万物皆可插入！浙大/哈佛/南洋理工提出Insert Anything，告别PS抠图，AI让世界无缝生长。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7Ficnb2ehPShfDudYtibS1fkY0Su3IFmdP3MkS9KDH1gsquQnXh8Ku6TPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学、哈佛大学、南洋理工大学联合提出了统一的图像插入框架Insert Anything，支持多种实际场景，包括艺术创作、逼真的脸部交换、电影场景构图、虚拟服装试穿、配饰定制和数字道具更换，下图展示</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494385&amp;idx=3&amp;sn=d73bf56eac35f71564b51bd7bb2bc07e&amp;chksm=fd6739e4c895ad762e694033c2459e3c761023feae006aed8a811449e550fa040051974e7786&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494385&amp;idx=4&amp;sn=67fdc97e51229b211bab7987341ac87e&amp;chksm=fd911a316444ef6ae795eccbd8f3a30b8c640fb7bbcc0976c60367a894c069909c7a856b32cd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>