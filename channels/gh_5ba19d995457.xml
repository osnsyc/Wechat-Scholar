<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[AI时代职场生存指南！微软公布“最容易被AI替代”和“最不容易被AI替代”职业报告，避开高危职业，拥抱新机遇！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45Iqouv4a8VOjh7iabrSiajsu7cpvdNxVzKonXeCaXxrhL17yricSm2vtJV63DA/640?wxtype=jpeg&amp;wxfrom=0"/><p>在科技日新月异的今天，生成式人工智能（AI）正以前所未有的速度渗透进我们的工作与生活。近日，微软研究院联合微软团队发布了一项重要研究——《Working with AI: Measuring the </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=1&amp;sn=6821a4cd9b855a8cee6766d9c8a55b25&amp;chksm=fd3e575a49958b01a2817db80a2011c7ab131c243efff247ef2e33b5893ebddcc9942809bca9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出新框架ImageRAG！RAG+AIGC提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JK3j8AP855QOPLGKEpd37E3bPLWmIOj4bSM2oUxbcSEQ3NFVFyqRhEKjhBGvFkPMAwAaMsbszianQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation论文链接：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=2&amp;sn=2e4ee84eb60755441043a6e20c33ded0&amp;chksm=fd0cddbe3403eed7be30fb2c5ada2c9604fa4f5fa9313e6045a0a8888cd8f3fefa3b3ad0bf2a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文了解 DeepResearch：AI 如何重塑深度研究与知识整合]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIo0ia75NSGFsObsIAKtZ35qIl2VrDtpaxMVkxU4QsGhZJdF0ZqOibRyJfONRdRTChR9oaFpPcAt00ug/300?wxtype=jpeg&amp;wxfrom=0"/><p>近年来，AI 工具逐渐从“快速问答”向“深度研究”跃迁。DeepResearch（深度研究）正是这一浪潮中的代表性技术，它通过多步骤推理、海量信息整合与结构化报告生成，将原本需要数天的人工研究任务压缩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=3&amp;sn=1dfd0fbea8dbdfb036e7a6b7a3dc7e91&amp;chksm=fd1f668fe4fe0777e78f07eb25b66028aa551866ea6ac8d1e453e42ac35d70c4185ca562d50f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南开提出1Prompt1Story，无需训练，可通过单个连接提示实现一致的文本到图像生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enzPNo4OCBUcdtmaQJs6N0wWib04FeoPN0dUqhYsAJa4gIVOeKpt04Ox35gLkECLB9LEJGNnrDPu9g/300?wxtype=jpeg&amp;wxfrom=0"/><p>（1Prompt1Story）是一种无训练的文本到图像生成方法，通过整合多个提示为一个长句子，并结合奇异值重加权（SVR）和身份保持交叉注意力（IPCA）技术，解决了生成图像中身份不一致的问题，同时保</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494525&amp;idx=4&amp;sn=df996bacb4a74e8df8fddf3c87c6063a&amp;chksm=fd52a93cb741df3e31740765f03a031bfac37323943192291aff3f3085ad33a550226f9969e8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 03 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI生成彻底告别AI味！FLUX.1-Krea-dev开源：美学控制与真实感双突破，兼容FLUX生态，3行代码即可调用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45IqouLvtSzXKAXQbVT0N76xGCRBHD3zZvWY3h5UC1xpD2KLKfw2b1iaZoR4A/640?wxtype=jpeg&amp;wxfrom=0"/><p>Black Forest Labs 和 Krea 一起开源了一个新的图像模型 FLUX.1-Krea-dev,旨在提供卓越的美学控制和图像质量。该检查点是一个引导式蒸馏模型，与FLUX.1-dev 完</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494502&amp;idx=1&amp;sn=42b064fd9195ced0fdeaf22e3a1899ef&amp;chksm=fd552e4dfc6f9840962061897581947172e262063bed08d4a1bdded4078c3589fc33c2842fba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekB7CXUYR45xqh1P2Q9zWuxgmicJiaO6JPkkhoaibkSARt6qftWXI9ofZjt9NK9vuibg0UrfhA2kTPRaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT今天介绍的文章来自公众号粉丝投稿，腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT，给定一个人像图像和一个衣物图像，就可以生成一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494502&amp;idx=2&amp;sn=09c0bd46a21900d950a75cbc149d8b86&amp;chksm=fda1f990c324c355b573527994ed24e1e4fb6155f154af9f0c37c95311417ad4f78097d369ea&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494502&amp;idx=3&amp;sn=3c39f468b26adba4939b5dd7539f4744&amp;chksm=fd46bd05c5a8ce34ee32e9c0509074d545cdfdd53d0d40f00c2d10f0fdbe53919e0d4df39515&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 北大提出FreeCloth：面向复杂人体衣物建模的自由生成方法，宽松服装实现高保真细节保留。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekZpjibRlqzZJvpnCtIusibumvetVwHLtQfibNRV5NCjOk9fMZ0qoTnYiblqn55YqgfyU1srg7kyibibCXA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京大学王亦洲课题组提出的名为 FreeCloth 的基于点云的混合式人体衣物建模方案，突破了现有方法在宽松衣物建模中的技术瓶颈。针对宽松衣物与骨骼运动关联性较弱的特点，该方法采用无约束自由生成网络</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494502&amp;idx=4&amp;sn=8671e6515c9ac2c100def1db6bc6433e&amp;chksm=fd9f574acf5c713f482c23f2d87d8f1fd712cb3151065cad10240692cc3f805455c073858803&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 02 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[智谱开源最强旗舰GLM‑4.5：挑战全球前列的开源旗舰大模型，专为智能体应用打造。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwVVjR2OrKwpn9VSkHhJHiavcjHQXgWGNzfttuXB3k7dzM4wc625Lbzr79ic8QdqP434KGiaQURcQTg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在 2025 年 7 月28日，智谱正式推出 GLM‑4.5 系列大模型，这是继 GLM‑4 系列之后的又一次全面升级，也是智谱首次面向智能 Agent 应用场景定制的旗舰级基础模型。GLM‑4.5 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494411&amp;idx=1&amp;sn=bf03f057f85c2584c882ad1d25893c0e&amp;chksm=fd8153ef19c6469610015ead3fcc18fced56226835b9e772b15fe3a19da0e5aed554bf70c0a2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[MeshAnything V2来了！30秒生成建模师级Mesh，最大可生成面数提升至1600。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elKcprhHqENugIHSUTwb3EOjn5XkV1zK43LvhbUTOvgJ8MMYraTDSoeD7ibTHT3bGcxX9ic5uAQfLGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>GitHub已揽星1.9k的MeshAnything项目上新了V2版本，由来自南洋理工大学、清华大学、帝国理工学院、西湖大学等研究人员完成。MeshAnything V2相比V1，使用了最新提出的Ad</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494411&amp;idx=2&amp;sn=a413c7b5d67f8256a1cddc9dfbf4c2dc&amp;chksm=fd31b7d707ad0fea71296c50bb0e142523946287776b1285cb24b3ca4098ceed3b530291f69e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[突破GPU内存限制！VGGT-Long开源：首次将单目重建推至千米级、无边界室外环境]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/rFGeIHcFicWekTZib9BbIiaTmjnAkRWiaU6oZOyDb1XYo2PaGL8LwFicFIe8v6aTqzZb3Yia0FKibVHttq7YHJ5gL6DbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>挖掘基础模型的潜力从单目RGB视频流中感知三维环境是自动驾驶的关键能力，然而现有方法在处理千米级长度且未标定的序列时仍面临困难。与小尺度的室内三维视觉任务不同，自动驾驶场景涉及长轨迹、稀疏的帧间关联、</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494411&amp;idx=3&amp;sn=cfe14310317924d22d48204a111fcf51&amp;chksm=fd5d38279d657f0a5978a3444b14246a5b7f780cecab3d3f35a8199801bddb684bc33b625cd2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从单口相声到群口辩论：中山大学&amp;美团开源MultiTalk：多角色对话生成SOTA模型，语音-视觉对齐精度达98.7%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enfUCFX9WW23BajIFJBpRq3lz9nCs5icOy90Hv0zVbmIjdyTsfJWWDS7Fo3ugfyXkMKIEyJEtsAoHg/300?wxtype=jpeg&amp;wxfrom=0"/><p>由中山大学、美团、港科大开源的 MultiTalk 可实现多虚拟人对话视频生成。在语音与嘴形同步方面达到了SOTA性能，并支持通过prompt实现人物、物体与场景的交互。相关链接主页：https://</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494411&amp;idx=4&amp;sn=1368947368c0905b8dbb87f3fcf142d9&amp;chksm=fd625ea8204b5c5770529ec2a2ed262dd308411839f33fffc8018cea9628d5ab4b2f5705f8a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 01 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一沙一世界，一花一天堂！腾讯发布首个开源、可仿真、沉浸式3D世界生成模型 HunyuanWorld-1.0!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPCjTfhE2exCxyco6laPao2lnHZq3ogpmmib5iasCmJnXmWuMH87RJ0LxT6CnuVbvj0gdyn5g39w6g/640?wxtype=jpeg&amp;wxfrom=0"/><p>计算机视觉与图形学中，从文本或图像创建可沉浸交互的 3D 世界挑战重重。现有基于视频的方法多样却缺 3D 一致性与渲染效率，基于 3D 的方法有几何一致性，但受训练数据和内存效率限制。腾讯开源的 Hu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494385&amp;idx=1&amp;sn=e0adc354dad8f32f1aa8625e918a7a6b&amp;chksm=fdba33584d8f35ede3c538b7bbe57671aa61817a86cb7ac00d2b02fb29c7ccdd772a1811407f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[让SDXL实现50倍加速！中山&amp;字节最新对抗训练+双空间判别，单步生成新标杆！性能狂飙]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoia1S5Ym7bibDIvuNABiayExIP2s1GG5jBXCzgctBupACNEyZWybv3icTdFsEZwl5CqqkmoQ0LiciazJ76Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章地址：https://arxiv.org/pdf/2507.18569 亮点直击对抗分布匹配（ADM）：提出一种新的对抗学习框架，利用扩散判别器在隐空间对齐真实和伪造分数估计器的预测，替代传统显式</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494385&amp;idx=2&amp;sn=880010a11bda7a1cf1f7ad4f6ffe35d1&amp;chksm=fdf917e4d34d7ef939f2504bae652668a1ccfce0b49f37667fc1697cb2ceccb17491c77b5ee6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑革命，万物皆可插入！浙大/哈佛/南洋理工提出Insert Anything，告别PS抠图，AI让世界无缝生长。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7Ficnb2ehPShfDudYtibS1fkY0Su3IFmdP3MkS9KDH1gsquQnXh8Ku6TPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学、哈佛大学、南洋理工大学联合提出了统一的图像插入框架Insert Anything，支持多种实际场景，包括艺术创作、逼真的脸部交换、电影场景构图、虚拟服装试穿、配饰定制和数字道具更换，下图展示</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494385&amp;idx=3&amp;sn=d73bf56eac35f71564b51bd7bb2bc07e&amp;chksm=fd6739e4c895ad762e694033c2459e3c761023feae006aed8a811449e550fa040051974e7786&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494385&amp;idx=4&amp;sn=67fdc97e51229b211bab7987341ac87e&amp;chksm=fd911a316444ef6ae795eccbd8f3a30b8c640fb7bbcc0976c60367a894c069909c7a856b32cd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 31 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别繁琐！ComfyUI LoRA Manager上线！配方管理+一键集成，模型查找与下载“零等待”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enbjDSflysJFeRa1uPbPgmjKl0F8kLoBicOVibPKVBTiaPZejd9PaWA3NQ7pjbhFejD8lORouqAXsjOA/640?wxtype=jpeg&amp;wxfrom=0"/><p>unsetunsetComfyUI LoRA管理器unsetunset使用 ComfyUI 的终极 LoRA 伴侣彻底改变您的工作流程！ComfyUI 提供全面的工具集，简化 LoRA 模型的组织、下</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494334&amp;idx=1&amp;sn=00db8edd31cf655de3f724b1000f5b9b&amp;chksm=fdc04332369e001152aef44f7a5bf24614a77f2eabb26e0a4051d9d7e279aa51abaa4c483300&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯发布混元-3D 2.0: 首个开源高质3D-DiT生成大模型，几何结构更加精致，纹理色彩更加丰富。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enScf5fx9rxa1dXnvYHW4G815SyibP84GYLJGItGoKdb7k8ibSoFf2UCRYRf4VJVbpVm4IevhxibbLDw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过腾讯HunYuan-3D 1.0，感兴趣的小伙伴可以点击下面链接阅读~腾讯发布HunYuan-3D，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。HunY</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494334&amp;idx=2&amp;sn=738bb4f709c1d6052525dbf72ba0a14b&amp;chksm=fd288b3c805444807e18bd50c014ae1eacc1843882112ae669fbee8999d28c3a1f3d388545a2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[音乐版 ChatGPT 就在这里：Suno V3几秒钟内就可创建两分钟高质量的完整歌曲！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em1Jmm3JnCF4N6JNjZ7m3HZdP70FAps5gwtDs9CCtuIicp4h5fqd34SyiaBOOPtWEpDvK18SkJQYw2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>仅在过去的一年里，生成式人工智能在生成文本、图像甚至视频方面取得了重大进展，特别是使用OpenAI的新Sora工具。但音频，尤其是音乐却滞后了。Suno似乎正在破解人工智能音乐的密码。Suno正在建设</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494334&amp;idx=3&amp;sn=b51c12184ec21aea60217c78eb807c50&amp;chksm=fd4ec0613c255553c091ad8969ed93da4fcb12246c5843239747ce3378922b321efea45e6ccc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Story-Adapter：能够生成更高质量、更具细腻交互的故事图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekx1e8oxA3YKibkhot7h9UJZSKKULxCTzezvw8wSOvf1jqib40MePuLWQamEVrmH3RC3HsKvOkJ9S3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前已经给大家介绍过关于故事文本生成图像的相关内容，感兴趣的小伙伴可以点击以下链接阅读~字节&amp;南开提出StoryDiffusion：生成一致的图像和视频来讲述复杂故事，图灵奖得主Yann LeCun亲</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494334&amp;idx=4&amp;sn=90a5212efeab7b7d79cdee969577df2c&amp;chksm=fd4aca19be2ebfd7ebe7cebb1851fe09c085ccade92814290166b789d4416d34e7d9db1b440d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 30 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[企业/个人开发者狂欢！字节跳动宣布开源 Coze Studio 和 Coze Loop，AI Agent 开发进入平民化时代。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enbjDSflysJFeRa1uPbPgmjAcxaantLMyv9tXrOibIpxUX3DfMiap9YULj2wC2qf84tE3egdxibsq5pQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025 年 7 月 25 日，字节跳动宣布将其AI Agent开发平台Coze的两大核心项目——Coze Studio和Coze Loop——正式开源，而且是还是 Apache 2.0 协议，任何组</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494333&amp;idx=1&amp;sn=d3760f4b6c7f5bdbcbbea7fabf36b5b4&amp;chksm=fd618878a4528110105609da9ad07e475d822fb9478ed5ac685ca0fdd1885ce20ee49a15ffaf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494333&amp;idx=2&amp;sn=79c96ac4a3a61d21e5332a291de55e48&amp;chksm=fdd83c3764381455bbed871df26a3b69bd9ffcfe8547d6eff1b102e940eeab6eab984dbe2e85&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494333&amp;idx=3&amp;sn=d8227928a5ef5b44ce9eceea9728c635&amp;chksm=fd7eb40ff74f6db1704796fbf5153b361f97167b85c1c9c953e6a43d5501ecf7be4bad0e09f7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦&amp;字节提出layout-to-image新范式，支持基于布局的MM-DiT架构下可控图像生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekXX8zYF4UxzjmCibmVsNeNfHdzvia0ykHy5vQljhxHZhBKib0DHCIdedbOAMsic8KZ423vtGia19o4Wow/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇分享论文CreatiLayout: Siamese Multimodal Diffusion Transformer for Creative Layout-to-Image Generation</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494333&amp;idx=4&amp;sn=3754aaf24f5cba64798ec562dbe98725&amp;chksm=fd068feead28b39d3a2214cf3133378bab99c812b4bd1d8d7dcba65254c7afed805a3e665c1c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑进入视频时代！字节Seed&amp;新国大提出VINCIE，视频驱动扩散模型，概念合成效率提升300%。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ennrAAVlvm6a2ndtb8NAAAehQOd2pAp8oOdmjraUibFjm5UwibicaIfLZpvl4licgd3FvIqQuDnyebylw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在图像编辑领域，如何让模型真正理解并响应动态变化的上下文需求，始终是横亘在技术落地前的关键挑战。传统方法依赖专家设计的任务流程与分割修复等辅助模型，不仅数据标注成本高昂，更难以应对复杂多变的编辑场景。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494319&amp;idx=1&amp;sn=aa34b2508066ad87d8d9064b459dc87d&amp;chksm=fdb4b1fd6e5bd129392456675effecdb0f11c52e90bb251b88e704ba9206a18558bd5d327de2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494319&amp;idx=2&amp;sn=ea12b270a8c396ccc909cbf5fa448cba&amp;chksm=fdf68739535c71b122e003c6d6a506b479b5d7921d9e436f4a996e7acd7104364bd3aa91ca0f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Poetry2Image：专为中文古诗词图像生成，忠于原诗意境和语义。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emh13jOMSY9oYmD0NHOx8BcYfwYJj74Cog1EPA8EQnekKhKwrxDasX2PxLvN7VqWDL8nRUrassVIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>直接基于诗句中的文本进行图像生成通常会导致丢失图像中的关键元素。为了解决此问题，哈工大提出Poetry2Image，通过实施有针对性的图像校正解决这个问题，有效地捕捉这首诗所传达的语义和艺术精髓。Po</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494319&amp;idx=3&amp;sn=560c5696cf68d27a29d6bec67b566608&amp;chksm=fdcb990de8fcd4725a7d3e856ce9cc46e0c570107ac187d41fbcb06574ae2f103028894fbb94&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 艺术工具通讯]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2rrZo6MvQMib3yaV5BITXF7CQorbzEicSeSiaBVwm9FpIicKhJ3TeBW7JsFmeMmjr8CqMt5ibicJRkEmjnQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>创刊号 🎉AI 领域的发展速度令人惊叹，回想一年前我们还在为生成正确手指数量的人像而苦苦挣扎的场景，恍如隔世 😂。过去两年对开源模型和艺术创作工具而言具有里程碑意义。创意表达的 AI 工具从未像现在这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494319&amp;idx=4&amp;sn=e7b935214dcd48f6984c3d4ac725c67e&amp;chksm=fd60f6a187d887efa3dc3d30f239d861aec26d0611f30d4f7e18941212ba4ce942456d442e9f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>