<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[超多可玩！Open AI 更新GPT-4o 图像生成功能，以后工作流不存在了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enrqfSduqABGjibF2gGxXK1j4ZBMdCOCJnlf8tGU3PW5UWxyBEeaBOPcutYx5d89fDx22q1FYSZUWQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>昨天 GPT 4o 的图像生成功能上线。可以通过自然语言对话完成现在复杂的 SD 图像生成工作流的所有玩法。这是 Deep Research 以来 OpenAI 最有意义的模型更新。一句话指令就能完成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491229&amp;idx=1&amp;sn=0fa2659b4e2e9bdec87fee429c9a256e&amp;chksm=fddb89e17bc0ee96eb4d4624e96b373f3995b19e6c3928706e2405f1654a905ba79d6ada66d7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[非常好用的DeepSeek喂饭指令，快收藏备用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1rTwNmMicswteAFPxRBulbryWbJb5icNpRZVAQfxRenrx63X2LR3PjcPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>给大家推荐一些非常好用的DeepSeek喂饭指令，包含文本编辑、图文表格、求职面试、联网搜索、人际交往、新媒体运营等，直接上干货，大家可以收藏文章，以后可以直接用～感谢你看到这里，也欢迎点击关注下方公</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491229&amp;idx=2&amp;sn=38048f4a4a6ef2c61211371f5200e6a0&amp;chksm=fd7e080a6916245ed5b79d3396b18d32c94ccab53bff48639f601b7e76fe8738b4739870468a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DiffRhythm：创作完整歌曲，支持文本转音乐和纯音乐生成，MacOS 上可运行！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekwL7bBtjRiakD5gmicmnfguSfr2z00p2lt6zEhibKXszCpRoFYPwAibZibGQQbQ4FYynlgbdHicZZTZn7g/300?wxtype=jpeg&amp;wxfrom=0"/><p>。公众号之前已经和大家介绍过许多关于音乐生成的文章，感兴趣的小伙伴可以在公众号栏目中点击“AI音乐”获取更多信息。DiffRhythm是第一个能够创作完整歌曲的开源基于扩散的音乐生成模型。目前已经支持</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491229&amp;idx=3&amp;sn=6a7973931b49b2b6fea5622006bf61f8&amp;chksm=fd6552dee7ab7119a26332fa5fc13133cba12d4ba145930477b2901f2f73800625627e005d9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DPG-Bench榜首！智谱开源文生图模型CogView4：支持中英文输入和生成，免费商用授权！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekabsI7MyRPhcqTEHwmEMZhvC6lcJXaMUIXeLEHuiafYK4Her5iaKXhp5mbyiagGrmxyHV9FXCiccH0cQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在图像生成技术的浪潮中，智谱开源再次引领潮流，推出了全新的文生图模型——CogView4。这款模型不仅支持中英双语提示词输入，更擅长理解和遵循中文指令，让创意表达无界限。尤为值得一提的是，CogVie</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491229&amp;idx=4&amp;sn=c0ac542bf33849357a3e6b2be96b89e5&amp;chksm=fd5db0e303662e5e954baa42292984b06995245668abbf8f82accce6d267618f81eed80bc248&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[360智脑团队宣布成功复现Deepseek的强化学习效果，发布并开源其推理模型：Light-R1-14B-DS]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1tibSfW9w9neLqKv8yOAWicTQRj5CFQMD88lIrZoEJYOZjsuX1YrGljKQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在这个科技日新月异的时代，每一次技术的突破都可能引领行业的变革。近日，360智脑团队宣布成功复现了Deepseek的强化学习效果，并发布了业界首个14B级别的推理模型：Light-R1-14B-DS。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491192&amp;idx=1&amp;sn=ddf0de5fc176eed28aae9f367522ca71&amp;chksm=fd5296e49f451737fd4cb2d18c63ae26e5f295e1d133ddc95c0e4892e4317988d1e75e61180f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌推出PaliGemma 2 mix：用于多任务的视觉语言模型，开箱即用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZG3A9ureoTeOkRX7vpoweMqWfIXVPrnftNxPZXeKdfJFf3WSY8K2fGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>去年 12 月，谷歌推出了 PaliGemma 2 ，这是Gemma系列中的升级版视觉语言模型。该版本包含不同大小（3B、10B 和 28B 参数）的预训练检查点，可轻松针对各种视觉语言任务和领域进行</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491192&amp;idx=2&amp;sn=0948b7f02e3e7a3ea2a7a6a91777fd6c&amp;chksm=fd0cd43a4e1c28e740c205ec35f9e12ac87abe50b9eed43f39f2ad7766dca4eb46081bb5ee6b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CineMaster: 用于电影文本到视频生成的 3D 感知且可控的框架。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMLBRnvtbr9hh7W1ccXtbHEFc26iarR5N2r9CO0FlrI8VbA3yicts8jmfYqQu9BHcgSCETWsJ0PawQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>CineMaster是一种 3D 感知且可控的文本到视频生成方法允许用户在 3D 空间中联合操纵物体和相机，以创作高质量的电影视频。相关链接主页：cinemaster-dev.github.io论文介</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491192&amp;idx=3&amp;sn=0bcaf986af7175ff3b397f1bf0a76ac2&amp;chksm=fdb099d5abdd7874f257b1f9625958176034327afe8a8176041ae6a5cb838b35e04b1789fde2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491192&amp;idx=4&amp;sn=cf3f03dacd4113fd8726ee83511094ee&amp;chksm=fdd4b2734515a32d630b817af418d0d877fcd76f7f420eb4f2024e94675c1b14b74c461eb17d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IBM提出多模式图像文本到文本模型SmolDocling，可实现代码 | 公示 | 图表 | 表格 | 标题 高效转换！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eniaAibjBDYoftj8VvjntaLlaylgswEom4XlMibkcGxuU4WPZLbljDmFWMIMhdEh2dicYGoicXToiaibicmeQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>Docling团队联合IBM提出了一种多模式图像文本到文本模型SmolDocling，旨在实现高效的文档转换。它保留了 Docling 最受欢迎的功能，同时通过无缝支持DoclingDocuments</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=1&amp;sn=010ea784d33ceb329b4a04e147ca3153&amp;chksm=fdd8ae754e681e26bb8c60d581ec8e75ca5706d781fc2ab16e8e282f71e96204b7864abb448e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Seed-Music：字节跳动开发的音乐生成模型 支持多种数据输入生成和编辑音乐！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elIm6icxMVSQ1CxgxFiaRZRxgIpSB6lVKMSWd1DpYwO7bNGaOdrtXY1KXTzkCV8N36E83o4z8JLtxBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Seed-Music是一个由字节跳动研发的音乐生成模型，用户可以通过输入多模态数据（如文本描述、音频参考、乐谱、声音提示等）来生成音乐，并且提供了方便的后期编辑功能，比如修改歌词或旋律。Seed-Mu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=2&amp;sn=80c2ec88726a7f84465884cb48669d1e&amp;chksm=fda8dd3f13ed2c87d83ad45468cbcdd173027579147d66e67bf2d4f75b2d4dbca213339829c7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[震惊！东京大学提出ARTalk！语音驱动3D面部动画大突破！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JgxI2td6MuHkKtXCMBGlVyNoBucDYsH1Jct1PGOib0q03Jn6GdpLz4QjrI8emN5ohoxj6WzEHv54w/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model论文链接：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=3&amp;sn=1bb8126cf37e8a7b73a9348de9b19635&amp;chksm=fdc4d8e988c30a3bac9b8427a0da16eddf0a9cb6dd806279c085c24b69bf993f2f4303546b61&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekB7CXUYR45xqh1P2Q9zWuxgmicJiaO6JPkkhoaibkSARt6qftWXI9ofZjt9NK9vuibg0UrfhA2kTPRaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT今天介绍的文章来自公众号粉丝投稿，腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT，给定一个人像图像和一个衣物图像，就可以生成一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=4&amp;sn=601ed5357aa17567be89bfab06be7be7&amp;chksm=fd055b9e798e780cf50e543c44d5812d75a43ca52040a10453de614a26df5686bde92174bcb7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Window上6G显存就能跑文/图生3D？腾讯开源Hunyuan3D-2 Windows 便携版，轻松运行腾讯混元3D 2.0!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq6yAm26wF7SoU3RDfeYGDhleng8ndFk1MlsjEAbEoPWPzsibkOCMS4tkQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>混元 3D 2.0 Windows 整合包提供了 Hunyuan3D-2 的 Windows 便携版，简化安装流程，支持本地运行几何生成、纹理合成及文本转 3D 功能，适用于 NVIDIA GPU 用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491190&amp;idx=1&amp;sn=bc58d7fc1960c661be4d5a30379ab67d&amp;chksm=fd5b80db9573b90e52d69671fde6e3c4cc248b843a92a64573f2e0f759260866254dcf60eb13&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Mar 2025 23:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯发布混元-3D 2.0: 首个开源高质3D-DiT生成大模型，几何结构更加精致，纹理色彩更加丰富。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enScf5fx9rxa1dXnvYHW4G815SyibP84GYLJGItGoKdb7k8ibSoFf2UCRYRf4VJVbpVm4IevhxibbLDw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过腾讯HunYuan-3D 1.0，感兴趣的小伙伴可以点击下面链接阅读~腾讯发布HunYuan-3D，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。HunY</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491190&amp;idx=2&amp;sn=a04d0253994d6d588be8fc91e083b79a&amp;chksm=fdde11091b5bf784e6fa93653f648cb775e2630f6060111837af6052e4536e475666140c5909&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Mar 2025 23:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯HunYuan-3D 1.0，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elMhPFZCKibTiaBKrjL4Yql4lFH5tVlYMlAnW2RYL3JiaF4vHrEFr3z5TWpyzCAENlicH9DuH5PnpYic3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>HunYuan-3D支持文本到3D和图像到3D功能，包括网格和纹理提取在内，整个过程在 10 秒内完成。文本到 3D：用户可以通过简单的文本描述生成 3D 对象。例如，描述一片绿叶或一把棕色吉他，模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491190&amp;idx=3&amp;sn=b3c35203f25ea9310f8d632cd07ffdd6&amp;chksm=fd5ef028217832b26187a9e766a72fb582d47fa0ea7ec57550dec78a90b81dcfbae827d2bb58&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Mar 2025 23:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI听觉革命！港科大×月之暗面发布AudioX，文字/视频/图片秒变天籁神曲！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enAqmicvH5JOXsTyWrTA6QL4Qw0324EibX2dlA4ibkqCvfZTBSib6iaz47XXY5VgjdgsGwwMQ3jVeATNhA/640?wxtype=jpeg&amp;wxfrom=0"/><p>香港科技大学和月之暗面联合提出的专门用于从任意内容生成音频和音 乐模型AudioX。该模型能处理多种输入模态,包括文本、视频、图像、音乐和音频,生成高质量的音频输出。核心创新在于多模态掩码训练策略,通</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491146&amp;idx=1&amp;sn=6c7e44da48e935f95db6ca3730bba1f0&amp;chksm=fd4d73036dc39f75a159da28c3bffb453f1e290245b8de62476d22f13a97502059a66d4c4709&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Mar 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多身份定制化视频创作新突破！Ingredients：可将多个身份照片整合进视频创作实现个性化视频生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcicdv0XZf04MKlYliaBmemOkIOtBU0wKu89VAd3lkLkDU9GOLfc5OIqIjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在当今这个数字内容爆炸的时代，视频创作已成为连接人与人、传递信息与情感的重要桥梁。然而，如何高效、高质量地实现多身份定制化视频创作，一直是视频制作领域的一大挑战。近日，北京昆仑研究院的研究团队提出了一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491146&amp;idx=2&amp;sn=b3c6c4f24c56449c6f1ec94cb4604bb2&amp;chksm=fde2d699a238cb317e28b503cb77d9bc514d82529457cadd8a5da0efa43bf6fad0ce7f7a614c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Mar 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单张照片生成3D头部模型！Adobe提出FaceLift，从单一人脸图像重建360度头部模型。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4qXFbiaEqoEPejUQNwuqLOrpIE3WmoKJBxjrMnCoHDn3huArYyaCa7Ew/300?wxtype=jpeg&amp;wxfrom=0"/><p>FaceLift是Adobe和加州大学默塞德分校推出的单图像到3D头部模型的转换技术,能从单一的人脸图像中重建出360度的头部模型。FaceLift基于两阶段的流程实现:基于扩散的多视图生成模型从单张</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491146&amp;idx=3&amp;sn=43312724357bb1f07a3ea397ac79bbf9&amp;chksm=fdf6c7c4688fb74ea96b2e3e35696fdaeb18201a59cd7ed05909f4530ae087daaeb6ac596603&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Mar 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LBM：用于图像到图像直接快速转换，支持可控照明、图像恢复、物体移除等功能！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eniaAibjBDYoftj8VvjntaLlazzrjyAuCaxtUgTmwTpbpXdlUbj1mP1pmA9QicicVlSzvQAT83J2fYzAA/640?wxtype=jpeg&amp;wxfrom=0"/><p>LBM是一种新型、多功能且可扩展的方法，它依赖于潜在空间中的桥匹配来实现快速的图像到图像转换。该方法仅使用一个推理步骤即可在各种图像到图像任务中达到最佳效果。除了效率之外，该方法在不同图像转换任务（例</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491145&amp;idx=1&amp;sn=634fac8d9ea595075a47b53234a9bb6e&amp;chksm=fdd5ea90c709df77094ec95009f3bfc05b1c63bc308c459db6bc8df21dc5515d1d27c68bde06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 多实例扩散模型MIDI：可从单个图像创建高保真 3D 场景，模型&amp;代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emQH9S7pGDiaODq1bPiaoKg0UwQg0Pd1kyLMVicNPaNIDRbCcjvvBMqMbicEWI8LS5IVX4LjXG1tHR3Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>MIDI 是一种 3D 生成模型，用于从单幅图像生成合成 3D 场景。与依赖重建或检索技术的现有方法或采用多阶段逐个对象生成的最新方法不同，MIDI 将预训练的图像到 3D 对象生成模型扩展为多实例扩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491145&amp;idx=2&amp;sn=1fc54bdf95dfe0744559c199843bde39&amp;chksm=fd927151fd8eb3bbe9cbf32391801357cc9151e0ff890b22082dfee41432d0d7aaa8df0d2dc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491145&amp;idx=3&amp;sn=2ba230053e3532c4eaa82000472e9f44&amp;chksm=fdc6b343b7a3f3c4dbeee794937659987f7cdc636ec953cda7ae7a38e5415b491e1606e0b376&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 21 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从故事直接生成视频？一起来看DreamRunner如何重塑内容创作。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em0iaj7vmt3M8WRLr6mq22stzrb2ORCEYsI27cibQt41Hzt6FKUSn3V7ianSHVRapnj3w9FKpNt3jwDg/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天为大家介绍一种新的故事到视频生成方法-DreamRunner，它能够将文本脚本转化为长篇、多动作、多场景的视频，让故事跃然屏上。通过大型语言模型、检索增强技术和新颖的3D注意力模块，实现了对象精细</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491144&amp;idx=1&amp;sn=527085cf04e65dcc40786ac83f999b49&amp;chksm=fd0b62998addb3b9b1e4ac7a1a2c0e212795810c43f31a84ef65955f4af322d034cdcb888af3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[人类运动生成新方法MoMask：可将文本描述作为输入并生成相应的高质量人体运动动作]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enScf5fx9rxa1dXnvYHW4G8O9hft4BsqOTmwYEXsfgumPYvUYjCh2XTNsWpfHC7OEh6xL16D8nmMA/300?wxtype=jpeg&amp;wxfrom=0"/><p>该图展示了 MoMask （一种最先进的人体运动生成模型）生成的运动示例。MoMask 使用文本到运动范式进行操作，其中它将文本描述作为输入并生成相应的高质量人体运动。这种方法确保生成的动作准确反映给</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491144&amp;idx=2&amp;sn=b6c2ad0daa4abe41f377e4defea21fd3&amp;chksm=fd4391fd66eb48093f740f30f326c15465961868d925ea0432ffa11dbc53a7cb5e176e064051&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像超分辨新SOTA！南洋理工提出InvSR,利用大模型图像先验提高SR性能, 登上Huggingface热门项目。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emvRmmSX73ApBN83mPSIUnndGUoqrp8dTsfo3BKVIVGVNf5sWoXGauJCgAEaaCQm9Qb7QfuM34qZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>南洋理工大学的研究者们提出了一种基于扩散反演的新型图像超分辨率 (SR) 技术，可以利用大型预训练扩散模型中蕴含的丰富图像先验来提高 SR 性能。该方法的核心是一个深度噪声预测器，用于估计前向扩散过程</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491144&amp;idx=3&amp;sn=d449b3cd829b0149c870eee4453c8b52&amp;chksm=fdf6282d9b01e5e52e10a03f6ad5ee6937818f0b6f515f6122b8fa783f0255f0fde2c9d684af&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 20 Mar 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>