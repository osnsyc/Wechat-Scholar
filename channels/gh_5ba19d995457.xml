<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/XzhF92tBcezMLGZN5TwHm01JzyB611PyibhFUMaiaE6xaTcU7nCAumRAicJowUjC4ntxOOAkSvxOK0/132</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[Meta 开源视觉大模型 DINOv3，尖端图像表征，无需人工监督即可训练，数十个视觉榜单准测试性能SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emC8TzOo0tTPOfwjIibibRDG0V8FDngTwB5bIGKr0RDuL4kJibH8eGgHeZFrbt39SzRkrsY30LsWE7iaQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！Meta 发布了 DINOv3，它可以扩展图像的自监督学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495152&amp;idx=1&amp;sn=f4a92d43fec08dda4e3cbc565797dc8c&amp;chksm=fd8cc1e5d44c57b4d1f8809ffef4d86adbdfe5989de1ee7bc0616b5c9f579416ce4d9bf255b7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[MultiTalk：多角色对话生成SOTA模型，语音-视觉对齐精度达98.7%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enfUCFX9WW23BajIFJBpRq3lz9nCs5icOy90Hv0zVbmIjdyTsfJWWDS7Fo3ugfyXkMKIEyJEtsAoHg/300?wxtype=jpeg&amp;wxfrom=0"/><p>由中山大学、美团、港科大开源的 MultiTalk 可实现多虚拟人对话视频生成。在语音与嘴形同步方面达到了SOTA性能，并支持通过prompt实现人物、物体与场景的交互。相关链接主页：https://</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495152&amp;idx=2&amp;sn=c1f42e1f45eb32b7f7ace21c0639216a&amp;chksm=fd337b03250d62c566a1eb15e05c9211a746f260c0b21ad4a5dfe143ef8cd6182dfcff65f539&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Ultra3D：6.7 倍加速突破效率瓶颈，1024 分辨率下登顶 3D 生成性能巅峰。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elVVXYVXeZKg9ibO6JibLeUheArjN7Xm2cOz07j7Uy5AIOxXedaPSFmFxlbPp39YvTiao133ztkagpEQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在 3D 内容生成领域，稀疏体素表示虽为高分辨率建模带来曙光，但现有框架却因两阶段扩散流程中注意力机制的二次复杂度，陷入计算效率低下的困境。不过，南洋理工大学的研究团队带来了突破性成果！他们提出的 U</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495152&amp;idx=3&amp;sn=05647ef56a1f9a0044cdc48585e5331c&amp;chksm=fd4d7dae4ba1302528a509793fa2c2e980c48cdca31274b8689790560663a66a486ae1ad2ef8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICEdit，用1%资源实现图像编辑自由！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emC8TzOo0tTPOfwjIibibRDG0c0nJ4nYgG4w2wMKAG9zIwaZ80ickR27F8UI8tqjfgPnwuA0lFzEdqPA/640?wxtype=jpeg&amp;wxfrom=0"/><p>#图像编辑 #AIGC #图像生成 #AI 200M参数吊打商业巨头！浙大-哈佛开源图像编辑框架ICEdit，用「1%资源」实现图像编辑自由！一句指令即可生成海报级修图方案。@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495152&amp;idx=4&amp;sn=b6fa389fad6e5617a3409c83044cdffe&amp;chksm=fd041f22ed381d6821a8c33df13e2cf60697acce6debe40de60c678c29ce6ad6f733ae09345c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 19 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AIGC 进入「长剧情」时代！复旦&amp;微软开源StableAvatar: 首个端到端无限时长音频驱动人物视频生成新框架!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elUF9IVtYeIfxAic6O2PVdkZ6ibicJqGRtRialuUn0SquuKwJ2YMicpK76EO8sxcXRtosfDEcZ1jDd3icPQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由复旦大学、微软亚洲研究院、西安交通大学以及腾讯混元联合提</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495150&amp;idx=1&amp;sn=f074f8697f59e7d01a690a88e066866c&amp;chksm=fdbf592deec5d26fa608187d61d83e50881e066f50ca384768794dc3c4ebe13ccb58cf9d7ede&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工力作Sparc3D：开启三维重建可微分优化与高效生成新纪元。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enhd8Da8niase1WltgKePj289UYQ2FkGK7uxrgpyoOIA6cIHk7jU4q6hvNUWTsCz3qI24ic8ibqQ8GjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>由南洋理工大学推出 Sparc3D 是一个统一的框架，它将稀疏可变形行进立方体表示Sparcubes与新型编码器Sparconv-VAE相结合。Sparcubes 通过将有符号距离和变形场散射到稀疏立</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495150&amp;idx=2&amp;sn=4162a5793aaa1231cfc047098359a919&amp;chksm=fd1e5c36ef993a9403a5b2455ddb8868f64fcf4daf2186efacdfb412c028601b59f0750b04a1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源换脸写真模型InfiniteYou，可实现零样本身份ID一致保持，无缝集成FLUX、ControlNets、LoRAs！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFB9QEic6a0icic21hdjU7tWMfgnZWZ32D1adHqJcD4Z8fvzhEvH6KNghsZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个字节刚开源的换脸写真新模型InfiniteYou，这是一种先进的零样本身份ID一致性保持模型，由字节跳动基于文生图领域最强开源模型FLUX模型研发的。InfiniteYou专注于利用</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495150&amp;idx=3&amp;sn=1c8e5ac36b5d99ca42d96652266a14cb&amp;chksm=fd590a20b72117730f65d60f9ce02fd664cf65a3bd5ed4c1e555bd5fcf68af23c3926260f5cd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节DreamVVT整套服装虚拟试穿视频介绍]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elUF9IVtYeIfxAic6O2PVdkZ6ZPibOZ3wJIV8Gp6nDbuK6zQreKstfQHpbFsboicr1qKuJ18sLr0fwdQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>#虚拟试衣 #视频输出 #数字人 #AIGC 字节 DreamVVT 支持整套服装的虚拟试穿，包括上衣、下装、裙子、鞋子、袜子等等。如果用户只上传一件上衣，模型可以自动生成并匹配合适的下装和鞋子，从而完成整套服装。@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495150&amp;idx=4&amp;sn=7f1520751c0cfd39664bbcc45feb8415&amp;chksm=fd5f3598a80f92b08296d9f3e619e01f873800c64aabcf6febe32feb39b7ce482438bdc765a4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 18 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI动画生成再升级！复旦与阿里携手推出AnyI2V：无需训练，一键将任意图片转化为生动动态视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPCjTfhE2exCxyco6laPaoGjxUcS00ev7tShvfYPrqmuL44lIbCscz0valofq4jerwicPITdNalWA/640?wxtype=jpeg&amp;wxfrom=0"/><p>基于特定条件创建动画图像的能力长期以来一直是人工智能领域的一大挑战。传统方法通常需要使用大量数据集进行大量训练，耗时且适应性较差。由复旦大学、阿里巴巴等提出了一种突破性的方法 AnyI2V，它无需训练</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495124&amp;idx=1&amp;sn=b12f592c45e1fc27397413a976fa1622&amp;chksm=fd80b4a2ea4a624c29b882dee07dacf5d6124aada5d77b9330e5eb31554300818b9bf9b490c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 17 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[GLM-4.5发布，全网最全测评和使用教程来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsHgQAGzWZAw7w0DN2CHNyJVXbIyX9SNAxpATxA26bXJceE4KgFwcxcZuXrYH7YB54T4WhQYnobTmQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>就在刚刚，智谱正式发布新一代旗舰模型 GLM-4.5，专为智能体应用打造的基础模型。Hugging Face 与 ModelScope 平台同步开源，模型权重遵循 MIT License。开源地址：h</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495124&amp;idx=2&amp;sn=7287c190cd7e8686ab5e5b828d50b53c&amp;chksm=fdbff084b1d493918e0473083b0ddabb3931298791ce1ca120de139228be6ded693473361e5a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 17 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[华科&amp;京东提出CAIG | 基于CTR驱动的广告图像生成，代码已开源！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/VFicX5Qfj1eAGKXmJ8FAZTQEbuX588HslrApDHibznibl7WvYh1fR2kOs5bQKgVjgagyTuYNjZiapicTzqrP95HEiaOA/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2502.06823项目链接：https://github.com/Chenguoz/CAIG01 | 导言现有的广告图片生成方法大多侧重于美观度</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495124&amp;idx=3&amp;sn=b1a64ec67faded1dd3f0e7c8b37098e0&amp;chksm=fdfe885257c321c3367f27bfeb29afa01ffbc60bb5f2e37d7fea3966ab6040dac06ee0df1223&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 17 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[耶鲁大学和Adobe提出SynthLight：智能重塑人像照明，打造完美光影！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elPyLquFq9rYTicjFkPwyh9fFVDfMwbeuJFlesWohTUXxZRSXxUpCJVwUUib0mdhjaia5sa6Ciaibic8AQg/300?wxtype=jpeg&amp;wxfrom=0"/><p>耶鲁大学和Adobe提出一种用于人像重新照明的扩散模型SynthLight，该方法将图像重新照明视为重新渲染问题，其中像素会根据环境照明条件的变化而变化。在真实肖像照片上可以产生逼真的照明效果，包括颈</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247495124&amp;idx=4&amp;sn=6a6d993ffeaa01349ca36ad11ff5199c&amp;chksm=fdd8dbe48884ed53e2c6831c8d2897db1c0dd488ad8eeb9e1097191baaf2ba5cd2533f37aa86&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 17 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | Meta LeCun 团队发布DINO-World：基于隐空间仅 1/12 参数量实现SOTA视频预测。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHfvNQb2qunX03KlPmVP7Nnt13a90Sibey9ew3yxyABzKhRvmibJYJFcR2zsibuicYLm5A9LJDEkUH2A/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494930&amp;idx=1&amp;sn=69e745e59076a1c3933a354cc726e6bb&amp;chksm=fdef306462687cadaaa06e110c966501a1599f43a0b986c7bc83a2a5312b1d0cc20d79e5f010&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 16 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[手机实时跑3D数字人！阿里开源MNN-TaoAvatar，打造本地离线智能数字人新标杆。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8O7Mx0HicAQzYnr62ZEJLwjCaTF4Xg9G65OJibjU82ibBkicGN8Zdt93yM9ibvqO1zSU5WvX0ehVP4QA/300?wxtype=jpeg&amp;wxfrom=0"/><p>TaoAvatar 是由阿里巴巴淘天 Meta 技术团队研发的 3D 真人数字人技术，这一技术能在手机或 XR 设备上实现 3D 数字人的实时渲染以及 AI 对话的强大功能，为用户带来逼真的虚拟交互体</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494930&amp;idx=2&amp;sn=a1a25c863e78548883af86bbe513ff60&amp;chksm=fd604a9e841c9bd4ebd0ccdc38324948cb0db36ca8fc1577e5f3fd126c6b8704795ac88b68a4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 16 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[港大和达摩院联合发布头号玩家PlayerOne模型：世界首款“自我中心”模拟器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHfvNQb2qunX03KlPmVP7NV9Te4yUeb0q58Xh8Th5BuRiciczdMyKxZReBxmc9QnlTzOhkjDzzH2mQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>#视频生成 #AIGC #数字人 港大和达摩院联合发布头号玩家PlayerOne模型：世界首款“自我中心”模拟器！@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494930&amp;idx=3&amp;sn=b81892c19e9f16c18e411de6d6d24ea6&amp;chksm=fd5df84881ed581f233d7848d76db3927ee637864327f657e626f0f95c93c655553f7c78a393&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 16 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节&amp;港中文等提出Captain Cinema，当「无限记忆」打破〈盗梦空间〉的第四面墙。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ennrAAVlvm6a2ndtb8NAAAeECKiaXibgWMfXuoBib9zKibRu3JMzPKAibRp6rfe0wartxB8M8rwGXMibnyw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由约翰霍普金斯大学、字节跳动，斯坦福大学、香港中文大学联合提出的 Captain Cinema旨在创作具有专业电影级品质的多场景电影，同时 通过超长上下文记忆保持角色和场景的一致性。你可以成为导演，用</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494930&amp;idx=4&amp;sn=29cbfdbb03b6ae91f2312c7b462581ac&amp;chksm=fd45339622057e2a7fe3a42e074ffd0a886e96de51509285cdafd5c1e7f66d7c735aef8279a1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 16 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源全模态融合智能体框架Pixelle MCP，任意comfyui工作流快速封装成MCP，可在大语言模型中直接调用！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHfvNQb2qunX03KlPmVP7NxhmLYKcMTmvYJ34jFrSIWdhcjKTyExkTxPWcYGlRAwCYvHvxauaVbA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！阿里开源的 Pixelle-MCP 实现了 ComfyUI 工作流向 LLM 可调用工具的自动转化，可以把任意comfyui工作流快速封装成MC</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494929&amp;idx=1&amp;sn=ae203a7fce93fa37fb10f268c45b60a1&amp;chksm=fdc067308233e0f496cd123a482f038431ac7e5eb7ad3fed3fd6d1c893dcbe341b71a6061e9b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 00:27:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494929&amp;idx=2&amp;sn=bb523f35aa70640c3b3d4ca7a24a4d9c&amp;chksm=fdf04fa6814859f20c9639aa71db2fc0ba2ea6d9259de41879cbbf3794531033d5d1fbbb2d0b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 00:27:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[单图6D姿态估计新突破！OnePoseViaGen: 一个视频即可6D位姿估计，助力6D姿态估计迈向真实机器人应用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHfvNQb2qunX03KlPmVP7NHFPn2KB0ADOBRicJyEBHRF3r0TMicE2aC5zSwC7LzNZQeuBgklVnVNZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494929&amp;idx=3&amp;sn=1d65077567f8b8aca989b63a688bc015&amp;chksm=fd8bc7917163aa809901111599c286559a11442774f24148f073b1ea4cef43037c83b519814d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 00:27:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯 HunyuanCustom 音频驱动的人物自定义功能，更加灵活可控的音频驱动人物动画。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHfvNQb2qunX03KlPmVP7N1B5uL5vtvU7uHVNqlyXmI75OJNxTiazzsRInyUsLX5e3LviclBEErl2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>#视频生成 #AIGC #数字人 #音频生成 腾讯HunyuanCustom 首次实现了音频驱动的人物自定义功能，角色会在带有文字描述的场景中朗读相应的音频，从而实现更加灵活可控的音频驱动人物动画。</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494929&amp;idx=4&amp;sn=49758bfa5d62e9f5dff8f36d03e3f39c&amp;chksm=fd7c1eec94d1c02aafcc4c3583eaa4345bb1b9bfec3bc4b35c5ba3483d9a312910b3a3866840&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 15 Aug 2025 00:27:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[大厂顶会时代]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ensS7ceBQK3LgAWruqia1yI6vAFT7lfqMe7QRVyGwR12PRTtWvlcnTbLkPkpPtOSeNiabIHQh1dgVYg/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025年上半年顶会落下帷幕，除了前沿学术成果展示，另一条暗线贯穿始终—国内互联网大厂对顶尖AI人才的疯狂争夺。不少公司将招聘会搬进顶会现场，offer 现场秒发，顶会现场更像是人才交易市场，高效且直</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494928&amp;idx=1&amp;sn=bf5ca924dcd13c956470298545bd9dd9&amp;chksm=fd49c7a4450214588f2d542f479920eb6fa7a0b03037f6dfef7e80fcf3ec0bc9141749405c31&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[开源多模态大模型OCRFlux：一键实现PDF转Markdown，跨页合并+超强精度新标杆，3090即可部署。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS9ap95maylurzbBmTbxsUrzB6Pu5VpohGDF6KFP4MxUQwERrp3mzYSpSp7tG1uh71uh8icTcbnibw/300?wxtype=jpeg&amp;wxfrom=0"/><p>OCRFlux 是一款轻量级但功能强大的多模式工具包，可显著推进 PDF 到 Markdown 的转换，擅长处理复杂的布局、复杂的表格解析和跨页面内容合并。卓越的解析质量在发布的基准测试OCRFlux</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494928&amp;idx=2&amp;sn=1be14f1a21e9e79aa3d4fc20b0461cd8&amp;chksm=fd3994b8147f03cb14ff4dafd4913ae03ac3262cdc0291a861960728382eb6696b641fdd10cf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源 30 亿参数统一模型 Ovis-U1，多模式理解、文生图、图像编辑样样精通，多项学术基准测试领先。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuDmLq7R1rRFldNX6Em3MD3ic6VVyQ7fibbkHSDXdsLJJKPKURibic6bQdSKAoTkLHaP0dHSb0n5P6Zw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Ovis-U1 建立在 Ovis 系列的基础上，是一个拥有 30 亿参数的统一模型，它在一个强大的框架内 无缝集成了多模式理解、文本到图像生成和图像编辑。亮点统一能力：单一模型擅长三大核心任务：理解复</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494928&amp;idx=3&amp;sn=ab143e23802a69aa26fc146b774a7de8&amp;chksm=fdb4bc6d39b971792e96dfaeacc946bafe023bffa2ff3505b7d5e7d4da6439e5a3c4c58b75aa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS9ap95maylurzbBmTbxsUBufml81pOvT0I5g2ZtLml2vHhHSwwl6iavgrqCCccLj9libuaHeFicVfw/640?wxtype=jpeg&amp;wxfrom=0"/><p>#视频生成 #数字人 #音频生成 #AIGC 腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494928&amp;idx=4&amp;sn=f7c29439a3a9672a6a873864c059c0fd&amp;chksm=fd15ec7a3478d658dcd906ded91e42fd95afb1ecb9c099ae35f14ec42d08ca250378185d82b7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICML 2025 | 快手&amp;上交提出统一多模态生成理解模型Orthus：多模态理解/图像编辑/图文交织生成一键搞定。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS9ap95maylurzbBmTbxsUXBl59yV39yTV5acYvVOcsiaOw34OfkpCAn1D8zgUY7HqKoHeVEofZDA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494917&amp;idx=1&amp;sn=671053332cb85d6ced0cd1431ab13675&amp;chksm=fda1790caceaa1d8cf3bb8e938bf9bd8267be50b15e35e145f092e41a86e1112f9616b43ae36&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[最强大开源动漫视频生成模型:Index‑AniSora]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS9ap95maylurzbBmTbxsUrUV5MaYBiaBvcYdib46sKeYhh2b2bTbcwPUia0fTewWtcux9Y95bvZpYA/640?wxtype=jpeg&amp;wxfrom=0"/><p>#视频生成 #动漫生成 #AIGC 哔哩哔哩献给二次元世界的礼物——Index‑AniSora，目前最强大的开源动漫视频生成模型。它支持一键生成多种动漫风格的视频镜头，包括番剧片段、国创动画、漫画改编、VTuber 内容、动画 PV、鬼畜（MAD）等！@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494917&amp;idx=2&amp;sn=5b6d791e1dfdb785e12b158b75215a43&amp;chksm=fdb48828b2282d254bbfb672afa2ce52757bc5b0c397b5408e43884f19e159bfe18cd06d89d6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[GroundingBooth：一个用于文本到图像的定制框架，支持多主题和文本联合接地定制！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekibUN5oqyRgSButjKACUwRIxoR4VWqymzeNXHxsW4rxM6qoeicJM6XkODXXx3zP4H0duuNP0vk91Sg/300?wxtype=jpeg&amp;wxfrom=0"/><p>GroundingBooth是一个用于文本到图像的接地定制框架。首先提取文本描述和图像的特征，然后通过一种特殊的注意力机制来控制这些特征的结合。这个机制就像是一个精密的筛子，确保每个对象和背景之间的信</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494917&amp;idx=3&amp;sn=9a204f811845b8a227e9d126f4f33595&amp;chksm=fdc120ebe9a690e773ffa938e58e99b5cefa52f6a64add20243e6a1a553e8d1bb275cd659080&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[EasyControl，开源免费「吉卜力」风格图像生成，效果不输给GPT-4o!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em0MYZfia0NNWIydHR67Nd8ZcyPBnBHCy6ovmVtV6Yjjia8SwiauEmzwqlb5UBZorPxJrmoL7qTm4gug/300?wxtype=jpeg&amp;wxfrom=0"/><p>由 Tiamat AI 联合上海科技大学、新加坡国立大学及 Liblib AI 团队推出的DiT（Diffusion Transformer）控制框架-EasyControl，可以为 Diffusio</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494917&amp;idx=4&amp;sn=18b65cf3e4e1becb4a86010a03d4315c&amp;chksm=fd0316797192d11e1cadbc6cdac0baa9472f884e3a8f5103693b030ec38f0ab475b245695906&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 13 Aug 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[单图6D姿态估计新突破！OnePoseViaGen: 一个视频即可6D位姿估计，助力6D姿态估计迈向真实机器人应用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHfvNQb2qunX03KlPmVP7NHFPn2KB0ADOBRicJyEBHRF3r0TMicE2aC5zSwC7LzNZQeuBgklVnVNZA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494916&amp;idx=1&amp;sn=f21ee90da0906bc579e5e34e39a47744&amp;chksm=fdc171c7edc0066b3f5702a512aa3f9314d00d5549f6e74e200dfd22cb3df70e0264ef3ddd4d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 11 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OnePoseViaGen，一个视频即可6D位姿估计]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p></p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494916&amp;idx=2&amp;sn=214da507229ba8f46101ce07ee43d9f3&amp;chksm=fdcc4e16f462a87cb7d2e11da90f6c2b67424f179e135e73d239934083010c42accdddf9fe70&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 11 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节推出统一多模态模型 BAGEL，GPT-4o 级的图像生成能力直接开源了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRre72SQ3NTx8amQXBMt77z295uWjzKl5kweQFLEMa31vXicZ35AvS4Lfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节推出的 BAGEL 是一个开源的统一多模态模型，他们直接开源了GPT-4o级别的图像生成能力。（轻松拿捏“万物皆可吉卜力”玩法~）。可以在任何地方对其进行微调、提炼和部署，它以开放的形式提供与 G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494916&amp;idx=3&amp;sn=f04478a256a37ed8c36025fc3de0358a&amp;chksm=fd3c9ef9469f18ddddb5ba5c401e62fbe078423556a86e4f21cfe641986d06f58054fd2e151b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 11 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 多实例扩散模型MIDI：可从单个图像创建高保真 3D 场景，模型&amp;代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emQH9S7pGDiaODq1bPiaoKg0UwQg0Pd1kyLMVicNPaNIDRbCcjvvBMqMbicEWI8LS5IVX4LjXG1tHR3Ww/300?wxtype=jpeg&amp;wxfrom=0"/><p>MIDI 是一种 3D 生成模型，用于从单幅图像生成合成 3D 场景。与依赖重建或检索技术的现有方法或采用多阶段逐个对象生成的最新方法不同，MIDI 将预训练的图像到 3D 对象生成模型扩展为多实例扩</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494916&amp;idx=4&amp;sn=4b258ec31a36db331c91f6cccccdf9de&amp;chksm=fdae67d3c0c27ecc50375bfd2cfe50954bcbd72e4903c14d0264bb8f4b7b7701288fbce21d33&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 11 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[视频虚拟试穿来了！字节&amp;清华提出 DreamVVT，解锁虚拟试穿多元场景无限可能。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elRibQicbES3yE84iaQribf4r53ibnIUoUDzUYcFR7j2RLbO1XGm9IrlzVCYkaL6AUNGOrF1DHgTlzY29w/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494867&amp;idx=1&amp;sn=b7ecb091eb550eafc2226dc84f8c2805&amp;chksm=fdfed29954fb81f8cb0477210b19156e00b1aebe0ac6cb5cfae717055f27dfa8768096f95433&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 10 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[节点不再乱！ComfyUI 发布 Subgraph 功能，打造模块化工作流]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE4HtQ3D6DGudMXGnMwuibV6Uc6pkhAc0TKpHKFjJGtdE9MVjycicIEibX68VuKAr1tc4N0e2diaibKB9hQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击蓝字关注我吧！🎉 ComfyUI Subgraph 功能正式上线模块化构建工作流，从此不再怕节点爆炸我们很高兴地宣布：ComfyUI Subgraph（子图）功能，现已正式在最新版本中上线。这一更</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494867&amp;idx=2&amp;sn=e964d6bb375e152e49dec259feb08b17&amp;chksm=fd323a24cc7399a337081688c2b978f8c08de06506d3178203f16f3c315c9f95666a53d6c03f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 10 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字体控狂喜！Liblib AI 黑科技 RepText：无需理解文字，AI就能 1:1 复刻多国语言视觉效果。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elFfbYTqwA595BOINVFyGzKJTeUTfexNWrNdN8IAiaUICEpfK2hvFm6G9wMRKkN6XcT63ldibkLQRdg/300?wxtype=jpeg&amp;wxfrom=0"/><p>Liblib AI提出了 RepText，可以使预训练的单语文本转图像生成模型能够以用户指定的字体准确渲染，或者更准确地说，复制多语种视觉文本，而无需真正理解这些字体。这样不管是中文、日文、韩文还是其</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494867&amp;idx=3&amp;sn=e4a8f4c7abe3eab3fe802e9ba3989b76&amp;chksm=fd1431ea445605072776a8472451b816ca66c11754ea739af7da68ef908a8d857ad82c37bb12&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 10 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[集成 R1 后的 GroundingDINO 究竟强在哪？一文带你看清 DINO-R1 的性能变革]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ3cCzjflZrObrcGTNoJJwzrOXe4jyYx9eDs8QIOJ4W5grQyGf2tTwtS8ooDFDop2w2gcbw8UuNhCw/300?wxtype=jpeg&amp;wxfrom=0"/><p> 导读在开始今天的分享之前，我们不妨先思考一个问题：为什么大语言模型，如 GPT 系列、DeepSeek 等，在数学推理、代码生成等任务中能够展现出强大的泛化能力和对人类意图的良好对齐？除了依赖海量高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494867&amp;idx=4&amp;sn=1dcd14dd6a727a3ec61dfc3d02f83e1b&amp;chksm=fdc802b2e11906dc81bc4169cb81d3073a0c810129021c643f5cda98896caa1b9a7ee5a3022b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 10 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[音频生成新突破！矿大&amp;快手提出首个多模态音频生成框架AudioGen-Omni，一键搞定视频转音频/语音/歌曲。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elRibQicbES3yE84iaQribf4r53AxtApIOia6OQ4SnoHIHFxB48CDpTpqxVdWMuwIPeocp39ZEvHXiaOEQA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494797&amp;idx=1&amp;sn=2562fe693c02cf94e052ff9c36e247ef&amp;chksm=fdb1d2bf9ac959a4bb432c0bad4ae3fb5d9a3a752ec9a233015e59ab32f748e049a804e67200&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[刷新SOTA！这个开源OCR凭1.7B参数AI视觉模型，实现全能文档解析。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NYaM5gOXKDOT9FZgBmNRUN6jsYYsc8oUlrH1bwgXH3zuEp6exwxFlbwycYk7svJuSoJu2XPrVxm0Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>好久没推OCR开源了，今天找到一个猛的，项目很新，劲头很足，它最大的特点，是基于视觉大模型。现在的OCR已经不只是文字识别了，更重要的是一些其他格式的内容，像是公式、表格、多语言等等。这个轻量级的视觉</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494797&amp;idx=2&amp;sn=cb95542381ffbb16cf80cfd5f430a91e&amp;chksm=fd139abbdab762d742f6c50d15cbe7cd41cbe768fac2a7fbf6d43c3c0643af47a393d6d87920&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源多模态生成模型新标杆！OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494797&amp;idx=3&amp;sn=39b73870838ed74397bfcc59eac75ceb&amp;chksm=fd1b38ea13276ca4bc1a5254d90d897f2309b4d19139fa0440662540cde60c4d528260bbe0ac&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别"纸片人"试衣！阿里&amp;浙大提出3DV-TON，用3D几何骨架+动态纹理场，让虚拟模特"活"出真实衣褶！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECFZTEAl6XrNJIs6kBFtCKh4H4USr1Odbdw4IOg8SSgUfrQQVgR52lmA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里联合浙大提出3DV-TON，可生成高保真度和时间一致的视频试穿结果，3DV-TON是一种基于几何和纹理 3D 引导的新型扩散框架。 可处理各种类型的服装和身体姿势，同时准确还原服装细节并保持一致的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494797&amp;idx=4&amp;sn=79c08ffad44224d192818b4732a26a87&amp;chksm=fde94e99c9873defedcf9761c7e862fb3cdfb346b3a1ca9be9267363152fe8478d2f126c8625&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[通用世界模型来了！Google重磅发布Genie 3：动态世界实时生成，24帧720p引领多样化交互式潮流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekOicvEwNdEEX8G6p02iaJaXic52OlLuL4CxeBEjguQBkKSDsz3mYaibzgZ3MUywGpmREfiagMhS3Tfribw/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494700&amp;idx=1&amp;sn=aaeeda359d67bfcfe19b63fef9944211&amp;chksm=fd48729d3be5f948c6a722ec6f754679043cd062e9dc13d8791afb11f198c4ab71c02f02321b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 05:42:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出从单一主题发展到多主题定制的通用框架UNO，通过情境生成释放更多可控性。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elo3s89icGNibsPQVXGhctg9WDrsYXyWyFSyqXzUDm6eOsD3G2Z7XbSMUPZrQw19LsCTpuzPx9KiaCWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494700&amp;idx=2&amp;sn=66bc8b33928c0446b1cac041d6ee4cac&amp;chksm=fd7dbd044c97e6064b57a231b70a46fd83a5b40cbd835fb4f04decbbc0ceac5b4ecdcb63b1ff&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 05:42:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 字节DreamFit: 多主题电商服装迁移！轻量级即插即用任意服装模特匹配]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGSxicUBwA56Pek0VwHmNacVsMhP7pROSIyva554J3rL1LBI4t5lpvM0icF2YaPAtfrN22ICPibd001Fg/300?wxtype=jpeg&amp;wxfrom=0"/><p> DreamFit:为服装增加电商模特DreamFit简介今天文章介绍一款新的虚拟试衣框架：DreamFit，这是一款结合了一种专门为以服装为中心的人类生成量身定制的轻量级任何服装编码器。DreamF</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494700&amp;idx=3&amp;sn=b0d1758ac1a9fbce33067a01de6362ff&amp;chksm=fd269b18c0621100ddcfcf754e3c1cf88f80b0f55bb4795d5981e4d89f9af674d92168f9e4a6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 05:42:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[文生图新架构！清华提出MADFormer！混合自回归与扩散的Transformer模型！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Ir9WHCQBicWXDuF5MpvmWMQh4QPfVT8nXE9Tnw27035bkagHHFhhyzApmdO2oxAbKbOs56pmZG7JQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generati</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494700&amp;idx=4&amp;sn=9113db2461c76632b19e1c7efdeb56ce&amp;chksm=fd02f366efba02b0b45af662f12c46082e97ef76cd61c57d00e23623dae6e41742b7ee3399cd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 09 Aug 2025 05:42:19 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ACL2025 | 15篇多模态论文揭示未来AI走向]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekOicvEwNdEEX8G6p02iaJaXicibt3piaL92aeAvhxXRMUgDdias9VYCZpwIJV2vz8icMy5PkicJ7ACickYkuQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>多模态人工智能正以前所未有的速度重塑我们理解世界的方式，它让机器能够像人类一样，融合视觉、语言、声音等多重信息进行感知、推理与创造。作为自然语言处理与计算语言学的顶级盛会，近日召开的ACL（计算语言学</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494686&amp;idx=1&amp;sn=61d889434ef73982a5d8f9c5f36261ee&amp;chksm=fd5e06741a5e37d024ff6f280ff0a0fd84956636048112e30ea420a7fd400ba2f5747c12af43&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 11:31:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节、港理工提出 Many-for-Many，支持10+任务，8B参数“逆袭”商业视频生成引擎。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXr1okRdYbDMkiaMBJd2BP7Rly0sBNFZKib2sPFdbSs7MvfFpF6hn5uyKnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节、港理工提出超强统一视觉模型 Many-for-Many，如何凭它让 8B 模型“逆袭”商业引擎？字节跳动与香港理工大学提出统一框架 Many-for-Many，它借助众多视觉生成和操作任务的训练</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494686&amp;idx=2&amp;sn=3687cbd59ce36a284cca75ce7267fe67&amp;chksm=fdec84a3d54694f4370241b9fae451b1726c2720d28e157e7174ddea725c415f69ff56c0cf11&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 11:31:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源二次元风格生成Neta Lumina，从Furry到国风，全方位赋能动漫创作新体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnnuuc8trMqQZdXicVSnCicAT0JorhOHp7RZ0picPcQW6vmQULK0icb6qeo3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>Neta Lumina是由 Neta.art 实验室开发的高质量动漫风格图像生成模型。基于上海人工智能实验室 Alpha-VLLM 团队发布的 开源Lumina-Image-2.0，利用大量高质量动漫</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494686&amp;idx=3&amp;sn=a1704781dc8bf41f55f7babd4081ae57&amp;chksm=fd1faf195a963535ba4a3ed6e71287c1514bf2803e103c59d34ccb53bf33445c9022894a3416&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 11:31:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大×字节提出ComfyMind：生成/编辑/推理三连冠，开源领域再掀狂潮。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elI7B3IZQkA99hvyeKlzPzyeqYm9eaK3j5oUNFlRDs6yaz4YvOHWYMnpeWHk5ic5s7zDkXrP7RYtBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、字节跳动提出的一款基于 ComfyUI 平台构建的协作式 AI 系统ComfyMind，旨在实现稳健且可扩展的通用生成功能。在 ComfyBench、GenEval 和 Reason-</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494686&amp;idx=4&amp;sn=23451ad9c334ee58ee77919d2e8195ad&amp;chksm=fdf413ca6c0406cb96672b4d46be19f959c02cd633d1ad335ffd33a4e89fd81356770f55c064&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 08 Aug 2025 11:31:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 港科大&amp;商汤等提出3D生成框架CoPart和首个3D物体数据集，开启3D生成“从一到多”新纪元。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emibFb2yjWOaTxdIcy45IqouPaRapq8gWkGsbxM1dTO9s8LcAth8EpxCCuuF5TTMQPvpUxibvkflknA/640?wxtype=jpeg&amp;wxfrom=0"/><p>香港科技大学、香港中文大学、商汤科技研究院提出了一个全新的基于部件的 3D 生成框架CoPart ，它能够通过多个上下文部件潜在特征来表示 3D 对象，并同时生成连贯的 3D 部件。并且还发布了首个已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=1&amp;sn=91ac5035c23845d5ebbc8e7c22593048&amp;chksm=fd264d523ecfd9c20cec2808d13c910f453a8fc64f3dcab7130d1108bf821f40e213f637c502&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[自动生成ComfyUI工作流？英伟达提出ComfyGen：通过LLM来生成匹配文本的工作流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eny4Iriba5NSXkHvLxicLITJDqnLYd3byQhrC0bKwIGSOFEPvibmO8gTicw8bg8Y16oLT3TR7jWM7j2AA/300?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyGen的核心在于通过LLM来匹配给定的文本提示与合适的工作流程。该方法从500个来自用户的多样化提示生成图像，随后使用一系列美学预测模型对生成结果进行评分。这些评分与相应的工作流程形成了一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494560&amp;idx=2&amp;sn=1a210355a13a70904ac362f166b39866&amp;chksm=fdac5bf7acb4c86844eb5f91193e4ecfe12dd7d5c67211e864f845eef1516bd47d7c4556a86f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>