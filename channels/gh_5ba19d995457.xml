<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491916&amp;idx=1&amp;sn=4ea56c7ef212c03aafe58a705bf754e9&amp;chksm=fde5c0ea964257ccd012db7745bc71a40df150d8b780a1bb9156a2b0c6c5732e9d9bee259841&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源项目FastAPI-MCP，一键将FastAPI转换成MCP服务器，以后API=MCP。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5Nb69coNJjYwLrdDicA1kP6DUhlXhePTVYrhoZAuibXQhPthJOnFxIiaZvibmjL3GjGytM1LVUhBq7tJDg/300?wxtype=jpeg&amp;wxfrom=0"/><p>这是我这个月看过的最有价值的开源项目了。MCP发布之后，很多粉丝朋友都有疑问，MCP跟API有什么区别呢？简单来说，MCP就是规定格式的API，这样才可以被AI模型来调用。现在有海量的API，但都没有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491916&amp;idx=2&amp;sn=0d562e2519be09f89594e2817c42f897&amp;chksm=fd2cc98de2b5bbea6026bb2c0c2aa1f0239c4d07234ef3756712bf7647a7a5eb78e10ddbbff1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[100行代码讲透MCP原理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Z6bicxIx5naKuiafCtyF9icibwMCms6KxKgjSUDiajzIYfNuq5mEOiaDgITUQArGsx5eg6yibh8d7rfYBhoeu5l61icpFA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里妹导读本文通过100行代码看到MCP的核心原理并不复杂，但它的设计巧妙深入理解使我们能够超越简单的SDK使用，创建更强大、更灵活的AI应用集成方案。当我开始研究 Model Context Pro</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491916&amp;idx=3&amp;sn=7dc92a4432626222af9b3db4e140ea55&amp;chksm=fd490668e800658e4c892829c557c407357d54a674054968330034c6b7db2c97e50020d97499&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文带你了解，MOE 架构是什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIrjh2Jy92UibXavMpGEKRelbCqXiaEc6hkxXvNNtIibfW3p5bo1jGWB6icwh68qvkWZsqN65HicvwiaN28w/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言：从“全能大脑”到“专家团队”你是否想过，为什么ChatGPT能回答复杂问题，而手机语音助手却常“卡壳”？答案或许藏在一种名为**MOE（Mixture of Experts，混合专家模型）**的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491916&amp;idx=4&amp;sn=5831dbe4829208a0ef75a02be9688546&amp;chksm=fd3e9ed88e87966ccacad514d2e205e8c74b98565e1911aba42b66934f8e628a2c1c05f42306&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Apr 2025 16:05:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里EMO2重磅升级！手部动作生成+超逼真表情，音频驱动人像视频生成再进化！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGYiaHtTElCkzOGD9sY0N1Qp8FDJqnDN5BkTWSW0TSu1sYeAgQzRiaicMcRw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的音频驱动的人像视频生成方法EMO，感兴趣的小伙伴可以点击下面链接阅读~阿里最新EMO：只需要提供一张照片和一段音频，即可生成会说话唱歌的AI视频此外公众号的底部</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491887&amp;idx=1&amp;sn=eccb959bef4a92d52871c1fc9d75ef6c&amp;chksm=fdb9e72434abf67020fb315d86c912b7f6c4aa5538df1a14a489d010b4d1bac6f1c59303ef1c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 最强吉卜力风格工作流EasyCN来袭，风格统一+操作简便+输出稳定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/ACyQFjNqyE6xg4dG7Ndtia8iag86UJ7LAcFTmCaJMwrHhZMoY5Fjia4QeyYvmmygPtEbYjX3d9emmuUYf6flou1YA/300?wxtype=jpeg&amp;wxfrom=0"/><p>最近的ComfyUI圈子，可谓是“神仙打架”级别的热闹。就在你还在研究ControlNet怎么接线、LoRA怎么调风格时，一套堪称“傻瓜级”的全自动吉卜力风格生成流程，已经在社区悄悄流行开来。Easy</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491887&amp;idx=2&amp;sn=f041acf88c2814cb02ef9586e9b3c3de&amp;chksm=fda4ca31923e49555d440e8d959a32510218d066b2e7d03d532c60c175d5ad4c14317cd4da62&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大提出Turbo2K！2K视频生成20倍加速+VAE蒸馏，4K级画质触手可及！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5L3TwauXAyuAgh1Bpxlpf7qvZlS0Lvz5aNJNCTblRfiaCxEIINia2EHfd2DdfWKfLLBzfITOic5MYmzw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Turbo2K: Towards Ultra-Efficient and High-Quality 2K Video Synthesis论文链接：https://arxiv.o</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491887&amp;idx=3&amp;sn=85c6c046af1416ecd74aa50291ac78b3&amp;chksm=fd99881eb9023587959e3b871b4b6bb3ea1c7b93b5657037ef70246ff5f724ba12605e86ccba&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[olmOCR：重塑PDF文本处理，让语言模型更智能、更强大！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en4IAQ3D7RpAMNb2namtUvCm06G4XyBQk2BvFF6sibwR50ffvQBeE8kk0ZM9vwsVG26eMLdZ9kcia7w/300?wxtype=jpeg&amp;wxfrom=0"/><p>olmOCR，这是一个高性能工具包，旨在将 PDF 和文档图像转换为干净、结构化的纯文本。 olmOCR的主要特点包括：高精度文本提取：经过大量多样化PDF内容的训练，采用独特的提示技术，显著提高文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491887&amp;idx=4&amp;sn=f29e5d2e22a2eb84aed11a084666ae54&amp;chksm=fd9d23aa592e8ad04686ffdd286e70f05143d6be863165fd92d97e9c1c5fd8b9691dbd571dbf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 22 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[GPT4o平替？腾讯混元&amp;InstantX开源InstantCharacter，可实现跨角色外观、姿势和风格开放域个性化生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2mVMulTo5LC5G2oFcJtOgsuJWSCokK4anUcgT9xP5mIuHTqbM9wOvIw/640?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元联合InstantX团队提出全新角色定制生图框架 InstantCharacter，与当前的SoTA方法GPT4o取得了相当的结果，然而，GPT4o并未开源。相比之下，InstantChara</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491827&amp;idx=1&amp;sn=542cd31eb492311f3cd937d7e6375712&amp;chksm=fd8560d9f29e579f17f53b1bd560c601e1378ae3d6c4ff0a84ab48c089f8819ae28ba9ec37cc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 21 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[炸裂！ComfyUI 原生支持 HiDream-I1，全新文本转图神器来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2ibyrQzlh4BO0Xa83u0NI5WzuIBs5KCqMafPkjLwMiapJ0TVwXCaj6ibIQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>ComfyUI 原生支持 HiDream-I1，全新文本转图神器来了！大家好，这不是演习！ComfyUI 终于官宣——原生支持 HiDream-I1 模型啦！对于熟悉图像生成的小伙伴来说，这可是一件值</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491827&amp;idx=2&amp;sn=0a724594fbeaf36deea7e36f19e3d138&amp;chksm=fdbc10c6b4ef7e0fc6c9a161fbcb04ce4667b5f6542646be7a0ecfc7aec304a66b68882cd39d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 21 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI编程神器Cursor，保姆级教程来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2hb9jqgpc7UzDRY9moSN30Gu953gF5tc8bQ8g3TMX1lth40K1FeMuKw/300?wxtype=jpeg&amp;wxfrom=0"/><p>一、下载与安装（很丝滑~）Cursor 是什么？想象一下，你有一个能把你的创意变成现实的造梦 AI 助手。不管你是想利用 AI 提高办公效率、开启科研提效模式，还是做一个小游戏、开发一个网站，甚至自己</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491827&amp;idx=3&amp;sn=6ed618468d6b51b7c75818f6dd82d23e&amp;chksm=fd8ce7ae0fda202592ceefc41b4799f4d31b260d0256451415e66d75f416b1eda12a68144047&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 21 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[智谱发布GLM-4-32B系列模型，以32B模型参数比肩GPT-4o和DeepSeek V3/R1。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2GuZkgYicCnsBNHL18lHx1JdkI1UvGtUYV709l07L3xhibpDZtW2lQvEQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>2025年4月14日，中国AI领军企业智谱AI正式推出GLM-4-32B-0414系列大模型，以32B参数量实现全方位能力跃升。该系列创新性融合对话、推理、沉思等多元智能模块，在基准测试中展现出与GP</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491827&amp;idx=4&amp;sn=0bc0a8dc344c0e60e21ac1233fd8b7c1&amp;chksm=fde16b4ac55b9446405609465bb700543069440ceb29cd4a3138d00369f6863cc04639a42625&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 21 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里&amp;北邮提出基于Wan2.1的音频驱动数字人FantasyTalking，只需输入肖像、语音和文字即可生成动画。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en6YOGtn3XXJMye1oxLXOtQU407yMKvXQv0r7RibwF9tY6RoaWiaXTsGib66ALF1tYibibzZZ51ibfTjibCA/640?wxtype=jpeg&amp;wxfrom=0"/><p>由高德地图、阿里巴巴、北邮联合提出首个基于Wan2.1的音频驱动数字人FantasyTalking，只需输入肖像图像、语音和文字，即可生成表情丰富、肢体动作自然且具有身份特征的动画肖像。此外，Fant</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491795&amp;idx=1&amp;sn=326ca41376543a378380dae43b76882b&amp;chksm=fdbb801dbd1febd3b582023f6e5cb817175c6f7ae3d469f68da2b8db9ea3dd66001c2082e1cf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 20 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[如何使用DeepSeek进行科研图表绘制？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsFkhhJibgYhskdb4vjUEaTlFuY2pp216d97E3UsjQZuBJkB8oBHK2OrmMP1t3zaSDLBxT6GhVGv5rQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>有时候我们写论文或者看 blog，看到别人画的很好看的结构图，觉得自己肯定画不了这么好。但是现在可以让大模型来帮我们结构图。一共需要用到两个工具：大模型、Draw.io。下面的示例会使用 Claude</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491795&amp;idx=2&amp;sn=43fc9ce193f725418275a72c0cd928d1&amp;chksm=fdf425c1097f3df250fea2036670fecddac3304d0dcb1eec903f8f844dec0b77124829a2895e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 20 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TripoSG:一键使用AI在数秒内生成3D设计,支持文本/图像/涂鸦等多种方式，引领3D生成潮流！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eks71KCI53QzfLjA27o9Yf3eNhhBOwNK1fL9KrI6VvmwpTtHQY75YN6kpUNFib9wnGUtDzn1YjAYicw/300?wxtype=jpeg&amp;wxfrom=0"/><p>TripoAI发布了最新3D生成模型 TripoSG，能够生成与输入图像精确对应的高保真 3D 形状样本。涵盖各种复杂结构、多样风格、富有想象力的设计、多对象组合以及细节丰富的输出，展现了其强大的生成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491795&amp;idx=3&amp;sn=26f1ab77c42c0d16fc3e4841a2a6b08f&amp;chksm=fd2c6a3143870ede234a5c4db0e9527295cb149b3e0062430457549f0fee130524ad618c0d22&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 20 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布视频基础大模型Seaweed，70亿参数超越同类140亿参数视频模型效果，单GPU就可生成1080P！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrSjMIibqt135GUNpF74oSRXfm9iakLUsJ4cuaJkMv3pwe9GUibyujB4o5rb4L0I9e4f2iacOibCyryMg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Seaweed 是“Seed-Video”的缩写，是一项旨在构建视频生成基础模型的研究成果。该网页展示了拥有约 70 亿 (7B) 个参数的扩散变换器 (Diffusion Transformer)，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491794&amp;idx=1&amp;sn=a4cfd9fc45abc7660b5839d51c6b03f7&amp;chksm=fd8a60aa7bce87131d12d6d46ee5e880c447352f454bd96c891da64a14a0c70c2a26341a1250&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 19 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DiffRhythm：创作完整歌曲，支持文本转音乐和纯音乐生成，MacOS 上可运行！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekwL7bBtjRiakD5gmicmnfguSfr2z00p2lt6zEhibKXszCpRoFYPwAibZibGQQbQ4FYynlgbdHicZZTZn7g/300?wxtype=jpeg&amp;wxfrom=0"/><p>。公众号之前已经和大家介绍过许多关于音乐生成的文章，感兴趣的小伙伴可以在公众号栏目中点击“AI音乐”获取更多信息。DiffRhythm是第一个能够创作完整歌曲的开源基于扩散的音乐生成模型。目前已经支持</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491794&amp;idx=2&amp;sn=f08f2167ee7ff69b2d0748fdfbeb7969&amp;chksm=fd9a4ca23515fbcd0e02deff11ee985aebac602cabf7671ae5755daadfe0c5135d508a6fe076&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 19 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文带你了解，MOE 架构是什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIrjh2Jy92UibXavMpGEKRelbCqXiaEc6hkxXvNNtIibfW3p5bo1jGWB6icwh68qvkWZsqN65HicvwiaN28w/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言：从“全能大脑”到“专家团队”你是否想过，为什么ChatGPT能回答复杂问题，而手机语音助手却常“卡壳”？答案或许藏在一种名为**MOE（Mixture of Experts，混合专家模型）**的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491794&amp;idx=3&amp;sn=97203ea7e6f33b29bc6c9713ab66da8b&amp;chksm=fdcb9c7d857bb53d6e4a5e423312c8ffc9edd0c880e84f9fc2198fbcdbc66d6cac499ed3530d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 19 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里提出OmniTalker，从文本联合生成语音和说话视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src=""/><p>阿里的通义实验提出了 OmniTalker，一个从文本联合生成语音和说话视频的统一框架，它减轻了现有方法中冗余计算、错误积累和视听风格不匹配的痛苦。支持零样本上下文多模态生成、情感表达生成、长视频一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491794&amp;idx=4&amp;sn=5ea59b009a5a7b1f58948ce9be29857c&amp;chksm=fdaa8d4c27d42ee60212396c44abe5d84a18b132b99241f924b3c96225fe9fd6516a962b3c67&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 19 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[昆仑万维提出开源版视频生成模型SkyReels-A2，可实现多图输入作为参考高效生成视频，超多玩法等你探索！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enVH0KHB0ibRLR8832tzUvuvdkWH11Nf1Uf6BHKPKFWcDgU7CS3eDJLljlAQJtIr9zMPUjsQfIhbdw/640?wxtype=jpeg&amp;wxfrom=0"/><p>SkyReels-A2 模型利用视频扩散变换器的创新方法，通过编码参考图像的空间和语义特征，可实现用多图输入作为参考素材高效生成视频。可应用的场景如将角色、目标和背景参考图像合成自然的视频，多人参考构</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491792&amp;idx=1&amp;sn=69ef1186dee26ebfa3c63686a09e9ae8&amp;chksm=fd50057c8c308fe57175d0fe33a9e32efa59dba717badee9a39d1ac3d448ffd9b1bac828bf25&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 18 Apr 2025 23:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源十几小时狂揽1w多星！OpenAI发布Codex对抗200亿美金估值的Cursor。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NZ43JrlIJgibBibt8N99shfdnOPJY6xeYVicBV6NjusfibaIZNdsNyyCZOOibNkIY1dmo8XAZmibw70eJicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天不聊OpenAI刚发布的 o3 和 o4-mini，那些功能最近看的有点多，估计你们也看累了，一起来聊聊Codex。OpenAI十几个小时之前开源了Codex。意图很明显了，Cursor的蛋糕，他</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491792&amp;idx=2&amp;sn=3c1da997b2c7dc15068fb174dd4f9e3d&amp;chksm=fdcaf326fde2665db87a6b7cc27b235c61615540ad6e0c9aa32a6599ffc8cbee0056315ca803&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 18 Apr 2025 23:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[智谱发布GLM-4-32B系列模型，以32B模型参数比肩GPT-4o和DeepSeek V3/R1。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enVH0KHB0ibRLR8832tzUvuvZVg3YCibtVk7ez9fBG3YojNuRcIAA53k3lxvT0RO1AhCZP7RD3xCeOg/300?wxtype=jpeg&amp;wxfrom=0"/><p>2025年4月14日，中国AI领军企业智谱AI正式推出GLM-4-32B-0414系列大模型，以32B参数量实现全方位能力跃升。该系列创新性融合对话、推理、沉思等多元智能模块，在基准测试中展现出与GP</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491792&amp;idx=3&amp;sn=b39e36727be4aa37b3d09b76689a77d4&amp;chksm=fd840a574cd398c17781a7d3bf617225cc45d643d348df1c5cae86351162a637df2eb9617f4e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 18 Apr 2025 23:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[效果炸裂！Controlnet作者新作FramePack颠覆视频生成编码，6G显存即可完成单图到60秒视频生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enVH0KHB0ibRLR8832tzUvuvUibuQww4kQjU0wfGW53cHlodyDyxiaOOdpiaia1bE6iaBV5JtOvtQrTaZZw/640?wxtype=jpeg&amp;wxfrom=0"/><p>近日，Controlnet作者又提出了一项效果炸裂的工作FramePack，它是一个预测下一帧（下一帧部分）的神经网络结构，可以逐步生成视频。FramePack 将输入上下文压缩为恒定长度，从而使生成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491758&amp;idx=1&amp;sn=c6d0a711beb71e4079e898e6e0372cd0&amp;chksm=fdaad40b0160133340cae79462fa0c14714b08e2aa82ce3f47c5674145045b15f5e90891e54c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[何恺明ResNet登顶！Transformer上榜，Nature揭秘21世纪引量用最多的论文！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enVH0KHB0ibRLR8832tzUvuvv61hliaCtCmwKxj7UnYBmnEjyQGdzZlWPCTFficm9IuyicCN1lurhYgVQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文转载自公众号：小白学视觉 如有侵权，请联系删除~21世纪第一个25年，AI领域被引最高25篇论文都有哪些？近日，Nature头版独家文章，揭秘了不同科学领域最具影响力的论文。然而，令人意外的是，那</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491758&amp;idx=2&amp;sn=80e5d9127eaeac1c02f36008e753462c&amp;chksm=fd248ee85636e99d14a07739bc1e7379ce41dfdacfba0703a9aba13569d4548e655d8b23034a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌研究院联手牛津大学推出Bolt3D！7秒内单GPU生成高保真3D，推理成本直降300倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LR8w1T4XSJwAUg3UkzLpMRYxbTOuSXUEpxZVs5u18QTNFMFHe41E6SY6vfhMbJicRDetQWdibB3Nicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Bolt3D: Generating 3D Scenes in Seconds论文链接：https://arxiv.org/pdf/2503.14445开源代码：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491758&amp;idx=3&amp;sn=936f190bd28ac27b2c6c3b3900447811&amp;chksm=fdaa1a0bdd88e3c6a4eeb0c48031f9546be9aa562051b8df0b8745fc7ff5888ecd11b98c3fa8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Apr 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科&amp;腾讯&amp;清华提出全球首个多模态Mamba生成框架ACTalker，支持多信号输入，数字人嘴型同步再升级！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enM1R1hvr6fIvNPnJ8HAkjER32Qr4uJljRDnNXhyE9UPgfaB2EKia2QjfDCSEHzibXgefW4NfoP8eNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由港科大、腾讯、清华联合发布的全球首个多模态Mamba驱动框架ACTalker，它是一个端到端的视频扩散框架，支持多信号控制和单信号控制，用于生成说话头部视频可以实现单/多信号随心切换，虚拟人嘴型同步</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491758&amp;idx=4&amp;sn=99758216ac460e8e82af4b4d2813cac0&amp;chksm=fd21d79c4abea941273c73e9270ba86f4e834aaf434540e11eec5e60c23e091bd6c7f88a828f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 17 Apr 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>