<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/640?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492417&amp;idx=1&amp;sn=3e618911b65e80fe7f5299f9030b505d&amp;chksm=fde7f8dea8bd157294d8f88a92b9592b17e581136eab2c825c2e5057cc76812bb5221840e62f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 16:46:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 字节DreamFit: 多主题电商服装迁移！轻量级即插即用任意服装模特匹配]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGSxicUBwA56Pek0VwHmNacVsMhP7pROSIyva554J3rL1LBI4t5lpvM0icF2YaPAtfrN22ICPibd001Fg/300?wxtype=jpeg&amp;wxfrom=0"/><p> DreamFit:为服装增加电商模特DreamFit简介今天文章介绍一款新的虚拟试衣框架：DreamFit，这是一款结合了一种专门为以服装为中心的人类生成量身定制的轻量级任何服装编码器。DreamF</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492417&amp;idx=2&amp;sn=951f4a2208789a68eb0c854feb3f9fb4&amp;chksm=fd010ed550e295f246fe8367fb4a8afedb05044c46e6c0e7aca4878a6adf392b39d8cd3cb65b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 16:46:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IC-Light升级，支持视频重打光! RelightVid可在多视频场景中重照明，支持文本提示、背景视频和HDR输入！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6QSiaic7OicOck7L6SeBvmG8KxGGhaK7IiaIoGtBJsFyM7LffJExAYwxgr09hKHicONPnN40NOq3Cib7A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经和大家介绍过ControlNet作者关于图像重打光的工作IC-light，这篇论文也是获得了ICLR2025的满分评分，感兴趣的小伙伴可以点击下面链接阅读！ICLR 2025满分论文，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492417&amp;idx=3&amp;sn=830e9f98ed2fd93d355c132b62cf4ae8&amp;chksm=fd4997cc1023e708e92cb84e2ceeda70aeed1e98fcf3d4b1359607a1ca3b414b6ad6fda6a95c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 16:46:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[TripoSG:一键使用AI在数秒内生成3D设计,支持文本/图像/涂鸦等多种方式，引领3D生成潮流！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eks71KCI53QzfLjA27o9Yf3eNhhBOwNK1fL9KrI6VvmwpTtHQY75YN6kpUNFib9wnGUtDzn1YjAYicw/300?wxtype=jpeg&amp;wxfrom=0"/><p>TripoAI发布了最新3D生成模型 TripoSG，能够生成与输入图像精确对应的高保真 3D 形状样本。涵盖各种复杂结构、多样风格、富有想象力的设计、多对象组合以及细节丰富的输出，展现了其强大的生成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492417&amp;idx=4&amp;sn=72b7073c0f74ec3046da3214d4b91865&amp;chksm=fdd370daa028cf1803be96592fd24aa26b63033d3267487884e6270c3073bcea8e47eca9177b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 13 May 2025 16:46:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[200M参数吊打商业巨头！浙大-哈佛开源ICEdit，用1%资源实现图像编辑自由！一句指令生成海报级修图方案。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekBUypVTojw9NicChAveibQcTLDAqzMNvNlVcY8Qyp0Uw8xV4We94zZVeNGOiaduoVu37rdJoZlxoibZg/640?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学联合哈佛大学提出一种高效的基于指令的图像编辑框架ICEdit，与以往的方法相比，ICEdit仅需1%的可训练参数（200M）和0.1% 的训练数据（50k），就展现出强大的泛化能力，能够处理各</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492357&amp;idx=1&amp;sn=4119d0fb9949e7a9ddb074ac9995b590&amp;chksm=fd7180cb3708e62393465567312dd544877e84952bf15b7fa5259e849b1ea610f6aac369b89f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 16:46:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[太强了！浙大联合上海AI Lab提出视觉统一Diffusion架构DICEPTION！各种视觉任务一网打尽！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcb6XeOfGM7ic3jww1VGas5hyQ5UbdLhbhjcqHwrckdlwdXIvppjK9PlGZVkxMpOMiaT6tDJ32KOqiaA/300?wxtype=jpeg&amp;wxfrom=0"/><p>数源AI 最新论文解读系列论文名：DICEPTION: A Generalist Diffusion Model for Visual Perceptual Tasks论文链接：https://arx</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492357&amp;idx=2&amp;sn=037ae94a5186916a0f761ae334cb6f27&amp;chksm=fdcdb6978318282db037dd5ca44acf747a4b0a6b18d13c8fad6c65e64b68669d96647e9522e2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 16:46:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[月之暗面开源音频模型Kimi-Audio，从「语音转文字」到「读心对话」，让AI听懂人类 “弦外之音”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNEC7g7nZPhc47aJoHlH9ymyhbNzAvibM4Zam09k4hqrh7JZEIVIibOtic48A/300?wxtype=jpeg&amp;wxfrom=0"/><p>近期，Kimi在语音交互领域发布了Kimi-Audio模型，这是一个开源音频基础模型，在音频理解、生成和对话方面表现出色。AI让机器不仅 “听到” 声音，更能 “听懂” 语言背后的情感、意图和语境。K</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492357&amp;idx=3&amp;sn=68103ed19d5a25e424ded77986ceb345&amp;chksm=fd8cdf0474e8e1ba56012210610d0bcc2888499ed47bf096417398cafdfc56ad87bba24ba45f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 16:46:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[如何使用DeepSeek进行科研图表绘制？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsFkhhJibgYhskdb4vjUEaTlFuY2pp216d97E3UsjQZuBJkB8oBHK2OrmMP1t3zaSDLBxT6GhVGv5rQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>有时候我们写论文或者看 blog，看到别人画的很好看的结构图，觉得自己肯定画不了这么好。但是现在可以让大模型来帮我们结构图。一共需要用到两个工具：大模型、Draw.io。下面的示例会使用 Claude</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492357&amp;idx=4&amp;sn=ef83fee7ff201de37dfe4823aacf25a1&amp;chksm=fda8f371c11e041b6877f0121922ec92d3a82a87df2d4f388b0070214e27bfebefe060ed5e46&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 12 May 2025 16:46:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出高效文生图新框架FlowTok，可实现文本和图像无缝衔接比，比PixArt 快3倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECxwAibKNhTZ8hJo5SVEib892Bw9ibAqiavicF5qn1bjb71Z4qShC1Wdka5Xw/640?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出了一个精简却强大的框架FlowTok，通过将图像编码为紧凑的一维 token 表示，实现文本和图像之间的无缝衔接。FlowTok内存效率极高，所需的训练资源显著减少，采样速度也显著提升，同时性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492325&amp;idx=1&amp;sn=4be16a8063a2b985e1fd99e70dabcba5&amp;chksm=fd9a3c5219d1b9c17e9cb204527797ba2d31706cc3feb0afefa17d73ed497642d06dd5a93a9a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[重磅突破！只需一张图，一键生成沉浸式4D全景世界！HoloTime重塑VR/AR体验（北大等）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icogEQhMxTpcKl9HOR9TzDQaPT45zyr698A5aD6iaDhBAAywD0P7R5TakNMbMSMEZbJCm0CooRytvdsw/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2504.21650 主页链接：https://zhouhyocean.github.io/holotime/ 代码链接：https://gith</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492325&amp;idx=2&amp;sn=137ce893c6df7c8ba3a221d16f9ee21c&amp;chksm=fd7d78b6b0fd607f678e905211b357ccb64701489a06e3f21845ebfa039ccb953dc0c4193991&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里EMO2重磅升级！手部动作生成+超逼真表情，音频驱动人像视频生成再进化！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGYiaHtTElCkzOGD9sY0N1Qp8FDJqnDN5BkTWSW0TSu1sYeAgQzRiaicMcRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的音频驱动的人像视频生成方法EMO，感兴趣的小伙伴可以点击下面链接阅读~阿里最新EMO：只需要提供一张照片和一段音频，即可生成会说话唱歌的AI视频此外公众号的底部</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492325&amp;idx=3&amp;sn=c119b9339ce1be9a0c507905ddabb8a4&amp;chksm=fd5edc42e40ac31b32e549dea46da99915def15adf7d941687599975d186f0364e507e4df7bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一文了解：大模型 Agent 开发框架有哪些？它们的区别是什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIr8DNP5MR3eP0zlA9JsT0hBHpz7mIT9yRpuDv80p9ANexpSib1fao2maWhK8nPVqlRMv4h1P6M8ia8Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>——大模型时代，如何选择适合的 Agent 开发工具？引言随着大模型技术的爆发，AI Agent（智能代理）逐渐成为落地应用的核心载体。它不仅能理解语言，还能自主规划、调用工具、执行任务，真正让大模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492325&amp;idx=4&amp;sn=6c223ebb631fd99d843621c3e55df620&amp;chksm=fd763ade105ef21f0c0fb57468b41091cae6a92bff6a22602afbbe0b0777cb4cfeafa1c8ca72&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 11 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR2025 | 同济提出无需训练的肖像动画框架FaceShot，让表情包、动漫人物、玩具等“开口说话”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECN5vlsQZr9AOKKvriaYqbhSHH5y8IBJg25HQaMqclHrVZ7Dp9ObVuiaww/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天和大家分享同济大学的最新研究FaceShot: 一举打破肖像动画模型“驱动真人”的局限，FaceShot 的动画效果可应用于各个领域的角色，包括 3D 动漫、表情符号、2D 动漫、玩具、动物等等。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492288&amp;idx=1&amp;sn=42c7b4a8c8241a17a56a0f20b5d3e4ee&amp;chksm=fd251729c065f10c423aadf985697cfa3dbcd2cb9170de9e37a1954703a1b33561241bc16d56&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 16:08:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 Highlight | 清华提出一键式视频扩散模型VideoScene，从视频到 3D 的桥梁，一步到位！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en6YOGtn3XXJMye1oxLXOtQDu8lVia8rZmBpsouclpUQ8eY6ebkIhqsCQhQiabYLqW83mluezLMicI1g/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华大学的研究团队首次提出了一种一步式视频扩散技术 VideoScene，专注于 3D 场景视频生成。它利用了 3D-aware leap flow distillation 策略，通过跳跃式跨越冗余</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492288&amp;idx=2&amp;sn=7b987747ea46801d8a9c8217d4b9eac1&amp;chksm=fdbf72c12a933ddee3c505db6195413c32efad4ec5cdc60ca2a52443bfaf2e778c9e034bb402&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 16:08:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Qwen3发布，再次登顶全球大模型开源王座，再见DeepSeek。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NZTI0d3fFk1nSJ44lvqzpibvN6pGVwcafWz269r3hd0VjByWXH94FyS8CvTxq2UJ47eIIia3iaN2iaBaw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日凌晨，Qwen3终于发布。网友直呼“等得好苦”。我也想说，明知道大家都在等着，你今天才发布，咋不等五一大家都放假了再发布呢？？？？？Qwen系列也是超越众多模型再次登顶开源王座。旗舰模型 Qwen</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492288&amp;idx=3&amp;sn=fdea136ae01c7e014331e0ef1750f593&amp;chksm=fdbb0086e657e21e2ddc7253e43b9db79f83dd208b9eb9f96fea841ef5b2e1d78fdaccfbd944&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 16:08:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 艺术工具通讯]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2rrZo6MvQMib3yaV5BITXF7CQorbzEicSeSiaBVwm9FpIicKhJ3TeBW7JsFmeMmjr8CqMt5ibicJRkEmjnQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>创刊号 🎉AI 领域的发展速度令人惊叹，回想一年前我们还在为生成正确手指数量的人像而苦苦挣扎的场景，恍如隔世 😂。过去两年对开源模型和艺术创作工具而言具有里程碑意义。创意表达的 AI 工具从未像现在这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492288&amp;idx=4&amp;sn=369b17783cba4a801940499bdde312ca&amp;chksm=fda3bfe263ceae4039731ec67c1b32b8e2923e0bfdf2c7a17c206991a8dca9b7b9f170e76eae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 10 May 2025 16:08:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[月之暗面开源音频模型Kimi-Audio，从「语音转文字」到「读心对话」，让AI听懂人类 “弦外之音”！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNEC7g7nZPhc47aJoHlH9ymyhbNzAvibM4Zam09k4hqrh7JZEIVIibOtic48A/640?wxtype=jpeg&amp;wxfrom=0"/><p>近期，Kimi在语音交互领域发布了Kimi-Audio模型，这是一个开源音频基础模型，在音频理解、生成和对话方面表现出色。AI让机器不仅 “听到” 声音，更能 “听懂” 语言背后的情感、意图和语境。K</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492287&amp;idx=1&amp;sn=92def84f0ac1d364a13d26c853b9a39a&amp;chksm=fde6d6362b85c6e1325bd0fefa0084043da9dbaee17b52ae355f2b42c087b11fbcf99f06c86e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑革命，万物皆可插入！浙大/哈佛/南洋理工提出Insert Anything，告别PS抠图，AI让世界无缝生长。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7Ficnb2ehPShfDudYtibS1fkY0Su3IFmdP3MkS9KDH1gsquQnXh8Ku6TPQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>浙江大学、哈佛大学、南洋理工大学联合提出了统一的图像插入框架Insert Anything，支持多种实际场景，包括艺术创作、逼真的脸部交换、电影场景构图、虚拟服装试穿、配饰定制和数字道具更换，下图展示</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492287&amp;idx=2&amp;sn=2066bf4a0c95d1c2ea4fa6ce5d95d39d&amp;chksm=fd29478572360d392afff4550e2784fe0447f9ea2630546e69b12341d44ab46fb10e70d2da0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI编程神器Cursor，保姆级教程来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2hb9jqgpc7UzDRY9moSN30Gu953gF5tc8bQ8g3TMX1lth40K1FeMuKw/300?wxtype=jpeg&amp;wxfrom=0"/><p>一、下载与安装（很丝滑~）Cursor 是什么？想象一下，你有一个能把你的创意变成现实的造梦 AI 助手。不管你是想利用 AI 提高办公效率、开启科研提效模式，还是做一个小游戏、开发一个网站，甚至自己</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492287&amp;idx=3&amp;sn=9e95273e2e2b4defd0ac7e661a883cb7&amp;chksm=fd98f335a66322a2c14e466dce4a6492c019aa59132e5a60afb57888e407e9fe9a101f9cbe90&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 09 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字体控狂喜！Liblib AI 黑科技 RepText：无需理解文字，AI就能 1:1 复刻多国语言视觉效果。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elFfbYTqwA595BOINVFyGzKJTeUTfexNWrNdN8IAiaUICEpfK2hvFm6G9wMRKkN6XcT63ldibkLQRdg/640?wxtype=jpeg&amp;wxfrom=0"/><p>Liblib AI提出了 RepText，可以使预训练的单语文本转图像生成模型能够以用户指定的字体准确渲染，或者更准确地说，复制多语种视觉文本，而无需真正理解这些字体。这样不管是中文、日文、韩文还是其</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=1&amp;sn=c8dde389ff8a0f42b34061cab88073b6&amp;chksm=fdf0f9eb452a4892b7f82eb19acd65b1e14c37788d677c80c74ef52200b5b244326f795075eb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[142页深度解析：DeepSeek-R1的推理技术综述，AI的“思考”秘密大公开]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic74EgPzUnjibrG5SK0JmT8ksETRvVrR1XcCZjqetgGsxyQHiaa0hCYjVTIMhicnh9kAXbQjIYxYwDkxQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek-R1 就像是AI界的“思考者”，能够像人类一样进行复杂的推理和思考。在数学、编程、科学推理这些超难的任务上，它的表现简直逆天，直接对标OpenAI的o1正式版，妥妥的推理界“学霸”！</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=2&amp;sn=079a63c4faae9de36a250d6ab0172ab5&amp;chksm=fdbe448b6fa60dbe059c47e784aa4264a1e74e7ad1e11a13ef38aca213bf9d42b93cff16ca52&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港大&amp;Adobe联合提出图像生成模型PixelFlow，可直接在原始像素空间中运行，无需VAE即可进行端到端训练。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em57kq23EbSGQ52kUcSia6n8oTIJOicficBicZpibaJQgm7tEpQJ6psVkrLse6pjDUwqiaktvnGSEiaL6xPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港大学和Adobe联合提出了一种直接在原始像素空间中运行的图像生成模型PixelFlow，这种方法简化了图像生成过程，无需预先训练的变分自编码器 (VAE)，并使整个模型能够端到端训练。通过高效的级</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=3&amp;sn=03fb4e2b61fadb948acca9a182753435&amp;chksm=fd2f4f32850f34ec24a30633e9d9a6b5dc40c34fe93c497fee4fda605c32e158e15136caa975&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[英伟达提出最强「描述一切」模型 (DAM)，可生成图像或视频特定区域的详细描述，拿下7个基准SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECib2BYEbUlY3dMInZdicOKQibQAMwDLHA4kgviaROXJC16pncBthoyHBQJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达提出「描述一切」模型 (DAM)，这是一个强大的多模态大型语言模型，可以生成图像或视频中特定区域的详细描述。用户可以使用点、框、涂鸦或蒙版来指定区域，DAM 将提供这些区域的丰富且符合上下文的描</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492286&amp;idx=4&amp;sn=f87c6e35673a2de357f72417d46f40f5&amp;chksm=fdfe4ee608f84dfdbcaa172b57b0a824299ec9506d3453fbedd94f7f78e5c142221d1f694654&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 08 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别"纸片人"试衣！阿里&amp;浙大提出3DV-TON，用3D几何骨架+动态纹理场，让虚拟模特"活"出真实衣褶！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECFZTEAl6XrNJIs6kBFtCKh4H4USr1Odbdw4IOg8SSgUfrQQVgR52lmA/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里联合浙大提出3DV-TON，可生成高保真度和时间一致的视频试穿结果，3DV-TON是一种基于几何和纹理 3D 引导的新型扩散框架。 可处理各种类型的服装和身体姿势，同时准确还原服装细节并保持一致的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492245&amp;idx=1&amp;sn=160b95e244bf15f744324d221dc1dd79&amp;chksm=fdab9b8eeb0c58bd47cbac63040faf64c489e4abf3f0c42c0b6e22004deca12ce38d5d437ee7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌研究院联手牛津大学推出Bolt3D！7秒内单GPU生成高保真3D，推理成本直降300倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LR8w1T4XSJwAUg3UkzLpMRYxbTOuSXUEpxZVs5u18QTNFMFHe41E6SY6vfhMbJicRDetQWdibB3Nicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Bolt3D: Generating 3D Scenes in Seconds论文链接：https://arxiv.org/pdf/2503.14445开源代码：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492245&amp;idx=2&amp;sn=44b4076684d67ccb8491aae4497914ab&amp;chksm=fd7833f99e5a68599ff7aa5385ccc22036a213863ca81ce63f08c58154bc30754eef5b1f7e09&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[如何使用DeepSeek进行科研图表绘制？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsFkhhJibgYhskdb4vjUEaTlFuY2pp216d97E3UsjQZuBJkB8oBHK2OrmMP1t3zaSDLBxT6GhVGv5rQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>有时候我们写论文或者看 blog，看到别人画的很好看的结构图，觉得自己肯定画不了这么好。但是现在可以让大模型来帮我们结构图。一共需要用到两个工具：大模型、Draw.io。下面的示例会使用 Claude</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247492245&amp;idx=3&amp;sn=5be82eee7d99fa053a202314f30e008e&amp;chksm=fd56add71bd4b4380107f11e0c1ff35383155d3ea37144bd199060773f3ae69066116af486a5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 07 May 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>