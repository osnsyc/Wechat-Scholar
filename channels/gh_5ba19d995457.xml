<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[高质量开源二次元风格图像生成模型Neta Lumina，从Furry到国风，全方位赋能动漫创作新体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnnuuc8trMqQZdXicVSnCicAT0JorhOHp7RZ0picPcQW6vmQULK0icb6qeo3A/640?wxtype=jpeg&amp;wxfrom=0"/><p>Neta Lumina是由 Neta.art 实验室开发的高质量动漫风格图像生成模型。基于上海人工智能实验室 Alpha-VLLM 团队发布的 开源Lumina-Image-2.0，利用大量高质量动漫</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494060&amp;idx=1&amp;sn=a20eebec1beb20ed911d356094ecb7a2&amp;chksm=fdde39531d16ffa08c3cd377398230d383667a06fdb8e0a459a44e0032ce817e5b6b0bd008fe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OmniAvatar：让静态照片“活”过来，音频驱动全身动态视频生成新纪元！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHjoNmnhIZ1WlEINYQPhBVwHtIicGD7DRHo7WEJn1mYDaiaRkEf8ES1uzXk9uBREDlwHfWKdLcqs2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>OmniAvatar：“全能”的数字人视频生成。OmniAvatar 是一个基于LoRA的高效的音频驱动全身人像视频生成系统，支持从音频 + 单张图像 + 提示语生成自然、表达丰富的视频，仅需一条音频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494060&amp;idx=2&amp;sn=aeb5da8b53d66ac305bfc902eaafa605&amp;chksm=fd719e47eb741df63ed88601e8d70ffececaa704bbb794ce2797fc95f4e20c72891c6c1a0fb3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494060&amp;idx=3&amp;sn=c0d6d8df9cdd570fabd8b3a50b45ebec&amp;chksm=fdb45ed38b6035a6f69ebd8e54ea86d965c59e78e40e525e58c664a1bc9a958f213fac466355&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DreamActor-H1，让产品与模特“一键生成”高保真交互视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48RPbNymvllhYib3H7VZyk223eWwAma3ovH2vTKZCY7Hg7zPurzD9kpqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>DreamActor-H1 是一个基于扩散变换器 (DiT) 的创新框架，能够根据配对的人与产品图像生成高质量的人与产品演示视频。DreamActor-H1 基于大规模混合数据集进行训练，并结合多类别</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494060&amp;idx=4&amp;sn=d54c16d65743a821708f577633e48ffc&amp;chksm=fd889d72b8c82aed489631733801718df7075762d62a1393cbde5a5bf0ade9a21ba6cd2da13b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 08 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[重磅！黑森林实验室开放 FLUX.1 Kontext [dev]权重，120 亿参数黑科技，重塑图像编辑格局！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnn2bgzfAyBa1WiaESib9rM1Nz4l8rxIE1JdrFUviauFI2D6iaYeqtn00kOdA/640?wxtype=jpeg&amp;wxfrom=0"/><p>迄今为止，所有功能强大的生成式图像编辑模型都只能作为专有工具使用。如今，黑森林实验室发布了 FLUX.1 Kontext [dev]，这是FLUX.1 Kontext [pro]的开发者版本，它在一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494059&amp;idx=1&amp;sn=fc21ac36afe7b0218348f3015e41e238&amp;chksm=fdc36173e8147a5a9a5e64906f8abfe7d24a04324397e01c13a0b8e48ac02b6c7c3e5dce989b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI界的"六边形战士"！港科大×字节提出ComfyMind：生成/编辑/推理三连冠，开源领域再掀狂潮]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elI7B3IZQkA99hvyeKlzPzyeqYm9eaK3j5oUNFlRDs6yaz4YvOHWYMnpeWHk5ic5s7zDkXrP7RYtBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、字节跳动提出的一款基于 ComfyUI 平台构建的协作式 AI 系统ComfyMind，旨在实现稳健且可扩展的通用生成功能。在 ComfyBench、GenEval 和 Reason-</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494059&amp;idx=2&amp;sn=8d9f8a6f9061de481329f1e0d96d617f&amp;chksm=fd17c05448ec1253f445f517389231c19c486253683c8744c28853ec65b65d5bd2680b4efcc1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工力作Sparc3D：开启三维重建可微分优化与高效生成新纪元。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enhd8Da8niase1WltgKePj289UYQ2FkGK7uxrgpyoOIA6cIHk7jU4q6hvNUWTsCz3qI24ic8ibqQ8GjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>由南洋理工大学推出 Sparc3D 是一个统一的框架，它将稀疏可变形行进立方体表示Sparcubes与新型编码器Sparconv-VAE相结合。Sparcubes 通过将有符号距离和变形场散射到稀疏立</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494059&amp;idx=3&amp;sn=8c6a99ce9411602bf664cb73a62c0ec0&amp;chksm=fd20362e1ed8d53767b53e3882be7f8ce1c3e07e470c4a57fdc50f2a30e277f64f16e8c247e5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OmniConsistency: 一种基于扩散模型的风格一致性插件，用于高质量图像风格化。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic6Yl0kTibHR6qeAggicnWLicFJTdTmKJibxibXDMjL83Ixvlciaqcwyoro532IvxIK9M3hB7eZ096Yw6jVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>OmniConsistency 提出一种基于扩散模型的风格一致性插件，通过两阶段训练策略和滚动LoRA 银行机制，实现了在多种风格下的风格一致性和内容保真度，性能接近商业级模型 GPT-4o。在图像风</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494059&amp;idx=4&amp;sn=fc6159a5f08a18af583e896a2cf38ef2&amp;chksm=fd4e96f03c4ec6d6591ea8c971fde95953d56bda3cc451c6f6b100781d47d21430cc98acb9fc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[清华大学&amp;IDEA推出GUAVA：单幅图像生成实时可动画3D上半身，渲染速度突破0.1秒，表情与动作实时同步。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48yKhiadt9NN3KPxkMsuNZZxMYJMZSYDV5RsGLlXBfUxecaFP3xYF5UHA/640?wxtype=jpeg&amp;wxfrom=0"/><p>由清华大学深圳国际研究生院、国际数字经济学院（IDEA）联合提出的 一个用于快速可动画的上半身 3D 高斯形象重建框架GUAVA，对于每张图像，GUAVA 可以在亚秒级时间内通过前馈推理重建 3D 上</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494058&amp;idx=1&amp;sn=0a6f42b794c38bb573c59adfe8cd2ae9&amp;chksm=fd124426eb50aca6d46b2fc5ce2eac358a446692a1a4cb644e9e7529bcceedd67924708a19f6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICIR2025 | CubeDiff：无需考虑失真，重新利用基于扩散的图像模型来生成360°全景图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6qavvqaKicyhfbe1wrRfKuEmZbfJ8LvrOgQJMgZYG5CztqNUPPASQbtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给大家介绍过许多关于3D生成的文章，感兴趣的同学可以点击公众号菜单栏查看3D生成专栏，创作不易，欢迎大家点点赞和在看~CubeDiff是一种使用基于扩散的图像模型生成 360° 全景</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494058&amp;idx=2&amp;sn=c93a9d4ab69d09a23e7384d37105f8a9&amp;chksm=fdbff2ea7f542dd2e1f8c5738a2ff62344f9cf6d648c4c03e29c466520c3888ceb0cba733b10&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D 生成新 SOTA！SECERN AI 提出 方法 SVAD，单张图像合成超逼真3D Avatar！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJczQ6xAAgVU8NYrMphwhLiaiajhcsCMja0TDYcr6RulFp9C6Yt1mtcbiamA/300?wxtype=jpeg&amp;wxfrom=0"/><p>SECERN AI提出的3D生成方法SVAD通过视频扩散生成合成训练数据，利用身份保留和图像恢复模块对其进行增强，并利用这些经过优化的数据来训练3DGS虚拟形象。SVAD在新的姿态和视角下保持身份一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494058&amp;idx=3&amp;sn=2562b52332304d65038e31251952fbb4&amp;chksm=fd2d3fa43371e2a3374595cc0325976e353f38dcdb581953cb534868eebbca7f3dae4816a101&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多领域SOTA诞生！Vid2World：打通视频扩散到世界模型的“任督二脉”｜清华、重大]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icoiaeFVcHGjGc24PwYRxSa3SRzxraaxquD1Y4eiapCrHo7GN2pjc3L4XfolskYUicsqxRONc0Q9o3iaR8g/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文链接：https://arxiv.org/pdf/2505.14357 项目链接：https://knightnemo.github.io/vid2world/ 生成效果速览亮点直击首个系统性探索</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494058&amp;idx=4&amp;sn=b2abc84cbc6080c2bc07b54c10edd3b8&amp;chksm=fdfc65e9780900b97eeaf1eed8bd085da6eb997732c926db0b89d1ca9836d8ebb8b225257c06&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 06 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态图像生成新宠 Janus-4o？ShareGPT-4o-Image 打造数据集新标杆，将图像生成与 GPT-4o 对齐。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuDmLq7R1rRFldNX6Em3MD70vY7fwf61HKoCJgXp8J9PtlYAbkvyRcqskzia0Ubz28BAkMOjkHS3w/640?wxtype=jpeg&amp;wxfrom=0"/><p>ShareGPT-4o-Image 是一个大规模、高质量的图像生成数据集，其中所有图像均由 GPT-4o 的图像生成功能生成。该数据集旨在将开放式多模态模型与 GPT-4o 在视觉内容创作方面的优势相</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494021&amp;idx=1&amp;sn=5fd1fe324eda2fe504110c9a3f6d9ef4&amp;chksm=fd4e97e7d22d1d01a086db85cb5ae3525fea8293523cf959b286ad100ba5221c49870bb5049f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节、港理工提出超强统一视觉生成模型 Many-for-Many，支持10+任务，8B参数“逆袭”商业视频生成引擎。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXr1okRdYbDMkiaMBJd2BP7Rly0sBNFZKib2sPFdbSs7MvfFpF6hn5uyKnw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节、港理工提出超强统一视觉模型 Many-for-Many，如何凭它让 8B 模型“逆袭”商业引擎？字节跳动与香港理工大学提出统一框架 Many-for-Many，它借助众多视觉生成和操作任务的训练</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494021&amp;idx=2&amp;sn=7210e41ce700c1e1b20db9b0b42bd12b&amp;chksm=fd6851ad4579aaa3a8d7c9067859bc2d486b1921539a9e39948242b0311dc7467f5ea1c8ee4e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[集成 R1 后的 GroundingDINO 究竟强在哪？一文带你看清 DINO-R1 的性能变革]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ3cCzjflZrObrcGTNoJJwzrOXe4jyYx9eDs8QIOJ4W5grQyGf2tTwtS8ooDFDop2w2gcbw8UuNhCw/300?wxtype=jpeg&amp;wxfrom=0"/><p> 导读在开始今天的分享之前，我们不妨先思考一个问题：为什么大语言模型，如 GPT 系列、DeepSeek 等，在数学推理、代码生成等任务中能够展现出强大的泛化能力和对人类意图的良好对齐？除了依赖海量高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494021&amp;idx=3&amp;sn=d84421a27f13e41d22b529de5ec09a82&amp;chksm=fd4b6e2c19f64a1d14a6d23410cecb13ece5ddcf45fde5c16eb23d893cd403551716555f93a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 | 解锁虚拟试衣新姿势！智象未来提出SPM-Diff，大幅提升真实性、可控性，让衣服“贴身”又自然！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrh9ic75wTHs9dqezVrp8tteQeOdKicBiciaVprFFxw2NDD0xvwlGbvdtfzxm3Z3f8AmbzvLDk7lMYeg/300?wxtype=jpeg&amp;wxfrom=0"/><p>网购衣服总担心“买家秀”和“卖家秀”天差地别？虚拟试衣不自然、细节难还原的问题一直困扰着消费者。智象未来团队提出SPM-Diff算法，成功攻克虚拟试衣两大难题，论文《Incorporating vis</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494021&amp;idx=4&amp;sn=5434bd393c199b75f811d3585e0d1caf&amp;chksm=fd569f4b686bf769e1507fe0f59890f5c1d8bdb5317e804741c980ca5d10e0c4f7254af5f0a8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 05 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从文本到3D动画：AnimaX 前馈 3D 动画框架，解锁任意骨骼动画无限可能。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPbvzXyQzXhAWo1QdPyhvibR2nOgLfk3jfXRCH64V0YMReDLI4nZbR5kKceDeR0YnSEialEZiahJyQQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>AnimaX 是一个前馈 3D 动画框架，它将视频扩散模型的运动先验与基于骨骼的动画的可控结构连接起来。传统的运动合成方法要么局限于固定的骨骼拓扑结构，要么需要在高维变形空间中进行昂贵的优化。相比之下</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493998&amp;idx=1&amp;sn=f19ff6bcd77a2bca4c99181ac7c4b3a0&amp;chksm=fdfb18b45bb8cd9b39a6f24dc1d44996569d640ee1c5d39d502476016ae7c2880f4270f8ba28&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[BLIP3-o：融合自回归与扩散模型的统一多模态架构，开创CLIP特征驱动的图像理解与生成新范式!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek5oLyjfCjICEWyMhWNvFXDN37WVtXa4JeBibibTSdNGmBP0wSFhuUAJkiaz9qNwiccNW4SuNJ7FvduuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>BLIP3-o 是一个统一的多模态模型，它将自回归模型的推理和指令遵循优势与扩散模型的生成能力相结合。与之前扩散 VAE 特征或原始像素的研究不同，BLIP3-o 扩散了语义丰富的CLIP 图像特征，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493998&amp;idx=2&amp;sn=81a73478e596f3370618d8cc0ab8bae1&amp;chksm=fdebc27e7fa0b7ce3000088f794e21d901d158b9ce4741ffb90e9e968f3905c7a4f1a4e7894c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Hallo4：让AI肖像“活”起来！新型扩散框架实现高保真音频驱动动画生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq56s1kIaYWsxKESfb9riaHUQVlW3JfPib9AP6mL8Hk0Ec5R0f43HYJ8aw/300?wxtype=jpeg&amp;wxfrom=0"/><p>复旦联合百度发布扩散框架Hallo4，实现了准确的唇音同步、自然的面部表情，并能够稳健地处理各种角色身份和环境场景中快速的语音节奏和突然的上身运动。相关链接论文：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493998&amp;idx=3&amp;sn=dc3d781c7cf0f889a0b6cd0fbf4a4a54&amp;chksm=fd6140987112ba35f2c6669f35f18469a2a62f0b408ba0a49d72e276ba001d295a690b0fb933&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工力作Sparc3D：开启三维重建可微分优化与高效生成新纪元。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enhd8Da8niase1WltgKePj289UYQ2FkGK7uxrgpyoOIA6cIHk7jU4q6hvNUWTsCz3qI24ic8ibqQ8GjQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>由南洋理工大学推出 Sparc3D 是一个统一的框架，它将稀疏可变形行进立方体表示Sparcubes与新型编码器Sparconv-VAE相结合。Sparcubes 通过将有符号距离和变形场散射到稀疏立</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493997&amp;idx=1&amp;sn=cd6b211f235e412dbdbf985ac3d41d5a&amp;chksm=fd2fdaafbb4fda8d8bce2e0b5acd581b74d8f9c3df1a3aa241f107a93e04ad4df057058e98a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从文本到3D的“零训练”革命！英伟达&amp;康奈尔大学提出 ArtiScene：通过2D中介实现高保真3D场景合成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48HPJzGndEliaF6RR9oS2mcY6tk1tO13iaxO3UHzBrtzwlN2jFlpv4651g/300?wxtype=jpeg&amp;wxfrom=0"/><p>由英伟达和康奈尔大学提出的 ArtiScene 是一种无需训练、语言驱动的 3D 场景生成流程，它可以根据文本提示，设计出丰富多样、美观且易于编辑的场景，涵盖各种类别和风格。下图中展示了四种结果，并附</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493997&amp;idx=2&amp;sn=fa712969765e54352fb0d6bad06ee4e6&amp;chksm=fd12c5ae9d63bce137b71eeb023e413726b74bbbba7ce440dc085a903d58a99de5007fb94471&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D 生成新 SOTA！SECERN AI 提出 方法 SVAD，单张图像合成超逼真3D Avatar！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJczQ6xAAgVU8NYrMphwhLiaiajhcsCMja0TDYcr6RulFp9C6Yt1mtcbiamA/300?wxtype=jpeg&amp;wxfrom=0"/><p>SECERN AI提出的3D生成方法SVAD通过视频扩散生成合成训练数据，利用身份保留和图像恢复模块对其进行增强，并利用这些经过优化的数据来训练3DGS虚拟形象。SVAD在新的姿态和视角下保持身份一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493997&amp;idx=3&amp;sn=3debae9075d389f13eab2c735c7397f9&amp;chksm=fdaf54cdc2fde0f96624b0c7cee6a0b4fada173707e699e4d605e1442c2b86fb6c8da1b3af01&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493997&amp;idx=4&amp;sn=487263bc886fe6809d1441968bb676d2&amp;chksm=fd3cf639d69dfe1b97ae7bd2342e843433ac5ab47155d419f4f1ab6dea69a1175e06f85b1f2b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SyncTalk++：高斯泼溅技术赋能，101帧/秒实时渲染逼真说话人头像]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPbvzXyQzXhAWo1QdPyhvibDibqYDF1ukDdJ8FKtqNSro8CoyUXcEHSoiaNicyJ5coqGdSlXCY3aTU1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>由中国人民大学、北京邮电大学、中国科学院、清华大学以及北京航空航天大学联合提出的SyncTalk可以合成同步说话头部视频，采用三平面哈希表示来维护主体身份。它可以生成同步的唇部动作、面部表情和稳定的头</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=1&amp;sn=f1e6be8976b9968058cda9d6b20810b4&amp;chksm=fd12b940baa9686c3dee45399fb2b7533f13c6b5252692764df1bd62d0349dc3f624e576b474&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里EMO2重磅升级！手部动作生成+超逼真表情，音频驱动人像视频生成再进化！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGYiaHtTElCkzOGD9sY0N1Qp8FDJqnDN5BkTWSW0TSu1sYeAgQzRiaicMcRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的音频驱动的人像视频生成方法EMO，感兴趣的小伙伴可以点击下面链接阅读~阿里最新EMO：只需要提供一张照片和一段音频，即可生成会说话唱歌的AI视频此外公众号的底部</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=2&amp;sn=2ee591723ec234b4f7e3ba841c947ba7&amp;chksm=fd4f258e14b0b54a91e7f40ad7c7ce78b41cd8c48ff1ae6b658072727c8a08ccca1a12a160f4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[6秒音频即可克隆AI语音！FLOAT数字人生成语音/口型/表情，情感同步超惊艳，文中附工作流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJcmBGicWjwiauMpFknBOofINibzHjBSIibjwDHKYvhnzulS1E2KIPicobCywA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的 FLOAT 是一种基于流匹配的音频驱动的说话肖像视频生成方法，可以增强语音驱动的情感运动。该方法唇形同步质量高，生成速度还很快。6秒音频完美生成语音/口型/表情。情绪转移由于 FLO</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=3&amp;sn=9311d2fba8792a48d886b1a94db125b5&amp;chksm=fd617e8bed8dfb625fc3400dc9b081fc3bfae803e6c86cb23a717cf3ef5564bd15c65395733e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源数字人克隆神器HeyGem：1秒视频生成4K超高清AI形象，用AI重塑数字人创作生态！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRrgxstWFTNfP8vOAkR5RI8GOy83ObgNDrZJL0p3TTnAIBViacS7PlySow/300?wxtype=jpeg&amp;wxfrom=0"/><p>在虚拟形象与数字内容需求激增的当下，传统3D数字人制作的高昂成本（动辄数十万美元）与复杂流程，让许多行业望而却步。而今天，一款由Duix.com团队打造的开源AI项目HeyGem，正以颠覆性技术打破这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=4&amp;sn=9f6a5a3403a6c92f97f2c3a90e3c6d04&amp;chksm=fd890b709cca9aca5d674fa96c98e82dcbf0ed60eca76986b409cca0a39d250d95f8c45ae1f0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>