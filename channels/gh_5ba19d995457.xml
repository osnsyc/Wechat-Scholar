<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[字节、港理工提出超强统一视觉生成模型 Many-for-Many，支持10+任务，8B参数“逆袭”商业视频生成引擎。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXr1okRdYbDMkiaMBJd2BP7Rly0sBNFZKib2sPFdbSs7MvfFpF6hn5uyKnw/640?wxtype=jpeg&amp;wxfrom=0"/><p>字节、港理工提出超强统一视觉模型 Many-for-Many，如何凭它让 8B 模型“逆袭”商业引擎？字节跳动与香港理工大学提出统一框架 Many-for-Many，它借助众多视觉生成和操作任务的训练</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493405&amp;idx=1&amp;sn=3e4dbfd14d343d8579f4e0e26b307296&amp;chksm=fdc76cd68e28d8b3bf2db5a5b2cfe602e17d080f17999081e6fd09f699dc5a51e253eb0bfca0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 13 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[集成 R1 后的 GroundingDINO 究竟强在哪？一文带你看清 DINO-R1 的性能变革]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vgev6PHxuZ3cCzjflZrObrcGTNoJJwzrOXe4jyYx9eDs8QIOJ4W5grQyGf2tTwtS8ooDFDop2w2gcbw8UuNhCw/300?wxtype=jpeg&amp;wxfrom=0"/><p> 导读在开始今天的分享之前，我们不妨先思考一个问题：为什么大语言模型，如 GPT 系列、DeepSeek 等，在数学推理、代码生成等任务中能够展现出强大的泛化能力和对人类意图的良好对齐？除了依赖海量高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493405&amp;idx=2&amp;sn=1d9c87227f8d4a595b840a46386d63b3&amp;chksm=fdefb42de663cb93dd41f40e5105834443bfee347580c94b6f29dc50332b129dc78b3b64defb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 13 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FramePack-F1：敏神全新算法重大更新！低显存ComfyUI可体验长视频生成]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGQdbH5tvxzar5TAtTxFX4G9Q9nTTmDOUmW2D7RDQfQTgEAkgeSRpgiaLL0F0qMLAoUcd96ndJ2Esmw/300?wxtype=jpeg&amp;wxfrom=0"/><p> FramePack-F1：全新算法和模型更新FramePack-F1简介在昨天的文章已经介绍过敏神最新基于混元视频的力作FramePack-F1模型，这是仅从前向帧预测未来帧的 FramePack </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493405&amp;idx=3&amp;sn=277d0c1f3b062dadbff33e2bef789f36&amp;chksm=fd4510fef013d2d4ae8640533415e179cbfdd3d760891017c9e00d1cc5cf8791bb800d9881e7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 13 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[英伟达提出最强「描述一切」模型 (DAM)，可生成图像或视频特定区域的详细描述，拿下7个基准SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECib2BYEbUlY3dMInZdicOKQibQAMwDLHA4kgviaROXJC16pncBthoyHBQJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达提出「描述一切」模型 (DAM)，这是一个强大的多模态大型语言模型，可以生成图像或视频中特定区域的详细描述。用户可以使用点、框、涂鸦或蒙版来指定区域，DAM 将提供这些区域的丰富且符合上下文的描</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493405&amp;idx=4&amp;sn=bc1636527e4265783664c3d1853f72c5&amp;chksm=fd3c92d5c2f567ff800a410359bb871e3f8c29847d9b37669157da12be8d92e905eebf8da02f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 13 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI界的"六边形战士"！港科大×字节提出ComfyMind：生成/编辑/推理三连冠，开源领域再掀狂潮]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elI7B3IZQkA99hvyeKlzPzyeqYm9eaK3j5oUNFlRDs6yaz4YvOHWYMnpeWHk5ic5s7zDkXrP7RYtBA/640?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、字节跳动提出的一款基于 ComfyUI 平台构建的协作式 AI 系统ComfyMind，旨在实现稳健且可扩展的通用生成功能。在 ComfyBench、GenEval 和 Reason-</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493383&amp;idx=1&amp;sn=e3cf68d2740fdfd4fbeda2a116a351f0&amp;chksm=fd5de759b3729f260c883d730d074271b5c576c0cc066ac70d0d3603a0605a647f7dc9bc1dbc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 12 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大&amp;快手提出统一上下文视频编辑框架 UNIC，各种视频编辑任务一网打尽，还可进行多项任务组合！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrbAeApibeaxibS3pqDl8gmHOmyuzVnspI2tpOfRwXqcA6LGNdsjAjUyWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、快手科技提出的UNIC（统一上下文视频编辑）是一个简单而有效的框架，它以上下文的方式统一单个模型中的各种视频编辑任务。从此，视频编辑用着一个工具就够了！ID插入ID交换删除ID相机控制</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493383&amp;idx=2&amp;sn=23b42708652a9dbf4dc058328447d4bf&amp;chksm=fdbbf20cae17c8a76bbb029d9d9ebd1e393e9c1fed49fe65c3233c5e529a8d297dba8838968a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 12 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源换脸写真模型InfiniteYou，可实现零样本身份ID一致保持，无缝集成FLUX、ControlNets、LoRAs！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFB9QEic6a0icic21hdjU7tWMfgnZWZ32D1adHqJcD4Z8fvzhEvH6KNghsZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个字节刚开源的换脸写真新模型InfiniteYou，这是一种先进的零样本身份ID一致性保持模型，由字节跳动基于文生图领域最强开源模型FLUX模型研发的。InfiniteYou专注于利用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493383&amp;idx=3&amp;sn=207b3f3d47a18879592dc3a9355ed652&amp;chksm=fd4bbfdc1f330dae8c72471e53b8f5a2b65b27f2c256628f893e138c2e62612b37e0db86cf95&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 12 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[加利福尼亚大学提出TULIP！视觉-语言模型的新王者！AI性能全面碾压CLIP！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KsLicuyg3oA0dGOnwBictNTE782KtlqwlaVEmKrVyKAO0YzauujiaGWFqaYjHzZqKD5rLk8dQLKZtEg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：TULIP: Towards Unified Language-Image Pretraining论文链接：https://arxiv.org/pdf/2503.15485开源</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493383&amp;idx=4&amp;sn=618e16b5d3990c8378523ee6bda40d1c&amp;chksm=fd52291605ffd1d94d0e7abc651d286e42751b37b7762525ea2dbc5847dce26c6b7a938d7efa&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 12 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦联合百度发布Hallo4：让AI肖像“活”起来！新型扩散框架实现高保真音频驱动动画生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq56s1kIaYWsxKESfb9riaHUQVlW3JfPib9AP6mL8Hk0Ec5R0f43HYJ8aw/640?wxtype=jpeg&amp;wxfrom=0"/><p>复旦联合百度发布扩散框架Hallo4，实现了准确的唇音同步、自然的面部表情，并能够稳健地处理各种角色身份和环境场景中快速的语音节奏和突然的上身运动。相关链接论文：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493382&amp;idx=1&amp;sn=39ffd852e2ccd283cb9c564d565ba08f&amp;chksm=fd339e12fb401aa3f0a1b511e037be5faae1d733d59e62e6dbb2fefda798cdfbd64653043195&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[大模型再现黑马！英伟达开源Llama-Nemotron系列模型，效果优于DeepSeek-R1。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafoC1ibJ7eE1fvbrtrICXG1kaXfiaqibBmibzznCUHyiaB4NGTibwK6pmBM0hA/300?wxtype=jpeg&amp;wxfrom=0"/><p>近日，英伟达推出了 Llama-Nemotron 系列模型（基于 Meta AI 的 Llama 模型构建）—— 一个面向高效推理的大模型开放家族，具备卓越的推理能力、推理效率，并采用对企业友好的开放</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493382&amp;idx=2&amp;sn=e165a22ba5dbade025d8e720714e318d&amp;chksm=fd41db51e43660c6a273cbf3ca9bf8a6361499eea144951b7ce0b8a8ced43f2cab4df595a1c6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦&amp;腾讯优图提出基于扩散的情感说话头像生成方法DICE-Talk，可为说话的肖像生成生动多样的情感。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekBUypVTojw9NicChAveibQcTccRrbh6qA2W0fWIHSYHibiaqHEFxVLBnicZtkEricIgpsqDf5wqctkvqRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>复旦大学和腾讯优图联合提出DICE-Talk，这是一个用于生成具有生动、身份保留的情感表达的谈话头部视频的新框架。可以为会说话的肖像创作出生动多样的情感表达。相关链接论文：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493382&amp;idx=3&amp;sn=fa8393a66c634f95b73f0c58e8a5fb7b&amp;chksm=fd769d4f98388a5e69c7bfbbeb0f415a537a271920c9068baabb38ff4756569ce14291045159&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[告别"纸片人"试衣！阿里&amp;浙大提出3DV-TON，用3D几何骨架+动态纹理场，让虚拟模特"活"出真实衣褶！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECFZTEAl6XrNJIs6kBFtCKh4H4USr1Odbdw4IOg8SSgUfrQQVgR52lmA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里联合浙大提出3DV-TON，可生成高保真度和时间一致的视频试穿结果，3DV-TON是一种基于几何和纹理 3D 引导的新型扩散框架。 可处理各种类型的服装和身体姿势，同时准确还原服装细节并保持一致的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493382&amp;idx=4&amp;sn=810a8f2ed7e85962c691485b3f4ee9d2&amp;chksm=fdfebe94aa4a5e24ae593709f6e5cba5ccad19f711b823cade08a1892c78a25b46ddb98f6645&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 11 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[北大开源音频编辑模型PlayDiffusion，可实现音频局部编辑，比传统 AR 模型的效率高出 50 倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrNiaI7jyJY1V0kehM0SnqlBl50OPjfm0JQ5fD6SvsSa8sDtR2Rb2UIng/640?wxtype=jpeg&amp;wxfrom=0"/><p>北大开源了一个音频编辑模型PlayDiffusion，可以实现类似图片修复(inpaint)的局部编辑功能 - 只需修改音频中的特定片段，而无需重新生成整段音频。此外，它还是一个高性能的 TTS 系统</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493344&amp;idx=1&amp;sn=cd7a033f01702d16ab78e468a4e2ea51&amp;chksm=fdeaaea0054f3933cdf4c0455051ba3f156109c7ef2186a7f906b56877f208ab80faa4188e7d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌研究院联手牛津大学推出Bolt3D！7秒内单GPU生成高保真3D，推理成本直降300倍！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5LR8w1T4XSJwAUg3UkzLpMRYxbTOuSXUEpxZVs5u18QTNFMFHe41E6SY6vfhMbJicRDetQWdibB3Nicg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Bolt3D: Generating 3D Scenes in Seconds论文链接：https://arxiv.org/pdf/2503.14445开源代码：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493344&amp;idx=2&amp;sn=c41ba28a98ad5d0b2fb6f80ac5ea9a8d&amp;chksm=fde434eabd8222f83b984fe11435d0f3be3475f0dc5e176b346abd57376eeed73771f97419b6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI界新王炸，输入提示词秒变PS大神？阶跃星辰开源图像编辑模型Step1X-Edit：19B参数对标GPT-4o。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2el0tf0f2Ybm2uFN97TrfHYoqefkVHtmLwhySToicQuQpmNJTBkEoLFpYZ12wzayha9Qna8FEyr9LfQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>阶跃星辰公司近期宣布开源自家图像编辑领域模型Step1X-Edit，它使用多模态大语言模型处理参考图像和用户的编辑指令，提取潜在嵌入并与扩散图像解码器集成以获得目标图像。Step1X-Edit凭借其强</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493344&amp;idx=3&amp;sn=7fee0720d3c728783d312c47692b869b&amp;chksm=fd5ba1f342e98cd98b1b6ac9d1dd2101dba2dbbd690df6c53f6da9586c4e81af08c0fb18142b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493344&amp;idx=4&amp;sn=2f36e4d56dad64b11164f209abe8ae5a&amp;chksm=fd9a52830e4b5da0eda48b5555649bc2e7ea5c6578e14f25cdfc045dc3d86ef1c8650c2ead05&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大&amp;快手提出统一上下文视频编辑框架 UNIC，各种视频编辑任务一网打尽，还可进行多项任务组合！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrbAeApibeaxibS3pqDl8gmHOmyuzVnspI2tpOfRwXqcA6LGNdsjAjUyWg/640?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、快手科技提出的UNIC（统一上下文视频编辑）是一个简单而有效的框架，它以上下文的方式统一单个模型中的各种视频编辑任务。从此，视频编辑用着一个工具就够了！ID插入ID交换删除ID相机控制</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493298&amp;idx=1&amp;sn=d87b5597b0df1fad80a5bbb050c9d119&amp;chksm=fdfdd7153586f15e1380a4a7ec94b36a5a87173c1297c5013112a1b7ddd81728b56c5f35be45&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节提出从单一主题发展到多主题定制的通用框架UNO，通过情境生成释放更多可控性。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elo3s89icGNibsPQVXGhctg9WDrsYXyWyFSyqXzUDm6eOsD3G2Z7XbSMUPZrQw19LsCTpuzPx9KiaCWg/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节跳动的智能创作团队提出了一个从单一主题发展到多主题定制的通用框架UNO，从少到多的泛化：通过情境生成释放更多可控性。能够将不同的任务统一在一个模型下。在单主题和多主题驱动的生成中都能实现高度一致性</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493298&amp;idx=2&amp;sn=f9e4b5f9594e2496705f42effee6d6e4&amp;chksm=fd9c79d502f7a140c1ecaf6f4bf83b3521b02002ab0ea6d4430d0be9d59195bcef6e97216b89&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[小红书提出新面部视频交换方法DynamicFace，可生成高质量且一致的视频面部图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4wY9icyCBJHtpRNSEtIVu23ib2dMfGUzdVZH7hKlE7v6ZRLfdk46k3hHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>DynamicFace是一种新颖的面部视频交换方法，旨在生成高质量且一致的视频面部图像。该方法结合了扩散模型的强大能力和可插拔的时间层，以解决传统面部交换技术面临的两个主要挑战：在保持源面部身份的同时</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493298&amp;idx=3&amp;sn=b294673d9395fc252326e0a052a41250&amp;chksm=fd8a4164387bd306acf66453ba0544270e786d094c309cdf5f3823c4276f46447c879891d3d5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯混元&amp;InstantX开源InstantCharacter，跨角色外观、姿势和风格个性化生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloBQe14a8ohz069lCGESt2mVMulTo5LC5G2oFcJtOgsuJWSCokK4anUcgT9xP5mIuHTqbM9wOvIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元联合InstantX团队提出全新角色定制生图框架 InstantCharacter，与当前的SoTA方法GPT4o取得了相当的结果，然而，GPT4o并未开源。相比之下，InstantChara</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493298&amp;idx=4&amp;sn=7e5a577ea9daf9fb97e6944db710b072&amp;chksm=fdb3785291cae3796b3b1990d3513e8280fd7fd66527d74f725f6152b278c9ef574732b77c36&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 09 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Ctrl-Crash 助力交通安全：可控生成逼真车祸视频，防患于未然]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrPLRrD1QZ9zibv4a5SaD1ia2jKGyHkiaBTqokY1CyAp4XtkGfscoppegZg/640?wxtype=jpeg&amp;wxfrom=0"/><p>视频扩散技术虽发展显著，但多数驾驶数据集事故事件少，难以生成逼真车祸图像，而提升交通安全又急需逼真可控的事故模拟。为此，论文提出可控车祸视频生成模型 Ctrl-Crash，它以边界框、碰撞类型、初始图</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493297&amp;idx=1&amp;sn=12ed43995c160a7091085cca6bcb1538&amp;chksm=fdc82cb44c0a5a715da2fe56dcfc62d60588684d6b06260eb09b40f6fc4bcca6eb164dbca1bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 08 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节跳动提出Pixel-SAIL!单一Transformer实现三大突破，性能不降反升！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enmjqTKh2qwkPiauc2Ejsn7FaBqSnQoJ9kCcgiaLM8xcMAdQ0wHUuCOjSJTlKTZnXGTL0jj8qibLthSw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding论文链接：https://arxiv.org/pd</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493297&amp;idx=2&amp;sn=bd1eb99fea1fa657a1093fdbc36025a6&amp;chksm=fde353a956d09ab014351e47b2d32fef8034f03ae9d0364aabff20b5ed72d42526d9ab98eecc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 08 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493297&amp;idx=3&amp;sn=16004a996874ff96455e6be6f78240ed&amp;chksm=fd5a55d724d55f68883c0e46053db7a37e4d18bdeaf044007ea69016f5c5dc09ec9892085120&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 08 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICIR2025 | CubeDiff：无需考虑失真，重新利用基于扩散的图像模型来生成360°全景图]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6qavvqaKicyhfbe1wrRfKuEmZbfJ8LvrOgQJMgZYG5CztqNUPPASQbtg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经给大家介绍过许多关于3D生成的文章，感兴趣的同学可以点击公众号菜单栏查看3D生成专栏，创作不易，欢迎大家点点赞和在看~CubeDiff是一种使用基于扩散的图像模型生成 360° 全景</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493297&amp;idx=4&amp;sn=c6ae1c1a55b6d18894ca513ea308bae4&amp;chksm=fd4ea9e692da8e4bdccf9377b9fd1600757f3af322e501df337ed301be40dc440c61bae87d9a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 08 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SIGGRAGH 2025 | AI视频生成黑科技！港大&amp;达摩院发布分层视频生成LayerFlow：再也不用视频抠图了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrOLuSb7ibEOeR0QxWLzfAOwCiaOpIxJgUv6jqX41ckXO1MREb9QUViaYibA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章来自公众号读者投稿，论文提出了一个统一的分层视频生成解决方案 LayerFlow，给定每一层的提示词，LayerFlow 能够生成带有透明alpha通道的前景、干净的背景以及二者结合的全景视频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=1&amp;sn=6fe5a49d65ebe5aac00e62de40e181b1&amp;chksm=fdaa8f60082a9d6302f07f6900a756203e40fef0ae7e5b9974851e02da33fb27b4258eee8d96&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[StepFun提出Step-Video-T2V！300亿参数视频生成大模型！可生成204帧视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcJicm2I75ZP1rkl1ZMqicoKfreYnRFLqFBbibqBpPJl9LzNL6OUXy1tmllZuicN8KGIYIbPRjfSZnnOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model论</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=2&amp;sn=c768d79299959655b4272ee4b124ede9&amp;chksm=fd2722a27debec182008aa67bfcc307595d7eb751fb7b436036fbcc933ef1c41e87edb1efd07&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Apple提出UniGen！多模态理解生成统一xii新架构！CoT - V提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KqpbKjwyf8GDnoGZ1ANRZVHSofem5JIanFIxSibozXUibNxHviaUIPE6FTh1nw9lCf16QMqWDaqf7cg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniGen: Enhanced Training&amp;Test-Time Strategies for Unified Multimodal Understanding and </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=3&amp;sn=28e556b89d07c4427a34551cadd23fea&amp;chksm=fdeabdd2736c698ef95a36cbabc7eb5eca25ba66a0061008e277a99da139857b0f9b6fba4bca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=4&amp;sn=61c41a21175f84251746b6916b89e5ed&amp;chksm=fd174d6754a6b7bcacf613ccb28dc88773d58bd162049590cfc7e0a98c6170df1dfd588dd656&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>