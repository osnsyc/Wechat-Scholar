<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[企业/个人开发者狂欢！字节跳动宣布开源 Coze Studio 和 Coze Loop，AI Agent 开发进入平民化时代。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enbjDSflysJFeRa1uPbPgmjAcxaantLMyv9tXrOibIpxUX3DfMiap9YULj2wC2qf84tE3egdxibsq5pQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>2025 年 7 月 25 日，字节跳动宣布将其AI Agent开发平台Coze的两大核心项目——Coze Studio和Coze Loop——正式开源，而且是还是 Apache 2.0 协议，任何组</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494333&amp;idx=1&amp;sn=d3760f4b6c7f5bdbcbbea7fabf36b5b4&amp;chksm=fd618878a4528110105609da9ad07e475d822fb9478ed5ac685ca0fdd1885ce20ee49a15ffaf&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494333&amp;idx=2&amp;sn=79c96ac4a3a61d21e5332a291de55e48&amp;chksm=fdd83c3764381455bbed871df26a3b69bd9ffcfe8547d6eff1b102e940eeab6eab984dbe2e85&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494333&amp;idx=3&amp;sn=d8227928a5ef5b44ce9eceea9728c635&amp;chksm=fd7eb40ff74f6db1704796fbf5153b361f97167b85c1c9c953e6a43d5501ecf7be4bad0e09f7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[复旦&amp;字节提出layout-to-image新范式，支持基于布局的MM-DiT架构下可控图像生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekXX8zYF4UxzjmCibmVsNeNfHdzvia0ykHy5vQljhxHZhBKib0DHCIdedbOAMsic8KZ423vtGia19o4Wow/300?wxtype=jpeg&amp;wxfrom=0"/><p>本篇分享论文CreatiLayout: Siamese Multimodal Diffusion Transformer for Creative Layout-to-Image Generation</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494333&amp;idx=4&amp;sn=3754aaf24f5cba64798ec562dbe98725&amp;chksm=fd068feead28b39d3a2214cf3133378bab99c812b4bd1d8d7dcba65254c7afed805a3e665c1c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 29 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑进入视频时代！字节Seed&amp;新国大提出VINCIE，视频驱动扩散模型，概念合成效率提升300%。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ennrAAVlvm6a2ndtb8NAAAehQOd2pAp8oOdmjraUibFjm5UwibicaIfLZpvl4licgd3FvIqQuDnyebylw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在图像编辑领域，如何让模型真正理解并响应动态变化的上下文需求，始终是横亘在技术落地前的关键挑战。传统方法依赖专家设计的任务流程与分割修复等辅助模型，不仅数据标注成本高昂，更难以应对复杂多变的编辑场景。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494319&amp;idx=1&amp;sn=aa34b2508066ad87d8d9064b459dc87d&amp;chksm=fdb4b1fd6e5bd129392456675effecdb0f11c52e90bb251b88e704ba9206a18558bd5d327de2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI创作从此无所不能！复旦大学提出UniCombine！多条件可控生成的终极武器！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KrBKjz80g2WN9kgcLCdSvBgBqO9AvwpQCkInibAg65CoUM759Xzic4Ynw8E0DGia05YuibNc81chZQFg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer论文链接：https:/</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494319&amp;idx=2&amp;sn=ea12b270a8c396ccc909cbf5fa448cba&amp;chksm=fdf68739535c71b122e003c6d6a506b479b5d7921d9e436f4a996e7acd7104364bd3aa91ca0f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Poetry2Image：专为中文古诗词图像生成，忠于原诗意境和语义。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emh13jOMSY9oYmD0NHOx8BcYfwYJj74Cog1EPA8EQnekKhKwrxDasX2PxLvN7VqWDL8nRUrassVIw/300?wxtype=jpeg&amp;wxfrom=0"/><p>直接基于诗句中的文本进行图像生成通常会导致丢失图像中的关键元素。为了解决此问题，哈工大提出Poetry2Image，通过实施有针对性的图像校正解决这个问题，有效地捕捉这首诗所传达的语义和艺术精髓。Po</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494319&amp;idx=3&amp;sn=560c5696cf68d27a29d6bec67b566608&amp;chksm=fdcb990de8fcd4725a7d3e856ce9cc46e0c570107ac187d41fbcb06574ae2f103028894fbb94&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 艺术工具通讯]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/5LJDib8HPR2rrZo6MvQMib3yaV5BITXF7CQorbzEicSeSiaBVwm9FpIicKhJ3TeBW7JsFmeMmjr8CqMt5ibicJRkEmjnQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>创刊号 🎉AI 领域的发展速度令人惊叹，回想一年前我们还在为生成正确手指数量的人像而苦苦挣扎的场景，恍如隔世 😂。过去两年对开源模型和艺术创作工具而言具有里程碑意义。创意表达的 AI 工具从未像现在这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494319&amp;idx=4&amp;sn=e7b935214dcd48f6984c3d4ac725c67e&amp;chksm=fd60f6a187d887efa3dc3d30f239d861aec26d0611f30d4f7e18941212ba4ce942456d442e9f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 28 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI生成电影新革命！字节&amp;港中文等提出Captain Cinema，当「无限记忆」打破〈盗梦空间〉的第四面墙。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ennrAAVlvm6a2ndtb8NAAAeECKiaXibgWMfXuoBib9zKibRu3JMzPKAibRp6rfe0wartxB8M8rwGXMibnyw/640?wxtype=jpeg&amp;wxfrom=0"/><p>由约翰霍普金斯大学、字节跳动，斯坦福大学、香港中文大学联合提出的 Captain Cinema旨在创作具有专业电影级品质的多场景电影，同时 通过超长上下文记忆保持角色和场景的一致性。你可以成为导演，用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494318&amp;idx=1&amp;sn=6bf1a40ac4cff47d4ae11f07db81ea05&amp;chksm=fd6cc02bc103bf5f3b7c1816d044b952140109d2610b6119aeefef7de4ab8e337cb152624230&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里最强代码模型Qwen3-Coder发布：多尺寸选择，开启编码新体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em9xtmb1LYQQ3l0fNDDWpS4R9kV73WWUJibv1BBPEzpA4GiczgHXPoApCNSWLpvhlypT6L0bvGhTEUA/300?wxtype=jpeg&amp;wxfrom=0"/><p>阿里推出了迄今为止最具代理性的代码模型Qwen3-Coder，Qwen3 -Coder有多种尺寸可供选择，首先推出的是最强大的版本：Qwen3-Coder-480B-A35B-Instruct。它具有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494318&amp;idx=2&amp;sn=741183eb685a5164df579e59c95175da&amp;chksm=fd704d1e87a21bce0c21ab3ce316c858a888c4d2d670467e19ead99f2f0210aea9bb7f3954f0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 机器人双臂操控新突破！KStar Diffuser如何解决自碰撞与运动约束世纪难题？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojvz9clmicqUEHWru0TSQwicibDxwd6pXeiac1QbZwUoibnWeMnE5ib2jBibpdEXVK5T4bFCwMWWK9BcS4dg/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2503.10743亮点直击与现有方法仅在笛卡尔空间中优化末端执行器姿态不同，提出了一种新颖的时空机器人图，显式地建模机器人物理配置，以指导生成动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494318&amp;idx=3&amp;sn=9566b386d2548ecb07e7751571683f7e&amp;chksm=fd77915f965b801367f1bb7df7557f9c2b7d211d91e830e28d5d1be0845c2ba97eea2ac39a51&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源多模态生成模型新标杆！OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494318&amp;idx=4&amp;sn=074035dd45ebd4756116439aa1693984&amp;chksm=fd80af7055dbb4f117082a3681755809e29dd77faa5723971741f3cf745b737e01a46bcbd5fb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 27 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工提出 Ultra3D：6.7 倍加速突破效率瓶颈，1024 分辨率下登顶 3D 生成性能巅峰。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elVVXYVXeZKg9ibO6JibLeUheArjN7Xm2cOz07j7Uy5AIOxXedaPSFmFxlbPp39YvTiao133ztkagpEQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在 3D 内容生成领域，稀疏体素表示虽为高分辨率建模带来曙光，但现有框架却因两阶段扩散流程中注意力机制的二次复杂度，陷入计算效率低下的困境。不过，南洋理工大学的研究团队带来了突破性成果！他们提出的 U</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494284&amp;idx=1&amp;sn=cea7e65dd5ccf09f1386a29a33ca20a6&amp;chksm=fd6bc9e87837ba2224a45389d9a7239de6e52dfdb66d0a7b668eb6565ca4eda39e3c993d4c13&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Jul 2025 03:32:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从文本到3D的“零训练”革命！英伟达&amp;康奈尔大学提出 ArtiScene：通过2D中介实现高保真3D场景合成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48HPJzGndEliaF6RR9oS2mcY6tk1tO13iaxO3UHzBrtzwlN2jFlpv4651g/300?wxtype=jpeg&amp;wxfrom=0"/><p>由英伟达和康奈尔大学提出的 ArtiScene 是一种无需训练、语言驱动的 3D 场景生成流程，它可以根据文本提示，设计出丰富多样、美观且易于编辑的场景，涵盖各种类别和风格。下图中展示了四种结果，并附</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494284&amp;idx=2&amp;sn=ff46e830afa0c44d78be7bd299fa033c&amp;chksm=fd06e608ed0cd51765151c788d5c3ed7732e30eedfcc856ac542417a3aa26193b7314662cde5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Jul 2025 03:32:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工力作Sparc3D：开启三维重建可微分优化与高效生成新纪元。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enhd8Da8niase1WltgKePj289UYQ2FkGK7uxrgpyoOIA6cIHk7jU4q6hvNUWTsCz3qI24ic8ibqQ8GjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>由南洋理工大学推出 Sparc3D 是一个统一的框架，它将稀疏可变形行进立方体表示Sparcubes与新型编码器Sparconv-VAE相结合。Sparcubes 通过将有符号距离和变形场散射到稀疏立</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494284&amp;idx=3&amp;sn=f6b862e8a50403d358e378ff24a37c28&amp;chksm=fdd8635c097f9e6b788c992c4c125ae0d8d257e3f4c9d86e8d0b38cc6dcd48c6e63b5f016074&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Jul 2025 03:32:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[突破高分辨率3D建模算力瓶颈！南大&amp;复旦提出 Direct3D‑S2：8卡即可训练，革新 1024³ 分辨率3D生成格局！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elCicOusPT4UMbWRggQc9icnnibKbtwkfQH4wt4miaD9ltwEVcbK2fR9bxibXxuHKTtr0qEAr49WVVsnag/300?wxtype=jpeg&amp;wxfrom=0"/><p>介绍 在 3D 生成领域，高分辨率建模长期受算力限制，传统方法以符号距离SDF函数等体积表示生成 1024³分辨率 3D 形状，计算与内存压力巨大，成本高昂。而今天给大家介绍的 Direct3D‑S2</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494284&amp;idx=4&amp;sn=53ec9ec787d76685e3052c4bb6927525&amp;chksm=fd3337c0cbf2e4c68cc74937047ec62e4ffdb5025286a3aa547dac39e9dd17c1a05f99a44541&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 26 Jul 2025 03:32:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里最强代码模型Qwen3-Coder发布：多尺寸选择，开启编码新体验！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em9xtmb1LYQQ3l0fNDDWpS4R9kV73WWUJibv1BBPEzpA4GiczgHXPoApCNSWLpvhlypT6L0bvGhTEUA/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里推出了迄今为止最具代理性的代码模型Qwen3-Coder，Qwen3 -Coder有多种尺寸可供选择，首先推出的是最强大的版本：Qwen3-Coder-480B-A35B-Instruct。它具有</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494276&amp;idx=1&amp;sn=3f35ab38b7dfcaecfb3d4cf5f71e1a6a&amp;chksm=fdc98f94baf937334eeeae91b2e2862025cf8ee8faa4e3d1ae24936745d219b7f454aa812e2e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[蚂蚁推出Ming-Omni：图像、文本、语音三模态无缝融合，一网打尽复杂任务！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48J6PaQ6vvBzg7xSUic6gUlNictqMXib837dJ3ia9U0lib3hc3BMuQHGGd8fA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Ming-lite-omni 是 Ming-omni 的轻量版本，源自 Ling-lite，具有28亿激活参数。Ming-lite-omni 是一个统一的多模态模型，能够处理图像、文本、音频和视频，并</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494276&amp;idx=2&amp;sn=13b58957989b6c7996897f74ea0b4537&amp;chksm=fdee885b4470a35a7a57728982c0a99c972f5688b045203496c0a60c36e3a9d4c51697c250c1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[FlashFace: 具有高保真身份保存的人像个性化方法，效果超越InstantID，人脸定制化更逼真了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekGB20aoopfDW9Ia72SmdXIpHxTUXCIsjaFY2ob7ymtpQcesNrLicxwJME93bc3QPGgQ9eWOpYd9VA/300?wxtype=jpeg&amp;wxfrom=0"/><p>FlashFace技术是由香港大学、阿里巴巴集团、蚂蚁集团共同研发的一项实用工具，用户可以通过提供一张或几张参考面部图像和文本提示，就可以轻松地即时个性化自己的相片。与现有的人像定制方法相比，Flas</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494276&amp;idx=3&amp;sn=5e655dd02f2c65ebc304037a9602a42a&amp;chksm=fddbae1be1204cdd3d0ce922bab8d040d579cbec5d1469d7c896fea0ac1f7fc337c4ae85c177&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[PlayerOne横空出世：港大×达摩院重塑虚拟世界交互范式，动作捕捉驱动AAA级场景自由探索。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enfUCFX9WW23BajIFJBpRq3xvD6IHNj8gocPOicHAPyQsE13dEpzsl31yyrObIKhz86FlHOmK6LtVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天介绍的文章来自公众号读者投稿，由香港大学与阿里达摩院联合研发的PlayerOne模型正式亮相。该技术突破传统虚拟场景构建范式，通过单张图像输入即可生成高保真动态虚拟世界，并支持用户以实时动作捕捉实</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494276&amp;idx=4&amp;sn=2537b65d5d366cb381b9607b06e537de&amp;chksm=fd3edcf7d003087fe7490544d733902b449a303ac723fbd753a562b46cd331564a295d4635d0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 24 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | 中海洋提出虚拟试穿通用框架OmniVTON：首个无需训练，首创多人试穿，解锁虚拟试穿新玩法！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enDjkDdGWUtr9tUMAgfKEsSXEyFsBSBt07vqsaSfHCBGu6HTtsWZZULSH22C3xOTlJseL1bvGtnmQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>之前已经给大家介绍了很多关于虚拟试穿的文章，本公众号也总结了虚拟试衣专题在公众号菜单栏，感兴趣的小伙伴可以在公众号内搜索“虚拟试衣”阅读～在基于图像的虚拟试穿（VTON）领域，In-Shop监督方法虽</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494244&amp;idx=1&amp;sn=2fc765ccb9a7b8019ebb0ec2dc018654&amp;chksm=fdcb271a70b4c13e10a9ab7851d3abd7ad0340fb29e9929b8a7b0dfb1e63b75c281d8cc369d2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR2025 | 同济提出无需训练的肖像动画框架FaceShot，让表情包、动漫人物、玩具等“开口说话”]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emXysHeAOso1q4PjdgGCNECN5vlsQZr9AOKKvriaYqbhSHH5y8IBJg25HQaMqclHrVZ7Dp9ObVuiaww/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天和大家分享同济大学的最新研究FaceShot: 一举打破肖像动画模型“驱动真人”的局限，FaceShot 的动画效果可应用于各个领域的角色，包括 3D 动漫、表情符号、2D 动漫、玩具、动物等等。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494244&amp;idx=2&amp;sn=10671ddeb51b359b6fb549e68e8f66fb&amp;chksm=fdd033b40bf2d4cda9a79fdac0a598e29f2528ce8d5cf1f18115545c171b43de3c11323c6c77&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[6秒音频即可克隆AI语音！FLOAT数字人生成语音/口型/表情，情感同步超惊艳，文中附工作流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJcmBGicWjwiauMpFknBOofINibzHjBSIibjwDHKYvhnzulS1E2KIPicobCywA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的 FLOAT 是一种基于流匹配的音频驱动的说话肖像视频生成方法，可以增强语音驱动的情感运动。该方法唇形同步质量高，生成速度还很快。6秒音频完美生成语音/口型/表情。情绪转移由于 FLO</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494244&amp;idx=3&amp;sn=2659d8631c4ec20000486087ce5584c6&amp;chksm=fd788a70fa1deab6dda5fbb4844df4a106b07e5a7cca2ab8a5fabffcdc2a21276804422afcb7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[StochSync：可在任意空间中生成高质量360°全景图和3D网格纹理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enXFFuKUPQcYLlG3aibBhJtN7xgJCpXZE7HoaWiahrDNLktV0doUSl1wRalx4MZej02YkgNsTVfSbpg/300?wxtype=jpeg&amp;wxfrom=0"/><p>StochSync方法可以用于在任意空间中生成图像，尤其是360°全景图和3D网格纹理。该方法利用了预训练的图像扩散模型，以实现zero-shot生成，消除了对新数据收集和单独训练生成模型的需求。St</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247494244&amp;idx=4&amp;sn=5f01342a8e09cc6cd151dec09614e840&amp;chksm=fd72ec70f1aec85839092d6060000696d78918f5298dc6f5a4d8c02bc25e59e65f92c956fe63&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 23 Jul 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>