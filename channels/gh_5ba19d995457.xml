<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[公众号10000粉丝啦！与你分享一些背后的故事。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elTZAO7nveGZkbHy0bhiclickcAadUYAHdJYejmtfmCcZepy9KMBonLvAMVMbMLnSHjut1bHbicpv0NQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天，AIGC Studio 的订阅数突破了10,000。这是一个值得纪念的时刻，写公众号这一年多以来，从0到1的艰难破冰，从1到100的惊喜积累，从100到1000的稳步前行，再到如今突破五位数的里</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491310&amp;idx=1&amp;sn=b6358af617dc430d4ac40cdece1c1485&amp;chksm=fd6b0550389109cde939aac7e03bd76b5bf0533ce2d6b4fe05e4932a0e6f3a9ed55703a7709a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 28 Mar 2025 16:15:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Google 发布最新开源模型 Gemma 3 性能超越DeepSeek V3、o3mini为全球第二强开源模型！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1Tx7TDib2JZlYSOcIeFibGx26nJ97mYDqomS6G9eBfNYd12uHm60HC3icw/640?wxtype=jpeg&amp;wxfrom=0"/><p>Google 发布其开源模型系列最新模型 Gemma 3。Gemma 3是一个高性能、可移植的轻量级 AI 模型，适用于单 GPU 或 TPU 部署，支持多语言和复杂任务。 主要特点总结如下：支持 1</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491230&amp;idx=1&amp;sn=e8ccaaf50ede7fa24d7335bd53901fa5&amp;chksm=fd9edb25254cab81a6cec126c80833690cd59ff1550c7ae2b19799a778c6a25dcfeca1fa65fd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Manus平替来了！CAMEL-AI开源OWL，开源框架中排名第一,上线一天获得3.3K stars！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elm4qdlMbfjmuJgIxhRCCZM2MncOeQfmqwBKZQvXFoLhraCN3dyfhhWYcnRH9edJicQVVA1ZkS0Azg/300?wxtype=jpeg&amp;wxfrom=0"/><p>昨天的文章中跟大家介绍了OpenManus,感兴趣的小伙伴可以点击以下链接阅读~OpenManus：5个人三小时复刻开源版Manus，不需邀请码, GitHub已获 8k+ star！今天给大家介绍的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491230&amp;idx=2&amp;sn=32a85b1dee0d8a27e118ecd01a938c43&amp;chksm=fd203bf285ac989c8a638d0b0e76be8aea2521f562f1a4ae09b9212de3cd4c00f06e27a2149e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D虚拟人ExAvatar：由简短视频建模转化为3D数字形象。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekzqB2EbDBmquHlenf6YcicAWMXQALDcXjabJaEKqR2IKMpyViauaiaoCFPWRkVQPGibAUElFHg6rBNzw/300?wxtype=jpeg&amp;wxfrom=0"/><p>ExAvatar是由DGIST和Meta公司的Codec Avatars Lab联合研发的一项技术，能够通过捕捉视频中的动作和表情，转化为栩栩如生的3D数字形象。这项技术解决了以往技术中的难题，提高了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491230&amp;idx=3&amp;sn=40387a744cfafd679e91231963032897&amp;chksm=fd97fb8abb80f70f337d8c3b6c19b6d2b9172b84e49294830d517f8a30cea6cc3a0f78705021&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | OmniGen-ComfyUI：简化多任务图像生成和编辑操作,一键生成任意你想要的效果！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek3AzrrMoNWTaibIOp0yQxuUdhncrj6uxibR6BDtnnc5GUloGNfcX0jbZfEnkb7yqhSkm5IicnKTPlfA/300?wxtype=jpeg&amp;wxfrom=0"/><p>还记得之前的文章中给大家介绍过的OmniGen么？感兴趣的小伙伴可以点击下面链接阅读~统一图像生成模型OmniGen：可由多模态提示直接生成各种图像。今天给大家介绍OmniGen的Comfyui实现，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491230&amp;idx=4&amp;sn=cba9283d47d70ff5ec6334b06a1a79de&amp;chksm=fd40cd393213c7851f0581ef5a53d42c19421e5b7e98c449d7c6c8ecc4a5a894bb9a70e9beb7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 27 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超多可玩！Open AI 更新GPT-4o 图像生成功能，以后工作流不存在了？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enrqfSduqABGjibF2gGxXK1j4ZBMdCOCJnlf8tGU3PW5UWxyBEeaBOPcutYx5d89fDx22q1FYSZUWQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>昨天 GPT 4o 的图像生成功能上线。可以通过自然语言对话完成现在复杂的 SD 图像生成工作流的所有玩法。这是 Deep Research 以来 OpenAI 最有意义的模型更新。一句话指令就能完成</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491229&amp;idx=1&amp;sn=0fa2659b4e2e9bdec87fee429c9a256e&amp;chksm=fddb89e17bc0ee96eb4d4624e96b373f3995b19e6c3928706e2405f1654a905ba79d6ada66d7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[非常好用的DeepSeek喂饭指令，快收藏备用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1rTwNmMicswteAFPxRBulbryWbJb5icNpRZVAQfxRenrx63X2LR3PjcPg/300?wxtype=jpeg&amp;wxfrom=0"/><p>给大家推荐一些非常好用的DeepSeek喂饭指令，包含文本编辑、图文表格、求职面试、联网搜索、人际交往、新媒体运营等，直接上干货，大家可以收藏文章，以后可以直接用～感谢你看到这里，也欢迎点击关注下方公</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491229&amp;idx=2&amp;sn=38048f4a4a6ef2c61211371f5200e6a0&amp;chksm=fd7e080a6916245ed5b79d3396b18d32c94ccab53bff48639f601b7e76fe8738b4739870468a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DiffRhythm：创作完整歌曲，支持文本转音乐和纯音乐生成，MacOS 上可运行！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekwL7bBtjRiakD5gmicmnfguSfr2z00p2lt6zEhibKXszCpRoFYPwAibZibGQQbQ4FYynlgbdHicZZTZn7g/300?wxtype=jpeg&amp;wxfrom=0"/><p>。公众号之前已经和大家介绍过许多关于音乐生成的文章，感兴趣的小伙伴可以在公众号栏目中点击“AI音乐”获取更多信息。DiffRhythm是第一个能够创作完整歌曲的开源基于扩散的音乐生成模型。目前已经支持</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491229&amp;idx=3&amp;sn=6a7973931b49b2b6fea5622006bf61f8&amp;chksm=fd6552dee7ab7119a26332fa5fc13133cba12d4ba145930477b2901f2f73800625627e005d9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[DPG-Bench榜首！智谱开源文生图模型CogView4：支持中英文输入和生成，免费商用授权！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekabsI7MyRPhcqTEHwmEMZhvC6lcJXaMUIXeLEHuiafYK4Her5iaKXhp5mbyiagGrmxyHV9FXCiccH0cQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在图像生成技术的浪潮中，智谱开源再次引领潮流，推出了全新的文生图模型——CogView4。这款模型不仅支持中英双语提示词输入，更擅长理解和遵循中文指令，让创意表达无界限。尤为值得一提的是，CogVie</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491229&amp;idx=4&amp;sn=c0ac542bf33849357a3e6b2be96b89e5&amp;chksm=fd5db0e303662e5e954baa42292984b06995245668abbf8f82accce6d267618f81eed80bc248&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 26 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[360智脑团队宣布成功复现Deepseek的强化学习效果，发布并开源其推理模型：Light-R1-14B-DS]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en80K0Wz4kInlLuiaJ7kP5t1tibSfW9w9neLqKv8yOAWicTQRj5CFQMD88lIrZoEJYOZjsuX1YrGljKQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>在这个科技日新月异的时代，每一次技术的突破都可能引领行业的变革。近日，360智脑团队宣布成功复现了Deepseek的强化学习效果，并发布了业界首个14B级别的推理模型：Light-R1-14B-DS。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491192&amp;idx=1&amp;sn=ddf0de5fc176eed28aae9f367522ca71&amp;chksm=fd5296e49f451737fd4cb2d18c63ae26e5f295e1d133ddc95c0e4892e4317988d1e75e61180f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[谷歌推出PaliGemma 2 mix：用于多任务的视觉语言模型，开箱即用。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZG3A9ureoTeOkRX7vpoweMqWfIXVPrnftNxPZXeKdfJFf3WSY8K2fGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>去年 12 月，谷歌推出了 PaliGemma 2 ，这是Gemma系列中的升级版视觉语言模型。该版本包含不同大小（3B、10B 和 28B 参数）的预训练检查点，可轻松针对各种视觉语言任务和领域进行</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491192&amp;idx=2&amp;sn=0948b7f02e3e7a3ea2a7a6a91777fd6c&amp;chksm=fd0cd43a4e1c28e740c205ec35f9e12ac87abe50b9eed43f39f2ad7766dca4eb46081bb5ee6b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CineMaster: 用于电影文本到视频生成的 3D 感知且可控的框架。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekMLBRnvtbr9hh7W1ccXtbHEFc26iarR5N2r9CO0FlrI8VbA3yicts8jmfYqQu9BHcgSCETWsJ0PawQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>CineMaster是一种 3D 感知且可控的文本到视频生成方法允许用户在 3D 空间中联合操纵物体和相机，以创作高质量的电影视频。相关链接主页：cinemaster-dev.github.io论文介</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491192&amp;idx=3&amp;sn=0bcaf986af7175ff3b397f1bf0a76ac2&amp;chksm=fdb099d5abdd7874f257b1f9625958176034327afe8a8176041ae6a5cb838b35e04b1789fde2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491192&amp;idx=4&amp;sn=cf3f03dacd4113fd8726ee83511094ee&amp;chksm=fdd4b2734515a32d630b817af418d0d877fcd76f7f420eb4f2024e94675c1b14b74c461eb17d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 25 Mar 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[IBM提出多模式图像文本到文本模型SmolDocling，可实现代码 | 公示 | 图表 | 表格 | 标题 高效转换！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eniaAibjBDYoftj8VvjntaLlaylgswEom4XlMibkcGxuU4WPZLbljDmFWMIMhdEh2dicYGoicXToiaibicmeQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>Docling团队联合IBM提出了一种多模式图像文本到文本模型SmolDocling，旨在实现高效的文档转换。它保留了 Docling 最受欢迎的功能，同时通过无缝支持DoclingDocuments</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=1&amp;sn=010ea784d33ceb329b4a04e147ca3153&amp;chksm=fdd8ae754e681e26bb8c60d581ec8e75ca5706d781fc2ab16e8e282f71e96204b7864abb448e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Seed-Music：字节跳动开发的音乐生成模型 支持多种数据输入生成和编辑音乐！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elIm6icxMVSQ1CxgxFiaRZRxgIpSB6lVKMSWd1DpYwO7bNGaOdrtXY1KXTzkCV8N36E83o4z8JLtxBQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Seed-Music是一个由字节跳动研发的音乐生成模型，用户可以通过输入多模态数据（如文本描述、音频参考、乐谱、声音提示等）来生成音乐，并且提供了方便的后期编辑功能，比如修改歌词或旋律。Seed-Mu</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=2&amp;sn=80c2ec88726a7f84465884cb48669d1e&amp;chksm=fda8dd3f13ed2c87d83ad45468cbcdd173027579147d66e67bf2d4f75b2d4dbca213339829c7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[震惊！东京大学提出ARTalk！语音驱动3D面部动画大突破！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JgxI2td6MuHkKtXCMBGlVyNoBucDYsH1Jct1PGOib0q03Jn6GdpLz4QjrI8emN5ohoxj6WzEHv54w/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model论文链接：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=3&amp;sn=1bb8126cf37e8a7b73a9348de9b19635&amp;chksm=fdc4d8e988c30a3bac9b8427a0da16eddf0a9cb6dd806279c085c24b69bf993f2f4303546b61&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekB7CXUYR45xqh1P2Q9zWuxgmicJiaO6JPkkhoaibkSARt6qftWXI9ofZjt9NK9vuibg0UrfhA2kTPRaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT今天介绍的文章来自公众号粉丝投稿，腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT，给定一个人像图像和一个衣物图像，就可以生成一个</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491191&amp;idx=4&amp;sn=601ed5357aa17567be89bfab06be7be7&amp;chksm=fd055b9e798e780cf50e543c44d5812d75a43ca52040a10453de614a26df5686bde92174bcb7&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 24 Mar 2025 16:10:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Window上6G显存就能跑文/图生3D？腾讯开源Hunyuan3D-2 Windows 便携版，轻松运行腾讯混元3D 2.0!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq6yAm26wF7SoU3RDfeYGDhleng8ndFk1MlsjEAbEoPWPzsibkOCMS4tkQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>混元 3D 2.0 Windows 整合包提供了 Hunyuan3D-2 的 Windows 便携版，简化安装流程，支持本地运行几何生成、纹理合成及文本转 3D 功能，适用于 NVIDIA GPU 用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491190&amp;idx=1&amp;sn=bc58d7fc1960c661be4d5a30379ab67d&amp;chksm=fd5b80db9573b90e52d69671fde6e3c4cc248b843a92a64573f2e0f759260866254dcf60eb13&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Mar 2025 23:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯发布混元-3D 2.0: 首个开源高质3D-DiT生成大模型，几何结构更加精致，纹理色彩更加丰富。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enScf5fx9rxa1dXnvYHW4G815SyibP84GYLJGItGoKdb7k8ibSoFf2UCRYRf4VJVbpVm4IevhxibbLDw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过腾讯HunYuan-3D 1.0，感兴趣的小伙伴可以点击下面链接阅读~腾讯发布HunYuan-3D，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。HunY</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491190&amp;idx=2&amp;sn=a04d0253994d6d588be8fc91e083b79a&amp;chksm=fdde11091b5bf784e6fa93653f648cb775e2630f6060111837af6052e4536e475666140c5909&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Mar 2025 23:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯HunYuan-3D 1.0，支持文本到3D和图像到3D，10秒即可生成高分辨率细3D模型。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elMhPFZCKibTiaBKrjL4Yql4lFH5tVlYMlAnW2RYL3JiaF4vHrEFr3z5TWpyzCAENlicH9DuH5PnpYic3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>HunYuan-3D支持文本到3D和图像到3D功能，包括网格和纹理提取在内，整个过程在 10 秒内完成。文本到 3D：用户可以通过简单的文本描述生成 3D 对象。例如，描述一片绿叶或一把棕色吉他，模型</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491190&amp;idx=3&amp;sn=b3c35203f25ea9310f8d632cd07ffdd6&amp;chksm=fd5ef028217832b26187a9e766a72fb582d47fa0ea7ec57550dec78a90b81dcfbae827d2bb58&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 23 Mar 2025 23:19:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI听觉革命！港科大×月之暗面发布AudioX，文字/视频/图片秒变天籁神曲！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enAqmicvH5JOXsTyWrTA6QL4Qw0324EibX2dlA4ibkqCvfZTBSib6iaz47XXY5VgjdgsGwwMQ3jVeATNhA/640?wxtype=jpeg&amp;wxfrom=0"/><p>香港科技大学和月之暗面联合提出的专门用于从任意内容生成音频和音 乐模型AudioX。该模型能处理多种输入模态,包括文本、视频、图像、音乐和音频,生成高质量的音频输出。核心创新在于多模态掩码训练策略,通</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491146&amp;idx=1&amp;sn=6c7e44da48e935f95db6ca3730bba1f0&amp;chksm=fd4d73036dc39f75a159da28c3bffb453f1e290245b8de62476d22f13a97502059a66d4c4709&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Mar 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多身份定制化视频创作新突破！Ingredients：可将多个身份照片整合进视频创作实现个性化视频生成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcicdv0XZf04MKlYliaBmemOkIOtBU0wKu89VAd3lkLkDU9GOLfc5OIqIjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在当今这个数字内容爆炸的时代，视频创作已成为连接人与人、传递信息与情感的重要桥梁。然而，如何高效、高质量地实现多身份定制化视频创作，一直是视频制作领域的一大挑战。近日，北京昆仑研究院的研究团队提出了一</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491146&amp;idx=2&amp;sn=b3c6c4f24c56449c6f1ec94cb4604bb2&amp;chksm=fde2d699a238cb317e28b503cb77d9bc514d82529457cadd8a5da0efa43bf6fad0ce7f7a614c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Mar 2025 16:07:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单张照片生成3D头部模型！Adobe提出FaceLift，从单一人脸图像重建360度头部模型。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4qXFbiaEqoEPejUQNwuqLOrpIE3WmoKJBxjrMnCoHDn3huArYyaCa7Ew/300?wxtype=jpeg&amp;wxfrom=0"/><p>FaceLift是Adobe和加州大学默塞德分校推出的单图像到3D头部模型的转换技术,能从单一的人脸图像中重建出360度的头部模型。FaceLift基于两阶段的流程实现:基于扩散的多视图生成模型从单张</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247491146&amp;idx=3&amp;sn=43312724357bb1f07a3ea397ac79bbf9&amp;chksm=fdf6c7c4688fb74ea96b2e3e35696fdaeb18201a59cd7ed05909f4530ae087daaeb6ac596603&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 22 Mar 2025 16:07:00 +0000</pubDate>
    </item>
  </channel>
</rss>