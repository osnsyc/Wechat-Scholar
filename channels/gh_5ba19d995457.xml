<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[SyncTalk++：高斯泼溅技术赋能，101帧/秒实时渲染逼真说话人头像]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPbvzXyQzXhAWo1QdPyhvibDibqYDF1ukDdJ8FKtqNSro8CoyUXcEHSoiaNicyJ5coqGdSlXCY3aTU1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>由中国人民大学、北京邮电大学、中国科学院、清华大学以及北京航空航天大学联合提出的SyncTalk可以合成同步说话头部视频，采用三平面哈希表示来维护主体身份。它可以生成同步的唇部动作、面部表情和稳定的头</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=1&amp;sn=f1e6be8976b9968058cda9d6b20810b4&amp;chksm=fd12b940baa9686c3dee45399fb2b7533f13c6b5252692764df1bd62d0349dc3f624e576b474&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里EMO2重磅升级！手部动作生成+超逼真表情，音频驱动人像视频生成再进化！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGYiaHtTElCkzOGD9sY0N1Qp8FDJqnDN5BkTWSW0TSu1sYeAgQzRiaicMcRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的音频驱动的人像视频生成方法EMO，感兴趣的小伙伴可以点击下面链接阅读~阿里最新EMO：只需要提供一张照片和一段音频，即可生成会说话唱歌的AI视频此外公众号的底部</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=2&amp;sn=2ee591723ec234b4f7e3ba841c947ba7&amp;chksm=fd4f258e14b0b54a91e7f40ad7c7ce78b41cd8c48ff1ae6b658072727c8a08ccca1a12a160f4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[6秒音频即可克隆AI语音！FLOAT数字人生成语音/口型/表情，情感同步超惊艳，文中附工作流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJcmBGicWjwiauMpFknBOofINibzHjBSIibjwDHKYvhnzulS1E2KIPicobCywA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的 FLOAT 是一种基于流匹配的音频驱动的说话肖像视频生成方法，可以增强语音驱动的情感运动。该方法唇形同步质量高，生成速度还很快。6秒音频完美生成语音/口型/表情。情绪转移由于 FLO</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=3&amp;sn=9311d2fba8792a48d886b1a94db125b5&amp;chksm=fd617e8bed8dfb625fc3400dc9b081fc3bfae803e6c86cb23a717cf3ef5564bd15c65395733e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源数字人克隆神器HeyGem：1秒视频生成4K超高清AI形象，用AI重塑数字人创作生态！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRrgxstWFTNfP8vOAkR5RI8GOy83ObgNDrZJL0p3TTnAIBViacS7PlySow/300?wxtype=jpeg&amp;wxfrom=0"/><p>在虚拟形象与数字内容需求激增的当下，传统3D数字人制作的高昂成本（动辄数十万美元）与复杂流程，让许多行业望而却步。而今天，一款由Duix.com团队打造的开源AI项目HeyGem，正以颠覆性技术打破这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=4&amp;sn=9f6a5a3403a6c92f97f2c3a90e3c6d04&amp;chksm=fd890b709cca9aca5d674fa96c98e82dcbf0ed60eca76986b409cca0a39d250d95f8c45ae1f0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一键生成高质量美学海报！港科大&amp;美团提出PosterCraft，文字渲染与艺术融合，从创意到成品只需一步！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elRPnxm15EcjBGoXOC5AYqzmibC3IibyVqwj02b3JZwTrRYibZ5X4eYgJcibSRkrEYHSF6tueI2pO8OFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一款由香港科技大学和美团联合开发的创新性海报生成模型框架：PosterCraft，其擅长精确的文本渲染、抽象艺术的无缝集成、醒目的布局和风格的和谐。PosterCraft 的设计理念是统</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=1&amp;sn=042efb2f0be566babedf29039f088eb1&amp;chksm=fdd41c5f5bde337606a1e854b5e2833790a2c77e24360fecb7bce53459c3151c3233d0972600&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[机械工业出版社《AIGC驱动工业智能设备》推荐~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekXhZDAiay6OPIoc0eYXlRohIGkuUlnCzvaKicjaicliadzAF5hrUcY83Z2RwOBKD2YSonMqVLYNdIT4A/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的书籍来自机械工业出版社的《AIGC驱动工业智能设备》，该书从基础入手，深入讲解AI技术的基本概念和原理。通过通俗易懂的讲解和示例，帮助读者建立坚实的理论基础，为后续章节的深入学习打下良</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=2&amp;sn=b44fbdd8152b7ec37ab3d94e12626e84&amp;chksm=fdeabb5c586c02ac27ba81a3b193503424e26563ac0306479e034cbe23f6556f4db79ef8c5ce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[海报设计师福音！微软联合清北提出Glyph-ByT5-v2，支持10国语言图文海报生成，效果惊艳！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekUlTbakAQ9PkRVtjuPOYtMklfrlDVxgTLUqQxQB6Xzp3hd7zxxMa0HXnBhpURAxPhMlClBWcF7eQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华&amp;北大&amp;微软&amp;利物浦大学联合提出Glyph-ByT5-v2这款工具支持多语言图文生成，包括英语、中文、日文、韩文、法文、德文、西班牙文、意大利文、葡萄牙文和俄文。以下分别展示中、英、日、韩图文的视</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=3&amp;sn=d75c8c35398fe4102e5be53c1f6fa48e&amp;chksm=fd25e727acee7c04a8dd6fef2a5f226c7de7a8a812a8dc829a67a0a03de58f8d2e618968671c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[海报生成如此简单！OPPO联合港中文发布基于LLM的GlyphDraw2！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohSUo8HgvDM5ics74rw4x4dOxyVe2Bw6dl7ayia1P5xsIdxG3BnXoHkibyiaOmzUenkfKDX8YQ85uea2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIGC Studio”文章链接：https://arxiv.org/pdf/2407.02252 github链接(待开源)：https://github.com/OPPO-Me</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=4&amp;sn=08c5903a2e4948a7c9241e62db7504b8&amp;chksm=fd2a5483225f0f7953fba9b9595e9d3d70802d8ea4076bd339421ef4b941285be68fe0247d56&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[科研人神器，论文秒变海报！Paper2Poster：一键生成顶会级学术Poster，再也不用为赶会熬夜做PPT啦。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ele6MdnMwUcFcDzM1rn9UbH2rVZPFxHmzrmY7icJmAlfTmrY7niam10ibJeWm7Lrk76urBe1ZJ7MZftA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由滑铁卢大学、新加坡国立大学、牛津大学提出的面向科学论文的多模式海报自动化生成方法Paper2Poster，主要解决了如何根据论文创建海报以及如何评估海报。AI能否根据论文设计出精美的海报？GPT-4</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=5&amp;sn=d25c39e136ea92237f3ca68e68a94162&amp;chksm=fd8721c28f0311f19ae0a0cccc3552d3b484c5e8569dbe696817bdad1dcff798ce2594825353&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从文本到3D的“零训练”革命！英伟达&amp;康奈尔大学提出 ArtiScene：通过2D中介实现高保真3D场景合成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48HPJzGndEliaF6RR9oS2mcY6tk1tO13iaxO3UHzBrtzwlN2jFlpv4651g/640?wxtype=jpeg&amp;wxfrom=0"/><p>由英伟达和康奈尔大学提出的 ArtiScene 是一种无需训练、语言驱动的 3D 场景生成流程，它可以根据文本提示，设计出丰富多样、美观且易于编辑的场景，涵盖各种类别和风格。下图中展示了四种结果，并附</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493907&amp;idx=1&amp;sn=071f03657998bd85efa79e5deb857c5a&amp;chksm=fd0981b3bf7d19329ae6a37545aaa13d09057f241558d8390915fb17b05201766d64be8f4517&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493907&amp;idx=2&amp;sn=64b1a5b864284cfdc070a146b49bc03e&amp;chksm=fdc48f93c83a786d986844fdb52431444ba3271e76ba7cd15128f4427a5add791415303f12a2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493907&amp;idx=3&amp;sn=0c95efada41fc0ab7eacecd6cede3f20&amp;chksm=fdfd7f9d97fbe715e4cd6fac215adb4aaa38acd4ebc5ad05b701233cf696b990b1a045310c99&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节推出统一多模态模型 BAGEL，GPT-4o 级的图像生成能力直接开源了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRre72SQ3NTx8amQXBMt77z295uWjzKl5kweQFLEMa31vXicZ35AvS4Lfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节推出的 BAGEL 是一个开源的统一多模态模型，他们直接开源了GPT-4o级别的图像生成能力。（轻松拿捏“万物皆可吉卜力”玩法~）。可以在任何地方对其进行微调、提炼和部署，它以开放的形式提供与 G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493907&amp;idx=4&amp;sn=50659c6d0be512223a5de492083f0463&amp;chksm=fde16184817066c0f7c5f5823cbe442a6cc4478c43e988110fc2970b71a4c3288994771b8e26&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI数字人新突破！OmniAvatar：让静态照片“活”过来，音频驱动全身动态视频生成新纪元！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHjoNmnhIZ1WlEINYQPhBVwHtIicGD7DRHo7WEJn1mYDaiaRkEf8ES1uzXk9uBREDlwHfWKdLcqs2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>OmniAvatar：“全能”的数字人视频生成。OmniAvatar 是一个基于LoRA的高效的音频驱动全身人像视频生成系统，支持从音频 + 单张图像 + 提示语生成自然、表达丰富的视频，仅需一条音频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493858&amp;idx=1&amp;sn=459d14fe28c93abffe87be12b97c522d&amp;chksm=fddc4fbb4d4df57114c09933dc2af666ef75118e5abd9c3d7c941775284285f7e35dc257d88f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 29 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OmniConsistency: 一种基于扩散模型的风格一致性插件，用于高质量图像风格化。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic6Yl0kTibHR6qeAggicnWLicFJTdTmKJibxibXDMjL83Ixvlciaqcwyoro532IvxIK9M3hB7eZ096Yw6jVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>OmniConsistency 提出一种基于扩散模型的风格一致性插件，通过两阶段训练策略和滚动LoRA 银行机制，实现了在多种风格下的风格一致性和内容保真度，性能接近商业级模型 GPT-4o。在图像风</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493858&amp;idx=2&amp;sn=263a017e9a4836be956587acb7e8f881&amp;chksm=fdd5870c1b51bdceecf2d5fcbcc92c59cf8673a1dd6463daf8e2997688cfd40acbbe53f3fb89&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 29 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源多模态生成模型新标杆！OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493858&amp;idx=3&amp;sn=9c756f16563c41cf42b185e49554a050&amp;chksm=fd12f490cd655fd862332fb27f1601f0fe47399597da05d7c94337b81a7159ebbda06648f872&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 29 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超越SOTA！浙大&amp;斯坦福提出 DiffLocks，单图头发 3D 重建精度提升30%，首次支持非洲式卷发生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48OPjpkTnf2mQjjRuiawRZ5BrVMBtgVJ4QGZRnabuCSKficVh97iaqr4QzQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>由浙江大学、斯坦福大学等联合提出的DiffLocks，给定一张 RGB 图像，DiffLocks 使用扩散模型生成精确的 3D 发束。该模型基于一个包含 RGB 图像和相应 3D 发束的新型合成头发数</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493858&amp;idx=4&amp;sn=9f50665830cbdf6f15461d23057fc785&amp;chksm=fd02bb50b619535e25a8ce5525fd23bd34e454a1249612c3e8d7cbbd6cfe0402cc2f4ae7c1e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 29 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[机械工业出版社《AIGC驱动工业智能设备》推荐~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekXhZDAiay6OPIoc0eYXlRohIGkuUlnCzvaKicjaicliadzAF5hrUcY83Z2RwOBKD2YSonMqVLYNdIT4A/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的书籍来自机械工业出版社的《AIGC驱动工业智能设备》，该书从基础入手，深入讲解AI技术的基本概念和原理。通过通俗易懂的讲解和示例，帮助读者建立坚实的理论基础，为后续章节的深入学习打下良</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493805&amp;idx=1&amp;sn=e011f7e6f7f12d05e3ea952941daee6c&amp;chksm=fd0488bfa724989be4c8dd714890efab7a6b5bec80a689309138ae3761d2c4f577452d8a16b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 28 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[美团LLIA登场，让照片“开口说话”不卡顿：低延迟、高帧率，音频驱动肖像视频进入实时交互时代！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48pVRHuhqxC0rZetfMaQO9vH1icmibhHy1HIl7coV7ubJl4gO4TZRJKv4w/640?wxtype=jpeg&amp;wxfrom=0"/><p>美团提出了一种基于扩散模型的音频驱动人像视频生成框架LLIA。该方法实现了低延迟、流畅且真实的双向通信。在NVIDIA RTX 4090D显卡上，该模型在384×384分辨率下最高帧率可达78 FPS</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493790&amp;idx=1&amp;sn=366e009b9ffc8d4c7a5dc430de28732c&amp;chksm=fd4c9fc1cd1af69cd1b2a67d2907000f4012e05e139b0d617c25fc1b361cefd5d466a4883f71&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 27 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq5BIttmnJoy6onMGT6hEJiblmfujJkZFpZjpO6usAYRtw7aj1tZbJZYw/300?wxtype=jpeg&amp;wxfrom=0"/><p>腾讯混元团队提出的 HunyuanVideo-Avatar 是一个基于多模态扩散变换器（MM-DiT）的模型，能够生成动态、情绪可控和多角色对话视频。支持仅 10GB VRAM 的单 GPU运行，支持</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493790&amp;idx=2&amp;sn=2fef17851b32fe0303906936a0fc78da&amp;chksm=fd149a9632a0d794e229375a46821c35d7228e88629ed23f3e877af7b2c8ae29d390927296d8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 27 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI版玩具总动员！Articulate AnyMesh：开放词汇3D可动对象建模，自动给任意物体上关节然后动起来。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emlTwYmibs5btPianRd5BcicyicU9XuKiapM6UREY9FwGXMiclic5aK1IZY2K3p9ywZlqBwIYKbtdPJUg9jw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由马萨诸塞大学阿默斯特分校、上海交通大学、卡内基梅隆大学以及麻省理工学院提出了一个开放词汇的3D可动对象建模框架 Articulate AnyMesh，能够以开放词汇的方式将任何刚性 3D 网格转换为</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493790&amp;idx=3&amp;sn=976a7c78a2ab0772279b873c013c4fcc&amp;chksm=fd45ed03a803c648d1ce8e2515fbc33aec0040475d261347728382814a73c1979bec1eb5c841&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 27 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI界的"六边形战士"！港科大×字节提出ComfyMind：生成/编辑/推理三连冠，开源领域再掀狂潮]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elI7B3IZQkA99hvyeKlzPzyeqYm9eaK3j5oUNFlRDs6yaz4YvOHWYMnpeWHk5ic5s7zDkXrP7RYtBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、字节跳动提出的一款基于 ComfyUI 平台构建的协作式 AI 系统ComfyMind，旨在实现稳健且可扩展的通用生成功能。在 ComfyBench、GenEval 和 Reason-</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493790&amp;idx=4&amp;sn=49423cce96d58d15d7dd9efb1d09001d&amp;chksm=fd8c20e8762120cb6c33a1899352b2b8dec74971d3388d360788ec72e059e36772d2cdb4f713&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 27 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源多模态生成模型新标杆！OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/640?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493789&amp;idx=1&amp;sn=ac58f5ea6bea434235c7ca2e7bb0b2a4&amp;chksm=fdd67fe2f6e5474d04f19cd431698a293ab1bcd64e56efa93c8f18bfc8b09cf4511b3cf1431f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 26 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[UniRelight：用AI重新定义光影，一张图片也能“玩转”重光照！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic7KwJk2LgWQGVllkaSM8Yden54sxzolLeKOFFxwK9icp1NVTJKWB0YicQloE0ZSIvv1TppUDEibwHmGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>UniRelight 是一种基于视频扩散模型的新型重光照技术，能够在单次推理中联合估计场景的反照率并合成重光照输出，显著提升了跨场景的泛化能力和视觉效果。在视频处理领域，我们是不是经常因为缺乏高质量的</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493789&amp;idx=2&amp;sn=e65fa9371048f301bc4c1cea8eaa0ccc&amp;chksm=fd9562965274c906bc22cf3f5986624cc9e3ee4c15b88b0b77ffd3d401f7b26c3d4c386856de&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 26 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[文生图新架构！清华提出MADFormer！混合自回归与扩散的Transformer模型！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5Ir9WHCQBicWXDuF5MpvmWMQh4QPfVT8nXE9Tnw27035bkagHHFhhyzApmdO2oxAbKbOs56pmZG7JQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generati</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493789&amp;idx=3&amp;sn=cc8ef879ad4f49695204a467fb4019a0&amp;chksm=fdeac8a98186185d77d7d170cb7098200ccd314e56acbb73e5c74fc64ac44abbd41fb24bcd23&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 26 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[多模态任务大一统！蚂蚁推出Ming-Omni：图像、文本、语音三模态无缝融合，一网打尽复杂任务！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48J6PaQ6vvBzg7xSUic6gUlNictqMXib837dJ3ia9U0lib3hc3BMuQHGGd8fA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Ming-lite-omni 是 Ming-omni 的轻量版本，源自 Ling-lite，具有28亿激活参数。Ming-lite-omni 是一个统一的多模态模型，能够处理图像、文本、音频和视频，并</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493789&amp;idx=4&amp;sn=4641e20e9ef06f598cd597c861a21932&amp;chksm=fde54945fe6826bb23e9f84b659454e4417f4cb6acaeb6606adad91bc5c50addc5b91e22ac62&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 26 Jun 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>