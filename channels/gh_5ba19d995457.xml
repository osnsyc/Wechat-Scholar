<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://wx.qlogo.cn/mmhead/XzhF92tBcezMLGZN5TwHm01JzyB611PyibhFUMaiaE6xaTcU7nCAumRAicJowUjC4ntxOOAkSvxOK0/132</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[AI 多人生成新突破！复旦大学联合阶跃星辰提出WithAnyone，让 AI 合照不止“在一起”，更像真的“一起”。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emQKGZTwb4erK5UqoPicKiaNxVzoYkr79DnNXK3aKJJibRbwoLX7gecMfYQiaGQ17CtE0dzZv4ULHuqLQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！让 AI 合照，终于有了“在一起”的真实感。过去的“AI</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496738&amp;idx=1&amp;sn=3e7cb71675148f17870cf39186e7e540&amp;chksm=fd3c883c739eed6240c84497f06b5f5d4c6d12e71d63215e40b07d2b32cbaa49df4db35607a4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Nov 2025 00:13:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一文详解具身智能：世界模型（World Models）系统性综述。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic5pz1CM8LfC8yORHD0VTynbjNDWncib8icQlxHjBmzvBkXhHmyVvpTaPty0mG8HiaibJpWLxbia0IYVd0w/300?wxtype=jpeg&amp;wxfrom=0"/><p>经典文章回顾：一文梳理主流大模型推理部署框架：vLLM、SGLang、TensorRT-LLM、ollama、XInference一文梳理主流热门智能体框架：Dify、Coze、n8n、AutoGen</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496738&amp;idx=2&amp;sn=9fe40e472fac5cb9a8b3968905b253cd&amp;chksm=fd3bc16935e846c4124789bf3d4c297f1f64e6ccc45f49e87d30e6c9fb7a9d2dcdaafafdf017&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Nov 2025 00:13:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[手机上实时跑3D数字人？阿里开源MNN-TaoAvatar，打造本地离线智能数字人新标杆。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek8O7Mx0HicAQzYnr62ZEJLwjCaTF4Xg9G65OJibjU82ibBkicGN8Zdt93yM9ibvqO1zSU5WvX0ehVP4QA/300?wxtype=jpeg&amp;wxfrom=0"/><p>TaoAvatar 是由阿里巴巴淘天 Meta 技术团队研发的 3D 真人数字人技术，这一技术能在手机或 XR 设备上实现 3D 数字人的实时渲染以及 AI 对话的强大功能，为用户带来逼真的虚拟交互体</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496738&amp;idx=3&amp;sn=b0398a90b2bb0c2efad9ea6f33402866&amp;chksm=fdf64a82f37f646a4e5fff7746bf657a66c347b547fc4cf910a97a6c3f9d3cba83a9727056bd&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Nov 2025 00:13:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[PlayerOne横空出世：港大×达摩院重塑虚拟世界交互范式，动作捕捉驱动AAA级场景自由探索。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enfUCFX9WW23BajIFJBpRq3xvD6IHNj8gocPOicHAPyQsE13dEpzsl31yyrObIKhz86FlHOmK6LtVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天介绍的文章来自公众号读者投稿，由香港大学与阿里达摩院联合研发的PlayerOne模型正式亮相。该技术突破传统虚拟场景构建范式，通过单张图像输入即可生成高保真动态虚拟世界，并支持用户以实时动作捕捉实</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496738&amp;idx=4&amp;sn=aef257145a5766b13835f8052899418a&amp;chksm=fd1df66bc9881447e4954a7f745f77717fc87160cf291a5615b697e0c13c1ebeb62d45ec35bb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 05 Nov 2025 00:13:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[图像编辑迈向新高度！天津大学&amp;快手提出GRAG：4行代码搞定图像编辑精准控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emoK0Qlia1UfbJSCCnEc0R0Pe0jSiaicKfViaLawMO9H5PiakeJsByEWZNExJiaqQechJad9icicdzmlx7osQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！天津大学与快手科技的研究团队针对基于扩散变换器的图像编辑技</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496718&amp;idx=1&amp;sn=0bc3d69e431d6b7ade205022012d8b2e&amp;chksm=fdfe48f73b376c6c310a359fe393e01e46cee2cc623fef7479dfe854ac78087a3525758c8775&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[3万字长文！通俗解析大语言模型LLM原理]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsF9IX893mLWvOX1icNGOEu8rqxnLlXRvSOvWuY8zfQr9TzNSmiaPxawVGgO4V6UkI4L9HTqMUXib3JbA/300?wxtype=jpeg&amp;wxfrom=0"/><p>Datawhale干货 作者：陈思州，Datawhale成员为了便于大家更系统的入门和学习，最近，我们会为大家分享关于AI智能体的系列内容：《Hello-Agents》项目正式发布，一起从零学习智能</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496718&amp;idx=2&amp;sn=23d991371d85d08d6416580e976976fc&amp;chksm=fdd53fd45772bce4afd1fd6dc1363dee87fea875a573e442d6e2b59a8cef96a35380212e8edc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 图像生成新宠！StepFun 开源 14B 参数自回归模型 NextStep - 1，图像生成与图像编辑一键搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emLic2Rhpf3QYj2hoRbhoUGYqUKvsakZV7mEREOapr4qUib9cuiaq32lm19qdE1FqCHAiaWqbRdYekc5A/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！在科技飞速发展的当下，AI 图像生成领域正经历着翻天覆地的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496718&amp;idx=3&amp;sn=1b5db3bf4febfe13b7b75115400a89e9&amp;chksm=fddaf9da7405d606ec7ead8acb0508c1af7792b5582befe6bc00a5dd642dfb91db85af8ba467&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[CLIP为何搞不定分割与检测？哈工大团队开源通用视觉任务新框架：突破开放词汇稠密感知瓶颈！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQhStl9HDM6GcOr3QDheUhWnTstzlpacic9HQc2VSI1YMX5Lafwo6gBia6Jqbia9MEWd5YYGYjR5Yu5Ow/300?wxtype=jpeg&amp;wxfrom=0"/><p>面向2D检测、3D分割、6D姿态估计的通用基础模型基础模型已经改变了计算机视觉领域：CLIP 首次将图像与文本连接起来，DINO 擅长捕捉语义结构，SAM 提供精确的分割掩码。视觉领域需求更广泛的任务</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496718&amp;idx=4&amp;sn=1ee4ba0fb5b311923c84dd34d2edf89b&amp;chksm=fdf72c6c4bab91a3336b868d6b4c8a64c62e52e7886d6409a2c17d66d098cbb76d1ae0c83eed&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UniVoice：首个在大语言模型中统一自回归语音识别和流匹配语音合成的框架。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elVvJqr6VPt6K3YBxNuIKgoJVth6pTQebiafMjJmYHFwu2B7mAMbokhUFImUX3oOrhYscl1nc6apsw/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！厦大联合上海创智学院等单位发布统一语音处理框架UniVoi</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496707&amp;idx=1&amp;sn=7728bf3aa1786706cc7dcf052bd0a0c5&amp;chksm=fd29c2411fcdd31534fd8c596b006e183d2c7a377d14e99fadc266c57783fbe9a309ba2955d4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[达摩院提出ReSpace！自回归文本驱动3D室内场景合成与编辑新框架！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IUS026bgrHtl19k8iaTzNl8icef5pd4T4TvpwHoxzu1cyROia6klKjBkbZgib9aibULqBb20gpjfNRAAw/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：ReSpace: Text-Driven 3D Scene Synthesis and Editing with Preference Alignment论文链接：https:</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496707&amp;idx=2&amp;sn=162b39804a40f1937a5bd3533f42ad4e&amp;chksm=fdd28c06900ca70089c3c9ebe47291f1b40d26d50cd73aa8b002bf09add5122830abecef0095&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[OminiControl：一个新的FLUX通用控制模型，单个模型实现图像主题控制和深度控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuCwIlu7cc4lHd3hwJicoyYEn3PFyv0qTxQYEgq8VntmUj91vEEYPJjMADiamfkH94icSBs7fF1Tn1A/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中和大家介绍过Flux团队开源了一系列工具套件，感兴趣的小伙伴可以点击下面链接阅读~AI图像编辑重大升级！FLUX.1 Tools发布，为创作者提供了更强大的控制能力。OminiContro</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496707&amp;idx=3&amp;sn=5d67e5585794f3f1bee7bb3f8e2491b9&amp;chksm=fddc1f6e9255ebbb23f46e930ce4e7e1a8627abf3062d9f24f1f3c5d7446fe0fa62ca0ad9a05&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源 DreamOmni2：多模态赋能突破传统局限，开启图像编辑与生成新高度。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emscrJryeqES6ReYP0UJe5EkqpQLGatVsmugRb4g89uJjGPQGQicLcM9ia3nWD6Tk4BLQRmypU88fSg/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！在图像编辑与生成领域，基于指令的编辑和主题驱动的生成虽有进</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496707&amp;idx=4&amp;sn=9e76c77760c6066cd30423480979d879&amp;chksm=fd135e0e0c520e1d0d0da949bc5c0bb0700f592f0b5f1bd2fc946d59092770f306e2ff8ddfb8&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 03 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ICCV 2025 | DiffusionGS：将 3DGS 嵌入 Diffusion，高速高分辨3D生成框架，代码模型已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eloAh0Z3Ac67GJibRojdPBlyBsYqYkVxV5a3O8glFeYcNxKwOL6t6Z2OegJRzO3SwARE1HH5DEiaWSw/640?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！本文来自公众号读者投稿，作者是约翰霍普金斯大学计算机科学系在读博士，于2023年和2020年获得清华大学工程硕士和</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496701&amp;idx=1&amp;sn=392f65928c9eb267eb1914adc82692a8&amp;chksm=fdb6fb0ba0665560b145b4a4e3cc5a839df2007be741b5ee80f8cacc553012b3ed852c8cbd89&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 智能体简史（万字总结）]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsEx7l2IYqNbMTWwMpv8BhFANYaKQPMo9ibG6yPicSoCfzRjAxhnmDORSROkakaMcRmmibiahIlDshwkOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Datawhale干货 作者：陈思州，Datawhale成员智能体是今年非常火的方向，2025年称为“智能体元年”。为了便于大家更系统的入门和学习，最近，我们会为大家分享关于AI智能体的实用内容：《</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496701&amp;idx=2&amp;sn=7a0f1c6a11caceb5108adc9b1a998c89&amp;chksm=fd03118a7d4256c6dc7bfcbd3e7cf642979daa65523b1eadccb629327a1b1aa1d3a36df34476&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[美团提出统一多模态模型OneCAT，一键搞定视觉问答/图像编辑/文生图任务，性能表现SOTA。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPlbWXgYsucwm25tHpGozZiadIia1cibavBMHkk3qMYjW7tFiaEna5OmM5ZcA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496701&amp;idx=3&amp;sn=fca13dceb4fa83bf073ae272f8cfb1e0&amp;chksm=fd1825241afb58b0456091a8845fdcc1f1102bb6314b40b3c9590f288e4b5ffff76ec06fd038&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别复杂命令行！微软 AI Shell 强势来袭，打造智能交互新体验。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPRJ5HXpW3eg5IdOCPZKiaIaVC28jfh8HaybK0oAsfZqADEItEUtNZSJQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！今天要给大家分享一个微软刚推出的超厉害工具—AI Shel</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496701&amp;idx=4&amp;sn=6cda6e71bd5c32350456cd9c29b9545c&amp;chksm=fd987f1d4b3e698a09e73dd817aea8fa36aeb1ce211f95416dc8c3f3f4a119eb356630d59798&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯混元开源世界模型HunyuanWorld-Mirror：支持多视图及视频输入，单卡部署，秒级生成各种3D表示！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPdE96iaSHrBWejI3J1cH9ibC4lxLTGpHqTICOKwfsXz2heP3GpicHKxaaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！HunyuanWorld-Mirror 是一个多功能的前馈</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=1&amp;sn=9f9b287b5cb343b6f645345e478ead35&amp;chksm=fd40f74f2c5a17fe38ef0224cd6d1fdc0ef5dbb677fc470be6392e94f71a69fb2eab6157d335&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Magic Mirror：可从单个参考图像生成电影级质量身份一致性和自然运动视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrL9coT0EQdTjZR7WCoOG6gAxgXB4PynfsscmlUfdakUvCDVQnWbSz48ZDHyhvW76iaaN3BpfbNqQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>Magic Mirror 可以生成合成身份配对的视频数据。该框架利用视频扩散模型，能够在保持身份一致性的同时，生成具有电影级质量和动态运动的视频。Magic Mirror 根据 ID 参考图像生成文本</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=2&amp;sn=eec7c1f06e194f07246a07954557b4e1&amp;chksm=fd86534c7ea92f798940090e3632dca0e343e3fa9380360c31c052504071adebed5437c2b372&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=3&amp;sn=90b3d0298ead36f5599f710fbd20d05e&amp;chksm=fdbb09b8efc28bee7b922bad692a3219c640f02358bc57d537cdac0a8153b160984c5ae3fa5a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[DeepSeek们的成本，是怎么计算的？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jEa2NN5eMic76LNKtDbp6JciaVMNpJ0DfXGyCBQINciblWxEtiaW2ibhfotlvKmwWXak89sQiabHFW56grOTBNPjGWfA/300?wxtype=jpeg&amp;wxfrom=0"/><p>DeepSeek彻底让全球都坐不住了。昨天，马斯克携“地球上最聪明的AI”——Gork 3在直播中亮相，自称其“推理能力超越目前所有已知模型”，在推理-测试时间得分上，也好于DeepSeek R1、O</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496618&amp;idx=4&amp;sn=56a38929c5bf94b5a36ca7ceccb1a48f&amp;chksm=fd7381a64090e5d742eb4a36d70cb8157bbdb83c4adc0acdbb49f52c17de3b27b621b3d30b15&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[告别复杂命令行！微软 AI Shell 强势来袭，打造智能交互新体验。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPRJ5HXpW3eg5IdOCPZKiaIaVC28jfh8HaybK0oAsfZqADEItEUtNZSJQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！今天要给大家分享一个微软刚推出的超厉害工具—AI Shel</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=1&amp;sn=f0a8032cc0909389e09d443889b98204&amp;chksm=fd65c7afd4b16ee872daf77143478976e33f6d59df050686a87eb4ac3639cbd89542a0348efc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[智源开源EditScore：为图像编辑解锁在线强化学习的无限可能。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPK6iabtkXfBZFRVtgrsE2o1leI63ibKg939BgF4ooKUhWEfSZ10px65Vw/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章来源：读者投稿文字来源：机器之心如有侵权，请联系删除随着多模态大模型的不断演进，指令引导的图像编辑（Instruction-guided Image Editing）技术取得了显著进展。然而，现有</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=2&amp;sn=f01ed4e3a91164b1804e8e5949118192&amp;chksm=fdc5fe89fe469147d0db8f373a59d56c5351955dc9dc1684b989c5c44c96ba70db0a12054581&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布 Waver 1.0：一句话生成10秒1080p多风格视频，创作轻松一键达！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em7A7COb17nQf31AE47soscoy7aHU25oPTiaxHictLptYsN4iafwUx2b2iaBpowibOUZJFdBKXSRcC9ib3A/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出的 Waver 1.0 是用于统一图像和视频生成的下一代通用基础模型系列，它基于整流变压器构建，专为实现工业级性能而设计。一体化模型：在单一集成框架内同时支持文本到视频 (T2V)、图像到视频</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=3&amp;sn=cdb913c2adaa4af16794fdc99a110ffb&amp;chksm=fd6086403c80c511fb15da9deff091e56c77f7f7224a6b49cb46df07b17f02c20b54ad280aa5&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[腾讯HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekQ3Nmc3fbNpth63WYWa7IPz0VreR3OZN1Te1uA2ypdJzkVTskDcl9xaYIsjI19fvRWodumj0UZ6w/640?wxtype=jpeg&amp;wxfrom=0"/><p>#视频生成 #数字人 #音频生成 #AIGC 腾讯开源 HunyuanVideo-Avatar，一张图+一段音频实现图中人物、动物甚至虚拟角色开口说话！@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496562&amp;idx=4&amp;sn=dfc65c48f30bbcbcc9c45e119bad03d4&amp;chksm=fdfb0bdfedd91753062647f5f2d2627111ba080e047f1c4bd8970bc13fc31f0fe70585f7a4fb&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[AI 图像生成新宠！StepFun 开源 14B 参数自回归模型 NextStep - 1，图像生成与图像编辑一键搞定！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emLic2Rhpf3QYj2hoRbhoUGYqUKvsakZV7mEREOapr4qUib9cuiaq32lm19qdE1FqCHAiaWqbRdYekc5A/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！在科技飞速发展的当下，AI 图像生成领域正经历着翻天覆地的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=1&amp;sn=10d4184e016e0d4949a29fae0537bcbe&amp;chksm=fdadfec1f9ed081783ed4c81446e55e77b921a3b129fb134a3de0e262868ca43e8d306c65986&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[Hallo4：让AI肖像“活”起来！新型扩散框架实现高保真音频驱动动画生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq56s1kIaYWsxKESfb9riaHUQVlW3JfPib9AP6mL8Hk0Ec5R0f43HYJ8aw/300?wxtype=jpeg&amp;wxfrom=0"/><p>复旦联合百度发布扩散框架Hallo4，实现了准确的唇音同步、自然的面部表情，并能够稳健地处理各种角色身份和环境场景中快速的语音节奏和突然的上身运动。相关链接论文：https://arxiv.org/p</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=2&amp;sn=a037eb00617587dd7061341aa19cd78b&amp;chksm=fdca80ba23508a175006b987deef38fc07c06f3f070bb78274abe4f1589e317dcd57e632fd5f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节发布风格&amp;主题优化定制模型 USO，任何场景+任意主题自由组合，高保真一致性输出，模型代码已开源。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elxI31iaYSzUGibFXibPx7ZT4tiafa1OQy2cwOTRicY23d73sOIEARSenF8FaojlXibI1Q8d3s4ciaNzpl8A/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节推出的USO是一个统一的风格-主题优化定制模型，也是 UXO 家族的最新成员。USO 可以在任何场景下自由组合任何主题和任何风格，输出具有高度主题/身份一致性和高度风格保真度的输出，同时确保自然、</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=3&amp;sn=bb858963bee25c27a8b7298478c7d4dd&amp;chksm=fd82fc63e4d9906fa9fec1e1044171706edf6179e7ceadc215ed6d511945e02a57dba2163f05&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ChatAnyone：实时交互式视频聊天。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFBvDo9xOjM1tdvD1dCdZr760dXoC4wLgicCauCgadtfian63zlxCvjB2iaw/640?wxtype=jpeg&amp;wxfrom=0"/><p>阿里通义实验室提出了一种风格化实时肖像视频生成框架ChatAnyone，使视频聊天从“会说话的头像”拓展到包含上半身交互的更具表现力和灵活性的形式。ChatAnyone方法支持高效、连续地生成分辨率最</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496533&amp;idx=4&amp;sn=91fd6e18725e32c71a9a1aedcd30d980&amp;chksm=fdc542faf74dacd7441049d7faa73e1d07fffe7e56a4bdfe1b2d48d2c8b745d55a191c824cae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[SIGGRAPH Asia 2025 | InfiniHuman：精确控制高保真3D虚拟形象生成，质量、速度、可控性新SOTA！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enOsWGSowG7dTvaQfLGpk8QicdBAs8Aib7va23bWsWpqu8icglxyMSNUvMZbiaDvbffJ5Il6VfmAZrQibA/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！已有的问题训练 3D 人体生成模型需要大规模、多样化且注释</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=1&amp;sn=bf43f95276575507f9fe7b1bafa56ac1&amp;chksm=fd9dbe291e25197c12a19a945d8426d3a0284f0d323678c6d942275861363f3d440adf7dfe1c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[PractiLight：无需大规模微调，扩散模型重新照明图像的“隐藏密码”是啥？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnlicYMzw1WzNwt5le6iaI9cTAtDXqeQhLib2EX5oj6diaoeWrR70g9ysxhaoNYpWZY23iakey176zJZA/300?wxtype=jpeg&amp;wxfrom=0"/><p>标题:PractiLight: 使用基础扩散模型进行实用光控制论文：https://arxiv.org/pdf/2509.01837项目：https://yoterel.github.io/Pract</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=2&amp;sn=8ef495b549f3e3a9c92b0dccab2d61a9&amp;chksm=fd9e4e6a5dcb964672d2df19778e1441b271d659edf07e1b8a3fe2443dcdbd1ecd205904459b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[ComposeMe：可基于文本对多属性（单人&amp;多人）多属性（身份、发型和服饰）随意组合和解耦控制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emWWjXopniaeJLQgrb3xQhEL7RSTXR33nIN4iaeIZzyicy21ek0qtCribmBzLEKIQKTXlZCuSFX5nE6gQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！ComposeMe 是一个以人为本的生成模型，能够对多个主</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=3&amp;sn=1818783d04017ce378e04da2cc13aed5&amp;chksm=fde80c8b9926fd0aeb0b2c32056521c9794613341a3db90171a63fed6d63575c14bf1906815e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[清华&amp;字节开源HuMo: 开启多模态可控人物视频生成新方向，输入文字/图片/音频即可生成电影级视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enwauO3kWoFyKnUPCqVjrPl5fon0zqaCYa1WAGMKib43ibDcv8gDnvjAAPXvsT4Mkr1cgVcibJpA2nLA/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由清华大学、字节跳动提出的 HuMo 是一个统一的、以人为</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496506&amp;idx=4&amp;sn=6564abd580965ba764cef195e76dbb88&amp;chksm=fd73bf6836dc9b17027c625fbfd75cf4e52e8d01b067031be52e06307f0bd7e3c0dbd09a948a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 28 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频编辑新突破！新加坡国立大学等提出视频编辑框架IMAGEdit，无需训练、即插即用，可实现任何主题的视频编辑。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emLic2Rhpf3QYj2hoRbhoUGYVMUFb9T05FusR4LFekAEqguwQXicMNaz2b4xr4qqaicYzthFWJxjTGUQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！由新加坡国立大学、南京理工大学、香港科技大学以及南京林业大</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=1&amp;sn=adcab57cca0b2c356cf78b25100d83ca&amp;chksm=fda4e414b31312459c984b050f560ac94752c0b1eed7b2398b03f615903f975de6de83c5db9d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大×字节提出ComfyMind：生成/编辑/推理三连冠，开源领域再掀狂潮。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elI7B3IZQkA99hvyeKlzPzyeqYm9eaK3j5oUNFlRDs6yaz4YvOHWYMnpeWHk5ic5s7zDkXrP7RYtBA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由香港科技大学、字节跳动提出的一款基于 ComfyUI 平台构建的协作式 AI 系统ComfyMind，旨在实现稳健且可扩展的通用生成功能。在 ComfyBench、GenEval 和 Reason-</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=2&amp;sn=53b8a5337447606a825e005533fa6fa4&amp;chksm=fd80ce8c5374e1a0916cd33d73821748be34c8a4e743c48f022c31934b0a75289e3ed552afd6&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一文带你了解，MOE 架构是什么？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/CibEZ9gjHpIrjh2Jy92UibXavMpGEKRelbCqXiaEc6hkxXvNNtIibfW3p5bo1jGWB6icwh68qvkWZsqN65HicvwiaN28w/300?wxtype=jpeg&amp;wxfrom=0"/><p>引言：从“全能大脑”到“专家团队”你是否想过，为什么ChatGPT能回答复杂问题，而手机语音助手却常“卡壳”？答案或许藏在一种名为**MOE（Mixture of Experts，混合专家模型）**的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=3&amp;sn=9cea44aea0eb7ea52fd0c928a228cee1&amp;chksm=fdb4d195c45c8ec21cef5697e144fc97bbff88541cf648ce3e24b3b9a37ef123ca8a8e62fc43&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UniRelight：用AI重新定义光影，一张图片也能“玩转”重光照！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic7KwJk2LgWQGVllkaSM8Yden54sxzolLeKOFFxwK9icp1NVTJKWB0YicQloE0ZSIvv1TppUDEibwHmGg/300?wxtype=jpeg&amp;wxfrom=0"/><p>UniRelight 是一种基于视频扩散模型的新型重光照技术，能够在单次推理中联合估计场景的反照率并合成重光照输出，显著提升了跨场景的泛化能力和视觉效果。在视频处理领域，我们是不是经常因为缺乏高质量的</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496489&amp;idx=4&amp;sn=eaa2b41cf41c3092b12fd7dbda307546&amp;chksm=fd5516fe692982b084b896cfd0ebb3b33b87b5a0464764f894da49b8409bca32d0f71a576014&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[视频风格迁移来了！PickStyle：使用上下文风格适配器进行视频到视频风格转换。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elEv3MSa6ccibpmEQKSzhgQ7UuWbPaLgc6zUuDRLlVC18cglPGyBxG5znGze4u2gwIy7ln9hKWS7Ug/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！利用扩散模型做视频风格迁移，想保留原视频内容的同时渲染成指</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496436&amp;idx=1&amp;sn=ec519cceab55c212ec4754abd6645bfc&amp;chksm=fd95784252e593a25c63614e4c1756d7c44400c3096f9f0a650e1a2339dab39e48381a763af1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[UIUC 提出视频虚拟试穿生成方法 Dress&amp;Dance，可直接生成 5 秒 24 帧 1152×720 分辨率试穿视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elxI31iaYSzUGibFXibPx7ZT4tBLMjqKcIp1dlicic4aiaiaHmttztn5oIPkYWibFSwfMWCgR2sdIddrNXBUA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在一系列示例中（包括随附视频中展示的示例），该方法生成了 时间连贯且逼真的结果，通常能够捕捉到细微的动态，并与输入提示保持高度一致。同一模型在各个任务中具有良好的泛化能力，展现出强大的组合性和对各种条</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496436&amp;idx=2&amp;sn=05d9319c9d4ed2a81a3f972c2090defd&amp;chksm=fd7b39e29362bfd6e2883f845ffbb6bc32caa491704f955b50e4ac073f6b2060bf8311a73240&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[TripoSG:一键使用AI在数秒内生成3D设计,支持文本/图像/涂鸦等多种方式，引领3D生成潮流！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eks71KCI53QzfLjA27o9Yf3eNhhBOwNK1fL9KrI6VvmwpTtHQY75YN6kpUNFib9wnGUtDzn1YjAYicw/300?wxtype=jpeg&amp;wxfrom=0"/><p>TripoAI发布了最新3D生成模型 TripoSG，能够生成与输入图像精确对应的高保真 3D 形状样本。涵盖各种复杂结构、多样风格、富有想象力的设计、多对象组合以及细节丰富的输出，展现了其强大的生成</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496436&amp;idx=3&amp;sn=ebf245d1e1bca9f593d46a91d99b45b5&amp;chksm=fdab3366473cd64fd694fe403adbcc572e86a08f58dad3086f2edf6ccea65bf8ab119da9603d&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[超越SOTA！浙大&amp;斯坦福提出 DiffLocks，单图头发 3D 重建精度提升30%，首次支持非洲式卷发生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48OPjpkTnf2mQjjRuiawRZ5BrVMBtgVJ4QGZRnabuCSKficVh97iaqr4QzQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>由浙江大学、斯坦福大学等联合提出的DiffLocks，给定一张 RGB 图像，DiffLocks 使用扩散模型生成精确的 3D 发束。该模型基于一个包含 RGB 图像和相应 3D 发束的新型合成头发数</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496436&amp;idx=4&amp;sn=26a3324ffc4b1b009a9547460d0468f0&amp;chksm=fd733c28bce4f795bc8f2fb43499ed1ac0127985050eb288dc85ef6c740669b81e4f5fceb5b4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[科研人福音！新加坡国立大学提出Paper2Video:可从学术论文自动生成演讲视频。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elEv3MSa6ccibpmEQKSzhgQ7Zy3hiaKHYib2lGSspRic4u1goQPDmRFrHAt8SY4ojfmAjmkgEjJryDqxg/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！新加坡国立大学推出了首个研究论文生成演示视频方法 Pape</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496397&amp;idx=1&amp;sn=d048d303f0963978f9001b982fd2b71b&amp;chksm=fda52a16bc1c8a7427649732be7c0036e3cee905c004c44a6c5dcf3802dba737113980a4bb0a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里开源 30 亿参数统一模型 Ovis-U1，多模式理解、文生图、图像编辑样样精通，多项学术基准测试领先。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enuDmLq7R1rRFldNX6Em3MD3ic6VVyQ7fibbkHSDXdsLJJKPKURibic6bQdSKAoTkLHaP0dHSb0n5P6Zw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Ovis-U1 建立在 Ovis 系列的基础上，是一个拥有 30 亿参数的统一模型，它在一个强大的框架内 无缝集成了多模式理解、文本到图像生成和图像编辑。亮点统一能力：单一模型擅长三大核心任务：理解复</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496397&amp;idx=2&amp;sn=8f3149189a584831eb339610c9b7a185&amp;chksm=fd1bbb35bc6fec02deb3a16aa3edbbbf85f7259704aa6c6bb6c3a18757e2c9e2ac0a76ac1ba1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[南加大&amp;Adobe重磅发布Comprehensive Relighting：一键换光+背景融合，助力视频达成“光影自由”新高度。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPCjTfhE2exCxyco6laPao3eibod5YTwwibyAUooUJyItngDiaCLt2D05dpqXaf3zZNZU7L9YG4LZAA/300?wxtype=jpeg&amp;wxfrom=0"/><p>南加大&amp;Adobe重磅研究:一键换光+背景融合,视频也能"光影自由"了!南加州大学联合 Adobe 提出一个通用且一致的重光照和协调模型Comprehensive Relighting，它可以控制单个</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496397&amp;idx=3&amp;sn=13e9988e0cc7b1f1a2bb8b29865242ec&amp;chksm=fd4019640589ffb05adaffd4dca38d4dca0b6531eda038c24ebcd44cf2f10e6cab212900a21f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[FabricDiffusion：一种将织物纹理从单个服装图像迁移到任意形状的 3D 服装的方法。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elxI31iaYSzUGibFXibPx7ZT4t9zr8jgdgznSHBpr8KPFptQVyDibTicfx7btZAHHl7PFvrF98ZKzwDg4w/640?wxtype=jpeg&amp;wxfrom=0"/><p>#服装生成 #diffusion #服装建模 #3D服装 谷歌和CMU提出FabricDiffusion：一种将织物纹理从单个服装图像迁移到任意形状的 3D 服装的方法。@AIGC工作室</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496397&amp;idx=4&amp;sn=b0bd55e22855263868709c7cf77f6e17&amp;chksm=fd3a2a779ea6eaf49a92814f8a84fc158a124f597634656b3af33b8b8bbbd18c1abacfe6df7e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源 DreamOmni2：多模态赋能突破传统局限，开启图像编辑与生成新高度。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emscrJryeqES6ReYP0UJe5EkqpQLGatVsmugRb4g89uJjGPQGQicLcM9ia3nWD6Tk4BLQRmypU88fSg/640?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！点击下方名片关注AIGC Studio公众号！获取最新AI前沿应用/AIGC实践教程！在图像编辑与生成领域，基于指令的编辑和主题驱动的生成虽有进</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496382&amp;idx=1&amp;sn=698d79361bc1532c1f05d8f8d8d0f248&amp;chksm=fdf8a6a4392d1a15a488ea5930b8cacfa250516b679e60ac559cdbf41a74930c64f3241286b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[一个无解码器的分割框架？南洋理工&amp;字节提出文本即掩码新范式，纯文本生成实现精准图像分割！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQhGsVbibiaaIKZVlmUPbRX8sicN7cpGUoAHZK4L4pKFqDJZ6qtxkGA500DicCkCNbUykZP8wia8nX1zO2Q/300?wxtype=jpeg&amp;wxfrom=0"/><p>多模态大语言模型如何重塑计算机视觉任务？大模型时代下的图像分割怎么做？还有什么更优雅的新范式？过去，开放世界图像分割的研究多基于 SAM、DINO 等视觉模型架构展开。今天我们重新聚焦于多模态大语言模</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496382&amp;idx=2&amp;sn=ee94c1e02f687d9c2660ccc4732ee37e&amp;chksm=fd8e11e5a54ccc56663bf579d0367955203624c3fa076bd5fae7bfb08b72c0f235791ef18d10&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[CLIP为何搞不定分割与检测？哈工大团队开源通用视觉任务新框架：突破开放词汇稠密感知瓶颈！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/x8Uwv7aoCQhStl9HDM6GcOr3QDheUhWnTstzlpacic9HQc2VSI1YMX5Lafwo6gBia6Jqbia9MEWd5YYGYjR5Yu5Ow/300?wxtype=jpeg&amp;wxfrom=0"/><p>面向2D检测、3D分割、6D姿态估计的通用基础模型基础模型已经改变了计算机视觉领域：CLIP 首次将图像与文本连接起来，DINO 擅长捕捉语义结构，SAM 提供精确的分割掩码。视觉领域需求更广泛的任务</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496382&amp;idx=3&amp;sn=3e81bf0fd7d9e6d0044ad860b1c2be67&amp;chksm=fd926cf30aea9c66106f4c6d463cd1c6072dd8d5b2bbdcf6405c99de4bed625b5005f2b27d0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[实时交互世界模型新突破! Skywork AI 发布 Matrix-Game 2.0：多组件协同攻克交互式世界模型实时生成难题。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekx8zwpPTniaJZsAwfrtcHvicKUBVZ5ZRTP8MvpFhyoqpVrXwR4ymQc9sX55F2kbswy8bXWbkY2gH3g/300?wxtype=jpeg&amp;wxfrom=0"/><p>添加微信号：AIGC_Tech，公众号小助手会拉你进群！扫描下方二维码，加入AIGC Studio知识星球！可以获得最新AI前沿应用/AIGC实践教程/大厂面试经验/算法刷题和IT各学科入门到精通学习</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496382&amp;idx=4&amp;sn=9e97aa598e4a0fc62a0721db1f99a87a&amp;chksm=fddf84119841deedd3a755fdbb699b311d255d38388825c883872cbc21f70dcf02bd7b77e56b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[港科大开源 World-To-Image，让T2I模型提示准确率狂飙8.1%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elnlicYMzw1WzNwt5le6iaI9cR5171t9co0Zibr73NZDzQxwk0fJaUicmJoQYiaW8ehHCWpPqAaRke2Dwg/640?wxtype=jpeg&amp;wxfrom=0"/><p>文章：https://arxiv.org/pdf/2510.04201代码：https://github.com/mhson-kyle/World-To-Image虽然文本转图像 (T2I) 模型可以</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=1&amp;sn=ee8c1871b4541c9cb5c837f88c61467e&amp;chksm=fd96fcbce34d36925205eb0e9cf3169fadc4c64ab288fcdeb4ea2de02b65dcff7be3c824a960&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
    <item>
      <title><![CDATA[当一群清华学霸开始较真扫地机算法]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/DOQ3oqzSJUGgRpf0B3qbE2C9X7xdq25icUWNmwCVAMceibXUAcZcn7a2LBCqiaYwhhqusRvHibDP5TBvOVYxFFY1fQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在追觅，最聪明的大脑盯上最琐碎的家务。作者｜王彬封面｜Unsplash扫地机作为消费品的故事，常常被归类于“消费升级”的一个注脚。最初，这只是一个新鲜的小电器，消费者尝鲜后就束之高阁。可在步入消费市场</p>]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247496334&amp;idx=2&amp;sn=555da5207619b12816baedfc471c676c&amp;chksm=fdebb3499cc6a6d4c587b8ae4e700f3c6c175f073772efa54293e8abadeb7dd1cf9307011120&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 23 Oct 2025 00:00:00 +0800</pubDate>
    </item>
  </channel>
</rss>