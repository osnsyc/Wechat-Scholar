<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  

  <channel>
    

    <title><![CDATA[AIGC Studio]]></title>
    

    <link>https://mp.weixin.qq.com/</link>
    

    <description><![CDATA[AIGC Studio公众号]]></description>
    

    <language>zh-cn</language>
    

    <image>
      

      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      

      <title>gh_5ba19d995457</title>
      

    </image>
    



























    <item>
      <title><![CDATA[魔发奇缘，3D发型生成新突破！TANGLED：可用任意样式和视点的图像生成 3D 发束]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekpCyj06iactRk96xGc32gLwfpjZlTjjCSbXm0Lib95G5D5yo7ElFr9uxtoh3BdCt4nr4ht1wrCGWWw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在数字时代，发型不仅是时尚的标志，更是个人文化身份的彰显。但传统3D发型生成技术往往难以捕捉复杂发型的细腻之美。为此，上海科技大学和华中科技大学推出了ANGLED技术，能从任意风格、视角的图像中，轻松</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=1&amp;sn=08ea1babf6f4a250fc1a070192d94a58&amp;chksm=fd18769d857fb9c659af26deb5e1e6cf9712edb5c11525b839cabbf45aedad95c9ac5643f482&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 23 Feb 2025 22:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[澳门大学提出DC-ControlNet！解耦控制条件！灵活性和精度超过ControlNet！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5IJObOoyvhRkCaPGyos7d8xL9KBFJiaWYgoicVEkmuuB7slvPLj3SIW9jx5pace0iagDibDDTLU1P3Lwg/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：DC-ControlNet: Decoupling Inter- and Intra-Element Conditions in Image Generation with Diffusion</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=2&amp;sn=de121316a3123aa0581f09725abe2bd6&amp;chksm=fd0068d3835af5ba38f14f910e10993f3a78f8da58fc4d63e8db4101161d28881299658a7a8b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 23 Feb 2025 22:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[开源版Deep Research，一句话创建Agent工作流帮你完成电脑上的复杂操作，股票分析也轻松实现。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NZM99XBibic0ksT7p0zTFpQHQT2lY40u4GloUhxMpWMlQLDWe9ic4uibxzibicD0eiauVkGszvokib9MfuhLg/300?wxtype=jpeg&amp;wxfrom=0"/><p>AI刚出来的时候就不断在说，后面非常多的工作就不需要人去做了，都是AI在做。之前很多人不相信，现在已经有很多公司在裁员了，而且裁员后业绩反而更好了。当然，我们平时也不愿意做一些繁琐重复的工作，让AI去</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=3&amp;sn=ebb27cdf7263a50217dd05d142035047&amp;chksm=fd3d55f1d3f84c431f8200a0e71d5b1cd624efc7849f4dd65cec876ccc1dedb7d71aceea768b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 23 Feb 2025 22:00:00 +0000</pubdate>
    </item>
    <item>
      <title><![CDATA[小红书提出新面部视频交换方法DynamicFace，可生成高质量且一致的视频面部图像。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4wY9icyCBJHtpRNSEtIVu23ib2dMfGUzdVZH7hKlE7v6ZRLfdk46k3hHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>DynamicFace是一种新颖的面部视频交换方法，旨在生成高质量且一致的视频面部图像。该方法结合了扩散模型的强大能力和可插拔的时间层，以解决传统面部交换技术面临的两个主要挑战：在保持源面部身份的同时</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490501&amp;idx=4&amp;sn=cf008a19b978ab7f5ca27c2f67b893ea&amp;chksm=fd0052e96469409dee07028c56d34eb9f9ca3e3ce152f5eed389aaa7f0af9935412864f20402&amp;scene=0&amp;xtrack=1#rd</link>
      <pubdate>Sun, 23 Feb 2025 22:00:00 +0000</pubdate>
    </item>
    <item>
      

      <title><![CDATA[免费才是王者？Grok 已冲到美区榜一！XAI 发布Grok3的详细介绍文章。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekY4qnP4C45mhDVMQH4yySsQTsdH9I7ZO4YVrBXiavb43OdiauyElcLrRLQ7u9GdAhXEoPjx4fhPicLw/640?wxtype=jpeg&amp;wxfrom=0"/><p>在 200 多万人的见证下，马斯克的 AI 公司 xAI 正式推出 Grok 3！ 果然，谁能让用户免费用好模型，谁就能起量。 目前，Grok 应用现在已经是美区榜一了。之前的文章中已经和大家介绍过相</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490500&amp;idx=1&amp;sn=5f22f6906758b94668bb934572218eae&amp;chksm=fd7a66827e9f4c9e52f116944324f02c7ec6350322e4ff5513066a90866aa16839738ac1c0bb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 22 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Animate Anyone 2来了！角色动画与环境之间更具互动性，动画真实感和一致性更高。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXWFznUMicvLicvkDmEwFhC2ibGGPzYD6cjmOwxrY9X4Vbv4qexWHZ3R7hibg/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的角色图像动画方法Animate Anyone，感兴趣的小伙伴可以点击下面链接阅读~阿里Animate Anyone：让任何静态图像动起来，让C罗、梅西、内马尔一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490500&amp;idx=2&amp;sn=f743c90e4bdaf7621f4f04d51a854ccf&amp;chksm=fd9b96d6f3cbfee3eff3c4366daa7a6db46ef0f140a449a9be63265e588bb1c32bbfac2d670b&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 22 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌推出PaliGemma 2 mix：用于多任务的视觉语言模型，开箱即用。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZG3A9ureoTeOkRX7vpoweMqWfIXVPrnftNxPZXeKdfJFf3WSY8K2fGQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>去年 12 月，谷歌推出了 PaliGemma 2 ，这是Gemma系列中的升级版视觉语言模型。该版本包含不同大小（3B、10B 和 28B 参数）的预训练检查点，可轻松针对各种视觉语言任务和领域进行</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490500&amp;idx=3&amp;sn=fff10e89e53cbc49d98ecd2a158352a0&amp;chksm=fd4af009eb86df9e052a7c7489667ae610f3d67d887014330dc832a9c728adc33b4e13b32f90&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 22 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一起来学吴恩达新课《Transformer中的注意力机制：PyTorch的概念和代码实现》！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekAuUNNvuhqhCqoRTbKeLmgw71mhsu9IWMRXCr0oO4oVk3w2IO8gPj33kicbvU4Z2uBRJFnQJXic8JA/300?wxtype=jpeg&amp;wxfrom=0"/><p>吴恩达新课《Transformer 中的注意力机制：PyTorch 中的概念和代码》来了！主要内容是深入浅出的理解Transformer架构的核心技术——注意力机制。该课程适合于有一定的 Python</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490500&amp;idx=4&amp;sn=0072125a0cbb3a44f9bed050fd3e970a&amp;chksm=fd83374661db4544c0ba398aa6416213141db8c51ff5864fd1fca51bf1992019b5b07fd6eb72&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Sat, 22 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一起来学吴恩达新课《Transformer中的注意力机制：PyTorch的概念和代码实现》！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekAuUNNvuhqhCqoRTbKeLmgw71mhsu9IWMRXCr0oO4oVk3w2IO8gPj33kicbvU4Z2uBRJFnQJXic8JA/640?wxtype=jpeg&amp;wxfrom=0"/><p>吴恩达新课《Transformer 中的注意力机制：PyTorch 中的概念和代码》来了！主要内容是深入浅出的理解Transformer架构的核心技术——注意力机制。该课程适合于有一定的 Python</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490475&amp;idx=1&amp;sn=11ec2e773b4d543e32e35584a12e3391&amp;chksm=fdca0eb586bcafe6ebca6157a954bd5af06121ce52e716d48823d1a2907aea0e240fa68cd788&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[首个文字生成手语模型来了！SignLLM通过文字描述来生成手语视频，目前已经支持八国手语！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emjicP7If65XYX4tPQXyr9lHCqPXiapc8ulVDfA37EA56NmoCwMkfhAebQyzWagLJMia7wl1t0O59HLQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>SignLLM 是目前第一个通过文字描述生成手语视频的多语言手语模型。该项目引入了首个多语言手语数据集 Prompt2Sign，它使用工具自动采集和处理网络上的手语视频，能够不断更新，且具有轻量化特点</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490475&amp;idx=2&amp;sn=d6d2e9f7af98df828572569875331053&amp;chksm=fde9616cdcd951b8221809a6e9ad0a7e126a52fac9b81ec2c208ed00e84d9deab832b7cb2c8a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[清华联合腾讯提出全模态模型Ola！图像、视频和音频等多模态理解一网打尽！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5ILy9I4g9e9dFh1achfYgv3N1UvxyxaO5FN5kwaEYDvzicXohJyGkQPum02iaiaiaoIyUCYuw4f7VG7cQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment论文链接：</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490475&amp;idx=3&amp;sn=1d3082902d2bc61721812a885a587d11&amp;chksm=fdd5cb799e5a09dfe4aab2e7061aba4e8159d5105cbd9c2f635d6243fc1595090f319d992f4c&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Github热门机器学习笔记:「从零构建大型语言模型」]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emtHS7t5ic0uQWb1AOhKNDRVQe1ibV5hcbvDj7icpDN1BtRicibpaHbuszyA75wydLlzCvmBKSLia5XJSLQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家推荐一份GitHub上很火的机器学习学习笔记《从零构建大型语言模型》，目前已经收获1.4K stars，，这份笔记完美展示了从零构建LLM的技术路线图，既有理论深度，又包含实践要点。每个核心</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490475&amp;idx=4&amp;sn=76bfc07e0f82953341107f3bd052b03f&amp;chksm=fd7fb984967a8950dff886d00042441bc12ac73523109553716a81804f91e2cab0fd6221fe4a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Fri, 21 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[谷歌推出PaliGemma 2 mix：用于多任务的视觉语言模型，开箱即用。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elkfS8ZYbyjmGoHEP6npRKZG3A9ureoTeOkRX7vpoweMqWfIXVPrnftNxPZXeKdfJFf3WSY8K2fGQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>去年 12 月，谷歌推出了 PaliGemma 2 ，这是Gemma系列中的升级版视觉语言模型。该版本包含不同大小（3B、10B 和 28B 参数）的预训练检查点，可轻松针对各种视觉语言任务和领域进行</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490439&amp;idx=1&amp;sn=e1ed5f5383dbd15a2b1868855ddebb2e&amp;chksm=fda2e81145b6732b62e028318fd1e653fd657372addb59c6b9b8f5915aefe3f7ff73bc2fead5&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[DeepSeek们的成本，是怎么计算的？]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/jEa2NN5eMic76LNKtDbp6JciaVMNpJ0DfXv52YEQqq4xTf9WUrtSejmqicfnUDqnZjib7GrNrJnMw22eSMwgbg8odw/300?wxtype=jpeg&amp;wxfrom=0"/><p>大模型混战，一边卷能力，一边卷“成本”。定焦One（dingjiaoone）原创作者 | 王璐编辑 | 魏佳DeepSeek彻底让全球都坐不住了。昨天，马斯克携“地球上最聪明的AI”——Gork 3在</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490439&amp;idx=2&amp;sn=cfa845064014dd1e045e72acec82074a&amp;chksm=fdb1e75e0d2e6ceb23beb3d9f6b256bfb50b07e94580af413ef5b66e492f14aa141ead46d74a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[马斯克全新发布Grok3模型，坐拥20万张卡的新王！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/vI9nYe94fsH9cZmp9X46ouoOXg3cwrPEkXVwv6oRupo8tbuYLibC6vwAv1LMw1M0JbUwyTMWlNibd2Obo6xhujiag/300?wxtype=jpeg&amp;wxfrom=0"/><p> Datawhale分享 最新发布：xAI，Grok 3刚刚，马斯克所说的“地表最强的 AI”终于来了。在 200 多万人的见证下，马斯克的 AI 公司 xAI 正式推出 Grok 3！“我们非常高兴</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490439&amp;idx=3&amp;sn=ba8e5136a610b5c1a8e8c705efa41a0b&amp;chksm=fd14e9ce05b7e0e09b18f35c67a9face2e3fa242e6048a61c293fb8579d35add9383f93930a9&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Thu, 20 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[4w Star！一个低成本微调DeepSeek的开源方案，悄悄火了]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em1HmyUKxNSkwicvdQ8NMBGYFcBaleAYz933cxSgezict1pspKaC1IcNtgBUtibWM48Zg6sczMR1bjlg/640?wxtype=jpeg&amp;wxfrom=0"/><p>文章来源：夕小瑶科技说 DeepSeek V3/ R1火爆全网，基于原始模型的解决方案和API服务已随处可见，陷入低价和免费内卷。如何站在巨人肩膀上，通过后训练（post-training）结合专业领</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=1&amp;sn=fa18deca3b2bcf128a387a31c301f781&amp;chksm=fd6ba6ac454e2dcf430747a6086c3bfe97b08d2e9d865e112e45e2d4bfa3165de0583adbcfeb&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[一文搞懂DeepSeek的技术演进之路：大语言模型、视觉语言理解、多模态统一模型]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic6bZ8AZw730k5S06S2AKhSycdsVgq61HibHXoXHUxwbibkSa74Uib0srhbxdiaibHxADIxvDeRt0SNaoAw/300?wxtype=jpeg&amp;wxfrom=0"/><p>本文撰写路径比较清晰，意在初步梳理DeepSeek技术的演进及进化之路，主要包括三大方向：大语言模型、视觉语言理解模型、多模态统一模型！大语言模型系列论文：DeepSeek-LLM -> DeepSe</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=2&amp;sn=a24a6403f726263ce60a8f93588ba90e&amp;chksm=fd1b6428801aef67712a9607f6e748b0b12c894f77d95d649961afc416c53e937e257d82086a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[StepFun提出Step-Video-T2V！300亿参数视频生成大模型！可生成204帧视频！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcJicm2I75ZP1rkl1ZMqicoKfreYnRFLqFBbibqBpPJl9LzNL6OUXy1tmllZuicN8KGIYIbPRjfSZnnOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model论</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=3&amp;sn=c6f8a757ae9834ad9ad2df1d9a837a19&amp;chksm=fd9a0ac665a3826364f86b7a1a397f8103243bc2551b4cc0f96ce1c239d208e220ec1da784f3&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekB7CXUYR45xqh1P2Q9zWuxgmicJiaO6JPkkhoaibkSARt6qftWXI9ofZjt9NK9vuibg0UrfhA2kTPRaQ/300?wxtype=jpeg&amp;wxfrom=0"/><p> 腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT今天介绍的文章来自公众号粉丝投稿，腾讯优图提出首个基于DiT的高保真虚拟试衣算法FitDiT，给定一个人像图像和一个衣物图像，就可以生成一个</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490415&amp;idx=4&amp;sn=8aee6a1069da7fa31e1524099e7692d9&amp;chksm=fdfb049a20f36a4aae141e866751086f84cec821866f37a227a0037c0625275577a6a687e251&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Wed, 19 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[Animate Anyone 2来了！角色动画与环境之间更具互动性，动画真实感和一致性更高。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXWFznUMicvLicvkDmEwFhC2ibGGPzYD6cjmOwxrY9X4Vbv4qexWHZ3R7hibg/640?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的角色图像动画方法Animate Anyone，感兴趣的小伙伴可以点击下面链接阅读~阿里Animate Anyone：让任何静态图像动起来，让C罗、梅西、内马尔一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490410&amp;idx=1&amp;sn=690c763931b8f47edbadd8e3645d87f5&amp;chksm=fd1d9f064b84d887400938ee1ede8d346ee9c1cbfec2f57268671088d566b22286f7ca59ad99&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[英伟达开源4K图像生成模型Sana，可在16G显存电脑部署，支持ComfyUI和LoRA训练。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6Zafxy9AicSRodyIcwlSHNT9mr6NOzfTpJPhveE41Xmh1RVMhhibAgXAt3qSb6eFx0HfpEYX74THA/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达开源了一个可以直接生成 4K 图片的模型 Sana。 Sana-0.6B 可以在 16GB 的笔记本电脑 GPU 上部署。生成 1024 × 1024 分辨率的图像只需不到 1 秒钟。官方已经支</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490410&amp;idx=2&amp;sn=c1c37a8e26cb942f19992c81a6fc1aeb&amp;chksm=fdba16fbec4f54f27d080e437a97106285842b2a1c7a2fb2fcb79abf7ecc37e32bf747546dfe&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[浙大提出RealCam-I2V！精确相机控制的新型视频生成I2V框架！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXW2QTHDiatN7k4pGOJfic1lBfxyVelPRsL0aibr9cCI1YRoX6z1QXcP1lKA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control论</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490410&amp;idx=3&amp;sn=bd09106b0864e0661e2988e6265dfc1c&amp;chksm=fdc91b76187c1db970054949b76ea411ab0368fc2437e05922e3e2eef5d88240b5779c41f0b4&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[多身份定制化视频创作新突破！Ingredients：可将多个身份照片整合进视频创作实现个性化视频生成。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcicdv0XZf04MKlYliaBmemOkIOtBU0wKu89VAd3lkLkDU9GOLfc5OIqIjQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>在当今这个数字内容爆炸的时代，视频创作已成为连接人与人、传递信息与情感的重要桥梁。然而，如何高效、高质量地实现多身份定制化视频创作，一直是视频制作领域的一大挑战。近日，北京昆仑研究院的研究团队提出了一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490410&amp;idx=4&amp;sn=f8b630700a48c69d68673a87989cfc5a&amp;chksm=fdd4e45d6b0ec8d3aea1d7fef328c9e781f091029a49ac94080a665e99c62996d33c1a63ce61&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Tue, 18 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[顶刊TPAMI 2025 | 北大、KAUST、字节联合提出“可逆扩散模型”赋能图像重建，代码已开源！]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eliaJugxYf63pLKlyU38UmXWYNXSWW0ic0Bj4lKqjoib7L8uQGd6oeHPNRicIBXHIPPGrZicUPA2KEndsw/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章来自公众号粉丝投稿，论文提出了一种可逆扩散模型（Invertible Diffusion Models，IDM）。这一方法通过引入（1）端到端的训练框架与（2）可逆网络设计，有效提升了图像重建</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490409&amp;idx=1&amp;sn=f1a8c96a032305419299f50c9c095e57&amp;chksm=fd011cd35eeab16e70c0860e9e79ec4b59bcb93dcf45bb1ea78910f7667f6ec156563f1a1b10&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[单张照片生成3D头部模型！Adobe提出FaceLift，从单一人脸图像重建360度头部模型。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elbUxtWfuPV6pAhibibicT3oe4qXFbiaEqoEPejUQNwuqLOrpIE3WmoKJBxjrMnCoHDn3huArYyaCa7Ew/300?wxtype=jpeg&amp;wxfrom=0"/><p>FaceLift是Adobe和加州大学默塞德分校推出的单图像到3D头部模型的转换技术,能从单一的人脸图像中重建出360度的头部模型。FaceLift基于两阶段的流程实现:基于扩散的多视图生成模型从单张</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490409&amp;idx=2&amp;sn=a2acdb42e8ba50155a141df760964df9&amp;chksm=fdee2de69285e7b2ed8595bc8de656fce7160d9a6b5a593de414ee5e5b6bc144415b38562c37&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[引领图像编辑领域的新潮流！Edicho：实现跨图像一致编辑的新方法(港科&amp;蚂蚁&amp;斯坦福)]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elSjibdLXhMBHvRNlreoaGcicEKO56ibffMsiau7qrg2gcpibqTFwwB20Tz8hX6wXGcTC684He5MiazvvzA/300?wxtype=jpeg&amp;wxfrom=0"/><p>在图像处理领域，如何实现跨图像的一致编辑一直是技术挑战。传统方法往往局限于单张图像的编辑，难以保证多张图像间编辑效果的一致性。香港科技大学、蚂蚁集团、斯坦福大学和香港中文大学联合提出Edicho，这一</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490409&amp;idx=3&amp;sn=b5d4decc400b914d9ab7d11dd671418c&amp;chksm=fd8d5eb83c58f8301d428845e50c7fa9afc97368de92b7fdf3ce81186a6e8a8372617cc26c31&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
    <item>
      

      <title><![CDATA[音频驱动肖像动画新方法LetsTalk,可生成与音频一致的逼真视频。]]></title>
      

      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elS0nh744Xc7tB6W08RA4SgfkcDFOIyH4xJ5xG8Ar9Y0Uvicw6xicJzbmEtb2yOzCDNqYMjzkS4eYpw/300?wxtype=jpeg&amp;wxfrom=0"/><p>之前的文章中已经给大家介绍过许多关于音频驱动的肖像图像生成动画方法，感兴趣的小伙伴可以点击下面链接阅读~复旦开源Hallo：只需输入一段音频和一张照片就可以让人物说话。开源EMO再升级！复旦|百度|南</p> ]]></description>
      

      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247490409&amp;idx=4&amp;sn=0157c71ca93e3294e9232f993dd79050&amp;chksm=fd02aa70c3320984dc9ec18edcead8362054eca29957661de3d858d2f9a0a2e2966d4c09a31a&amp;scene=0&amp;xtrack=1#rd</link>
      

      <pubdate>Mon, 17 Feb 2025 16:00:00 +0000</pubdate>
      

    </item>
  </channel>
  

</rss>
