<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[SIGGRAGH 2025 | AI视频生成黑科技！港大&amp;达摩院发布分层视频生成LayerFlow：再也不用视频抠图了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emb4MEj35KfTUoB1FWsgTXrOLuSb7ibEOeR0QxWLzfAOwCiaOpIxJgUv6jqX41ckXO1MREb9QUViaYibA/640?wxtype=jpeg&amp;wxfrom=0"/><p>本篇文章来自公众号读者投稿，论文提出了一个统一的分层视频生成解决方案 LayerFlow，给定每一层的提示词，LayerFlow 能够生成带有透明alpha通道的前景、干净的背景以及二者结合的全景视频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=1&amp;sn=6fe5a49d65ebe5aac00e62de40e181b1&amp;chksm=fdaa8f60082a9d6302f07f6900a756203e40fef0ae7e5b9974851e02da33fb27b4258eee8d96&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[StepFun提出Step-Video-T2V！300亿参数视频生成大模型！可生成204帧视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcJicm2I75ZP1rkl1ZMqicoKfreYnRFLqFBbibqBpPJl9LzNL6OUXy1tmllZuicN8KGIYIbPRjfSZnnOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model论</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=2&amp;sn=c768d79299959655b4272ee4b124ede9&amp;chksm=fd2722a27debec182008aa67bfcc307595d7eb751fb7b436036fbcc933ef1c41e87edb1efd07&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Apple提出UniGen！多模态理解生成统一xii新架构！CoT - V提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KqpbKjwyf8GDnoGZ1ANRZVHSofem5JIanFIxSibozXUibNxHviaUIPE6FTh1nw9lCf16QMqWDaqf7cg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：UniGen: Enhanced Training&amp;Test-Time Strategies for Unified Multimodal Understanding and </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=3&amp;sn=28e556b89d07c4427a34551cadd23fea&amp;chksm=fdeabdd2736c698ef95a36cbabc7eb5eca25ba66a0061008e277a99da139857b0f9b6fba4bca&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工 &amp; 牛津 &amp; 新加坡理工提出Amodal3R，可从遮挡 2D 图像重建完整 3D 资产，3D生成也卷起来了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enS6n92rGmqtJayOlicyqJq600IyDZicDbCN0IrvrTs03kGrs6dbzAyHZXniaUX6rcbNQPn1B25vgaJw/300?wxtype=jpeg&amp;wxfrom=0"/><p>Amodal3R 是一种条件式 3D 生成模型，能够从部分可见的 2D 物体图像中推测并重建完整的 3D 形态和外观，显著提升遮挡场景下的 3D 重建质量。给定图像中 部分可见的物体，Amodal3R</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493296&amp;idx=4&amp;sn=61c41a21175f84251746b6916b89e5ed&amp;chksm=fd174d6754a6b7bcacf613ccb28dc88773d58bd162049590cfc7e0a98c6170df1dfd588dd656&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 07 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[科研人神器，论文秒变海报！Paper2Poster：一键生成顶会级学术Poster，再也不用为赶会熬夜做PPT啦。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ele6MdnMwUcFcDzM1rn9UbH2rVZPFxHmzrmY7icJmAlfTmrY7niam10ibJeWm7Lrk76urBe1ZJ7MZftA/640?wxtype=jpeg&amp;wxfrom=0"/><p>由滑铁卢大学、新加坡国立大学、牛津大学提出的面向科学论文的多模式海报自动化生成方法Paper2Poster，主要解决了如何根据论文创建海报以及如何评估海报。AI能否根据论文设计出精美的海报？GPT-4</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493165&amp;idx=1&amp;sn=f80d94b583f1f121d7c81b7255426171&amp;chksm=fdfe52e4d437e21ebeedeecbf1e5bed09c293692b767d0862b481f61463ed939e9cf6b57041c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 06 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源换脸写真模型InfiniteYou，可实现零样本身份ID一致保持，无缝集成FLUX、ControlNets、LoRAs！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFB9QEic6a0icic21hdjU7tWMfgnZWZ32D1adHqJcD4Z8fvzhEvH6KNghsZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个字节刚开源的换脸写真新模型InfiniteYou，这是一种先进的零样本身份ID一致性保持模型，由字节跳动基于文生图领域最强开源模型FLUX模型研发的。InfiniteYou专注于利用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493165&amp;idx=2&amp;sn=f315cae10211d59cdd6a32edd4dbba9c&amp;chksm=fd5dabd07c2cd74c7a2b12b7cc8d2a756c8ad71a27c8658a408e29d8a25e8481faf8ee56f511&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 06 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像定制大一统？字节提出DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等任务，有效解决多泛化性冲突。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1Zrf8JKiaMovMsw9t4ZW4pibcVZlWM8AF7GsajlXAPWl5IJgnfQRpnvoA/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出了一个统一的图像定制框架DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等多项任务，不仅在广泛的图像定制场景中取得了高质量的结果，而且在适应多条件场景方面也表现出很强的灵活性。现在已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493165&amp;idx=3&amp;sn=628ad5b2dfa6439f0314a5b391213982&amp;chksm=fd7d9d7f05ecefbe6385bfede6812424cd9532567c03a695ac89e63fa614b9d24b214db445c4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 06 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[7k星星爆火！用微信聊天记录训练一个自己的数字分身回信息，还能克隆声音回复语音消息。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/l2VB7h1M5NarO1FqtJTNnAkBYibHt0foxa0Fe75VZQRCPicXrJ4JdcyBcfXfytFdyEnQK4gfA5aQ6UicqjUDAHFrA/300?wxtype=jpeg&amp;wxfrom=0"/><p>早就想拥有一个AI来帮我回消息，最好是能跟我说话风格极其相似的。今天发现一个好玩的开源项目，能根据微信的聊天记录，给自己做一个“数字分身”。而且，它不只是能回消息，还能学习你的音色回复语音消息。这难道</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493165&amp;idx=4&amp;sn=4bab2a7df63038d51cc8b24de7b64078&amp;chksm=fd411ee4597871cb3b0ce632b413d95cc77300eb94c5183e55ca1786a1d20496c23fa59aea8e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 06 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节 DreamFit 虚拟试衣：任意服装随心试，多风格人体模特一键匹配生成，轻量级即插即用！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1Sdlhwzib8OsMLEPMO37XskQtAwVfcflGHCc0lfCW6bzSeuACrjlKia8g/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天跟大家介绍一款由字节提出的新的虚拟试衣框架：DreamFit，这是一款结合了一种专门为以服装为中心的人类生成量身定制的轻量级任何服装编码器。DreamFit具有三个关键优势：轻量训练：只需8340</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493080&amp;idx=1&amp;sn=92b06cd8d24f3cf800b1f08e732210ce&amp;chksm=fd2f16bcdaf3755d40fabc6c5d209cab9cab4fdb18f307739c841c7442fda3f93477007feefc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ComfyUI | 字节DreamFit: 多主题电商服装迁移！轻量级即插即用任意服装模特匹配]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGSxicUBwA56Pek0VwHmNacVsMhP7pROSIyva554J3rL1LBI4t5lpvM0icF2YaPAtfrN22ICPibd001Fg/300?wxtype=jpeg&amp;wxfrom=0"/><p> DreamFit:为服装增加电商模特DreamFit简介今天文章介绍一款新的虚拟试衣框架：DreamFit，这是一款结合了一种专门为以服装为中心的人类生成量身定制的轻量级任何服装编码器。DreamF</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493080&amp;idx=2&amp;sn=7f5938c50b5bd2e9ed6188f30ab9d5d7&amp;chksm=fdda9279a34aa0ab91f7aad4692b0a213d19a1ce792b02f4940613a8c0f86c5b467f2372d2e0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[港科&amp;腾讯&amp;清华提出全球首个多模态Mamba生成框架ACTalker，支持多信号输入，数字人嘴型同步再升级！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enM1R1hvr6fIvNPnJ8HAkjER32Qr4uJljRDnNXhyE9UPgfaB2EKia2QjfDCSEHzibXgefW4NfoP8eNA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由港科大、腾讯、清华联合发布的全球首个多模态Mamba驱动框架ACTalker，它是一个端到端的视频扩散框架，支持多信号控制和单信号控制，用于生成说话头部视频可以实现单/多信号随心切换，虚拟人嘴型同步</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493080&amp;idx=3&amp;sn=309efd86db3e772e1bdb93cd12dac6f2&amp;chksm=fd2ce92a3c25c3c18f368bb2a6a798f62957bec6a63f032885dd18f03764f0382ffd5d6b9dfe&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[NVIDIA提出新框架ImageRAG！RAG+AIGC提升图像生成质量！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5JK3j8AP855QOPLGKEpd37E3bPLWmIOj4bSM2oUxbcSEQ3NFVFyqRhEKjhBGvFkPMAwAaMsbszianQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>今日论文推荐论文名：ImageRAG: Dynamic Image Retrieval for Reference-Guided Image Generation论文链接：https://arxiv.</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493080&amp;idx=4&amp;sn=c316ee50398a65e166e433a7ece927d7&amp;chksm=fd3a9eb7e9cc4f6f006699bbfa82de8e721c67ea4caf3901a1cee00f4763defdd9f121e4501f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[视频虚拟试穿新SOTA！浙大&amp;VIVO提出MagicTryOn，空间建模+服装细节控制，超真实视频虚拟试穿效果。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ennPiayiaaeIG5CI2J0TCvA3rib3yqyGPDFnjddlfHCxqicYv2usHU7ypheicxs9vxcdPIQRFHFiagsdOwQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>由浙江大学、维沃移动通信有限公司联合提出的视频虚拟试穿框架MagicTryOn，使用扩散 Transformer 替换了 U-Net 架构，并结合完全自注意力机制来联合建模视频的时空一致性。论文设计了</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493079&amp;idx=1&amp;sn=fddea29aeeffb173a2e17b038b45dea5&amp;chksm=fd40087016ca42417d14280df9913f1247aecb5ed3b1ce69846a921ae8ba73a8bdc4b3e54231&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 04 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 香港中文大学 MMLab 提出文生图模型 T2I - R1，文生图进入 R1 时刻！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1XALE57UTLoPLT6xjsxJW5tiaoo8VJdc0HMQQUAGdaNID9L9wkBMspWA/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学 MMLab 提出了一种基于双层次 CoT 推理框架与强化学习的新型文本生成图像模型 T2I-R1，该模型结合了语义级和 token 级的链式思维（CoT）推理过程，并通过强化学习进行增强</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493079&amp;idx=2&amp;sn=d8cef9c6728b4678f304c17e2006248f&amp;chksm=fd5055d579f81f1551eaccf7fbb74e02a25de46c6a9ba5b9761cff2961741590b16b0e25997c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 04 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Google DeepMind 发布最强视频生成工具 Veo 3, 可为作品添加音效、环境噪音、对话，文中附体验链接。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elcnWs2mR9uePicbSxmgsNGYEOvC44lWnQUfBAMbv2Kgy7vDib4ee4tlF1R091cfagJqdQWc10PdkUA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天跟大家介绍谷歌的视频生成模型 Veo 3，可为作品添加音效、环境噪音甚至对话，所有音频均可原生生成。它还能提供一流的音质，在物理效果、真实感和快速响应方面均表现卓越。相比 Veo2 的改变Veo </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493079&amp;idx=3&amp;sn=1b12efcbbac8ddf50dd6396da1c8ec8d&amp;chksm=fd682af2996804380610482c7c490b53f20f01acfe40bede769503cd9e0bf7d8648e465adec3&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 04 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源数字人克隆神器HeyGem：1秒视频生成4K超高清AI形象，用AI重塑数字人创作生态！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRrgxstWFTNfP8vOAkR5RI8GOy83ObgNDrZJL0p3TTnAIBViacS7PlySow/300?wxtype=jpeg&amp;wxfrom=0"/><p>在虚拟形象与数字内容需求激增的当下，传统3D数字人制作的高昂成本（动辄数十万美元）与复杂流程，让许多行业望而却步。而今天，一款由Duix.com团队打造的开源AI项目HeyGem，正以颠覆性技术打破这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493079&amp;idx=4&amp;sn=c7f2992d13eb5c6c17427002cdaaf7b5&amp;chksm=fd5cfdff477bc67c3d4063387b9f7031da726ca400de65247a3923592260b9630e39d64871ae&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 04 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[ICLR 2025 | 解锁虚拟试衣新姿势！智象未来提出SPM-Diff，大幅提升真实性、可控性，让衣服“贴身”又自然！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emrh9ic75wTHs9dqezVrp8tteQeOdKicBiciaVprFFxw2NDD0xvwlGbvdtfzxm3Z3f8AmbzvLDk7lMYeg/640?wxtype=jpeg&amp;wxfrom=0"/><p>网购衣服总担心“买家秀”和“卖家秀”天差地别？虚拟试衣不自然、细节难还原的问题一直困扰着消费者。智象未来团队提出SPM-Diff算法，成功攻克虚拟试衣两大难题，论文《Incorporating vis</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493078&amp;idx=1&amp;sn=d1e2a4ddcd0c6b2036760388a33f154a&amp;chksm=fd50f3d2938e33cc70752423720b16946756d33fb95c3e3a9061cc49d6c87e7539962663eb74&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 16:44:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图生3D新SOTA！港中文&amp;字节&amp;清华联合提出Hi3DGen:通过法线桥接从图像生成高保真 3D 几何图形。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elT6Ok13J4tBFt6yibibVpmCofpeSCJb5Do6ZzCr2Yv2wPial5QS5sdppZe8K6ubyDPzv4yf6QNaOicHw/300?wxtype=jpeg&amp;wxfrom=0"/><p>香港中文大学联合字节跳动和清华大学提出Hi3DGen，这是一个通过法线桥接从图像生成高保真三维几何体的全新框架。Hi3DGen 由图像到法线估计器、法线到几何学习方法以及三维数据合成流程三个关键组件组</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493078&amp;idx=2&amp;sn=886c9fbb9fa656d769f434570342f595&amp;chksm=fd02c648800d96235e50487969f27fb8d0305ab1976b259cc1bb55a0eefadf3f4b1a981d376c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 16:44:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节开源换脸写真模型InfiniteYou，可实现零样本身份ID一致保持，无缝集成FLUX、ControlNets、LoRAs！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekcpaxd048mMDrAunNibKNFB9QEic6a0icic21hdjU7tWMfgnZWZ32D1adHqJcD4Z8fvzhEvH6KNghsZw/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一个字节刚开源的换脸写真新模型InfiniteYou，这是一种先进的零样本身份ID一致性保持模型，由字节跳动基于文生图领域最强开源模型FLUX模型研发的。InfiniteYou专注于利用</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493078&amp;idx=3&amp;sn=693e2c223beef8e7c97e61fa077653ae&amp;chksm=fd584cffe95e22ca4b6dfc0db42d32997193bddd18d734b4ac9c8922ce678d33c3fb2047362a&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 16:44:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 机器人双臂操控新突破！KStar Diffuser如何解决自碰撞与运动约束世纪难题？]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icojvz9clmicqUEHWru0TSQwicibDxwd6pXeiac1QbZwUoibnWeMnE5ib2jBibpdEXVK5T4bFCwMWWK9BcS4dg/300?wxtype=jpeg&amp;wxfrom=0"/><p>文章链接：https://arxiv.org/pdf/2503.10743亮点直击与现有方法仅在笛卡尔空间中优化末端执行器姿态不同，提出了一种新颖的时空机器人图，显式地建模机器人物理配置，以指导生成动</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493078&amp;idx=4&amp;sn=86046125e032420f90b9c32ddec2691d&amp;chksm=fd1e90ed12f42d11e23897b34c2d8c5517abd5f0c5a54fbb47c8a99b912ef6d0598fb733da0e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 03 Jun 2025 16:44:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[图像定制大一统？字节提出DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等任务，有效解决多泛化性冲突。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1Zrf8JKiaMovMsw9t4ZW4pibcVZlWM8AF7GsajlXAPWl5IJgnfQRpnvoA/640?wxtype=jpeg&amp;wxfrom=0"/><p>字节提出了一个统一的图像定制框架DreamO，支持人物生成、 ID保持、虚拟试穿、风格迁移等多项任务，不仅在广泛的图像定制场景中取得了高质量的结果，而且在适应多条件场景方面也表现出很强的灵活性。现在已</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493040&amp;idx=1&amp;sn=408b9d6c8ab2246c5566771acbdc9b52&amp;chksm=fde077af982773950d58317b50384f58162e9659e4226a3106d34e31034fafbd18720e695cb2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 22:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[[ComfyUI]阿里WanX2.1：最强开源视频模型易主！静待社区生态开源直逼闭源，Vbench榜首第一]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/1BRxta5juGR4iczdl1w1JCwWwhHibiaD9umzM0GtLxG8EhR3dUBt02neC4QvYYvoFicjM1FhMAten8AeAnfhcCtHYA/300?wxtype=jpeg&amp;wxfrom=0"/><p> 阿里WanX2.1：文生和图生视频模型ComfyUI体验WanX 2.1简介在昨天的文章（阿里Wan2.1：最强开源视频，本地部署优先体验！Vbench榜首第一，超越Sora&amp;混元&amp;Gen3&amp;Pik</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493040&amp;idx=2&amp;sn=3e6c6208ee386883cc3ed29d93c569ff&amp;chksm=fd0944dd986d69d017e2f1dbb567d7471c8d717ed7b9e1faf8f94baa809e23bea347fe316db1&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 22:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[StepFun提出Step-Video-T2V！300亿参数视频生成大模型！可生成204帧视频！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Scy8opQtXAcJicm2I75ZP1rkl1ZMqicoKfreYnRFLqFBbibqBpPJl9LzNL6OUXy1tmllZuicN8KGIYIbPRjfSZnnOw/300?wxtype=jpeg&amp;wxfrom=0"/><p>论文名：Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model论</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493040&amp;idx=3&amp;sn=b0f39a563ae7e17b91d7a394d0dfffc9&amp;chksm=fdeb65a37cb2deac484b915babdd7111555c28a29a1100390fcc1f3ab26271507b1a36b65fcc&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 22:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[英伟达开源4K图像生成模型Sana，可在16G显存电脑部署，支持ComfyUI和LoRA训练。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek6Zafxy9AicSRodyIcwlSHNT9mr6NOzfTpJPhveE41Xmh1RVMhhibAgXAt3qSb6eFx0HfpEYX74THA/300?wxtype=jpeg&amp;wxfrom=0"/><p>英伟达开源了一个可以直接生成 4K 图片的模型 Sana。 Sana-0.6B 可以在 16GB 的笔记本电脑 GPU 上部署。生成 1024 × 1024 分辨率的图像只需不到 1 秒钟。官方已经支</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493040&amp;idx=4&amp;sn=a5e0f809d5486b41db803833bd720017&amp;chksm=fda56049095d6bf06c967a684a43330d8637ffd0793ae1923e94c57b4ac190a18b953724b918&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 02 Jun 2025 22:45:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[中科院提出图像定制方法MCA-Ctrl，无需调优的即可使用文本和复杂的视觉条件实现高质量的图像定制。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enKvWzJ9QLeWgYQiaKmEWxL1KFwReqeCxk2s3eVTGWZJ0ibicT6EGpGzrsJ4W6jtTm4fLh17icB9CJNyg/640?wxtype=jpeg&amp;wxfrom=0"/><p>中国科学院计算技术研究所研究团队提出了多方协作注意力控制方法( MCA - Ctrl )，这是一种无需调优的方法，能够使用文本和复杂的视觉条件实现高质量的图像定制。MCA-Ctrl 可用于文本驱动的主</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493039&amp;idx=1&amp;sn=1a0d8cd77139520d977de081b64e1d05&amp;chksm=fd7a0e8743f44c5ddb35650a19036a31ddea66dafc80ed76aa3e4d751c9ae9351fe224ea0d14&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 01 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[加利福尼亚大学提出TULIP！视觉-语言模型的新王者！AI性能全面碾压CLIP！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/Hcib3tqia6H5KsLicuyg3oA0dGOnwBictNTE782KtlqwlaVEmKrVyKAO0YzauujiaGWFqaYjHzZqKD5rLk8dQLKZtEg/300?wxtype=jpeg&amp;wxfrom=0"/><p>最新论文解读系列论文名：TULIP: Towards Unified Language-Image Pretraining论文链接：https://arxiv.org/pdf/2503.15485开源</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493039&amp;idx=2&amp;sn=58b3cfdb679889822a8f836395a540bb&amp;chksm=fdd2ade7ef0cc50907d5ef09aee348525f9f91c08e598e934e1cec10e5e8acfda57e1cbb024c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 01 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493039&amp;idx=3&amp;sn=bcb97491e538dc22a7109f16d002a44a&amp;chksm=fd3dc7d4ba091933aa419141d11377612766233605f58b52cc32c35ea4db163bd8cf7fab404f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 01 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[LBM：用于图像到图像直接快速转换，支持可控照明、图像恢复、物体移除等功能！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2eniaAibjBDYoftj8VvjntaLlazzrjyAuCaxtUgTmwTpbpXdlUbj1mP1pmA9QicicVlSzvQAT83J2fYzAA/300?wxtype=jpeg&amp;wxfrom=0"/><p>LBM是一种新型、多功能且可扩展的方法，它依赖于潜在空间中的桥匹配来实现快速的图像到图像转换。该方法仅使用一个推理步骤即可在各种图像到图像任务中达到最佳效果。除了效率之外，该方法在不同图像转换任务（例</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493039&amp;idx=4&amp;sn=4fbfb2da3225560352f22b382def7675&amp;chksm=fdc660b3a5d3d07d62cff7de7f39272b7d70164aed203f2ebe5caa841509a21376310098d1f4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 01 Jun 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>