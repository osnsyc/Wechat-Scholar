<?xml version="1.0" ?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title><![CDATA[AIGC Studio]]></title>
    <link>https://mp.weixin.qq.com/</link>
    <description><![CDATA[AIGC Studio公众号]]></description>
    <language>zh-cn</language>
    <image>
      <url>https://raw.githubusercontent.com/osnsyc/Wechat-Scholar/refs/heads/main/icon/gh_5ba19d995457.jpg</url>
      <title>gh_5ba19d995457</title>
    </image>
    <item>
      <title><![CDATA[从文本到3D动画：AnimaX 前馈 3D 动画框架，解锁任意骨骼动画无限可能。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPbvzXyQzXhAWo1QdPyhvibR2nOgLfk3jfXRCH64V0YMReDLI4nZbR5kKceDeR0YnSEialEZiahJyQQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>AnimaX 是一个前馈 3D 动画框架，它将视频扩散模型的运动先验与基于骨骼的动画的可控结构连接起来。传统的运动合成方法要么局限于固定的骨骼拓扑结构，要么需要在高维变形空间中进行昂贵的优化。相比之下</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493998&amp;idx=1&amp;sn=f19ff6bcd77a2bca4c99181ac7c4b3a0&amp;chksm=fdfb18b45bb8cd9b39a6f24dc1d44996569d640ee1c5d39d502476016ae7c2880f4270f8ba28&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[BLIP3-o：融合自回归与扩散模型的统一多模态架构，开创CLIP特征驱动的图像理解与生成新范式!]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek5oLyjfCjICEWyMhWNvFXDN37WVtXa4JeBibibTSdNGmBP0wSFhuUAJkiaz9qNwiccNW4SuNJ7FvduuQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>BLIP3-o 是一个统一的多模态模型，它将自回归模型的推理和指令遵循优势与扩散模型的生成能力相结合。与之前扩散 VAE 特征或原始像素的研究不同，BLIP3-o 扩散了语义丰富的CLIP 图像特征，</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493998&amp;idx=2&amp;sn=81a73478e596f3370618d8cc0ab8bae1&amp;chksm=fdebc27e7fa0b7ce3000088f794e21d901d158b9ce4741ffb90e9e968f3905c7a4f1a4e7894c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[Hallo4：让AI肖像“活”起来！新型扩散框架实现高保真音频驱动动画生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2em4gibISNFQR95biapR4RJ7Lq56s1kIaYWsxKESfb9riaHUQVlW3JfPib9AP6mL8Hk0Ec5R0f43HYJ8aw/300?wxtype=jpeg&amp;wxfrom=0"/><p>复旦联合百度发布扩散框架Hallo4，实现了准确的唇音同步、自然的面部表情，并能够稳健地处理各种角色身份和环境场景中快速的语音节奏和突然的上身运动。相关链接论文：https://arxiv.org/p</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493998&amp;idx=3&amp;sn=dc3d781c7cf0f889a0b6cd0fbf4a4a54&amp;chksm=fd6140987112ba35f2c6669f35f18469a2a62f0b408ba0a49d72e276ba001d295a690b0fb933&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Fri, 04 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[南洋理工力作Sparc3D：开启三维重建可微分优化与高效生成新纪元。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enhd8Da8niase1WltgKePj289UYQ2FkGK7uxrgpyoOIA6cIHk7jU4q6hvNUWTsCz3qI24ic8ibqQ8GjQ/640?wxtype=jpeg&amp;wxfrom=0"/><p>由南洋理工大学推出 Sparc3D 是一个统一的框架，它将稀疏可变形行进立方体表示Sparcubes与新型编码器Sparconv-VAE相结合。Sparcubes 通过将有符号距离和变形场散射到稀疏立</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493997&amp;idx=1&amp;sn=cd6b211f235e412dbdbf985ac3d41d5a&amp;chksm=fd2fdaafbb4fda8d8bce2e0b5acd581b74d8f9c3df1a3aa241f107a93e04ad4df057058e98a0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从文本到3D的“零训练”革命！英伟达&amp;康奈尔大学提出 ArtiScene：通过2D中介实现高保真3D场景合成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48HPJzGndEliaF6RR9oS2mcY6tk1tO13iaxO3UHzBrtzwlN2jFlpv4651g/300?wxtype=jpeg&amp;wxfrom=0"/><p>由英伟达和康奈尔大学提出的 ArtiScene 是一种无需训练、语言驱动的 3D 场景生成流程，它可以根据文本提示，设计出丰富多样、美观且易于编辑的场景，涵盖各种类别和风格。下图中展示了四种结果，并附</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493997&amp;idx=2&amp;sn=fa712969765e54352fb0d6bad06ee4e6&amp;chksm=fd12c5ae9d63bce137b71eeb023e413726b74bbbba7ce440dc085a903d58a99de5007fb94471&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D 生成新 SOTA！SECERN AI 提出 方法 SVAD，单张图像合成超逼真3D Avatar！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJczQ6xAAgVU8NYrMphwhLiaiajhcsCMja0TDYcr6RulFp9C6Yt1mtcbiamA/300?wxtype=jpeg&amp;wxfrom=0"/><p>SECERN AI提出的3D生成方法SVAD通过视频扩散生成合成训练数据，利用身份保留和图像恢复模块对其进行增强，并利用这些经过优化的数据来训练3DGS虚拟形象。SVAD在新的姿态和视角下保持身份一致</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493997&amp;idx=3&amp;sn=3debae9075d389f13eab2c735c7397f9&amp;chksm=fdaf54cdc2fde0f96624b0c7cee6a0b4fada173707e699e4d605e1442c2b86fb6c8da1b3af01&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[3D人脸黑科技！Pixel3DMM：单张RGB图像秒变3D人脸，姿势表情精准还原，几何精度碾压竞品15%！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elXFXA8pZKAq59wibWEHiaviafiabtefYD9pHZ4MPj0OpAkqBJmnicoxT1Oib952Bqw8Vt7paicb51B2WQfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>慕尼黑工业大学和伦敦大学学院提出了一款经过微调的 DINO ViT模型 Pixel3DMM，用于逐像素表面法线和 UV 坐标预测。从上到下，下图展示了 FFHQ 输入图像、估计的表面法线、根据预测的 </p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493997&amp;idx=4&amp;sn=487263bc886fe6809d1441968bb676d2&amp;chksm=fd3cf639d69dfe1b97ae7bd2342e843433ac5ab47155d419f4f1ab6dea69a1175e06f85b1f2b&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Thu, 03 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[SyncTalk++：高斯泼溅技术赋能，101帧/秒实时渲染逼真说话人头像]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2enPbvzXyQzXhAWo1QdPyhvibDibqYDF1ukDdJ8FKtqNSro8CoyUXcEHSoiaNicyJ5coqGdSlXCY3aTU1A/640?wxtype=jpeg&amp;wxfrom=0"/><p>由中国人民大学、北京邮电大学、中国科学院、清华大学以及北京航空航天大学联合提出的SyncTalk可以合成同步说话头部视频，采用三平面哈希表示来维护主体身份。它可以生成同步的唇部动作、面部表情和稳定的头</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=1&amp;sn=f1e6be8976b9968058cda9d6b20810b4&amp;chksm=fd12b940baa9686c3dee45399fb2b7533f13c6b5252692764df1bd62d0349dc3f624e576b474&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[阿里EMO2重磅升级！手部动作生成+超逼真表情，音频驱动人像视频生成再进化！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGYiaHtTElCkzOGD9sY0N1Qp8FDJqnDN5BkTWSW0TSu1sYeAgQzRiaicMcRw/300?wxtype=jpeg&amp;wxfrom=0"/><p>在之前的文章中已经和大家介绍过阿里提出的音频驱动的人像视频生成方法EMO，感兴趣的小伙伴可以点击下面链接阅读~阿里最新EMO：只需要提供一张照片和一段音频，即可生成会说话唱歌的AI视频此外公众号的底部</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=2&amp;sn=2ee591723ec234b4f7e3ba841c947ba7&amp;chksm=fd4f258e14b0b54a91e7f40ad7c7ce78b41cd8c48ff1ae6b658072727c8a08ccca1a12a160f4&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[6秒音频即可克隆AI语音！FLOAT数字人生成语音/口型/表情，情感同步超惊艳，文中附工作流。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elmzbxIf6OS3v7M1woTicaJcmBGicWjwiauMpFknBOofINibzHjBSIibjwDHKYvhnzulS1E2KIPicobCywA/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的 FLOAT 是一种基于流匹配的音频驱动的说话肖像视频生成方法，可以增强语音驱动的情感运动。该方法唇形同步质量高，生成速度还很快。6秒音频完美生成语音/口型/表情。情绪转移由于 FLO</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=3&amp;sn=9311d2fba8792a48d886b1a94db125b5&amp;chksm=fd617e8bed8dfb625fc3400dc9b081fc3bfae803e6c86cb23a717cf3ef5564bd15c65395733e&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源数字人克隆神器HeyGem：1秒视频生成4K超高清AI形象，用AI重塑数字人创作生态！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRrgxstWFTNfP8vOAkR5RI8GOy83ObgNDrZJL0p3TTnAIBViacS7PlySow/300?wxtype=jpeg&amp;wxfrom=0"/><p>在虚拟形象与数字内容需求激增的当下，传统3D数字人制作的高昂成本（动辄数十万美元）与复杂流程，让许多行业望而却步。而今天，一款由Duix.com团队打造的开源AI项目HeyGem，正以颠覆性技术打破这</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493996&amp;idx=4&amp;sn=9f6a5a3403a6c92f97f2c3a90e3c6d04&amp;chksm=fd890b709cca9aca5d674fa96c98e82dcbf0ed60eca76986b409cca0a39d250d95f8c45ae1f0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Wed, 02 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[一键生成高质量美学海报！港科大&amp;美团提出PosterCraft，文字渲染与艺术融合，从创意到成品只需一步！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elRPnxm15EcjBGoXOC5AYqzmibC3IibyVqwj02b3JZwTrRYibZ5X4eYgJcibSRkrEYHSF6tueI2pO8OFw/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍一款由香港科技大学和美团联合开发的创新性海报生成模型框架：PosterCraft，其擅长精确的文本渲染、抽象艺术的无缝集成、醒目的布局和风格的和谐。PosterCraft 的设计理念是统</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=1&amp;sn=042efb2f0be566babedf29039f088eb1&amp;chksm=fdd41c5f5bde337606a1e854b5e2833790a2c77e24360fecb7bce53459c3151c3233d0972600&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[机械工业出版社《AIGC驱动工业智能设备》推荐~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekXhZDAiay6OPIoc0eYXlRohIGkuUlnCzvaKicjaicliadzAF5hrUcY83Z2RwOBKD2YSonMqVLYNdIT4A/300?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的书籍来自机械工业出版社的《AIGC驱动工业智能设备》，该书从基础入手，深入讲解AI技术的基本概念和原理。通过通俗易懂的讲解和示例，帮助读者建立坚实的理论基础，为后续章节的深入学习打下良</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=2&amp;sn=b44fbdd8152b7ec37ab3d94e12626e84&amp;chksm=fdeabb5c586c02ac27ba81a3b193503424e26563ac0306479e034cbe23f6556f4db79ef8c5ce&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[海报设计师福音！微软联合清北提出Glyph-ByT5-v2，支持10国语言图文海报生成，效果惊艳！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekUlTbakAQ9PkRVtjuPOYtMklfrlDVxgTLUqQxQB6Xzp3hd7zxxMa0HXnBhpURAxPhMlClBWcF7eQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>清华&amp;北大&amp;微软&amp;利物浦大学联合提出Glyph-ByT5-v2这款工具支持多语言图文生成，包括英语、中文、日文、韩文、法文、德文、西班牙文、意大利文、葡萄牙文和俄文。以下分别展示中、英、日、韩图文的视</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=3&amp;sn=d75c8c35398fe4102e5be53c1f6fa48e&amp;chksm=fd25e727acee7c04a8dd6fef2a5f226c7de7a8a812a8dc829a67a0a03de58f8d2e618968671c&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[海报生成如此简单！OPPO联合港中文发布基于LLM的GlyphDraw2！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/mkhictoa3icohSUo8HgvDM5ics74rw4x4dOxyVe2Bw6dl7ayia1P5xsIdxG3BnXoHkibyiaOmzUenkfKDX8YQ85uea2w/300?wxtype=jpeg&amp;wxfrom=0"/><p>点击下方卡片，关注“AIGC Studio”文章链接：https://arxiv.org/pdf/2407.02252 github链接(待开源)：https://github.com/OPPO-Me</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=4&amp;sn=08c5903a2e4948a7c9241e62db7504b8&amp;chksm=fd2a5483225f0f7953fba9b9595e9d3d70802d8ea4076bd339421ef4b941285be68fe0247d56&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[科研人神器，论文秒变海报！Paper2Poster：一键生成顶会级学术Poster，再也不用为赶会熬夜做PPT啦。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ele6MdnMwUcFcDzM1rn9UbH2rVZPFxHmzrmY7icJmAlfTmrY7niam10ibJeWm7Lrk76urBe1ZJ7MZftA/300?wxtype=jpeg&amp;wxfrom=0"/><p>由滑铁卢大学、新加坡国立大学、牛津大学提出的面向科学论文的多模式海报自动化生成方法Paper2Poster，主要解决了如何根据论文创建海报以及如何评估海报。AI能否根据论文设计出精美的海报？GPT-4</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493975&amp;idx=5&amp;sn=d25c39e136ea92237f3ca68e68a94162&amp;chksm=fd8721c28f0311f19ae0a0cccc3552d3b484c5e8569dbe696817bdad1dcff798ce2594825353&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Tue, 01 Jul 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[从文本到3D的“零训练”革命！英伟达&amp;康奈尔大学提出 ArtiScene：通过2D中介实现高保真3D场景合成。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48HPJzGndEliaF6RR9oS2mcY6tk1tO13iaxO3UHzBrtzwlN2jFlpv4651g/640?wxtype=jpeg&amp;wxfrom=0"/><p>由英伟达和康奈尔大学提出的 ArtiScene 是一种无需训练、语言驱动的 3D 场景生成流程，它可以根据文本提示，设计出丰富多样、美观且易于编辑的场景，涵盖各种类别和风格。下图中展示了四种结果，并附</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493907&amp;idx=1&amp;sn=071f03657998bd85efa79e5deb857c5a&amp;chksm=fd0981b3bf7d19329ae6a37545aaa13d09057f241558d8390915fb17b05201766d64be8f4517&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[单图生成3D头像+AI编辑+多模态驱动？阿里LAM让虚拟人“活”了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en9libmJyfFzq4ma8I0IqAGY3dib7yN0HLOdysDOE9mgQUibQDzEyr5tB9daDg9fq9JmJqBeOgnB0zgQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>LAM 是一个能从一张图片中一次前向推理重建可动画3D高斯人头的模型，不依赖多视角训练或额外渲染网络，支持跨平台、低延迟、实时渲染，是虚拟人、AI聊天头像与AIGC人物生成的重大突破。特点总结如下：从</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493907&amp;idx=2&amp;sn=64b1a5b864284cfdc070a146b49bc03e&amp;chksm=fdc48f93c83a786d986844fdb52431444ba3271e76ba7cd15128f4427a5add791415303f12a2&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[CVPR 2025 | 字节提出个性化多人图像生成新方法ID-Patch，可生成多人合影、姿势可控。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2emCuicERoV3guOMh64VYNrcA6VO1uBfS3aIicTCtKS3eFEBxCVDPwXCyj0Fye0L4toEplkN73YiaibibFw/300?wxtype=jpeg&amp;wxfrom=0"/><p>相信扩散模型（DMs）大家一定都不陌生了，目前已经成为文本生成图像的核心方法，凭借强大的图像生成能力，正重塑艺术创作、广告设计、社交媒体内容生产格局。现在，用一段文字生成个性化头像都不算啥新鲜事儿了。</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493907&amp;idx=3&amp;sn=0c95efada41fc0ab7eacecd6cede3f20&amp;chksm=fdfd7f9d97fbe715e4cd6fac215adb4aaa38acd4ebc5ad05b701233cf696b990b1a045310c99&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[字节推出统一多模态模型 BAGEL，GPT-4o 级的图像生成能力直接开源了！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elzodISUKsiaVtsAvhTQ7mRre72SQ3NTx8amQXBMt77z295uWjzKl5kweQFLEMa31vXicZ35AvS4Lfw/300?wxtype=jpeg&amp;wxfrom=0"/><p>字节推出的 BAGEL 是一个开源的统一多模态模型，他们直接开源了GPT-4o级别的图像生成能力。（轻松拿捏“万物皆可吉卜力”玩法~）。可以在任何地方对其进行微调、提炼和部署，它以开放的形式提供与 G</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493907&amp;idx=4&amp;sn=50659c6d0be512223a5de492083f0463&amp;chksm=fde16184817066c0f7c5f5823cbe442a6cc4478c43e988110fc2970b71a4c3288994771b8e26&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Mon, 30 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[AI数字人新突破！OmniAvatar：让静态照片“活”过来，音频驱动全身动态视频生成新纪元！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2elHjoNmnhIZ1WlEINYQPhBVwHtIicGD7DRHo7WEJn1mYDaiaRkEf8ES1uzXk9uBREDlwHfWKdLcqs2w/640?wxtype=jpeg&amp;wxfrom=0"/><p>OmniAvatar：“全能”的数字人视频生成。OmniAvatar 是一个基于LoRA的高效的音频驱动全身人像视频生成系统，支持从音频 + 单张图像 + 提示语生成自然、表达丰富的视频，仅需一条音频</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493858&amp;idx=1&amp;sn=459d14fe28c93abffe87be12b97c522d&amp;chksm=fddc4fbb4d4df57114c09933dc2af666ef75118e5abd9c3d7c941775284285f7e35dc257d88f&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 29 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[OmniConsistency: 一种基于扩散模型的风格一致性插件，用于高质量图像风格化。]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/B1OJ3jLyfic6Yl0kTibHR6qeAggicnWLicFJTdTmKJibxibXDMjL83Ixvlciaqcwyoro532IvxIK9M3hB7eZ096Yw6jVg/300?wxtype=jpeg&amp;wxfrom=0"/><p>OmniConsistency 提出一种基于扩散模型的风格一致性插件，通过两阶段训练策略和滚动LoRA 银行机制，实现了在多种风格下的风格一致性和内容保真度，性能接近商业级模型 GPT-4o。在图像风</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493858&amp;idx=2&amp;sn=263a017e9a4836be956587acb7e8f881&amp;chksm=fdd5870c1b51bdceecf2d5fcbcc92c59cf8673a1dd6463daf8e2997688cfd40acbbe53f3fb89&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 29 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[开源多模态生成模型新标杆！OmniGen2：支持视觉理解、文生图、图像编辑等任务，探索高级多模态生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ek7H0AmSXtLibjgFibN8Hs8yrrhZa6JxHCHPbYCDGPOoQiaWTNCX0KMvXDq8E2VibCNrFhOQZicibkpSffw/300?wxtype=jpeg&amp;wxfrom=0"/><p>由北京人工智能研究院提出的 OmniGen2 是一个统一的多模态生成模型，它将强大的视觉理解、文本到图像的合成、基于指令的图像编辑以及主题驱动的上下文生成功能整合在一个框架内。它基于解耦架构，在保留高</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493858&amp;idx=3&amp;sn=9c756f16563c41cf42b185e49554a050&amp;chksm=fd12f490cd655fd862332fb27f1601f0fe47399597da05d7c94337b81a7159ebbda06648f872&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 29 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[超越SOTA！浙大&amp;斯坦福提出 DiffLocks，单图头发 3D 重建精度提升30%，首次支持非洲式卷发生成！]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2en2EDDB4tU8uPEQUN9G5w48OPjpkTnf2mQjjRuiawRZ5BrVMBtgVJ4QGZRnabuCSKficVh97iaqr4QzQ/300?wxtype=jpeg&amp;wxfrom=0"/><p>由浙江大学、斯坦福大学等联合提出的DiffLocks，给定一张 RGB 图像，DiffLocks 使用扩散模型生成精确的 3D 发束。该模型基于一个包含 RGB 图像和相应 3D 发束的新型合成头发数</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493858&amp;idx=4&amp;sn=9f50665830cbdf6f15461d23057fc785&amp;chksm=fd02bb50b619535e25a8ce5525fd23bd34e454a1249612c3e8d7cbbd6cfe0402cc2f4ae7c1e9&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sun, 29 Jun 2025 16:00:00 +0000</pubDate>
    </item>
    <item>
      <title><![CDATA[机械工业出版社《AIGC驱动工业智能设备》推荐~]]></title>
      <description><![CDATA[<img referrerpolicy="no-referrer" src="https://mmbiz.qpic.cn/mmbiz_jpg/0YFkDxAK2ekXhZDAiay6OPIoc0eYXlRohIGkuUlnCzvaKicjaicliadzAF5hrUcY83Z2RwOBKD2YSonMqVLYNdIT4A/640?wxtype=jpeg&amp;wxfrom=0"/><p>今天给大家介绍的书籍来自机械工业出版社的《AIGC驱动工业智能设备》，该书从基础入手，深入讲解AI技术的基本概念和原理。通过通俗易懂的讲解和示例，帮助读者建立坚实的理论基础，为后续章节的深入学习打下良</p> ]]></description>
      <link>http://mp.weixin.qq.com/s?__biz=MzU2OTg5NTU2Ng==&amp;mid=2247493805&amp;idx=1&amp;sn=e011f7e6f7f12d05e3ea952941daee6c&amp;chksm=fd0488bfa724989be4c8dd714890efab7a6b5bec80a689309138ae3761d2c4f577452d8a16b0&amp;scene=0&amp;xtrack=1#rd</link>
      <pubDate>Sat, 28 Jun 2025 16:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>